`code.txt`

```

```

`frontend/.env`

```
#REACT_APP_API_BASE_URL=http://localhost:5001/api
# OR for Vite:
VITE_API_BASE_URL=http://localhost:5001/api
VITE_ADMIN_USERNAME=admin@admin.com
VITE_ADMIN_PASSWORD=admin123

```

`frontend/eslint.config.js`

```javascript
import js from '@eslint/js'
import globals from 'globals'
import reactHooks from 'eslint-plugin-react-hooks'
import reactRefresh from 'eslint-plugin-react-refresh'

export default [
  { ignores: ['dist'] },
  {
    files: ['**/*.{js,jsx}'],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
      parserOptions: {
        ecmaVersion: 'latest',
        ecmaFeatures: { jsx: true },
        sourceType: 'module',
      },
    },
    plugins: {
      'react-hooks': reactHooks,
      'react-refresh': reactRefresh,
    },
    rules: {
      ...js.configs.recommended.rules,
      ...reactHooks.configs.recommended.rules,
      'no-unused-vars': ['error', { varsIgnorePattern: '^[A-Z_]' }],
      'react-refresh/only-export-components': [
        'warn',
        { allowConstantExport: true },
      ],
    },
  },
]

```

`frontend/index.html`

```html
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI TUTOR</title>

    <script src="https://cdn.jsdelivr.net/npm/d3@6"></script>
    <script src="https://cdn.jsdelivr.net/npm/markmap-lib@latest"></script>
    <script src="https://cdn.jsdelivr.net/npm/markmap-view@latest"></script>
    <script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@latest"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@latest/dist/style.css">
    <script src="https://cdn.jsdelivr.net/npm/mermaid@latest/dist/mermaid.min.js"></script>
    
    <script>
      document.addEventListener('DOMContentLoaded', () => {
        if (typeof mermaid !== 'undefined') {
          mermaid.initialize({ startOnLoad: false, theme: 'neutral' }); 
          console.log("Mermaid.js initialized globally with 'neutral' theme via index.html.");
        } else {
          console.error("Mermaid.js not found on window after script load. Mermaid diagrams may not render.");
        }
      });
    </script>

  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.jsx"></script>
  </body>
</html>
```

`frontend/postcss.config.js`

```javascript
export default {
  plugins: {
    'postcss-nesting': {},
    tailwindcss: {},
    autoprefixer: {},
  },
}
```

`frontend/src/App.css`

```css
/* #root {
  max-width: 1280px;
  margin: 0 auto;
  padding: 2rem;
  text-align: center;
}

.logo {
  height: 6em;
  padding: 1.5em;
  will-change: filter;
  transition: filter 300ms;
}
.logo:hover {
  filter: drop-shadow(0 0 2em #646cffaa);
}
.logo.react:hover {
  filter: drop-shadow(0 0 2em #61dafbaa);
}

@keyframes logo-spin {
  from {
    transform: rotate(0deg);
  }
  to {
    transform: rotate(360deg);
  }
}

@media (prefers-reduced-motion: no-preference) {
  a:nth-of-type(2) .logo {
    animation: logo-spin infinite 20s linear;
  }
}

.card {
  padding: 2em;
}

.read-the-docs {
  color: #888;
} */

```

`frontend/src/App.jsx`

```javascript
// frontend/src/App.jsx
import React, { useState, useEffect, useCallback } from 'react';
import { BrowserRouter as Router, Routes, Route, Navigate, useNavigate, useLocation } from 'react-router-dom';
import { useAuth as useRegularAuth } from './hooks/useAuth.jsx';
import { useAppState } from './contexts/AppStateContext.jsx';
import AuthModal from './components/auth/AuthModal.jsx';
import TopNav from './components/layout/TopNav.jsx';
import LeftPanel from './components/layout/LeftPanel.jsx';
import CenterPanel from './components/layout/CenterPanel.jsx';
import RightPanel from './components/layout/RightPanel.jsx';
import LeftCollapsedNav from './components/layout/LeftCollapsedNav.jsx';
import RightCollapsedNav from './components/layout/RightCollapsedNav.jsx';
import ChatHistoryModal from './components/chat/ChatHistoryModal.jsx';
import AdminDashboardPage from './components/admin/AdminDashboardPage.jsx';
import AdminProtectedRoute from './components/admin/AdminProtectedRoute.jsx';
import api from './services/api.js';
import toast from 'react-hot-toast';
import { motion, AnimatePresence } from 'framer-motion';

function MainAppLayout({ orchestratorStatus }) {
    const { user: regularUser, logout: regularUserLogout } = useRegularAuth();
    const {
        currentSessionId,
        isLeftPanelOpen,
        isRightPanelOpen,
        setSessionId: setGlobalSessionId,
    } = useAppState();
    const [appStateMessages, setAppStateMessages] = useState([]);
    const [isHistoryModalOpen, setIsHistoryModalOpen] = useState(false);
    const [isChatProcessing, setIsChatProcessing] = useState(false);

    const handleChatProcessingStatusChange = (isLoading) => {
        setIsChatProcessing(isLoading);
    };

    const handleRegularUserLogout = () => {
        regularUserLogout();
        setGlobalSessionId(null);
    };

    const handleNewChat = async () => {
        try {
            const data = await api.startNewSession(currentSessionId); 
            if (data && data.newSessionId) {
                setGlobalSessionId(data.newSessionId);
                toast.success("New chat started!");
            } else {
                toast.error("Could not start new chat session.");
            }
        } catch (error) {
            toast.error(`Failed to start new chat: ${error.message}`);
        }
    };

    const handleSelectSessionFromHistory = (sessionId) => {
        if (sessionId && sessionId !== currentSessionId) {
            setGlobalSessionId(sessionId);
            toast.success(`Loading session...`);
        }
        setIsHistoryModalOpen(false);
    };

    const { token: regularUserTokenValue } = useRegularAuth();

    const fetchChatHistory = useCallback(async (sid) => {
        if (!sid || !regularUserTokenValue) {
            setAppStateMessages([]);
            return;
        }
        try {
            const sessionData = await api.getChatHistory(sid);
            
            // --- THIS IS THE CORRECTED LOGIC ---
            // The API now returns messages pre-formatted with `sender`.
            // We no longer need to map or transform the data here.
            setAppStateMessages(Array.isArray(sessionData.messages) ? sessionData.messages : []);
            // --- END OF CORRECTION ---

        } catch (error) {
            toast.error(`History load failed: ${error.message}`);
        }
    }, [regularUserTokenValue]);

    useEffect(() => {
        if (currentSessionId && regularUserTokenValue) {
            fetchChatHistory(currentSessionId);
        } else if (!regularUserTokenValue) {
            setAppStateMessages([]);
        }
    }, [currentSessionId, regularUserTokenValue, fetchChatHistory]);

    return (
        <>
            <TopNav 
                user={regularUser} 
                onLogout={handleRegularUserLogout} 
                onNewChat={handleNewChat} 
                onHistoryClick={() => setIsHistoryModalOpen(true)} 
                orchestratorStatus={orchestratorStatus}
                isChatProcessing={isChatProcessing}
            />
            <div className="flex flex-1 overflow-hidden pt-16 bg-background-light dark:bg-background-dark">
                <AnimatePresence mode="wait">
                    {isLeftPanelOpen ? (
                        <motion.aside key="left-panel-main" initial={{ x: '-100%' }} animate={{ x: '0%' }} exit={{ x: '-100%' }} transition={{ type: 'spring', stiffness: 300, damping: 30 }} className="w-full md:w-72 lg:w-80 xl:w-96 bg-surface-light dark:bg-surface-dark border-r border-border-light dark:border-border-dark overflow-y-auto p-3 sm:p-4 shadow-lg flex-shrink-0 custom-scrollbar">
                            <LeftPanel />
                        </motion.aside>
                    ) : ( <LeftCollapsedNav /> )}
                </AnimatePresence>
                <main className={`flex-1 flex flex-col overflow-hidden p-1 sm:p-2 md:p-4 transition-all duration-300 ease-in-out ${isLeftPanelOpen ? 'lg:ml-0' : 'lg:ml-16 md:ml-14'} ${isRightPanelOpen ? 'lg:mr-0' : 'lg:mr-16 md:mr-14'}`}>
                    <CenterPanel 
                        messages={appStateMessages} 
                        setMessages={setAppStateMessages} 
                        currentSessionId={currentSessionId}
                        onChatProcessingChange={handleChatProcessingStatusChange}
                    />
                </main>
                <AnimatePresence mode="wait">
                    {isRightPanelOpen ? (
                        <motion.aside key="right-panel-main" initial={{ x: '100%' }} animate={{ x: '0%' }} exit={{ x: '100%' }} transition={{ type: 'spring', stiffness: 300, damping: 30 }} className="hidden md:flex md:flex-col md:w-72 lg:w-80 xl:w-96 bg-surface-light dark:bg-surface-dark border-l border-border-light dark:border-border-dark overflow-y-auto p-3 sm:p-4 shadow-lg flex-shrink-0 custom-scrollbar">
                            <RightPanel />
                        </motion.aside>
                    ) : ( <RightCollapsedNav /> )}
                </AnimatePresence>
            </div>
            <ChatHistoryModal isOpen={isHistoryModalOpen} onClose={() => setIsHistoryModalOpen(false)} onSelectSession={handleSelectSessionFromHistory} />
        </>
    );
}

function App() {
    const { token: regularUserToken, user: regularUser, loading: regularUserAuthLoading, setUser: setRegularUserInAuthContext } = useRegularAuth();
    const { theme, setSessionId: setGlobalSessionId, currentSessionId, isAdminSessionActive } = useAppState();
    const navigate = useNavigate();
    const location = useLocation();
    const [appInitializing, setAppInitializing] = useState(true);
    const [showAuthModal, setShowAuthModal] = useState(false);
    const [orchestratorStatus, setOrchestratorStatus] = useState({ status: "loading", message: "Connecting..." });

    useEffect(() => { document.documentElement.className = theme; }, [theme]);
    useEffect(() => { api.getOrchestratorStatus().then(setOrchestratorStatus); }, []);

    useEffect(() => {
        if (isAdminSessionActive) {
            setAppInitializing(false);
            setShowAuthModal(false);
            if (!location.pathname.startsWith('/admin')) {
                navigate('/admin/dashboard', { replace: true });
            }
            return;
        }
        if (regularUserAuthLoading) {
            setAppInitializing(true);
            return;
        }
        setAppInitializing(false);
        if (regularUserToken && regularUser) {
            setShowAuthModal(false);
            if (location.pathname.startsWith('/admin')) {
                navigate('/', { replace: true });
            } else if (!currentSessionId) {
                api.startNewSession(null).then(data => {
                    if (data && data.newSessionId) {
                        setGlobalSessionId(data.newSessionId);
                    }
                });
            }
        } else if (!location.pathname.startsWith('/admin')) {
            setShowAuthModal(true);
        }
    }, [regularUserAuthLoading, regularUserToken, regularUser, isAdminSessionActive, currentSessionId, navigate, location.pathname, setGlobalSessionId]);

    const handleAuthSuccess = (authData) => {
        setShowAuthModal(false);
        if (authData && !authData.isAdminLogin && authData.token) {
            api.startNewSession(null).then(data => {
                if (data && data.newSessionId) {
                    setGlobalSessionId(data.newSessionId);
                }
            });
            if (authData.email && authData._id) {
                setRegularUserInAuthContext({ id: authData._id, email: authData.email });
            }
        }
    };

    if (appInitializing) {
        return (
            <div className="fixed inset-0 flex items-center justify-center bg-background-light dark:bg-background-dark">
                <div className="animate-spin rounded-full h-12 w-12 border-t-4 border-b-4 border-primary"></div>
            </div>
        );
    }

    return (
        <div className="flex flex-col h-screen overflow-hidden font-sans">
            <AnimatePresence>
                {showAuthModal && <AuthModal isOpen={showAuthModal} onClose={handleAuthSuccess} />}
            </AnimatePresence>
            <Routes>
                <Route path="/admin/dashboard" element={<AdminProtectedRoute><AdminDashboardPage /></AdminProtectedRoute>} />
                <Route path="/*" element={isAdminSessionActive ? <Navigate to="/admin/dashboard" replace /> : (regularUserToken && regularUser) ? <MainAppLayout orchestratorStatus={orchestratorStatus} /> : null} />
            </Routes>
        </div>
    );
}

function AppWrapper() {
    return (
        <Router>
            <App />
        </Router>
    );
}

export default AppWrapper;
```

`frontend/src/components/admin/AdminDashboardPage.jsx`

```javascript
// frontend/src/pages/AdminDashboardPage.jsx
import React, { useState, useEffect, useCallback, useRef } from 'react';
import { useNavigate } from 'react-router-dom';
import { useAppState } from '../../contexts/AppStateContext.jsx';
import * as adminApi from '../../services/adminApi.js';
import Button from '../core/Button.jsx';
import IconButton from '../core/IconButton.jsx';
import Modal from '../core/Modal.jsx';
import { UploadCloud, FileText, Trash2, Eye, LogOut, Loader2, AlertTriangle, CheckCircle, RefreshCw } from 'lucide-react';
import toast from 'react-hot-toast';
import { format } from 'date-fns'; // For formatting dates

// --- AdminDocumentUpload Component (child of AdminDashboardPage) ---
function AdminDocumentUpload({ onUploadSuccess }) {
    const [selectedFile, setSelectedFile] = useState(null);
    const [isUploading, setIsUploading] = useState(false);
    const fileInputRef = useRef(null);

    const handleFileChange = (e) => {
        if (isUploading) return;
        const file = e.target.files && e.target.files[0];
        if (file) setSelectedFile(file);
        else setSelectedFile(null);
    };

    const handleUpload = async () => {
        if (!selectedFile) {
            toast.error("Please select a file to upload.");
            return;
        }
        setIsUploading(true);
        const toastId = toast.loading(`Uploading "${selectedFile.name}"...`);
        const formData = new FormData();
        formData.append('file', selectedFile);

        try {
            const authHeaders = adminApi.getFixedAdminAuthHeaders(); // Get Basic Auth headers
            const response = await adminApi.uploadAdminDocument(formData, authHeaders);
            toast.success(response.message || `Admin document "${selectedFile.name}" uploaded. Analysis initiated.`, { id: toastId });
            onUploadSuccess(); // Callback to refresh document list in parent
            setSelectedFile(null);
            if (fileInputRef.current) fileInputRef.current.value = null;
        } catch (error) {
            // error.message now comes from makeAdminApiRequest's error handling
            toast.error(error.message || `Failed to upload admin document "${selectedFile.name}".`, { id: toastId });
        } finally {
            setIsUploading(false);
        }
    };

    return (
        <div className="card-base p-4 mb-6">
            <h2 className="text-lg font-semibold mb-3 text-text-light dark:text-text-dark">Upload New Admin Document</h2>
            <div className="flex flex-col sm:flex-row items-stretch sm:items-center gap-3">
                <input
                    type="file"
                    ref={fileInputRef}
                    onChange={handleFileChange}
                    className="input-field flex-grow text-sm p-2.5 min-h-[44px]"
                    accept=".pdf,.docx,.txt,.md" // Should match allowedAdminExtensions in backend multer
                    disabled={isUploading}
                />
                <Button
                    onClick={handleUpload}
                    isLoading={isUploading}
                    disabled={!selectedFile || isUploading}
                    leftIcon={<UploadCloud size={16} />}
                    size="md" // Consistent with other buttons
                    className="w-full sm:w-auto !py-2.5" // Tailwind class for padding
                >
                    Upload
                </Button>
            </div>
            {selectedFile && !isUploading && (
                <p className="text-xs mt-2 text-text-muted-light dark:text-text-muted-dark">
                    Selected: {selectedFile.name} ({(selectedFile.size / 1024).toFixed(1)} KB)
                </p>
            )}
        </div>
    );
}

// --- Main AdminDashboardPage Component ---
function AdminDashboardPage() {
    const { setIsAdminSessionActive } = useAppState(); // For admin logout
    const navigate = useNavigate();

    const [documents, setDocuments] = useState([]); // List of admin documents
    const [isLoading, setIsLoading] = useState(true); // Loading state for document list
    const [error, setError] = useState(''); // Error message for document list fetching

    const [isAnalysisModalOpen, setIsAnalysisModalOpen] = useState(false);
    const [currentDocForModal, setCurrentDocForModal] = useState(null); // Doc whose analysis is being viewed
    const [analysisContent, setAnalysisContent] = useState(null); // {faq, topics, mindmap}
    const [isLoadingAnalysis, setIsLoadingAnalysis] = useState(false); // Loading state for fetching analysis

    const adminLogoutHandler = () => {
        setIsAdminSessionActive(false); // Clear the admin session flag in AppState
        toast.success("Admin logged out.");
        navigate('/'); // Navigate to the main page (AuthModal will show if no regular user)
    };

    const fetchAdminDocs = useCallback(async (showLoadingToast = false) => {
        let toastId;
        if (showLoadingToast) {
            toastId = toast.loading("Refreshing document list...");
        } else {
            setIsLoading(true); // For initial load or non-toast refresh
        }
        setError('');
        try {
            const authHeaders = adminApi.getFixedAdminAuthHeaders();
            const response = await adminApi.getAdminDocuments(authHeaders);
            setDocuments(Array.isArray(response.documents) ? response.documents : []);
            if (showLoadingToast) toast.success("Document list refreshed.", { id: toastId });
        } catch (err) {
            const errorMessage = err.message || "Failed to fetch admin documents.";
            setError(errorMessage);
            if (showLoadingToast) toast.error(errorMessage, { id: toastId });
            else toast.error(errorMessage); // Show toast on initial load failure too
        } finally {
            if (!showLoadingToast) setIsLoading(false);
        }
    }, []); // No dependencies that change frequently, getFixedAdminAuthHeaders is stable

    useEffect(() => {
        fetchAdminDocs(); // Fetch documents when component mounts
    }, [fetchAdminDocs]);

    const handleDeleteDocument = async (serverFilename, originalName) => {
        if (!window.confirm(`Are you sure you want to delete admin document "${originalName}"? This action will remove its record and any associated analysis.`)) return;
        
        const toastId = toast.loading(`Deleting "${originalName}"...`);
        try {
            const authHeaders = adminApi.getFixedAdminAuthHeaders();
            await adminApi.deleteAdminDocument(serverFilename, authHeaders);
            toast.success(`Admin document "${originalName}" deleted.`, { id: toastId });
            fetchAdminDocs(); // Refresh the list
            if (isAnalysisModalOpen && currentDocForModal?.serverFilename === serverFilename) {
                setIsAnalysisModalOpen(false); // Close modal if the deleted doc was being viewed
            }
        } catch (err) {
            toast.error(err.message || `Failed to delete "${originalName}".`, { id: toastId });
        }
    };

    const handleViewAnalysis = async (doc) => {
        setCurrentDocForModal(doc);
        setAnalysisContent(null);      // Clear previous analysis
        setIsAnalysisModalOpen(true); // Open modal
        setIsLoadingAnalysis(true);   // Set loading state for analysis
        try {
            const authHeaders = adminApi.getFixedAdminAuthHeaders();
            const response = await adminApi.getAdminDocumentAnalysis(doc.serverFilename, authHeaders);
            setAnalysisContent(response.analysis); // response.analysis = {faq, topics, mindmap}
            // toast.success(`Analysis loaded for ${doc.originalName}`); // Optional success toast
        } catch (err) {
            toast.error(`Failed to load analysis for ${doc.originalName}: ${err.message}`);
            setAnalysisContent({ error: `Failed to load analysis: ${err.message}` }); // Show error in modal
        } finally {
            setIsLoadingAnalysis(false);
        }
    };

    const renderAnalysisModalContent = () => {
        if (!currentDocForModal) return null; // Should not happen if modal is open

        if (isLoadingAnalysis) {
            return <div className="p-6 text-center"><Loader2 className="animate-spin text-primary inline-block mr-2"/>Loading analysis content...</div>;
        }
        if (!analysisContent) {
            return <div className="p-4 text-text-muted-light dark:text-text-muted-dark">No analysis data currently available for this document. It might still be processing or was skipped.</div>;
        }
        if (analysisContent.error) {
            return <div className="p-4 text-red-500 dark:text-red-400 text-sm">Error: {analysisContent.error}</div>;
        }

        // Check if all analysis fields are effectively empty or placeholder messages
        const isEmpty = (str) => !str || str.trim() === "" || str.toLowerCase().startsWith("skipped:") || str.toLowerCase().startsWith("notice:");
        const allAnalysesEmpty = isEmpty(analysisContent.faq) && isEmpty(analysisContent.topics) && isEmpty(analysisContent.mindmap);

        if (allAnalysesEmpty) {
            return <div className="p-4 text-text-muted-light dark:text-text-muted-dark">Analysis processing may have been skipped or resulted in no content for all types.</div>;
        }

        return (
            <div className="space-y-3 max-h-[70vh] overflow-y-auto custom-scrollbar p-1 pr-2">
                {Object.entries(analysisContent).map(([key, value]) => {
                    const displayValue = (typeof value === 'string' && value.trim()) ? value : `No content generated for ${key}.`;
                    return (
                        <details key={key} className="text-xs rounded-md border border-border-light dark:border-border-dark bg-surface-light dark:bg-surface-dark" open>
                            <summary className="font-medium cursor-pointer capitalize p-2 bg-gray-50 dark:bg-gray-700/60 hover:bg-gray-100 dark:hover:bg-gray-600/60 rounded-t-md transition-colors">
                                {key.replace(/([A-Z])/g, ' $1').trim()} {/* e.g., mindmap -> Mind Map */}
                            </summary>
                            <pre className="p-2.5 bg-white dark:bg-gray-800 text-text-light dark:text-text-dark text-[0.7rem] max-h-60 overflow-y-auto custom-scrollbar whitespace-pre-wrap break-words rounded-b-md">
                                <code>{displayValue}</code>
                            </pre>
                        </details>
                    );
                })}
            </div>
        );
    };
    
    // --- Main JSX for AdminDashboardPage ---
    return (
        <div className="min-h-screen bg-background-light dark:bg-background-dark text-text-light dark:text-text-dark p-4 sm:p-6">
            <header className="flex items-center justify-between mb-6 pb-3 border-b border-border-light dark:border-border-dark">
                <h1 className="text-2xl font-bold">Admin Dashboard</h1>
                <div className="flex items-center gap-2">
                    <IconButton
                        icon={RefreshCw}
                        onClick={() => fetchAdminDocs(true)} // Pass true to show loading toast
                        title="Refresh Document List"
                        variant="ghost"
                        size="md"
                        className="text-text-muted-light dark:text-text-muted-dark hover:text-primary"
                    />
                    <Button onClick={adminLogoutHandler} variant="danger" size="sm" leftIcon={<LogOut size={16}/>}>
                        Logout Admin
                    </Button>
                </div>
            </header>

            <AdminDocumentUpload onUploadSuccess={() => fetchAdminDocs(false)} /> {/* Don't show toast for auto-refresh */}

            <div className="card-base p-0 sm:p-4">
                <h2 className="text-lg font-semibold mb-3 text-text-light dark:text-text-dark px-4 sm:px-0 pt-4 sm:pt-0">
                    Uploaded Admin Documents
                </h2>
                {isLoading && (
                    <div className="flex items-center justify-center p-6">
                        <Loader2 size={24} className="animate-spin text-primary mr-2" /> Loading documents...
                    </div>
                )}
                {error && (
                    <div className="p-3 my-3 mx-4 sm:mx-0 bg-red-500/10 border border-red-500/30 text-red-600 dark:text-red-300 rounded-md text-sm flex items-center gap-2">
                        <AlertTriangle size={18} /> {error}
                        <button onClick={() => fetchAdminDocs(true)} className="ml-auto text-xs underline hover:text-red-400">Retry</button>
                    </div>
                )}
                {!isLoading && !error && documents.length === 0 && (
                    <p className="text-center text-sm text-text-muted-light dark:text-text-muted-dark py-6 px-4 sm:px-0">
                        No admin documents uploaded yet.
                    </p>
                )}
                {!isLoading && !error && documents.length > 0 && (
                    <div className="overflow-x-auto custom-scrollbar">
                        <table className="w-full text-sm text-left">
                            <thead className="bg-gray-50 dark:bg-gray-800">
                                <tr>
                                    <th className="px-3 sm:px-4 py-2.5 font-medium">Original Name</th>
                                    <th className="px-3 sm:px-4 py-2.5 font-medium hidden md:table-cell">Uploaded</th>
                                    <th className="px-3 sm:px-4 py-2.5 font-medium">Analysis Status</th>
                                    <th className="px-3 sm:px-4 py-2.5 font-medium text-center">Actions</th>
                                </tr>
                            </thead>
                            <tbody>
                                {documents.map((doc) => (
                                    <tr key={doc.serverFilename} className="border-b border-border-light dark:border-border-dark hover:bg-gray-50/50 dark:hover:bg-gray-700/30 transition-colors">
                                        <td className="px-3 sm:px-4 py-2 truncate max-w-[150px] sm:max-w-xs" title={doc.originalName}>{doc.originalName}</td>
                                        <td className="px-3 sm:px-4 py-2 whitespace-nowrap hidden md:table-cell">
                                            {doc.uploadedAt ? format(new Date(doc.uploadedAt), 'MMM d, yyyy HH:mm') : 'N/A'}
                                        </td>
                                        <td className="px-3 sm:px-4 py-2">
                                            {(doc.hasFaq || doc.hasTopics || doc.hasMindmap) ? (
                                                <span className="flex items-center text-green-600 dark:text-green-400 text-xs">
                                                    <CheckCircle size={14} className="mr-1"/> Generated
                                                </span>
                                            ) : (
                                                doc.analysisUpdatedAt ? // If updated but still no content, means it was empty
                                                <span className="text-gray-500 dark:text-gray-400 text-xs">Empty/Skipped</span> :
                                                <span className="text-yellow-500 dark:text-yellow-400 text-xs">Pending</span>
                                            )}
                                        </td>
                                        <td className="px-1 sm:px-4 py-2 text-center whitespace-nowrap">
                                            <IconButton
                                                icon={Eye}
                                                title="View Analysis"
                                                size="sm"
                                                variant="ghost"
                                                className="text-primary hover:text-primary-dark dark:text-primary-light dark:hover:text-primary-darker mr-0.5 sm:mr-1"
                                                onClick={() => handleViewAnalysis(doc)}
                                                disabled={isLoadingAnalysis && currentDocForModal?.serverFilename === doc.serverFilename}
                                            />
                                            <IconButton
                                                icon={Trash2}
                                                title="Delete Document"
                                                size="sm"
                                                variant="ghost"
                                                className="text-red-500 hover:text-red-700 dark:text-red-400 dark:hover:text-red-300"
                                                onClick={() => handleDeleteDocument(doc.serverFilename, doc.originalName)}
                                            />
                                        </td>
                                    </tr>
                                ))}
                            </tbody>
                        </table>
                    </div>
                )}
            </div>

            <Modal
                isOpen={isAnalysisModalOpen}
                onClose={() => setIsAnalysisModalOpen(false)}
                title={`Analysis Results: ${currentDocForModal?.originalName || 'Document'}`}
                size="2xl"
            >
                {renderAnalysisModalContent()}
            </Modal>
        </div>
    );
}

export default AdminDashboardPage;
```

`frontend/src/components/admin/AdminProtectedRoute.jsx`

```javascript
// frontend/src/components/admin/AdminProtectedRoute.jsx
import React from 'react';
import { Navigate, Outlet, useLocation } from 'react-router-dom';
import { useAppState } from '../../contexts/AppStateContext.jsx'; // Using AppStateContext
import toast from 'react-hot-toast'; // Optional: for a message if redirecting

function AdminProtectedRoute({ children }) { // Accept children for different react-router-dom versions
    const { isAdminSessionActive } = useAppState(); // Get the admin session flag
    const location = useLocation();

    if (!isAdminSessionActive) {
        // If admin session is not active, redirect the user.
        // Redirecting to the main page ('/') is a common approach.
        // The main App component's logic will then likely show the AuthModal
        // if no regular user is logged in either.
        console.log("AdminProtectedRoute: Admin session not active. Redirecting from", location.pathname);
        toast.error("Admin access required. Please log in as admin."); // Optional feedback
        return <Navigate to="/" state={{ from: location }} replace />;
    }

    // If admin session is active, render the child components (the protected route's content)
    return children ? children : <Outlet />; // Outlet is for v6 nested routes, children for direct wrapping
}

export default AdminProtectedRoute;
```

`frontend/src/components/analysis/AnalysisToolRunner.jsx`

```javascript
// frontend/src/components/analysis/AnalysisToolRunner.jsx
import React, { useState, useEffect, useCallback, useRef } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import api from '../../services/api.js';
import * as adminApi from '../../services/adminApi.js';
import toast from 'react-hot-toast';
import { ChevronDown, ChevronUp, Loader2, Eye, AlertTriangle, Sparkles, HelpCircle as DefaultIcon, Download, FileText, FileBarChart2 } from 'lucide-react';
import * as LucideIcons from 'lucide-react';
import Button from '../core/Button.jsx';
import IconButton from '../core/IconButton.jsx';
import Modal from '../core/Modal.jsx';
import { marked } from 'marked';
import MindmapViewer from './MindmapViewer.jsx';
import DOMPurify from 'dompurify';
import Prism from 'prismjs';
import { renderMathInHtml } from '../../utils/markdownUtils';
import { useAppState } from '../../contexts/AppStateContext.jsx';

marked.setOptions({
  breaks: true,
  gfm: true,
});

const createMarkup = (markdownText) => {
    if (!markdownText) return { __html: '' };
    let html = marked.parse(markdownText);
    html = renderMathInHtml(html);
    const cleanHtml = DOMPurify.sanitize(html, {
        USE_PROFILES: { html: true, mathMl: true, svg: true },
        ADD_TAGS: ['iframe'],
        ADD_ATTR: ['allow', 'allowfullscreen', 'frameborder', 'scrolling'],
    });
    return { __html: cleanHtml };
};

const localParseAnalysisOutput = (rawOutput) => {
    if (!rawOutput || typeof rawOutput !== 'string') {
        return { content: '', thinking: '' };
    }
    const thinkingMatch = rawOutput.match(/<thinking>([\s\S]*?)<\/thinking>/i);
    let thinkingText = '';
    let mainContent = rawOutput;

    if (thinkingMatch && thinkingMatch[1]) {
        thinkingText = thinkingMatch[1].trim();
        mainContent = rawOutput.replace(/<thinking>[\s\S]*?<\/thinking>\s*/i, '').trim();
    }
    return { content: mainContent, thinking: thinkingText };
};

const ENGAGEMENT_TEXTS = {
    faq: ["Analyzing FAQs...", "Identifying questions...", "Compiling answers..."],
    topics: ["Extracting topics...", "Identifying themes...", "Summarizing points..."],
    mindmap: ["Generating mind map...", "Structuring concepts...", "Visualizing..."],
    default: ["Processing...", "Thinking...", "Working on it..."]
};

const placeholderReasoningMessages = [
    "Retrieved stored analysis. No detailed AI reasoning provided.",
    "AI reasoning not available.",
    "Mock generation for",
    "Retrieved stored mindmap data. No specific thinking process recorded in content.",
    "Retrieved stored admin analysis entry, but content for this type was empty.",
    "Retrieved stored admin analysis."
];

function AnalysisToolRunner({ toolType, title, iconName, selectedDocumentFilename, isTargetAdminDoc }) {
    const [isSectionOpen, setIsSectionOpen] = useState(true);
    const [isDropdownOpen, setIsDropdownOpen] = useState(false);
    const [isLoading, setIsLoading] = useState(false);
    const [error, setError] = useState('');
    const [analysisContent, setAnalysisContent] = useState(null);
    const [aiReasoning, setAiReasoning] = useState(null);
    const [isModalOpen, setIsModalOpen] = useState(false);
    const [currentEngagementText, setCurrentEngagementText] = useState('');
    const [generatingDocType, setGeneratingDocType] = useState(null);

    const IconComponent = LucideIcons[iconName] || DefaultIcon;
    const modalAnalysisContentRef = useRef(null);
    const aiReasoningContentRef = useRef(null);
    const mindmapViewerRef = useRef(null);
    const { theme: appTheme } = useAppState();

    useEffect(() => {
        let intervalId;
        if (isLoading) {
            const texts = ENGAGEMENT_TEXTS[toolType] || ENGAGEMENT_TEXTS.default;
            let textIndex = 0;
            setCurrentEngagementText(texts[0]);
            intervalId = setInterval(() => {
                textIndex = (textIndex + 1) % texts.length;
                setCurrentEngagementText(texts[textIndex]);
            }, 1800);
        } else {
            setCurrentEngagementText('');
        }
        return () => clearInterval(intervalId);
    }, [isLoading, toolType]);

    useEffect(() => {
        if (!selectedDocumentFilename) {
            setIsLoading(false); setError(''); setAnalysisContent(null);
            setAiReasoning(null); setIsDropdownOpen(false);
        } else {
             setAnalysisContent(null); setAiReasoning(null);
             setIsDropdownOpen(false); setError(''); setIsLoading(false);
        }
    }, [selectedDocumentFilename]);

    useEffect(() => {
        if (isModalOpen && analysisContent && toolType !== 'mindmap' && modalAnalysisContentRef.current) {
            const timer = setTimeout(() => {
                if (modalAnalysisContentRef.current) Prism.highlightAllUnder(modalAnalysisContentRef.current);
            }, 50);
            return () => clearTimeout(timer);
        }
    }, [isModalOpen, analysisContent, toolType]);

    useEffect(() => {
        if (aiReasoningContentRef.current && aiReasoning && isDropdownOpen) {
            const timer = setTimeout(() => {
                if (aiReasoningContentRef.current) Prism.highlightAllUnder(aiReasoningContentRef.current);
            }, 0);
            return () => clearTimeout(timer);
        }
    }, [aiReasoning, isDropdownOpen]);

    const handleRunAnalysis = async () => {
        if (!selectedDocumentFilename) {
            toast.error("Please select a document first.");
            return;
        }
        setIsLoading(true); setError(''); setAnalysisContent(null);
        setAiReasoning(null); setIsDropdownOpen(false);

        const toastMessage = isTargetAdminDoc
            ? `Fetching stored ${title.toLowerCase()} for "${selectedDocumentFilename}"...`
            : `Generating ${title.toLowerCase()} for "${selectedDocumentFilename}"...`;
        const toastId = toast.loading(toastMessage);

        try {
            let response;
            if (isTargetAdminDoc) {
                const authHeaders = adminApi.getFixedAdminAuthHeaders();
                const adminAnalysisData = await adminApi.getAdminDocumentAnalysisByOriginalName(selectedDocumentFilename, authHeaders);

                if (adminAnalysisData && adminAnalysisData.analysis && adminAnalysisData.analysis[toolType] !== undefined) {
                    const rawOutput = adminAnalysisData.analysis[toolType];
                    if (rawOutput === null || typeof rawOutput !== 'string' || rawOutput.trim() === "") {
                         response = {
                            content: `Notice: No stored ${toolType} analysis found for admin document "${selectedDocumentFilename}".`,
                            thinking: "Retrieved stored admin analysis entry, but content for this type was empty."
                        };
                        toast.success(`No stored ${toolType} found for admin doc.`, { id: toastId });
                    } else {
                        const parsed = localParseAnalysisOutput(rawOutput);
                        response = { content: parsed.content, thinking: parsed.thinking || "Retrieved stored admin analysis." };
                        toast.success(`Retrieved stored admin ${title}.`, { id: toastId });
                    }
                } else {
                    throw new Error(`Admin analysis for type '${toolType}' not found.`);
                }
            } else {
                const payload = { filename: selectedDocumentFilename, analysis_type: toolType };
                response = await api.requestAnalysis(payload);
                if (response && response.content && !response.content.startsWith("Error:")) {
                    toast.success(`${title} generated!`, { id: toastId });
                } else {
                    toast.dismiss(toastId);
                }
            }

            if (response) {
                if (response.content && !response.content.startsWith("Error:") && !response.content.startsWith("Notice:")) {
                    setAnalysisContent(response.content);
                } else if (response.content) {
                    setAnalysisContent(response.content);
                    setError(response.content);
                    if (response.content.startsWith("Error:")) {
                         if (toast.isActive(toastId)) toast.error(`Error in ${title}: ${response.content.substring(0, 100)}...`, { id: toastId });
                         else toast.error(`Error in ${title}: ${response.content.substring(0, 100)}...`);
                    }
                } else {
                    setAnalysisContent(`No content was returned for ${title}.`);
                    setError(`No content returned for ${title}.`);
                    if (toast.isActive(toastId)) toast.warn(`No content generated for ${title}.`, { id: toastId });
                    else toast.warn(`No content generated for ${title}.`);
                }
                setAiReasoning(response.thinking || "AI reasoning not available.");
                setIsDropdownOpen(true);
            } else {
                throw new Error("Empty or invalid response from analysis service.");
            }
        } catch (err) {
            if (toast.isActive(toastId)) toast.dismiss(toastId);
            const errorMessage = err.message || `Failed to process ${title}.`;
            setError(errorMessage);
            setAnalysisContent(`Error: ${errorMessage}`);
            toast.error(errorMessage);
        } finally {
            setIsLoading(false);
        }
    };

    const handleGenerateDocument = async (docType) => {
        if (!analysisContent || generatingDocType) {
            return;
        }

        setGeneratingDocType(docType);
        const toastId = toast.loading(`Generating ${docType.toUpperCase()} document...`);

        try {
            const fullMarkdownContent = `## ${title}\n\n**Source Document:** \`${selectedDocumentFilename}\`\n\n---\n\n${analysisContent}`;
            
            const { fileBlob, filename } = await api.generateDocument({
                markdownContent: fullMarkdownContent,
                docType: docType,
                sourceDocumentName: selectedDocumentFilename
            });
            
            const url = window.URL.createObjectURL(fileBlob);
            const link = document.createElement('a');
            link.href = url;
            link.setAttribute('download', filename);
            document.body.appendChild(link);
            link.click();
            link.parentNode.removeChild(link);
            window.URL.revokeObjectURL(url);

            toast.success(`${docType.toUpperCase()} document downloaded.`, { id: toastId });

        } catch (err) {
            toast.error(`Failed to generate document: ${err.message}`, { id: toastId });
        } finally {
            setGeneratingDocType(null);
        }
    };

    const handleDownloadMindmap = async (format) => {
        if (mindmapViewerRef.current && mindmapViewerRef.current.getSvgElement) {
            const svgElement = mindmapViewerRef.current.getSvgElement();
            if (!svgElement) {
                toast.error("Mindmap SVG element not found or not rendered yet.");
                return;
            }
            const filenameBase = selectedDocumentFilename ? selectedDocumentFilename.split('.')[0] : 'mindmap';
            const filename = `${filenameBase}_${toolType}.${format}`;
            if (format === 'svg') {
                const serializer = new XMLSerializer();
                let svgString = serializer.serializeToString(svgElement);
                svgString = '<?xml version="1.0" standalone="no"?>\r\n' + svgString;
                const blob = new Blob([svgString], { type: 'image/svg+xml;charset=utf-8' });
                const url = URL.createObjectURL(blob);
                const link = document.createElement('a');
                link.href = url; link.download = filename; document.body.appendChild(link);
                link.click(); document.body.removeChild(link); URL.revokeObjectURL(url);
                toast.success("SVG downloaded!");
            } else if (format === 'png') {
                const pngToastId = toast.loading("Preparing PNG download...");
                try {
                    const { saveSvgAsPng } = await import('save-svg-as-png');
                    saveSvgAsPng(svgElement, filename, { scale: 2, backgroundColor: appTheme === 'dark' ? '#1E293B' : '#FFFFFF' });
                    toast.success("PNG download started!", { id: pngToastId });
                } catch (e) {
                    console.error("Error loading/using save-svg-as-png:", e);
                    toast.error(`Failed to export PNG: ${e.message}.`, { id: pngToastId });
                }
            }
        } else {
            toast.error("Mindmap viewer not ready or SVG not available.");
        }
    };

    const renderModalContent = () => {
        if (isLoading && !analysisContent) {
            return <div className="flex items-center justify-center h-48"><Loader2 size={32} className="animate-spin text-primary" /><p className="ml-2 text-text-muted-light dark:text-text-muted-dark">Loading analysis...</p></div>;
        }
        if (error && (!analysisContent || analysisContent === error)) {
             return <p className="p-4 text-center text-red-500 dark:text-red-400">{error}</p>;
        }
        if (!analysisContent) {
            return <p className="p-4 text-center text-text-muted-light dark:text-text-muted-dark">No analysis content available to display.</p>;
        }
        if (toolType === 'mindmap') {
            return <div className="mindmap-modal-content-wrapper min-h-[60vh] h-[calc(70vh-80px)] flex justify-center items-center"><MindmapViewer mermaidCode={analysisContent} ref={mindmapViewerRef} /></div>;
        }
        return <div ref={modalAnalysisContentRef} className="prose prose-sm dark:prose-invert max-w-none text-text-light dark:text-text-dark p-1 custom-scrollbar text-[0.8rem] leading-relaxed" dangerouslySetInnerHTML={createMarkup(analysisContent)} />;
    };

    const showReasoning = aiReasoning && !placeholderReasoningMessages.some(msg => aiReasoning.includes(msg));

    return (
        <div className="card-base p-3">
            <div className="flex items-center justify-between">
                <div className="flex items-center gap-2 text-sm font-medium text-text-light dark:text-text-dark focus:outline-none w-full text-left cursor-pointer hover:text-primary dark:hover:text-primary-light transition-colors" onClick={() => setIsSectionOpen(!isSectionOpen)} aria-expanded={isSectionOpen}>
                    <IconComponent size={16} className="text-primary dark:text-primary-light flex-shrink-0" />
                    <span className="flex-grow">{title}</span>
                </div>
                <div className="flex items-center gap-1 flex-shrink-0">
                    <Button onClick={handleRunAnalysis} variant="primary" size="sm" className="!px-3 !py-1 text-xs" isLoading={isLoading} disabled={!selectedDocumentFilename || isLoading} title={!selectedDocumentFilename ? "Select a document first" : `Run ${title} Analysis`}>
                       {isLoading ? (currentEngagementText.split(' ')[0] || "...") : "Run"}
                    </Button>
                    <IconButton icon={isSectionOpen ? ChevronUp : ChevronDown} onClick={() => setIsSectionOpen(!isSectionOpen)} size="sm" variant="ghost" className="p-1" aria-label={isSectionOpen ? "Collapse section" : "Expand section"} disabled={isLoading && isSectionOpen} />
                </div>
            </div>
            <AnimatePresence>
                {isSectionOpen && (
                    <motion.div key="tool-section-content" initial={{ height: 0, opacity: 0 }} animate={{ height: 'auto', opacity: 1 }} exit={{ height: 0, opacity: 0 }} transition={{ duration: 0.25, ease: "easeInOut" }} className="mt-2 pt-2 border-t border-border-light dark:border-border-dark overflow-hidden">
                        {isLoading && (<div className="text-xs text-text-muted-light dark:text-text-muted-dark p-2 flex items-center justify-center gap-2 animate-fadeIn"><Loader2 size={14} className="animate-spin"/> {currentEngagementText}</div>)}
                        {error && !isLoading && (!analysisContent || analysisContent === error) && (<div className="my-2 p-2 bg-red-500/10 border border-red-500/30 text-red-600 dark:text-red-300 rounded-md text-xs flex items-center gap-1"><AlertTriangle size={14} /> {error.length > 150 ? error.substring(0,147) + "..." : error}</div>)}
                        {!isLoading && (analysisContent || aiReasoning) && isDropdownOpen && (
                            <motion.div key="analysis-dropdown" initial={{ opacity: 0, y: -10 }} animate={{ opacity: 1, y: 0 }} exit={{ opacity: 0, y: -10 }} transition={{ duration: 0.2 }} className="mt-2 space-y-2">
                                {showReasoning && aiReasoning && (
                                    <details className="group text-xs rounded-md border border-border-light dark:border-border-dark bg-surface-light dark:bg-gray-800 shadow-sm">
                                        <summary className="flex items-center justify-between gap-1 p-2 cursor-pointer text-text-muted-light dark:text-text-muted-dark hover:bg-gray-50 dark:hover:bg-gray-700 transition-colors rounded-t-md"><span className="flex items-center gap-1.5 font-medium"><Sparkles size={14} className="text-accent" /> AI Reasoning</span><ChevronDown size={16} className="group-open:rotate-180 transition-transform" /></summary>
                                        <div ref={aiReasoningContentRef} className="p-2.5 prose prose-xs dark:prose-invert max-w-none text-text-light dark:text-text-dark max-h-60 overflow-y-auto custom-scrollbar text-[0.75rem] leading-relaxed bg-gray-50 dark:bg-gray-900/50 rounded-b-md" dangerouslySetInnerHTML={createMarkup(aiReasoning)} />
                                    </details>
                                )}
                                {analysisContent && !error && (
                                     <Button onClick={() => setIsModalOpen(true)} variant="outline" size="sm" fullWidth leftIcon={<Eye size={14}/>} className="!py-1.5 text-xs border-primary/70 text-primary hover:bg-primary/10 dark:border-primary-light/70 dark:text-primary-light dark:hover:bg-primary-light/10">View Full {title}</Button>
                                )}
                            </motion.div>
                        )}
                        {!isLoading && !isDropdownOpen && !error && (
                            <p className="text-xs text-text-muted-light dark:text-text-muted-dark p-2 text-center">{selectedDocumentFilename ? `Click "Run" to ${isTargetAdminDoc ? 'fetch stored' : 'generate'} ${title.toLowerCase()} for "${selectedDocumentFilename}".` : "Select a document to enable analysis."}</p>
                        )}
                    </motion.div>
                )}
            </AnimatePresence>
            <Modal
                isOpen={isModalOpen} onClose={() => setIsModalOpen(false)}
                title={`${title} for "${selectedDocumentFilename || 'document'}"`}
                size={toolType === 'mindmap' ? "3xl" : "xl"}
                footerContent={
                <>
                    {toolType === 'mindmap' && analysisContent && !error && (
                        <Button onClick={() => handleDownloadMindmap('svg')} variant="outline" size="sm" className="text-xs" leftIcon={<Download size={14}/>}>SVG</Button>
                    )}
                    
                    {toolType !== 'mindmap' && analysisContent && !error && (
                        <>
                           <Button 
                                onClick={() => handleGenerateDocument('pptx')} 
                                variant="outline" size="sm" className="text-xs" 
                                leftIcon={<FileBarChart2 size={14}/>}
                                isLoading={generatingDocType === 'pptx'}
                                disabled={!!generatingDocType}
                            >
                                {generatingDocType === 'pptx' ? 'Generating...' : 'Generate PPTX'}
                            </Button>
                           <Button 
                                onClick={() => handleGenerateDocument('docx')} 
                                variant="outline" size="sm" className="text-xs" 
                                leftIcon={<FileText size={14}/>}
                                isLoading={generatingDocType === 'docx'}
                                disabled={!!generatingDocType}
                            >
                                {generatingDocType === 'docx' ? 'Generating...' : 'Generate DOCX'}
                            </Button>
                        </>
                    )}

                    <div className="flex-grow"></div>
                    <Button onClick={() => setIsModalOpen(false)} variant="secondary" size="sm" className="text-xs" disabled={!!generatingDocType}>
                        Close
                    </Button>
                </>}
            >
                <div className={`max-h-[70vh] overflow-y-auto custom-scrollbar p-1 pr-2 rounded-md shadow-inner ${toolType === 'mindmap' ? 'bg-transparent dark:bg-transparent' : 'bg-gray-50 dark:bg-gray-800'}`}>
                    {selectedDocumentFilename && (
                        <p className="text-xs text-text-muted-light dark:text-text-muted-dark mb-2 border-b border-border-light dark:border-border-dark pb-1.5">
                            Source Document: <strong>{selectedDocumentFilename}</strong>
                        </p>
                    )}
                    {renderModalContent()}
                </div>
            </Modal>
        </div>
    );
}

export default AnalysisToolRunner;
```

`frontend/src/components/analysis/KnowledgeGraphViewer.jsx`

```javascript
// frontend/src/components/analysis/KnowledgeGraphViewer.jsx
import React, { useEffect, useState, useMemo } from 'react';
import Graph from 'react-vis-network-graph';
import { Loader2, AlertTriangle, ZoomIn, ZoomOut, Maximize } from 'lucide-react';
import { useTheme } from '../../hooks/useTheme';
import IconButton from '../core/IconButton.jsx';

const KnowledgeGraphViewer = ({ graphData }) => {
    const { theme } = useTheme();

    // --- FIX START: Add state to hold the network instance ---
    const [network, setNetwork] = useState(null);
    // --- FIX END ---

    // Memoize options to prevent re-renders
    const options = useMemo(() => {
        const isDark = theme === 'dark';
        return {
            layout: {
                hierarchical: {
                    enabled: true,
                    direction: 'UD', // Up-Down
                    sortMethod: 'directed',
                    levelSeparation: 150,
                    nodeSpacing: 200,
                },
            },
            nodes: {
                shape: 'box',
                borderWidth: 1.5,
                font: {
                    color: isDark ? '#E2E8F0' : '#0F172A',
                    size: 14,
                    face: 'Inter',
                },
                color: {
                    border: isDark ? '#4B5563' : '#9CA3AF',
                    background: isDark ? '#1E293B' : '#FFFFFF',
                    highlight: {
                        border: '#3b82f6',
                        background: isDark ? '#2563eb' : '#60a5fa',
                    },
                },
                shadow: true,
            },
            edges: {
                color: {
                    color: isDark ? '#64748B' : '#9CA3AF',
                    highlight: '#3b82f6',
                },
                arrows: {
                    to: { enabled: true, scaleFactor: 0.7 },
                },
                font: {
                    color: isDark ? '#94A3B8' : '#6B7280',
                    size: 10,
                    align: 'middle',
                    strokeWidth: 2,
                    strokeColor: isDark ? '#1E293B' : '#FFFFFF',
                },
                smooth: {
                    type: 'cubicBezier',
                    forceDirection: 'vertical',
                    roundness: 0.4,
                },
            },
            physics: {
                enabled: true,
                hierarchicalRepulsion: {
                    centralGravity: 0.0,
                    springLength: 100,
                    springConstant: 0.01,
                    nodeDistance: 200,
                    damping: 0.09,
                },
                solver: 'hierarchicalRepulsion',
            },
            interaction: {
                dragNodes: true,
                dragView: true,
                zoomView: true,
                tooltipDelay: 200,
            },
            height: '100%',
            width: '100%',
        };
    }, [theme]);

    const formattedGraph = useMemo(() => {
        if (!graphData || !graphData.nodes || !graphData.edges) {
            return { nodes: [], edges: [] };
        }
        const nodes = graphData.nodes.map(node => ({
            id: node.id,
            label: node.id,
            title: `Type: ${node.type}\nParent: ${node.parent || 'N/A'}\n\n${node.description}`,
            color: node.type === 'major' 
                ? { border: '#3b82f6', background: theme === 'dark' ? '#1E3A8A' : '#BFDBFE' } 
                : undefined,
        }));
        const edges = graphData.edges.map(edge => ({
            from: edge.from,
            to: edge.to,
            label: edge.relationship.replace(/_/g, ' '),
        }));
        return { nodes, edges };
    }, [graphData, theme]);

    // --- FIX START: These handlers will now work because 'network' is in state ---
    const handleZoomIn = () => network?.zoomIn();
    const handleZoomOut = () => network?.zoomOut();
    const handleFit = () => network?.fit();
    // --- FIX END ---

    if (!graphData) {
        return (
            <div className="flex items-center justify-center h-full">
                <Loader2 className="animate-spin text-primary mr-2" /> Loading graph data...
            </div>
        );
    }

    if (graphData.error) {
        return (
             <div className="flex flex-col items-center justify-center h-full text-red-500">
                <AlertTriangle size={32} className="mb-2" />
                <p className="font-semibold">Failed to load Knowledge Graph</p>
                <p className="text-xs">{graphData.error}</p>
            </div>
        );
    }
    
    if (formattedGraph.nodes.length === 0) {
        return (
             <div className="flex flex-col items-center justify-center h-full text-text-muted-light dark:text-text-muted-dark">
                <AlertTriangle size={32} className="mb-2" />
                <p>No graph data found for this document.</p>
             </div>
        );
    }

    return (
        <div className="relative w-full h-[70vh] border border-border-light dark:border-border-dark rounded-md bg-gray-50 dark:bg-gray-800/50">
            <Graph
                key={theme}
                graph={formattedGraph}
                options={options}
                // --- FIX START: Use the 'getNetwork' callback to update our state ---
                getNetwork={net => setNetwork(net)}
                // --- FIX END ---
            />
            <div className="absolute top-2 right-2 flex flex-col gap-1.5 bg-surface-light dark:bg-surface-dark p-1.5 rounded-md shadow-lg border border-border-light dark:border-border-dark">
                <IconButton icon={ZoomIn} onClick={handleZoomIn} title="Zoom In" size="sm" />
                <IconButton icon={ZoomOut} onClick={handleZoomOut} title="Zoom Out" size="sm" />
                <IconButton icon={Maximize} onClick={handleFit} title="Fit to View" size="sm" />
            </div>
        </div>
    );
};

export default KnowledgeGraphViewer;
```

`frontend/src/components/analysis/MindmapViewer.jsx`

```javascript
// frontend/src/components/analysis/MindmapViewer.jsx
import React, { useEffect, useRef, useState, useImperativeHandle, forwardRef } from 'react';
import toast from 'react-hot-toast';
import { escapeHtml } from '../../utils/helpers.js';

const MindmapViewer = forwardRef(({ mermaidCode }, ref) => {
    const svgContainerRef = useRef(null);
    const [error, setError] = useState(null);
    const [isMermaidReady, setIsMermaidReady] = useState(false);
    const [isLoading, setIsLoading] = useState(false);
    const [uniqueId] = useState(() => `mermaid-graph-${Math.random().toString(36).substr(2, 9)}`);

    useImperativeHandle(ref, () => ({
        getSvgElement: () => {
            return svgContainerRef.current?.querySelector('svg');
        }
    }));

    useEffect(() => {
        if (typeof window.mermaid !== 'undefined') {
            setIsMermaidReady(true);
        } else {
            const intervalId = setInterval(() => {
                if (typeof window.mermaid !== 'undefined') {
                    setIsMermaidReady(true);
                    clearInterval(intervalId);
                }
            }, 100);
            return () => clearInterval(intervalId);
        }
    }, []);

    useEffect(() => {
        if (!isMermaidReady || !mermaidCode || !svgContainerRef.current) {
            if (svgContainerRef.current) svgContainerRef.current.innerHTML = '';
            setError(null);
            setIsLoading(false);
            return;
        }

        const renderMermaidDiagram = async () => {
            setIsLoading(true);
            setError(null);
            if (!svgContainerRef.current) {
                setIsLoading(false);
                return;
            }
            svgContainerRef.current.innerHTML = '<div class="flex justify-center items-center h-full w-full text-sm text-text-muted-light dark:text-text-muted-dark"><div class="animate-spin rounded-full h-6 w-6 border-t-2 border-b-2 border-primary mr-2"></div>Rendering diagram...</div>';
            
            let codeToRender = mermaidCode.trim();
            
            // --- THIS IS THE FIX ---
            // New, more robust regex to find the diagram code.
            // It looks for a code block that CONTAINS a known diagram type (e.g., 'graph', 'mindmap').
            // It is no longer anchored to the start (^) of the string, so it can find the
            // block even if there's leading garbage or extra backticks from the LLM.
            const fenceRegex = /```(?:mermaid)?\s*([\s\S]*?(?:graph|mindmap|flowchart|sequenceDiagram)[\s\S]*?)\s*```/i;
            const match = codeToRender.match(fenceRegex);

            if (match && match[1]) {
                // If we found a fenced block, use its content.
                codeToRender = match[1].trim();
            } else {
                // Fallback for cases where LLM might forget the fences entirely.
                // We still trim to remove potential whitespace.
                codeToRender = codeToRender.trim();
            }
            // --- END OF FIX ---

            try {
                if (typeof window.mermaid === 'undefined') {
                    throw new Error("Mermaid library failed to load or initialize properly.");
                }

                const { svg, bindFunctions } = await window.mermaid.render(uniqueId, codeToRender);
                
                if (svgContainerRef.current) {
                    svgContainerRef.current.innerHTML = svg;
                    if (bindFunctions) {
                        bindFunctions(svgContainerRef.current);
                    }
                    const svgElement = svgContainerRef.current.querySelector('svg');
                    if (svgElement) {
                        svgElement.style.width = '100%';
                        svgElement.style.height = 'auto'; 
                        svgElement.style.maxWidth = '100%'; 
                        svgElement.style.display = 'block';
                    }
                }
            } catch (e) {
                console.error("Error rendering Mermaid diagram with input:", codeToRender, e);
                const errorMsg = e.message || "Failed to render mind map. Invalid Mermaid syntax?";
                setError(errorMsg);
                if (svgContainerRef.current) {
                    const codeSnippet = escapeHtml(codeToRender.substring(0, 200) + (codeToRender.length > 200 ? "..." : ""));
                    svgContainerRef.current.innerHTML = `<div class="p-4 text-center text-red-500 dark:text-red-400 text-xs break-all"><strong>Error rendering:</strong> ${escapeHtml(errorMsg)}<br><strong class='mt-2 block'>Input Code (first 200 chars):</strong><pre class='text-left text-xs bg-gray-100 dark:bg-gray-700 p-2 rounded mt-1 whitespace-pre-wrap'>${codeSnippet}</pre></div>`;
                }
            } finally {
                setIsLoading(false);
            }
        };

        const timer = setTimeout(renderMermaidDiagram, 100); 
        return () => clearTimeout(timer);
        
    }, [mermaidCode, uniqueId, isMermaidReady]);

    if (!isMermaidReady && !error) {
      return <div className="p-4 text-center text-text-muted-light dark:text-text-muted-dark text-xs">Waiting for Mermaid.js library...</div>;
    }
    if (error && (!isLoading || (svgContainerRef.current && svgContainerRef.current.innerHTML.includes('Error rendering')))) {
        return <div ref={svgContainerRef} className="mermaid-diagram-render-area w-full h-full flex justify-center items-center bg-gray-50 dark:bg-gray-800/50 p-2 rounded-md">
                {/* Error message will be injected by useEffect's catch block */}
               </div>;
    }
    
    if (isLoading) { 
         return <div ref={svgContainerRef} className="mermaid-diagram-render-area w-full h-full flex justify-center items-center bg-gray-50 dark:bg-gray-800/50 p-2 rounded-md">
            {/* Loading message is set by renderMermaidDiagram's initial innerHTML write */}
         </div>;
    }

    if (!mermaidCode && !error && isMermaidReady) { 
        return <p className="text-xs text-center text-text-muted-light dark:text-text-muted-dark p-4">No mind map data to display.</p>;
    }
    
    return (
        <div 
            ref={svgContainerRef} 
            className="mermaid-diagram-render-area w-full h-full flex justify-center items-center bg-gray-50 dark:bg-gray-800/50 p-2 rounded-md"
        >

        </div>
    );
});

export default MindmapViewer;

```

`frontend/src/components/analysis/PodcastGenerator.jsx`

```javascript
// frontend/src/components/analysis/PodcastGenerator.jsx
import React, { useState } from 'react';
import api from '../../services/api.js';
import toast from 'react-hot-toast';
import { Headphones, ChevronDown, ChevronUp } from 'lucide-react';
import Button from '../core/Button.jsx';
import { motion, AnimatePresence } from 'framer-motion';

function PodcastGenerator({ selectedDocumentFilename }) {
    const [isSectionOpen, setIsSectionOpen] = useState(true);
    const [isLoading, setIsLoading] = useState(false);
    const [podcastPurpose, setPodcastPurpose] = useState('review');
    const [podcastLength, setPodcastLength] = useState('standard');

    const handleGeneratePodcast = async () => {
        if (!selectedDocumentFilename) {
            toast.error("Please select a document first.");
            return;
        }
        setIsLoading(true);
        const toastId = toast.loading("Generating high-quality podcast script & audio. This may take a moment...");
        try {
            const { audioBlob, sourceDocumentName } = await api.generatePodcast({
                analysisContent: `A study session on: ${selectedDocumentFilename}`,
                sourceDocumentName: selectedDocumentFilename,
                podcastOptions: { studyPurpose: podcastPurpose, sessionLength: podcastLength }
            });
            
            toast.success("High-Quality Podcast is ready for download!", { id: toastId, duration: 5000 });

            const url = window.URL.createObjectURL(audioBlob);
            const link = document.createElement('a');
            const safeFilename = sourceDocumentName.split('.')[0].replace(/[^a-zA-Z0-9]/g, '_');
            link.href = url;
            link.setAttribute('download', `AI_Podcast_${safeFilename}.mp3`);
            document.body.appendChild(link);
            link.click();
            link.parentNode.removeChild(link);
            window.URL.revokeObjectURL(url);
        } catch (err) {
            const errorMessage = err.response?.data?.message || err.message || "Failed to generate podcast.";
            toast.error(errorMessage, { id: toastId });
        } finally {
            setIsLoading(false);
        }
    };

    return (
        <div className="card-base p-3">
            <div className="flex items-center justify-between cursor-pointer" onClick={() => setIsSectionOpen(!isSectionOpen)}>
                <div className="flex items-center gap-2 text-sm font-medium text-text-light dark:text-text-dark">
                    <Headphones size={16} className="text-accent" />
                    <span className="flex-grow">HQ Podcast Generator</span>
                </div>
                {isSectionOpen ? <ChevronUp size={18} /> : <ChevronDown size={18} />}
            </div>
            <AnimatePresence>
                {isSectionOpen && (
                    <motion.div initial={{ height: 0, opacity: 0 }} animate={{ height: 'auto', opacity: 1 }} exit={{ height: 0, opacity: 0 }} transition={{ duration: 0.2, ease: "easeInOut" }} className="mt-2 pt-2 border-t border-border-light dark:border-border-dark overflow-hidden">
                        <p className="text-xs text-text-muted-light dark:text-text-muted-dark mb-3">
                            Generate a high-quality, conversational audio study session from the selected document.
                        </p>
                        <div className="flex flex-col sm:flex-row gap-2 mb-3">
                            <div className="flex-1">
                                <label htmlFor="podcast-purpose" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark mb-1">Purpose</label>
                                <select id="podcast-purpose" value={podcastPurpose} onChange={(e) => setPodcastPurpose(e.target.value)} className="input-field !text-xs !py-1.5 !px-2 w-full" disabled={isLoading}>
                                    <option value="review">General Review</option>
                                    <option value="introduction">Introduction</option>
                                    <option value="exam_prep">Exam Prep</option>
                                    <option value="deep_dive">Deep Dive</option>
                                </select>
                            </div>
                            <div className="flex-1">
                                <label htmlFor="podcast-length" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark mb-1">Length</label>
                                <select id="podcast-length" value={podcastLength} onChange={(e) => setPodcastLength(e.target.value)} className="input-field !text-xs !py-1.5 !px-2 w-full" disabled={isLoading}>
                                    <option value="quick">Quick (~5-7m)</option>
                                    <option value="standard">Standard (~10-15m)</option>
                                    <option value="comprehensive">Comprehensive (~15-25m)</option>
                                </select>
                            </div>
                        </div>
                        <Button
                            onClick={handleGeneratePodcast}
                            variant="primary"
                            size="sm"
                            fullWidth
                            isLoading={isLoading}
                            disabled={!selectedDocumentFilename || isLoading}
                            title={!selectedDocumentFilename ? "Select a document first" : "Generate Podcast"}
                        >
                           {isLoading ? 'Generating Audio...' : 'Generate High-Quality Podcast'}
                        </Button>
                    </motion.div>
                )}
            </AnimatePresence>
        </div>
    );
}

export default PodcastGenerator;
// This code defines a React component for generating podcasts from selected documents.

```

`frontend/src/components/analysis/RightPanel.jsx`

```javascript
// // frontend/src/components/layout/RightPanel.jsx
// import React, { useState } from 'react';
// import { useAppState } from '../../contexts/AppStateContext';
// import AnalysisTool from '../analysis/AnalysisTool.jsx'; // Added .jsx
// import { PanelRightClose, ChevronDown, ChevronUp, Telescope } from 'lucide-react';
// import IconButton from '../core/IconButton.jsx'; // Added .jsx
// import { motion } from 'framer-motion';

// function RightPanel() {
//     const { setIsRightPanelOpen, selectedDocumentForAnalysis } = useAppState();
//     const [isAnalyzerOpen, setIsAnalyzerOpen] = useState(true);

//     const currentSelectedDocFilename = selectedDocumentForAnalysis?.originalName || null;

//     return (
//         <div className="flex flex-col h-full p-3 sm:p-4 bg-surface-light dark:bg-surface-dark text-text-light dark:text-text-dark custom-scrollbar">
//             <div className="flex items-center justify-between mb-4 pb-2 border-b border-border-light dark:border-border-dark">
//                 <h2 className="text-base font-semibold">Advanced Analyzer</h2>
//                 <IconButton 
//                     icon={PanelRightClose} 
//                     onClick={() => setIsRightPanelOpen(false)} 
//                     title="Close Analyzer Panel"
//                     variant="ghost"
//                     size="sm"
//                     className="text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
//                 />
//             </div>
            
//             <button 
//                 onClick={() => setIsAnalyzerOpen(!isAnalyzerOpen)}
//                 className="w-full flex items-center justify-between px-3 py-2.5 text-sm font-medium text-left bg-gray-50 dark:bg-gray-800 hover:bg-gray-100 dark:hover:bg-gray-700 rounded-md focus:outline-none shadow-sm border border-border-light dark:border-border-dark mb-3"
//             >
//                 <span className="flex items-center gap-2"><Telescope size={16} /> Analysis Tools</span>
//                 {isAnalyzerOpen ? <ChevronUp size={18} /> : <ChevronDown size={18} />}
//             </button>

//             {isAnalyzerOpen && (
//                 <motion.div 
//                     initial={{ height: 0, opacity: 0 }} 
//                     animate={{ height: 'auto', opacity: 1 }} 
//                     exit={{ height: 0, opacity: 0 }}
//                     transition={{ duration: 0.2, ease: "easeInOut" }}
//                     className="flex-grow space-y-3 overflow-y-auto custom-scrollbar pr-1"
//                 >
//                     {!currentSelectedDocFilename && (
//                         <div className="p-4 text-xs text-center text-text-muted-light dark:text-text-muted-dark bg-gray-50 dark:bg-gray-800 rounded-md border border-dashed border-border-light dark:border-border-dark">
//                             <p>Select a document from the left panel to enable analysis tools.</p>
//                         </div>
//                     )}
//                     <AnalysisTool toolType="faq" title="FAQ Generator" iconName="HelpCircle" selectedDocumentFilename={currentSelectedDocFilename} />
//                     <AnalysisTool toolType="topics" title="Key Topics Extractor" iconName="Tags" selectedDocumentFilename={currentSelectedDocFilename} />
//                     <AnalysisTool toolType="mindmap" title="Mind Map Creator" iconName="GitFork" selectedDocumentFilename={currentSelectedDocFilename} />
//                 </motion.div>
//             )}
//         </div>
//     );
// }
// export default RightPanel;











// frontend/src/components/analysis/RightPanel.jsx
import React, { useState } from 'react';
import { useAppState } from '../../contexts/AppStateContext';
// FIX: Use the new, more capable AnalysisToolRunner component
import AnalysisToolRunner from './AnalysisToolRunner.jsx'; // FIX: Corrected relative import path
import { PanelRightClose, ChevronDown, ChevronUp, Telescope } from 'lucide-react';
import IconButton from '../core/IconButton.jsx';
import { motion } from 'framer-motion';

function RightPanel() {
    // FIX: Get selectedSubject to determine if the document is an admin document
    const { setIsRightPanelOpen, selectedDocumentForAnalysis, selectedSubject } = useAppState();
    const [isAnalyzerOpen, setIsAnalyzerOpen] = useState(true);

    // FIX: Logic corrected to handle filename string directly
    const currentSelectedDocFilename = selectedDocumentForAnalysis || null;
    // FIX: Add logic to determine if the selected document is a "Subject" (admin doc)
    const isTargetAdminSubject = !!(selectedSubject && currentSelectedDocFilename && selectedSubject === currentSelectedDocFilename);

    return (
        <div className="flex flex-col h-full p-3 sm:p-4 bg-surface-light dark:bg-surface-dark text-text-light dark:text-text-dark custom-scrollbar">
            <div className="flex items-center justify-between mb-4 pb-2 border-b border-border-light dark:border-border-dark">
                <h2 className="text-base font-semibold">Advanced Analyzer</h2>
                <IconButton
                    icon={PanelRightClose}
                    onClick={() => setIsRightPanelOpen(false)}
                    title="Close Analyzer Panel"
                    variant="ghost"
                    size="sm"
                    className="text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
                />
            </div>

            <button
                onClick={() => setIsAnalyzerOpen(!isAnalyzerOpen)}
                className="w-full flex items-center justify-between px-3 py-2.5 text-sm font-medium text-left bg-gray-50 dark:bg-gray-800 hover:bg-gray-100 dark:hover:bg-gray-700 rounded-md focus:outline-none shadow-sm border border-border-light dark:border-border-dark mb-3"
            >
                <span className="flex items-center gap-2"><Telescope size={16} /> Analysis Tools</span>
                {isAnalyzerOpen ? <ChevronUp size={18} /> : <ChevronDown size={18} />}
            </button>

            {isAnalyzerOpen && (
                <motion.div
                    initial={{ height: 0, opacity: 0 }}
                    animate={{ height: 'auto', opacity: 1 }}
                    exit={{ height: 0, opacity: 0 }}
                    transition={{ duration: 0.2, ease: "easeInOut" }}
                    className="flex-grow space-y-3 overflow-y-auto custom-scrollbar pr-1"
                >
                    {!currentSelectedDocFilename && (
                        <div className="p-4 text-xs text-center text-text-muted-light dark:text-text-muted-dark bg-gray-50 dark:bg-gray-800 rounded-md border border-dashed border-border-light dark:border-border-dark">
                            <p>Select a document from the left panel to enable analysis tools.</p>
                        </div>
                    )}
                    {/* FIX: Use AnalysisToolRunner and pass the isTargetAdminDoc prop */}
                    <AnalysisToolRunner toolType="faq" title="FAQ Generator" iconName="HelpCircle" selectedDocumentFilename={currentSelectedDocFilename} isTargetAdminDoc={isTargetAdminSubject} />
                    <AnalysisToolRunner toolType="topics" title="Key Topics Extractor" iconName="Tags" selectedDocumentFilename={currentSelectedDocFilename} isTargetAdminDoc={isTargetAdminSubject} />
                    <AnalysisToolRunner toolType="mindmap" title="Mind Map Creator" iconName="GitFork" selectedDocumentFilename={currentSelectedDocFilename} isTargetAdminDoc={isTargetAdminSubject} />
                </motion.div>
            )}
        </div>
    );
}
export default RightPanel;
```

`frontend/src/components/auth/AuthModal.jsx`

```javascript
// frontend/src/components/auth/AuthModal.jsx
import React, { useState, useEffect } from 'react';
import { useAuth } from '../../hooks/useAuth.jsx';
import { useAppState } from '../../contexts/AppStateContext.jsx';
import LLMSelection from './LLMSelection.jsx';
import toast from 'react-hot-toast';
import { LogIn, UserPlus, X, KeyRound, AtSign, AlertCircle, HardDrive } from 'lucide-react';
import Button from '../core/Button.jsx';
import IconButton from '../core/IconButton.jsx';
import { motion } from 'framer-motion';

function AuthModal({ isOpen, onClose }) {
    const { login, signup } = useAuth();
    const { setIsAdminSessionActive, switchLLM: setGlobalLLM, selectedLLM } = useAppState();

    const [isLoginView, setIsLoginView] = useState(true);
    const [email, setEmail] = useState('');
    const [password, setPassword] = useState('');
    const [localSelectedLLM, setLocalSelectedLLM] = useState('gemini');
    const [apiKey, setApiKey] = useState('');
    const [ollamaUrl, setOllamaUrl] = useState('');
    const [error, setError] = useState('');
    const [loading, setLoading] = useState(false);
    
    const emailRegex = /^\w+([.-]?\w+)*@\w+([.-]?\w+)*(\.\w{2,3})+$/;

    useEffect(() => {
        if (isOpen) {
            setError('');
            setEmail('');
            setPassword('');
            setApiKey('');
            setOllamaUrl('');
            setLocalSelectedLLM(selectedLLM || 'gemini');
        } else {
            setIsLoginView(true);
        }
    }, [isOpen, selectedLLM]);

    const handleSubmit = async (e) => {
        e.preventDefault();
        setError('');

        if (!emailRegex.test(email) && !(isLoginView && email === (process.env.VITE_ADMIN_USERNAME || 'admin@admin.com'))) {
            return setError("Please enter a valid email address.");
        }
        if (password.length < 6) {
            return setError("Password must be at least 6 characters long.");
        }
        if (!isLoginView && localSelectedLLM === 'gemini' && !apiKey.trim()) {
            return setError("Gemini API Key is required.");
        }
        if (!isLoginView && localSelectedLLM === 'ollama' && !ollamaUrl.trim()) {
            return setError("Ollama URL is required.");
        }
        
        setLoading(true);
        const toastId = toast.loading(isLoginView ? 'Logging in...' : 'Creating account...');

        try {
            if (isLoginView) {
                const authDataResponse = await login({ email, password });
                if (authDataResponse.isAdminLogin) {
                    toast.dismiss(toastId);
                    toast.success("Admin login successful!");
                    setIsAdminSessionActive(true); 
                    onClose({ isAdminLogin: true });
                } else {
                    toast.dismiss(toastId);
                    toast.success(authDataResponse.message || 'Login Successful!');
                    onClose(authDataResponse);
                }
            } else { // Signup logic
                const signupData = {
                    email, password,
                    preferredLlmProvider: localSelectedLLM,
                };
                if (localSelectedLLM === 'gemini') {
                    signupData.apiKey = apiKey;
                } else if (localSelectedLLM === 'ollama') {
                    signupData.ollamaUrl = ollamaUrl;
                }

                const authDataResponse = await signup(signupData);
                setGlobalLLM(localSelectedLLM);
                toast.dismiss(toastId);
                toast.success(authDataResponse.message || 'Signup Successful!');
                onClose(authDataResponse);
            }
        } catch (err) {
            toast.dismiss(toastId);
            const errorMessage = err.response?.data?.message || err.message || `An error occurred.`;
            setError(errorMessage);
        } finally {
            setLoading(false);
        }
    };

    const inputWrapperClass = "relative";
    const inputIconClass = "absolute left-3 top-1/2 -translate-y-1/2 h-5 w-5 text-text-muted-light dark:text-text-muted-dark";
    const inputFieldStyledClass = "input-field pl-10 py-2.5 text-sm w-full";

    return (
        <div className="fixed inset-0 bg-black/70 backdrop-blur-sm flex items-center justify-center z-50 p-4 animate-fadeIn">
            <motion.div 
                key="auth-modal-content"
                initial={{ opacity: 0, scale: 0.95, y: -10 }}
                animate={{ opacity: 1, scale: 1, y: 0 }}
                exit={{ opacity: 0, scale: 0.95, y: 10 }}
                className="card-base p-6 sm:p-8 w-full max-w-md"
            >
                <div className="flex justify-between items-center mb-4">
                    <h2 className="text-xl sm:text-2xl font-bold">{isLoginView ? 'Welcome Back' : 'Create Your Account'}</h2>
                    <IconButton icon={X} onClick={() => onClose(null)} variant="ghost" size="sm" title="Close" />
                </div>

                {error && (
                    <div className="mb-4 p-3 bg-red-500/10 border border-red-500/30 text-red-600 dark:text-red-300 rounded-md text-sm flex items-center gap-2">
                        <AlertCircle size={16}/>{error}
                    </div>
                )}

                <form onSubmit={handleSubmit} className="space-y-5">
                    <div className={inputWrapperClass}>
                        <AtSign className={inputIconClass} />
                        <input type="text" id="auth-email" className={inputFieldStyledClass} placeholder="Email Address" value={email} onChange={(e) => setEmail(e.target.value)} required disabled={loading} />
                    </div>
                    <div className={inputWrapperClass}>
                        <KeyRound className={inputIconClass} />
                        <input type="password" id="auth-password" className={inputFieldStyledClass} placeholder="Password (min. 6 characters)" value={password} onChange={(e) => setPassword(e.target.value)} required minLength="6" disabled={loading} />
                    </div>

                    {!isLoginView && (
                        <div className="space-y-4 pt-2 animate-fadeIn">
                            <LLMSelection selectedLLM={localSelectedLLM} onLlmChange={setLocalSelectedLLM} disabled={loading} />
                            
                            <div style={{ display: localSelectedLLM === 'gemini' ? 'block' : 'none' }}>
                                <motion.div key="gemini-input" initial={{ opacity: 0 }} animate={{ opacity: 1 }}>
                                    <label htmlFor="api-key-input" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark mb-1">Gemini API Key <span className="text-red-500">*</span></label>
                                    <div className={inputWrapperClass}>
                                        <KeyRound className={inputIconClass} />
                                        <input type="password" id="api-key-input" className={inputFieldStyledClass} placeholder="Enter your Gemini API Key" value={apiKey} onChange={(e) => setApiKey(e.target.value)} required={localSelectedLLM === 'gemini'} disabled={loading} />
                                    </div>
                                </motion.div>
                            </div>
                        
                            <div style={{ display: localSelectedLLM === 'ollama' ? 'block' : 'none' }}>
                                <motion.div key="ollama-input" initial={{ opacity: 0 }} animate={{ opacity: 1 }}>
                                    <label htmlFor="ollama-url-input" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark mb-1">Ollama URL <span className="text-red-500">*</span></label>
                                    <div className={inputWrapperClass}>
                                        <HardDrive className={inputIconClass} />
                                        <input type="text" id="ollama-url-input" className={inputFieldStyledClass} placeholder="e.g., http://localhost:11434" value={ollamaUrl} onChange={(e) => setOllamaUrl(e.target.value)} required={localSelectedLLM === 'ollama'} disabled={loading} />
                                    </div>
                                </motion.div>
                            </div>
                        </div>
                    )}

                    <Button type="submit" fullWidth isLoading={loading} leftIcon={isLoginView ? <LogIn size={18}/> : <UserPlus size={18}/>} className="py-2.5 !text-base">
                        {isLoginView ? 'Login' : 'Sign Up'}
                    </Button>
                </form>

                <p className="mt-6 text-center text-sm">
                    <button onClick={() => setIsLoginView(!isLoginView)} className="font-medium text-primary hover:underline" disabled={loading}>
                        {isLoginView ? "Don't have an account? Sign Up" : "Already have an account? Login"}
                    </button>
                </p>
            </motion.div>
        </div>
    );
}
export default AuthModal;
```

`frontend/src/components/auth/LLMSelection.jsx`

```javascript
// frontend/src/components/auth/LLMSelection.jsx
import React from 'react';
import { HardDrive, Cloud } from 'lucide-react';

function LLMSelection({ selectedLLM, onLlmChange, disabled = false }) {
    const llms = [
        { id: 'ollama', name: 'Ollama LLM', description: 'Local & Private. Requires Ollama running.', Icon: HardDrive },
        { id: 'gemini', name: 'Gemini LLM', description: 'Cloud-based by Google. API Key may be required.', Icon: Cloud },
    ];

    return (
        <div>
            <label className="block text-sm font-medium text-text-light dark:text-text-dark mb-2">
                Choose Your LLM Provider
            </label>
            <div className="grid grid-cols-1 sm:grid-cols-2 gap-3">
                {llms.map((llm) => {
                    const isSelected = selectedLLM === llm.id;
                    return (
                        <button
                            key={llm.id}
                            type="button"
                            onClick={() => onLlmChange(llm.id)}
                            disabled={disabled}
                            className={`p-4 border rounded-lg text-left transition-all duration-150 focus:outline-none group focus:ring-2 focus:ring-offset-2 dark:focus:ring-offset-surface-dark focus:ring-primary
                                ${isSelected 
                                    ? 'bg-primary dark:bg-primary border-primary dark:border-primary-dark ring-2 ring-primary dark:ring-primary-dark shadow-lg' 
                                    : 'bg-surface-light dark:bg-surface-dark border-border-light dark:border-border-dark hover:border-primary-light dark:hover:border-primary-dark hover:shadow-md'
                                }
                                ${disabled ? 'opacity-70 cursor-not-allowed' : ''}
                            `}
                        >
                            <div className="flex items-center mb-1">
                                <llm.Icon size={20} className={`mr-2 transition-colors 
                                    ${isSelected 
                                        ? 'text-white dark:text-blue-100' // High contrast for selected
                                        : 'text-text-muted-light dark:text-text-muted-dark group-hover:text-primary dark:group-hover:text-primary-light'}`} />
                                <span className={`font-semibold transition-colors 
                                    ${isSelected 
                                        ? 'text-white dark:text-white' // High contrast for selected
                                        : 'text-text-light dark:text-text-dark group-hover:text-primary dark:group-hover:text-primary-light'}`}>
                                    {llm.name}
                                </span>
                            </div>
                            <p className={`text-xs transition-colors 
                                ${isSelected 
                                    ? 'text-blue-100 dark:text-blue-200' // High contrast for selected
                                    : 'text-text-muted-light dark:text-text-muted-dark'}`}>
                                {llm.description}
                            </p>
                        </button>
                    );
                })}
            </div>
        </div>
    );
}

export default LLMSelection;
```

`frontend/src/components/chat/ChatHistory.jsx`

```javascript
import React, { useRef, useEffect } from 'react';
import MessageBubble from './MessageBubble';
import { motion, AnimatePresence } from 'framer-motion';

function ChatHistory({ messages, botStatusPlaceholder }) {
    const chatHistoryRef = useRef(null);

    useEffect(() => {
        if (chatHistoryRef.current) {
            chatHistoryRef.current.scrollTop = chatHistoryRef.current.scrollHeight;
        }
    }, [messages, botStatusPlaceholder]);

    return (
        <div ref={chatHistoryRef} className="flex-1 overflow-y-auto p-4 space-y-4 custom-scrollbar">
            <AnimatePresence initial={false}>
                {messages.map((msg, index) => (
                    <motion.div
                        key={msg.id || `msg-${index}-${msg.timestamp}`}
                        layout
                        initial={{ opacity: 0, y: 20 }}
                        animate={{ opacity: 1, y: 0 }}
                        exit={{ opacity: 0, y: -10, transition: { duration: 0.15 } }}
                        transition={{ duration: 0.3, ease: "easeOut" }}
                    >
                        <MessageBubble
                            id={msg.id || `msg-${index}-${msg.timestamp}`}
                            sender={msg.sender}
                            text={msg.text}
                            thinking={msg.thinking}
                            references={msg.references}
                            timestamp={msg.timestamp}
                            sourcePipeline={msg.source_pipeline}
                        />
                    </motion.div>
                ))}
            </AnimatePresence>

            {botStatusPlaceholder && (
                <motion.div 
                    layout
                    key="bot-status-placeholder"
                    initial={{ opacity: 0, y: 10 }}
                    animate={{ opacity: 1, y: 0 }}
                    transition={{ duration: 0.3 }}
                    className="flex justify-start pl-2 mt-2"
                >
                    <div className="max-w-[85%] bg-gray-100 dark:bg-gray-800 text-gray-800 dark:text-gray-100 px-4 py-2 rounded-xl shadow-md animate-pulse text-sm">
                        {botStatusPlaceholder}
                    </div>
                </motion.div>
            )}
        </div>
    );
}

export default ChatHistory;

```

`frontend/src/components/chat/ChatHistoryModal.jsx`

```javascript
// src/components/chat/ChatHistoryModal.jsx
import React, { useState, useEffect, useCallback } from 'react';
import api from '../../services/api';
import toast from 'react-hot-toast';
import { X, MessageSquareText, Loader2, AlertTriangle, Trash2 } from 'lucide-react';
import Modal from '../core/Modal.jsx';
import IconButton from '../core/IconButton.jsx';

const formatDate = (dateString) => {
    if (!dateString) return 'N/A';
    try {
        return new Date(dateString).toLocaleString(undefined, { 
            month: 'short', day: 'numeric', year: 'numeric', hour: '2-digit', minute: '2-digit' 
        });
    } catch (e) {
        return 'Invalid Date';
    }
};

function ChatHistoryModal({ isOpen, onClose, onSelectSession }) {
    const [sessions, setSessions] = useState([]);
    const [selectedSessionId, setSelectedSessionId] = useState(null);
    const [sessionMessages, setSessionMessages] = useState([]);
    const [loadingSessions, setLoadingSessions] = useState(false);
    const [loadingMessages, setLoadingMessages] = useState(false);
    const [error, setError] = useState('');

    const fetchSessions = useCallback(async () => {
        if (!isOpen) return; 
        setLoadingSessions(true);
        setError('');
        try {
            const data = await api.getChatSessions();
            setSessions(Array.isArray(data) ? data : []);
        } catch (err) {
            toast.error("Failed to load chat sessions.");
            setError(err.message || "Could not fetch sessions.");
        } finally {
            setLoadingSessions(false);
        }
    }, [isOpen]);

    useEffect(() => {
        if (isOpen) {
            fetchSessions();
            setSelectedSessionId(null); 
            setSessionMessages([]);
        }
    }, [isOpen, fetchSessions]); 

    const handleSessionSelectForPreview = async (sessionId) => {
        if (selectedSessionId === sessionId && sessionMessages.length > 0) return; 

        setSelectedSessionId(sessionId);
        setLoadingMessages(true);
        setSessionMessages([]);
        setError(''); 
        try {
            const sessionData = await api.getChatHistory(sessionId);
            
            // --- THIS IS THE CORRECTED LOGIC ---
            // We trust the API to send correctly formatted data with the 'sender' property.
            const messagesArray = Array.isArray(sessionData.messages) ? sessionData.messages : [];
            setSessionMessages(messagesArray);
            // --- END OF CORRECTION ---

        } catch (err) {
            toast.error("Failed to load messages for this session.");
            setError(`Error loading messages: ${err.message}`);
        } finally {
            setLoadingMessages(false);
        }
    };

    const handleLoadSessionAndClose = () => {
        if (selectedSessionId) {
            onSelectSession(selectedSessionId); 
            onClose();
        } else {
            toast.error("Please select a session to load.");
        }
    };
    
    const handleDeleteSession = async (sessionIdToDelete, e) => {
        e.stopPropagation();
        if (!window.confirm(`Are you sure you want to delete this session? This action cannot be undone.`)) return;
        
        const toastId = toast.loading(`Deleting session...`);
        try {
            await api.deleteChatSession(sessionIdToDelete);
            toast.success(`Session deleted.`, { id: toastId });
            setSessions(prev => prev.filter(s => s.sessionId !== sessionIdToDelete)); 
            if (selectedSessionId === sessionIdToDelete) {
                setSelectedSessionId(null);
                setSessionMessages([]);
            }
        } catch (err) {
            toast.error(`Delete failed: ${err.response?.data?.message || err.message}`, { id: toastId });
        }
    };

    return (
        <Modal isOpen={isOpen} onClose={onClose} title="Chat History" size="2xl">
            <div className="flex flex-col md:flex-row gap-4 max-h-[70vh] h-[70vh]">
                <div className="w-full md:w-1/3 border-r border-border-light dark:border-border-dark pr-0 md:pr-2 overflow-y-auto custom-scrollbar">
                    <h3 className="text-sm font-semibold mb-2 text-text-light dark:text-text-dark px-1">Your Sessions</h3>
                    {loadingSessions && <div className="flex justify-center p-4"><Loader2 className="animate-spin text-primary" size={24}/></div>}
                    {!loadingSessions && !sessions.length && <p className="text-xs text-text-muted-light dark:text-text-muted-dark p-2">No past sessions found.</p>}
                    <ul className="space-y-1">
                        {sessions.map(session => (
                            <li key={session.sessionId} onClick={() => handleSessionSelectForPreview(session.sessionId)}
                                className={`p-2.5 rounded-md cursor-pointer text-xs transition-colors group relative hover:shadow-md
                                            ${selectedSessionId === session.sessionId ? 'bg-primary text-white' : 'bg-surface-light dark:bg-gray-800 hover:bg-gray-100 dark:hover:bg-gray-700'}`} >
                                <div className="font-medium truncate" title={session.preview}>{session.preview || `Session ${session.sessionId.substring(0,8)}`}</div>
                                <div className={`text-[0.7rem] ${selectedSessionId === session.sessionId ? 'text-blue-200' : 'text-text-muted-light dark:text-text-muted-dark'}`}>
                                    {formatDate(session.updatedAt)} - {session.messageCount} msgs
                                </div>
                                <IconButton icon={Trash2} size="sm" variant="ghost" title="Delete session"
                                    className="absolute top-1 right-1 p-1 text-red-400 hover:text-red-600 opacity-0 group-hover:opacity-100"
                                    onClick={(e) => handleDeleteSession(session.sessionId, e)} />
                            </li>
                        ))}
                    </ul>
                </div>

                <div className="w-full md:w-2/3 flex flex-col overflow-hidden mt-4 md:mt-0">
                    <h3 className="text-sm font-semibold mb-2 text-text-light dark:text-text-dark">Preview</h3>
                    <div className="flex-grow bg-gray-50 dark:bg-gray-800/50 p-3 rounded-md overflow-y-auto custom-scrollbar border border-border-light dark:border-border-dark">
                        {loadingMessages && <div className="flex justify-center p-4"><Loader2 className="animate-spin text-primary" size={24} /></div>}
                        
                        <div className="space-y-3 flex flex-col">
                            {sessionMessages.map(msg => {
                                const isUser = msg.sender === 'user';
                                return (
                                    <div key={msg.id} className={`flex w-full ${isUser ? 'justify-end' : 'justify-start'}`}>
                                        <div className={`p-2.5 rounded-lg shadow-sm w-fit max-w-[90%] text-xs
                                            ${isUser 
                                                ? 'bg-blue-500 text-white' 
                                                : 'bg-gray-200 text-gray-800 dark:bg-gray-700 dark:text-gray-100'
                                            }`}>
                                            <p className="font-semibold text-[0.7rem] mb-0.5">{isUser ? 'You' : 'AI Tutor'}</p>
                                            <p className="whitespace-pre-wrap break-words">{msg.text}</p>
                                            <p className={`text-[0.65rem] mt-1 text-right ${isUser ? 'opacity-70' : 'opacity-50'}`}>{formatDate(msg.timestamp)}</p>
                                        </div>
                                    </div>
                                );
                            })}
                        </div>

                        {!loadingMessages && !selectedSessionId && (
                            <div className="flex flex-col items-center justify-center h-full text-text-muted-light dark:text-text-muted-dark text-sm">
                                <MessageSquareText size={40} className="mb-3 opacity-50" />
                                <p>Select a session to view its messages.</p>
                            </div>
                        )}
                    </div>
                </div>
            </div>
            <div className="mt-6 pt-4 border-t border-border-light dark:border-border-dark flex justify-end gap-3">
                <button onClick={onClose} className="btn-secondary !text-xs !py-1.5 !px-3">Cancel</button>
                <button onClick={handleLoadSessionAndClose} className="btn-primary !text-xs !py-1.5 !px-3" disabled={!selectedSessionId || loadingMessages || loadingSessions}>Load Session</button>
            </div>
        </Modal>
    );
}

export default ChatHistoryModal;
```

`frontend/src/components/chat/ChatInput.jsx`

```javascript


// frontend/src/components/chat/ChatInput.jsx
import React, { useState, useEffect, useRef } from 'react';
import { Send, Mic, Plus, Brain, Zap, Globe, BookMarked } from 'lucide-react'; // Ensure BookMarked is imported
import { useWebSpeech } from '../../hooks/useWebSpeech';
import Button from '../core/Button.jsx'; 
import IconButton from '../core/IconButton.jsx';
import toast from 'react-hot-toast';
import blueBrain from "./../../assets/blueBrain.svg";
import { motion, AnimatePresence } from 'framer-motion';

function ChatInput({ 
    onSendMessage, 
    isLoading,
    useWebSearch,
    setUseWebSearch,
    useAcademicSearch, // This prop is now used
    setUseAcademicSearch, // This prop is now used
    criticalThinkingEnabled,
    setCriticalThinkingEnabled
}) {
    const [inputValue, setInputValue] = useState('');
    const { transcript, listening, isSpeechSupported, startListening, stopListening, resetTranscript } = useWebSpeech();
    const textareaRef = useRef(null);
    const [isMenuOpen, setIsMenuOpen] = useState(false);
    const menuRef = useRef(null);

    useEffect(() => {
        if (transcript) {
            setInputValue(prev => prev + (prev ? " " : "") + transcript);
            resetTranscript(); 
        }
    }, [transcript, resetTranscript]);
    
    useEffect(() => {
        if (textareaRef.current) {
            textareaRef.current.style.height = 'auto';
            textareaRef.current.style.height = `${Math.min(textareaRef.current.scrollHeight, 128)}px`;
        }
    }, [inputValue]);

    useEffect(() => {
        function handleClickOutside(event) {
            if (menuRef.current && !menuRef.current.contains(event.target)) {
                setIsMenuOpen(false);
            }
        }
        document.addEventListener("mousedown", handleClickOutside);
        return () => document.removeEventListener("mousedown", handleClickOutside);
    }, [menuRef]);

    const handleSubmit = (e) => {
        e.preventDefault();
        if (inputValue.trim() && !isLoading) {
            onSendMessage(inputValue.trim());
            setInputValue('');
        }
    };

    const handleKeyDown = (e) => {
        if (e.key === 'Enter' && !e.shiftKey && !isLoading) {
            e.preventDefault();
            handleSubmit(e);
        }
    };
    
    const handleWebSearchToggle = () => {
        const newWebSearchState = !useWebSearch;
        setUseWebSearch(newWebSearchState);
        toast(newWebSearchState ? "Web Search enabled." : "Web Search disabled.", { icon: newWebSearchState ? "" : "" });
        setIsMenuOpen(false);
    };

    // Handler for the Academic Search Toggle
    const handleAcademicSearchToggle = () => {
        const newState = !useAcademicSearch;
        setUseAcademicSearch(newState);
        toast(newState ? "Academic Search enabled." : "Academic Search disabled.", { icon: newState ? "" : "" });
        setIsMenuOpen(false);
    };

    const icon = criticalThinkingEnabled ? () => <img src={blueBrain} alt="Blue Brain" className="w-5 h-5" /> : Brain;

    return (
        <div className="p-2 sm:p-3 bg-surface-light dark:bg-surface-dark/50 backdrop-blur-sm rounded-b-lg shadow-inner">
            <form onSubmit={handleSubmit} className="flex items-end gap-2">
                <div className="relative" ref={menuRef}>
                    <IconButton
                        icon={Plus}
                        title="More Options"
                        onClick={() => setIsMenuOpen(!isMenuOpen)}
                        variant="ghost"
                        size="md" 
                        className="p-2 text-text-muted-light dark:text-text-muted-dark hover:text-primary"
                        disabled={isLoading}
                    />
                    <AnimatePresence>
                    {isMenuOpen && (
                        <motion.div
                            initial={{ opacity: 0, y: 10, scale: 0.95 }}
                            animate={{ opacity: 1, y: 0, scale: 1 }}
                            exit={{ opacity: 0, y: 10, scale: 0.95 }}
                            className="absolute bottom-full left-0 mb-2 w-52 bg-surface-light dark:bg-surface-dark rounded-lg shadow-xl border border-border-light dark:border-border-dark p-1 z-10"
                        >
                            {/* Web Search Button */}
                            <button
                                onClick={handleWebSearchToggle}
                                className={`w-full text-left flex items-center gap-2 px-3 py-2 text-sm rounded-md transition-colors ${
                                    useWebSearch
                                    ? 'bg-primary/10 text-primary dark:bg-primary-dark/20 dark:text-primary-light'
                                    : 'text-text-light dark:text-text-dark hover:bg-gray-100 dark:hover:bg-gray-700'
                                }`}
                            >
                                <Globe size={16} />
                                {useWebSearch ? 'Disable Web Search' : 'Enable Web Search'}
                            </button>

                            {/* --- THIS IS THE BUTTON THAT WAS MISSING --- */}
                            <button
                                onClick={handleAcademicSearchToggle}
                                className={`w-full text-left flex items-center gap-2 px-3 py-2 text-sm rounded-md transition-colors ${
                                    useAcademicSearch
                                    ? 'bg-purple-500/10 text-purple-600 dark:bg-purple-400/20 dark:text-purple-300'
                                    : 'text-text-light dark:text-text-dark hover:bg-gray-100 dark:hover:bg-gray-700'
                                }`}
                            >
                                <BookMarked size={16} />
                                {useAcademicSearch ? 'Disable Academic Search' : 'Enable Academic Search'}
                            </button>
                             
                             <button
                                onClick={() => {toast("File attachment coming soon!", { icon: "" }); setIsMenuOpen(false);}}
                                className="w-full text-left flex items-center gap-2 px-3 py-2 text-sm rounded-md text-text-muted-light dark:text-text-muted-dark hover:bg-gray-100 dark:hover:bg-gray-700"
                            >
                                <Zap size={16} />
                                Attach File (soon)
                            </button>
                        </motion.div>
                    )}
                    </AnimatePresence>
                </div>

                <textarea
                    ref={textareaRef}
                    value={inputValue}
                    onChange={(e) => setInputValue(e.target.value)}
                    onKeyDown={handleKeyDown}
                    placeholder={isLoading ? "Waiting for response..." : "Type your message or ask a question..."}
                    className="input-field flex-1 p-2.5 resize-none min-h-[44px] max-h-32 custom-scrollbar text-sm" 
                    rows="1"
                    disabled={isLoading}
                />

                {isSpeechSupported && (
                    <IconButton
                        icon={Mic}
                        onClick={() => listening ? stopListening() : startListening()}
                        title={listening ? "Stop listening" : "Start voice input"}
                        variant={listening ? "danger" : "ghost"} 
                        size="md"
                        className={`p-2 ${listening ? 'text-red-500 animate-pulse' : 'text-text-muted-light dark:text-text-muted-dark hover:text-primary'}`}
                        disabled={isLoading}
                    />
                )}

               <IconButton
                    icon={icon}
                    onClick={() => setCriticalThinkingEnabled(!criticalThinkingEnabled)}
                    title={criticalThinkingEnabled ? "Disable Critical Thinking (KG)" : "Enable Critical Thinking (KG)"}
                    variant="ghost"
                    size="md"
                    className={`p-2 ${criticalThinkingEnabled ? 'text-purple-500' : 'text-text-muted-light dark:text-text-muted-dark hover:text-primary'}`}
                    disabled={isLoading}
                />

                <Button 
                    type="submit"
                    variant="primary"
                    size="md" 
                    className="!p-2.5" 
                    disabled={isLoading || !inputValue.trim()}
                    isLoading={isLoading && !!inputValue.trim()} 
                    title="Send message"
                >
                    {(!isLoading || !inputValue.trim()) ? <Send size={20} /> : null}
                </Button>
            </form>
            
            <div className="flex flex-col items-center justify-center mt-2 px-2 text-center h-4">
                <AnimatePresence>
                    {useWebSearch && (
                        <motion.p
                            initial={{ opacity: 0, y: -5 }} animate={{ opacity: 1, y: 0 }} exit={{ opacity: 0, y: -5 }}
                            className="text-xs text-blue-500 dark:text-blue-400 flex items-center gap-1.5 font-medium"
                        >
                            <Globe size={12} /> Web Search is ON
                        </motion.p>
                    )}
                    {useAcademicSearch && (
                        <motion.p
                            initial={{ opacity: 0, y: -5 }} animate={{ opacity: 1, y: 0 }} exit={{ opacity: 0, y: -5 }}
                            className="text-xs text-purple-500 dark:text-purple-400 flex items-center gap-1.5 font-medium"
                        >
                            <BookMarked size={12} /> Academic Search is ON
                        </motion.p>
                    )}
                </AnimatePresence>
            </div>
        </div>
    );
}
export default ChatInput;
```

`frontend/src/components/chat/MessageBubble.jsx`

```javascript
// src/components/chat/MessageBubble.jsx
import React, { useEffect, useRef, useState } from 'react';
import { marked } from 'marked';
import Prism from 'prismjs';
import { motion, AnimatePresence } from 'framer-motion';
import { ChevronDown, Link as LinkIcon, Zap, Server, Volume2, StopCircle, ServerCrash, Copy, Check } from 'lucide-react';
import ThinkingDropdown from './ThinkingDropdown.jsx';
import { useTextToSpeech } from '../../hooks/useTextToSpeech.js';
import IconButton from '../core/IconButton.jsx';
import { renderMathInHtml } from '../../utils/markdownUtils';
import { getPlainTextFromMarkdown } from '../../utils/helpers.js'; // <-- IMPORT THE NEW HELPER
import DOMPurify from 'dompurify';

marked.setOptions({
  breaks: true,
  gfm: true,
});

const createMarkup = (markdownText) => {
    if (!markdownText) return { __html: '' };
    let rawHtml = marked.parse(markdownText);
    rawHtml = renderMathInHtml(rawHtml);
    const cleanHtml = DOMPurify.sanitize(rawHtml, {
        USE_PROFILES: { html: true, mathMl: true, svg: true },
        ADD_TAGS: ['iframe'],
        ADD_ATTR: ['allow', 'allowfullscreen', 'frameborder', 'scrolling'],
    });
    return { __html: cleanHtml };
};

const escapeHtml = (unsafe) => {
    if (typeof unsafe !== 'string') return '';
    return unsafe
         .replace(/&/g, "&")
         .replace(/</g, "<")
         .replace(/>/g, ">")
         .replace(/"/g, `"`)
         .replace(/'/g, "'");
};

const parseMessageWithThinking = (rawText) => {
    if (!rawText || typeof rawText !== 'string') {
        return { thinking: null, mainContent: rawText || '' };
    }
    const thinkingMatch = rawText.match(/<thinking>([\s\S]*?)<\/thinking>/i);
    let thinking = null;
    let mainContent = rawText;

    if (thinkingMatch && thinkingMatch[1]) {
        thinking = thinkingMatch[1].trim();
        mainContent = rawText.replace(/<thinking>[\s\S]*?<\/thinking>\s*/i, '').trim();
    }

    return { thinking, mainContent };
};

function MessageBubble({ sender, text, references, timestamp, sourcePipeline }) {
    const isUser = sender === 'user';
    const { speak, cancel, isSpeaking: isCurrentlySpeakingThisBubble, isSupported: ttsIsSupported } = useTextToSpeech();
    const contentRef = useRef(null);
    const [isCopied, setIsCopied] = useState(false);
    
    const { thinking: thinkingContent, mainContent } = parseMessageWithThinking(text);

    useEffect(() => {
        const timer = setTimeout(() => {
            if (contentRef.current) {
                Prism.highlightAllUnder(contentRef.current);
            }
        }, 50);
        return () => clearTimeout(timer);
    }, [mainContent]);

    const handleCopy = () => {
        if (isCopied) return;
        // --- THIS IS THE FIX ---
        // Convert the raw markdown content to plain text before copying.
        const plainTextToCopy = getPlainTextFromMarkdown(mainContent);
        navigator.clipboard.writeText(plainTextToCopy).then(() => {
            setIsCopied(true);
            setTimeout(() => setIsCopied(false), 1000); // Revert icon after 1 second
        }).catch(err => {
            console.error('Failed to copy text: ', err);
        });
        // --- END OF FIX ---
    };

    const formatTimestamp = (ts) => {
        if (!ts) return '';
        try {
            return new Date(ts).toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' });
        } catch (e) { return 'Invalid Time'; }
    };

    const getPipelineIcon = () => {
        if (!sourcePipeline) return null;
        const lowerPipeline = sourcePipeline.toLowerCase();
        if (lowerPipeline.includes('ollama')) return <Zap size={12} className="text-green-400" title="Ollama Powered" />;
        if (lowerPipeline.includes('gemini')) return <Server size={12} className="text-blue-400" title="Gemini Powered" />;
        if (lowerPipeline.includes('rag')) return <Zap size={12} className="text-purple-400" title="RAG Enhanced" />;
        if (lowerPipeline.includes('error')) return <ServerCrash size={12} className="text-red-400" title="Error" />;
        return null;
    };

    const handleToggleSpeech = () => {
        if (!ttsIsSupported || !mainContent) return;
        if (isCurrentlySpeakingThisBubble) {
            cancel();
        } else {
            speak({ text: mainContent });
        }
    };
    
    return (
        <div className={`flex flex-col ${isUser ? 'items-end' : 'items-start'} w-full group`}>
            
            {!isUser && thinkingContent && (
                <div className="max-w-[85%] md:max-w-[75%] w-full mb-1">
                    <ThinkingDropdown>
                        <pre className="text-xs text-text-muted-light dark:text-text-muted-dark whitespace-pre-wrap font-sans leading-relaxed">
                           {thinkingContent}
                        </pre>
                    </ThinkingDropdown>
                </div>
            )}
            
            <div 
                className={`message-bubble relative max-w-[85%] md:max-w-[75%] p-3 rounded-2xl shadow-md break-words ${
                    isUser 
                    ? 'bg-surface-light text-text-light border border-border-light dark:bg-primary-dark dark:text-white dark:border-transparent rounded-br-lg' 
                    : 'bg-surface-light dark:bg-surface-dark text-text-light dark:text-text-dark rounded-bl-lg border border-border-light dark:border-border-dark'
                }`}
            >
                <div 
                    ref={contentRef}
                    className="prose prose-sm dark:prose-invert max-w-none message-content leading-relaxed" 
                    dangerouslySetInnerHTML={createMarkup(mainContent || '')} 
                />
                
                <div className="flex items-center justify-end mt-1.5 text-xs gap-1">
                     <button
                        onClick={handleCopy}
                        title={isCopied ? 'Copied!' : 'Copy content'}
                        disabled={isCopied}
                        className="p-1 rounded-md text-text-muted-light dark:text-text-muted-dark hover:bg-gray-200 dark:hover:bg-gray-700 opacity-0 group-hover:opacity-100 transition-all duration-200 focus:outline-none"
                    >
                        <AnimatePresence mode="wait" initial={false}>
                            <motion.div
                                key={isCopied ? 'check' : 'copy'}
                                initial={{ scale: 0.6, opacity: 0, rotate: -30 }}
                                animate={{ scale: 1, opacity: 1, rotate: 0 }}
                                exit={{ scale: 0.6, opacity: 0, rotate: 30 }}
                                transition={{ duration: 0.15 }}
                            >
                                {isCopied ? (
                                    <Check size={16} className="text-green-500" />
                                ) : (
                                    <Copy size={16} />
                                )}
                            </motion.div>
                        </AnimatePresence>
                    </button>
                    <div className="flex items-center gap-2 pl-1 opacity-70">
                        {!isUser && getPipelineIcon() && <span className="mr-1">{getPipelineIcon()}</span>}
                        <span>{formatTimestamp(timestamp)}</span>
                        {!isUser && ttsIsSupported && mainContent && (
                            <IconButton
                                icon={isCurrentlySpeakingThisBubble ? StopCircle : Volume2}
                                onClick={handleToggleSpeech}
                                title={isCurrentlySpeakingThisBubble ? "Stop reading" : "Read aloud"}
                                size="sm"
                                variant="ghost"
                                className={`p-0.5 ${isCurrentlySpeakingThisBubble ? 'text-red-500' : 'text-text-muted-light dark:text-text-muted-dark hover:text-primary'}`}
                            />
                        )}
                    </div>
                </div>
            </div>

            {!isUser && references && references.length > 0 && (
                <div className="message-metadata-container max-w-[85%] md:max-w-[75%] mt-1.5 pl-2 space-y-1 opacity-0 group-hover:opacity-100 transition-opacity duration-200">
                    <details className="group/details text-xs" open>
                        <summary className="flex items-center gap-1 cursor-pointer text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light transition-colors">
                            <LinkIcon size={14} /> References
                            <ChevronDown size={14} className="group-open/details:rotate-180 transition-transform" />
                        </summary>
                        <ul className="mt-1 pl-1 space-y-0.5 text-[0.7rem]">
                            {references.map((ref, index) => (
                                <li 
                                    key={index} 
                                    className="text-text-muted-light dark:text-text-muted-dark hover:text-text-light dark:hover:text-text-dark transition-colors truncate"
                                    title={`Preview: ${escapeHtml(ref.content_preview || '')}\nSource: ${escapeHtml(ref.source || '')}`}
                                >
                                    <span className="font-semibold text-accent">[{ref.number}]</span> {escapeHtml(ref.source)}
                                </li>
                            ))}
                        </ul>
                    </details>
                </div>
            )}
        </div>
    );
}
export default MessageBubble;
```

`frontend/src/components/chat/ThinkingDropdown.jsx`

```javascript
// frontend/src/components/chat/ThinkingDropdown.jsx
import React, { useState } from 'react';
import { ChevronDown, BrainCircuit } from 'lucide-react';
import { motion, AnimatePresence } from 'framer-motion';

function ThinkingDropdown({ children }) {
    const [isOpen, setIsOpen] = useState(false);

    return (
        <div className="w-full">
            <button
                onClick={() => setIsOpen(!isOpen)}
                className="inline-flex items-center gap-1.5 text-xs font-medium text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light transition-colors py-1"
                aria-expanded={isOpen}
            >
                <BrainCircuit size={14} />
                <span>Thinking Process</span>
                <ChevronDown size={16} className={`transition-transform duration-200 ${isOpen ? 'rotate-180' : ''}`} />
            </button>
            <AnimatePresence initial={false}>
                {isOpen && (
                    <motion.div
                        key="content"
                        initial="collapsed"
                        animate="open"
                        exit="collapsed"
                        variants={{
                            open: { opacity: 1, height: 'auto', marginTop: '0.25rem' },
                            collapsed: { opacity: 0, height: 0, marginTop: '0' }
                        }}
                        transition={{ duration: 0.3, ease: 'easeInOut' }}
                        className="overflow-hidden"
                    >
                        {/* The vertical line and padding for the content */}
                        <div className="pl-4 border-l-2 border-gray-300 dark:border-gray-600">
                            {children}
                        </div>
                    </motion.div>
                )}
            </AnimatePresence>
        </div>
    );
}

export default ThinkingDropdown;
```

`frontend/src/components/common/ThemeToggle.jsx`

```javascript
import React from 'react';
import { Sun, Moon } from 'lucide-react';
import { useTheme } from '../../hooks/useTheme';

function ThemeToggle() {
    const { theme, toggleTheme } = useTheme();

    return (
        <button
            onClick={toggleTheme}
            className="p-2 rounded-full text-text-muted-light dark:text-text-muted-dark hover:bg-gray-200 dark:hover:bg-gray-700 transition-colors focus:outline-none focus:ring-2 focus:ring-primary"
            aria-label={theme === 'light' ? 'Switch to dark theme' : 'Switch to light theme'}
        >
            {theme === 'light' ? <Moon size={20} /> : <Sun size={20} />}
        </button>
    );
}

export default ThemeToggle;
```

`frontend/src/components/core/Button.jsx`

```javascript
// src/components/core/Button.jsx
import React from 'react';
import { Loader2 } from 'lucide-react'; // For loading spinner

const Button = ({
    children,
    onClick,
    type = 'button',
    variant = 'primary', // 'primary', 'secondary', 'danger', 'outline', 'ghost'
    size = 'md', // 'sm', 'md', 'lg'
    leftIcon,
    rightIcon,
    isLoading = false,
    disabled = false,
    fullWidth = false,
    className = '',
    ...props
}) => {
    const baseStyles = "font-semibold rounded-lg focus:outline-none focus:ring-2 focus:ring-opacity-75 transition-all duration-150 ease-in-out flex items-center justify-center gap-2";

    const variantStyles = {
        primary: "bg-primary hover:bg-primary-dark text-white focus:ring-primary",
        secondary: "bg-secondary hover:bg-secondary-dark text-white focus:ring-secondary",
        danger: "bg-red-500 hover:bg-red-600 text-white focus:ring-red-500",
        outline: "border border-primary text-primary hover:bg-primary-light dark:hover:bg-opacity-10 focus:ring-primary",
        ghost: "text-primary hover:bg-primary-light dark:hover:bg-opacity-10 focus:ring-primary",
    };

    const sizeStyles = {
        sm: "px-3 py-1.5 text-xs",
        md: "px-4 py-2 text-sm",
        lg: "px-6 py-3 text-base",
    };

    const widthStyle = fullWidth ? "w-full" : "";
    const isDisabled = disabled || isLoading;
    const finalDisabledStyle = isDisabled ? "opacity-60 cursor-not-allowed" : "cursor-pointer";

    const spinnerSize = size === 'sm' ? 14 : (size === 'lg' ? 20 : 16);
    
    return (
        <button
            type={type}
            onClick={onClick}
            disabled={isDisabled} // Use the corrected variable
            className={`${baseStyles} ${variantStyles[variant]} ${sizeStyles[size]} ${widthStyle} ${finalDisabledStyle} ${className}`}
            {...props}
        >
            {isLoading && (
                <Loader2 size={spinnerSize} className="animate-spin" />
            )}
            {!isLoading && leftIcon && <span className="icon-left">{leftIcon}</span>}

            <span className={isLoading ? 'ml-2' : ''}>{children}</span>

            {!isLoading && rightIcon && <span className="icon-right">{rightIcon}</span>}
        </button>
    );
};

export default Button;
```

`frontend/src/components/core/IconButton.jsx`

```javascript
import React from 'react';
import { Loader2 } from 'lucide-react';

const IconButton = ({
    icon: Icon, // Pass the Lucide icon component directly
    onClick,
    variant = 'ghost', // 'ghost', 'outline', 'subtle'
    size = 'md', // 'sm', 'md', 'lg'
    isLoading = false,
    disabled = false,
    className = '',
    title, // For accessibility and tooltips
    ariaLabel,
    ...props
}) => {
    const baseStyles = "rounded-md focus:outline-none focus:ring-2 focus:ring-opacity-75 transition-colors duration-150 flex items-center justify-center";

    const variantStyles = {
        ghost: "text-text-muted-light dark:text-text-muted-dark hover:bg-gray-200 dark:hover:bg-gray-700 focus:ring-primary",
        outline: "border border-gray-300 dark:border-gray-600 text-text-muted-light dark:text-text-muted-dark hover:border-primary hover:text-primary focus:ring-primary",
        subtle: "bg-gray-100 dark:bg-gray-700 text-text-light dark:text-text-dark hover:bg-gray-200 dark:hover:bg-gray-600 focus:ring-primary",
        danger: "text-red-500 hover:bg-red-100 dark:hover:bg-red-900 focus:ring-red-500"
    };

    const sizeStyles = {
        sm: "p-1.5", // Icon size typically 14-16px
        md: "p-2",   // Icon size typically 18-20px
        lg: "p-2.5", // Icon size typically 22-24px
    };
    
    const iconSizeMap = {
        sm: 16,
        md: 20,
        lg: 24,
    };

    const disabledStyle = (disabled || isLoading) ? "opacity-50 cursor-not-allowed" : "cursor-pointer";

    return (
        <button
            type="button"
            onClick={onClick}
            disabled={disabled || isLoading}
            className={`${baseStyles} ${variantStyles[variant]} ${sizeStyles[size]} ${disabledStyle} ${className}`}
            title={title}
            aria-label={ariaLabel || title}
            {...props}
        >
            {isLoading ? (
                <Loader2 size={iconSizeMap[size]} className="animate-spin" />
            ) : (
                Icon && <Icon size={iconSizeMap[size]} />
            )}
        </button>
    );
};

export default IconButton;
```

`frontend/src/components/core/Modal.jsx`

```javascript
// src/components/core/Modal.jsx
import React, { useEffect, useRef } from 'react';
import { X } from 'lucide-react';
import { motion, AnimatePresence } from 'framer-motion';

const Modal = ({
    isOpen,
    onClose,
    title,
    children,
    footerContent,
    size = 'md', // 'sm', 'md', 'lg', 'xl', '2xl', '3xl', '4xl', '5xl', 'full'
    closeOnOverlayClick = true,
    initialFocusRef, // Optional ref for focusing an element inside the modal on open
}) => {
    const modalRef = useRef(null);

    // Handle Escape key for closing
    useEffect(() => {
        const handleEscapeKey = (event) => {
            if (event.key === 'Escape' && isOpen) {
                onClose();
            }
        };
        if (isOpen) {
            document.addEventListener('keydown', handleEscapeKey);
        }
        return () => {
            document.removeEventListener('keydown', handleEscapeKey);
        };
    }, [isOpen, onClose]);

    // Handle focus trapping and initial focus
    useEffect(() => {
        if (isOpen) {
            // Set focus to the initialFocusRef or the modal itself
            if (initialFocusRef && initialFocusRef.current) {
                initialFocusRef.current.focus();
            } else if (modalRef.current) {
                modalRef.current.focus(); // Fallback to modal itself
            }

            // Basic focus trapping (can be made more robust with a library)
            const focusableElements = modalRef.current?.querySelectorAll(
                'button, [href], input, select, textarea, [tabindex]:not([tabindex="-1"])'
            );
            if (focusableElements && focusableElements.length > 0) {
                const firstElement = focusableElements[0];
                const lastElement = focusableElements[focusableElements.length - 1];

                const onKeyDown = (e) => {
                    if (e.key === 'Tab') {
                        if (e.shiftKey) { // Shift + Tab
                            if (document.activeElement === firstElement) {
                                lastElement.focus();
                                e.preventDefault();
                            }
                        } else { // Tab
                            if (document.activeElement === lastElement) {
                                firstElement.focus();
                                e.preventDefault();
                            }
                        }
                    }
                };
                modalRef.current?.addEventListener('keydown', onKeyDown);
                return () => modalRef.current?.removeEventListener('keydown', onKeyDown);
            }
        }
    }, [isOpen, initialFocusRef]);


    const sizeClasses = {
        sm: 'max-w-sm',
        md: 'max-w-md',
        lg: 'max-w-lg',
        xl: 'max-w-xl',
        '2xl': 'max-w-2xl',
        '3xl': 'max-w-3xl',
        '4xl': 'max-w-4xl',
        '5xl': 'max-w-5xl',
        full: 'max-w-full h-full rounded-none sm:rounded-lg sm:max-h-[95vh]', // Special case for full screen like
    };

    const backdropVariants = {
        visible: { opacity: 1, transition: { duration: 0.2, ease: "easeOut" } },
        hidden: { opacity: 0, transition: { duration: 0.15, ease: "easeIn" } },
    };

    const modalVariants = {
        hidden: { y: "-30px", opacity: 0, scale: 0.98, transition: { duration: 0.15, ease: "easeIn" } },
        visible: { y: "0", opacity: 1, scale: 1, transition: { type: "spring", stiffness: 400, damping: 30, duration: 0.3 } },
        exit: { y: "30px", opacity: 0, scale: 0.98, transition: { duration: 0.2, ease: "easeIn" } }
    };

    if (!isOpen) return null;

    return (
        <AnimatePresence mode="wait">
            {isOpen && (
                <motion.div
                    key="modal-backdrop"
                    className="fixed inset-0 z-50 flex items-center justify-center p-4 bg-black/70 dark:bg-black/80 backdrop-blur-sm"
                    initial="hidden"
                    animate="visible"
                    exit="hidden"
                    variants={backdropVariants}
                    onClick={closeOnOverlayClick ? onClose : undefined}
                    aria-labelledby="modal-title" // For screen readers
                    role="dialog" // Role for the backdrop itself, more specific roles on content
                    aria-modal="true" // Indicate it's a modal overlaying other content
                >
                    <motion.div
                        key="modal-content-wrapper" // Changed key for potential AnimatePresence behavior
                        ref={modalRef}
                        tabIndex={-1} // Make the modal itself focusable for fallback
                        className={`bg-surface-light dark:bg-surface-dark rounded-lg shadow-xl w-full ${sizeClasses[size]} flex flex-col overflow-hidden
                                    ${size === 'full' ? '' : 'max-h-[90vh] sm:max-h-[85vh]'}`} 
                                    // Apply max-h unless it's 'full' size
                        role="document" // The actual dialog content
                        aria-modal="true"
                        aria-labelledby={title ? "modal-title-text" : undefined} // Point to title if exists
                        initial="hidden"
                        animate="visible"
                        exit="exit"
                        variants={modalVariants}
                        onClick={(e) => e.stopPropagation()} // Prevent closing when clicking inside modal
                    >
                        {/* Modal Header */}
                        <div className="flex items-center justify-between px-5 py-3.5 border-b border-border-light dark:border-border-dark sticky top-0 bg-surface-light dark:bg-surface-dark z-10 flex-shrink-0">
                            {title && (
                                <h2 id="modal-title-text" className="text-lg font-semibold text-text-light dark:text-text-dark truncate pr-4">
                                    {title}
                                </h2>
                            )}
                            <button
                                onClick={onClose}
                                className="p-1.5 rounded-full text-text-muted-light dark:text-text-muted-dark 
                                           hover:bg-gray-200/80 dark:hover:bg-gray-700/80 
                                           hover:text-red-500 dark:hover:text-red-400 
                                           focus:outline-none focus:ring-2 focus:ring-primary dark:focus:ring-primary-light focus:ring-offset-1 dark:focus:ring-offset-surface-dark"
                                aria-label="Close modal"
                            >
                                <X size={20} />
                            </button>
                        </div>

                        {/* Modal Body */}
                        <div className="px-5 py-4 overflow-y-auto flex-grow custom-scrollbar">
                            {children}
                        </div>

                        {/* Modal Footer */}
                        {footerContent && (
                            <div className="px-5 py-3.5 border-t border-border-light dark:border-border-dark flex justify-end gap-3 sticky bottom-0 bg-surface-light dark:bg-surface-dark z-10 flex-shrink-0">
                                {footerContent}
                            </div>
                        )}
                    </motion.div>
                </motion.div>
            )}
        </AnimatePresence>
    );
};

export default Modal;
```

`frontend/src/components/documents/DocumentList.jsx`

```javascript


// frontend/src/components/documents/DocumentList.jsx
import React, { useState, useEffect, useCallback } from 'react';
import api from '../../services/api.js'; // Mocked for V1
import toast from 'react-hot-toast';
import { FileText, Edit3, Trash2, Loader2, AlertTriangle, CheckCircle } from 'lucide-react';
import IconButton from '../core/IconButton.jsx'; // Make sure IconButton is imported
import { useAuth } from '../../hooks/useAuth.jsx';

// Props from LeftPanel: onSelectDocument is selectDocumentForAnalysis from AppStateContext
// selectedDocument is selectedDocumentForAnalysis from AppStateContext
function DocumentList({ onSelectDocument, selectedDocument }) {
  const [files, setFiles] = useState([]);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState('');

  const fetchFiles = useCallback(async () => {
    setLoading(true);
    setError('');
    try {
      
      const response = await api.getFiles(); // Returns { filenames: ["A.txt", "B.pdf"] }
      const filenames = Array.isArray(response.filenames) ? response.filenames : [];
      setFiles(filenames);
      
    } catch (err) {
      console.error("Failed to fetch files:", err);
      setError(err.message || "Failed to fetch files.");
      toast.error("Could not load documents.");
    } finally {
      setLoading(false);
    }
  }, []);



  useEffect(() => {
    fetchFiles();
  }, [fetchFiles]);

  const handleDelete = async (filename) => {
    if (!window.confirm(`Are you sure you want to delete "${filename}"?`)) return;
    const toastId = toast.loading(`Deleting ${filename}...`);
    try {
      await api.deleteFile(filename); // Assumes this works with filename
      toast.success(`${filename} deleted.`, { id: toastId });
      fetchFiles();
      if (selectedDocument === filename) {
        onSelectDocument(null);
      }
    } catch (err) {
      toast.error(`Delete failed: ${err.message}`, { id: toastId });
    }
  };

  if (loading) {
    return (
      <div className="flex items-center justify-center p-4 text-text-muted-light dark:text-text-muted-dark">
        <Loader2 size={20} className="animate-spin mr-2" /> Loading documents...
      </div>
    );
  }

  if (error) {
    return (
      <div className="p-3 bg-red-500/10 border border-red-500/30 text-red-600 dark:text-red-300 rounded-md text-sm flex items-center gap-2">
        <AlertTriangle size={18} /> {error}
        <button onClick={fetchFiles} className="ml-auto text-xs underline hover:text-red-400">Retry</button>
      </div>
    );
  }

  if (files.length === 0) {
    return <p className="text-center text-xs text-text-muted-light dark:text-text-muted-dark p-4">No documents uploaded.</p>;
  }

  return (
    <div className="space-y-1.5 text-xs custom-scrollbar pr-1">
      {files.map(filename => {
        const isSelected = selectedDocument === filename;

        return (
          <div
            key={filename}
            onClick={() => onSelectDocument(isSelected ? null : filename)}
            className={`p-2.5 bg-surface-light dark:bg-gray-800 border rounded-md flex items-center justify-between hover:shadow-md transition-all duration-150 cursor-pointer
                        ${isSelected
                          ? 'ring-2 ring-primary dark:ring-primary-light shadow-lg border-primary dark:border-primary-light'
                          : 'border-border-light dark:border-border-dark hover:border-gray-400 dark:hover:border-gray-500'}`}
            title={`Select ${filename}`}
          >
            <div className="flex items-center gap-2 truncate">
              {isSelected ? (
                <CheckCircle size={16} className="text-green-500 flex-shrink-0" />
              ) : (
                <FileText size={16} className="text-primary dark:text-primary-light flex-shrink-0" />
              )}
              <span className={`truncate ${isSelected ? 'font-semibold text-primary dark:text-primary-light' : 'text-text-light dark:text-text-dark'}`}>
                {filename}
              </span>
            </div>
            <div className="flex-shrink-0 flex items-center gap-0.5">
              <IconButton
                icon={Trash2}
                size="sm"
                variant="ghost"
                title="Delete"
                onClick={(e) => {
                  e.stopPropagation();
                  handleDelete(filename);
                }}
                className="text-red-500 hover:text-red-700 dark:text-red-400 dark:hover:text-red-300 p-1"
              />
            </div>
          </div>
        );
      })}
    </div>
  );
}


export default DocumentList;
```

`frontend/src/components/documents/DocumentUpload.jsx`

```javascript
// frontend/src/components/documents/DocumentUpload.jsx
import React, { useState, useRef, useEffect } from 'react';
import api from '../../services/api.js';
import toast from 'react-hot-toast';
import { UploadCloud, FileText, XCircle, Paperclip } from 'lucide-react';
import Button from '../core/Button.jsx';
import { motion } from 'framer-motion';

// Define the stages for our static simulation
const RAG_STAGES = [
    { name: "Uploading", duration: 1500, message: "Transferring your document to the server..." },
    { name: "Processing", duration: 2000, message: "Validating file format and structure..." },
    { name: "Extracting", duration: 3000, message: "Extracting text and content from your document..." },
    { name: "Chunking", duration: 1500, message: "Breaking document into manageable segments..." },
    { name: "Embedding", duration: 4000, message: "Converting content to searchable vectors..." },
    { name: "Analyzing", duration: 3000, message: "Indexing content for optimal retrieval..." },
];

function DocumentUpload({ onUploadSuccess }) {
    const [selectedFile, setSelectedFile] = useState(null);
    const [isProcessing, setIsProcessing] = useState(false);
    const [progress, setProgress] = useState(0);
    const [currentStage, setCurrentStage] = useState('');
    const [stageMessage, setStageMessage] = useState('');
    const [errorMessage, setErrorMessage] = useState('');
    const [dragActive, setDragActive] = useState(false);

    const fileInputRef = useRef(null);
    const processingTimeoutRef = useRef(null);
    
    useEffect(() => {
        return () => {
            if (processingTimeoutRef.current) {
                clearTimeout(processingTimeoutRef.current);
            }
        };
    }, []);

    const handleFileChange = (e) => {
        if (isProcessing) return;
        const file = e.target.files && e.target.files[0];
        if (file) {
            setSelectedFile(file);
            setErrorMessage('');
        }
    };

    const handleDrag = (e) => { e.preventDefault(); e.stopPropagation(); if (isProcessing) return; setDragActive(e.type === "dragenter" || e.type === "dragover"); };
    const handleDrop = (e) => { e.preventDefault(); e.stopPropagation(); if (isProcessing) return; setDragActive(false); const file = e.dataTransfer.files && e.dataTransfer.files[0]; if (file) { setSelectedFile(file); setErrorMessage(''); }};

    const resetState = () => {
        setSelectedFile(null);
        setIsProcessing(false);
        setProgress(0);
        setCurrentStage('');
        setStageMessage('');
        setErrorMessage('');
        if (fileInputRef.current) fileInputRef.current.value = null;
    };
    
    const runProgressSimulation = (stageIndex = 0) => {
        if (stageIndex >= RAG_STAGES.length) return;

        const stage = RAG_STAGES[stageIndex];
        setCurrentStage(stage.name);
        setStageMessage(stage.message);
        
        const totalDuration = RAG_STAGES.reduce((acc, s) => acc + s.duration, 0);
        const elapsedDuration = RAG_STAGES.slice(0, stageIndex).reduce((acc, s) => acc + s.duration, 0);
        setProgress(Math.round((elapsedDuration / totalDuration) * 100));

        processingTimeoutRef.current = setTimeout(() => {
            runProgressSimulation(stageIndex + 1);
        }, stage.duration);
    };

    const handleUpload = async () => {
        if (!selectedFile) {
            toast.error("Please select a file first.");
            return;
        }

        setIsProcessing(true);
        setErrorMessage('');
        runProgressSimulation(0);

        const formData = new FormData();
        formData.append("file", selectedFile);
        
        try {
            await api.uploadFile(formData);

            if (processingTimeoutRef.current) clearTimeout(processingTimeoutRef.current);
            setCurrentStage("Ready");
            setStageMessage("Document successfully processed and ready to use!");
            setProgress(100);
            toast.success(`'${selectedFile.name}' processed successfully!`);
            
            setTimeout(() => {
                resetState();
                if (onUploadSuccess) onUploadSuccess();
            }, 2500);

        } catch (error) {
            if (processingTimeoutRef.current) clearTimeout(processingTimeoutRef.current);
            const msg = error.response?.data?.message || error.message || "Upload failed.";
            setErrorMessage(msg);
            toast.error(`Upload failed: ${msg}`);
            setIsProcessing(false);
            setCurrentStage('Failed');
            setProgress(100);
        }
    };

    if (isProcessing) {
        return (
            <div className="card-base p-4 mb-4">
                <h3 className="font-semibold text-text-light dark:text-text-dark">
                     Processing: <span className="font-normal truncate">{selectedFile.name}</span>
                </h3>
                <div className="relative w-full bg-gray-200 dark:bg-gray-700 rounded-full h-2.5 my-2">
                    <motion.div
                        className={`h-2.5 rounded-full ${errorMessage ? 'bg-red-500' : 'bg-primary'}`}
                        initial={{ width: '0%' }}
                        animate={{ width: `${progress}%` }}
                        transition={{ duration: 0.5, ease: 'linear' }}
                    />
                </div>
                <div className="flex justify-between text-xs text-text-muted-light dark:text-text-muted-dark">
                    <span>{errorMessage ? 'Error' : `Stage: ${currentStage}`} ({progress}%)</span>
                </div>
                <p className="text-xs text-center mt-2 h-4">{errorMessage || stageMessage}</p>
                {errorMessage && (
                    <Button onClick={resetState} fullWidth variant="danger" size="sm" className="mt-3">
                        Close
                    </Button>
                )}
            </div>
        );
    }
    
    return (
        <div className="mb-4 p-1">
            <label
                htmlFor="file-upload-input"
                onDragEnter={handleDrag} onDragLeave={handleDrag} onDragOver={handleDrag} onDrop={handleDrop}
                className={`flex flex-col items-center justify-center w-full h-36 px-4 transition-colors duration-200 ease-in-out bg-surface-light dark:bg-gray-800 border-2 border-dashed rounded-lg cursor-pointer border-border-light dark:border-border-dark hover:border-primary dark:hover:border-primary-light ${dragActive ? "border-primary dark:border-primary-light ring-2 ring-primary dark:ring-primary-light bg-primary/10 dark:bg-primary-dark/20" : ""}`}
            >
                <div className="flex flex-col items-center justify-center text-center">
                    <Paperclip size={36} className={`mb-2 transition-colors ${dragActive ? 'text-primary dark:text-primary-light' : 'text-text-muted-light dark:text-text-muted-dark'}`} />
                    <p className="mb-1 text-sm text-text-muted-light dark:text-text-muted-dark">
                        <span className="font-semibold text-primary dark:text-primary-light">Click to upload</span> or drag and drop
                    </p>
                    <p className="text-xs text-text-muted-light dark:text-text-muted-dark">PDF, DOCX, TXT, PPTX, code files</p>
                </div>
                <input ref={fileInputRef} id="file-upload-input" type="file" className="hidden" onChange={handleFileChange}
                       accept=".pdf,.doc,.docx,.ppt,.pptx,.txt,.py,.js,.md,.html,.xml,.json,.csv,.log,.c,.cpp,.java" />
            </label>

            {selectedFile && (
                <div className="mt-2 p-2 bg-gray-100 dark:bg-gray-700 rounded-md flex items-center justify-between text-sm animate-fadeIn">
                    <div className="flex items-center gap-2 truncate">
                        <FileText size={18} className="text-primary flex-shrink-0" />
                        <span className="truncate text-text-light dark:text-text-dark" title={selectedFile.name}>{selectedFile.name}</span>
                        <span className="text-text-muted-light dark:text-text-muted-dark text-xs whitespace-nowrap">
                            ({(selectedFile.size / 1024).toFixed(1)} KB)
                        </span>
                    </div>
                    <button onClick={() => setSelectedFile(null)} className="text-red-500 hover:text-red-700 dark:hover:text-red-400 transition-colors p-1 rounded-full hover:bg-red-500/10">
                        <XCircle size={18} />
                    </button>
                </div>
            )}

            <Button
                onClick={handleUpload}
                fullWidth
                className="mt-3 text-sm min-h-[38px]"
                variant="primary"
                disabled={!selectedFile}
                leftIcon={<UploadCloud size={16} />}
            >
                Upload Document
            </Button>
        </div>
    );
}

export default DocumentUpload;
```

`frontend/src/components/documents/SubjectList.jsx`

```javascript
// frontend/src/components/documents/SubjectList.jsx
import React from 'react';
import { Library, CheckCircle, Loader2, AlertTriangle } from 'lucide-react'; // Added AlertTriangle

function SubjectList({
    subjects,           // Array of subject name strings
    selectedSubject,    // Currently selected subject name (string or null)
    onSelectSubject,    // Function to call when a subject is selected (passes subjectName or null)
    isLoading,          // Boolean to indicate if subjects are being fetched
    error               // String error message if fetching failed
}) {
    if (isLoading) {
        return (
            <div className="flex items-center justify-center p-4 text-text-muted-light dark:text-text-muted-dark text-xs">
                <Loader2 size={16} className="animate-spin mr-2" /> Loading subjects...
            </div>
        );
    }

    if (error) {
        return (
            <div className="p-2 my-1 bg-red-500/10 border border-red-500/30 text-red-600 dark:text-red-300 rounded-md text-xs flex items-center justify-center gap-1">
                <AlertTriangle size={14} /> {error}
            </div>
        );
    }

    if (!subjects || subjects.length === 0) {
        return <p className="text-center text-xs text-text-muted-light dark:text-text-muted-dark p-3">No subjects configured by admin yet.</p>;
    }

    return (
        <div className="space-y-1.5 text-xs custom-scrollbar pr-1 max-h-60 overflow-y-auto"> {/* Added max-h and overflow */}
            {/* Option to deselect/choose general chat */}
            <div
                onClick={() => onSelectSubject(null)} // Pass null to deselect
                className={`p-2.5 bg-surface-light dark:bg-gray-800 border rounded-md flex items-center justify-between hover:shadow-md transition-all duration-150 cursor-pointer
                            ${!selectedSubject // Highlighted if no subject is selected
                                ? 'ring-2 ring-primary dark:ring-primary-light shadow-lg border-primary dark:border-primary-light'
                                : 'border-border-light dark:border-border-dark hover:border-gray-400 dark:hover:border-gray-500'}`}
                title="Select General Chat (No Specific Subject)"
            >
                <div className="flex items-center gap-2 truncate">
                    {!selectedSubject ? (
                        <CheckCircle size={16} className="text-green-500 flex-shrink-0" />
                    ) : (
                        // Using a generic icon, or you can use a different one for "none"
                        <Library size={16} className="text-gray-400 dark:text-gray-500 flex-shrink-0" />
                    )}
                    <span className={`truncate ${!selectedSubject ? 'font-semibold text-primary dark:text-primary-light' : 'text-text-light dark:text-text-dark'}`}>
                        -- General Chat --
                    </span>
                </div>
            </div>

            {/* List of available subjects */}
            {subjects.map(subjectName => {
                const isSelected = selectedSubject === subjectName;
                return (
                    <div
                        key={subjectName}
                        onClick={() => onSelectSubject(isSelected ? null : subjectName)} // Toggle selection
                        className={`p-2.5 bg-surface-light dark:bg-gray-800 border rounded-md flex items-center justify-between hover:shadow-md transition-all duration-150 cursor-pointer
                                    ${isSelected
                                        ? 'ring-2 ring-primary dark:ring-primary-light shadow-lg border-primary dark:border-primary-light'
                                        : 'border-border-light dark:border-border-dark hover:border-gray-400 dark:hover:border-gray-500'}`}
                        title={`Select Subject: ${subjectName}`}
                    >
                        <div className="flex items-center gap-2 truncate">
                            {isSelected ? (
                                <CheckCircle size={16} className="text-green-500 flex-shrink-0" />
                            ) : (
                                <Library size={16} className="text-primary dark:text-primary-light flex-shrink-0" />
                            )}
                            <span className={`truncate ${isSelected ? 'font-semibold text-primary dark:text-primary-light' : 'text-text-light dark:text-text-dark'}`}>
                                {subjectName}
                            </span>
                        </div>
                        {/* No actions like delete for subjects from this view */}
                    </div>
                );
            })}
        </div>
    );
}

export default SubjectList;
```

`frontend/src/components/layout/CenterPanel.jsx`

```javascript
// frontend/src/components/layout/CenterPanel.jsx
import React, { useState, useEffect, useRef } from 'react';
import ChatHistory from '../chat/ChatHistory';
import ChatInput from '../chat/ChatInput';
import api from '../../services/api';
import { useAuth as useRegularAuth } from '../../hooks/useAuth';
import { useAppState } from '../../contexts/AppStateContext';
import toast from 'react-hot-toast';

const THINKING_VARIANTS = [" Thinking...", " Processing...", " Analyzing query..."];
const RAG_ANALYSIS_VARIANTS = [" Reviewing documents...", " Finding relevant info...", " Combining sources..."];
const WEB_ANALYSIS_VARIANTS = [" Searching the web...", " Filtering results...", " Reading latest info..."];
const ACADEMIC_ANALYSIS_VARIANTS = [" Searching academic papers...", " Reviewing studies...", " Compiling research..."];
const GENERAL_ANALYSIS_VARIANTS = [" Analyzing context...", " Searching knowledge base..."];
const GENERATION_VARIANTS = [" Generating response...", " Crafting answer...", " Preparing explanation..."];

const getRandomItem = (arr) => arr[Math.floor(Math.random() * arr.length)];
const wait = (ms) => new Promise(resolve => setTimeout(resolve, ms));

function CenterPanel({ messages, setMessages, currentSessionId, onChatProcessingChange }) {
    const { token: regularUserToken } = useRegularAuth();
    const { selectedLLM, systemPrompt, selectedDocumentForAnalysis, selectedSubject } = useAppState();

    const [useWebSearch, setUseWebSearch] = useState(false);
    const [useAcademicSearch, setUseAcademicSearch] = useState(false);
    const [criticalThinkingEnabled, setCriticalThinkingEnabled] = useState(false);
    const [botStatusPlaceholder, setBotStatusPlaceholder] = useState(null);
    const isMountedRef = useRef(true);
    const simulationControllerRef = useRef(new AbortController());
    const [isActuallySendingAPI, setIsActuallySendingAPI] = useState(false);

    const abortControllerRef = useRef(null);

    useEffect(() => {
        isMountedRef.current = true;
        return () => {
            isMountedRef.current = false;
            simulationControllerRef.current.abort();
            if (abortControllerRef.current) {
                abortControllerRef.current.abort();
            }
        };
    }, []);

    useEffect(() => {
        const documentContext = selectedSubject || selectedDocumentForAnalysis;
        if (documentContext && (useWebSearch || useAcademicSearch)) {
            setUseWebSearch(false);
            setUseAcademicSearch(false);
            toast("Web and Academic Search disabled automatically while a document is selected.", { icon: "" });
        }
    }, [selectedDocumentForAnalysis, selectedSubject, useWebSearch, useAcademicSearch]);

    const runStatusSimulation = async (isRagActive, isWebActive, isAcademicActive, signal) => {
        let analysisVariants;
        if (isWebActive) analysisVariants = WEB_ANALYSIS_VARIANTS;
        else if (isAcademicActive) analysisVariants = ACADEMIC_ANALYSIS_VARIANTS;
        else if (isRagActive) analysisVariants = RAG_ANALYSIS_VARIANTS;
        else analysisVariants = GENERAL_ANALYSIS_VARIANTS;

        const sequence = [
            { message: getRandomItem(THINKING_VARIANTS), duration: 1200 },
            { message: getRandomItem(analysisVariants), duration: 1500 },
            { message: getRandomItem(GENERATION_VARIANTS), duration: 1300 },
        ];

        for (const stage of sequence) {
            if (signal.aborted) return;
            setBotStatusPlaceholder(stage.message);
            await wait(stage.duration + (Math.random() * 400 - 200));
        }
    };

    const handleSendMessage = async (inputText) => {
        if (!inputText.trim() || !regularUserToken || !currentSessionId || isActuallySendingAPI) return;

        if (abortControllerRef.current) {
            abortControllerRef.current.abort();
        }
        abortControllerRef.current = new AbortController();

        const userMessage = {
            id: `user-${Date.now()}`, sender: 'user', role: 'user', text: inputText.trim(),
            parts: [{ text: inputText.trim() }], timestamp: new Date().toISOString(),
        };

        setMessages(prev => [...prev, userMessage]);
        onChatProcessingChange(true);
        setIsActuallySendingAPI(true);

        if (criticalThinkingEnabled) {
            await handleStreamingSendMessage(inputText);
        } else {
            await handleStandardSendMessage(inputText);
        }
    };

    // --- MODIFIED: The streaming handler has been updated ---
    const handleStreamingSendMessage = async (inputText) => {
        setBotStatusPlaceholder(" Engaging multi-step reasoning...");
        
        const payload = {
            query: inputText.trim(), sessionId: currentSessionId, useWebSearch, useAcademicSearch,
            systemPrompt, criticalThinkingEnabled, documentContextName: selectedSubject || selectedDocumentForAnalysis,
        };

        try {
            const response = await fetch(`${import.meta.env.VITE_API_BASE_URL}/chat/message`, {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Authorization': `Bearer ${regularUserToken}`,
                },
                body: JSON.stringify(payload),
                signal: abortControllerRef.current.signal,
            });

            if (!response.ok) {
                const errorData = await response.json();
                throw new Error(errorData.message || `Server responded with status ${response.status}`);
            }

            const reader = response.body.getReader();
            const decoder = new TextDecoder();
            
            // --- THIS IS THE FIX ---
            // This variable will now hold the full message object, not just a string.
            let finalBotMessageObject = null;

            while (true) {
                const { done, value } = await reader.read();
                if (done) break;

                const chunk = decoder.decode(value, { stream: true });
                const lines = chunk.split('\n\n').filter(line => line.startsWith('data: '));
                
                for (const line of lines) {
                    const jsonString = line.replace('data: ', '');
                    try {
                        const eventData = JSON.parse(jsonString);
                        if (eventData.type === 'thought') {
                            setBotStatusPlaceholder(` ${eventData.content}`);
                        } else if (eventData.type === 'final_answer') {
                            // The `content` is now the full message object
                            finalBotMessageObject = eventData.content;
                        } else if (eventData.type === 'error') {
                            throw new Error(eventData.content);
                        }
                    } catch (e) {
                        console.error("Error parsing SSE chunk:", jsonString, e);
                    }
                }
            }
            
            // Once the stream is finished, add the final message object to state
            if (finalBotMessageObject) {
                 const messageWithClientSideData = {
                    ...finalBotMessageObject,
                    id: `bot-${Date.now()}`,
                    sender: 'bot',
                    role: 'model',
                    timestamp: new Date().toISOString(),
                    parts: [{ text: finalBotMessageObject.text || '' }]
                 };
                setMessages(prev => [...prev, messageWithClientSideData]);
            }
            // --- END OF FIX ---
        } catch (error) {
            if (error.name === 'AbortError') {
                console.log("Fetch request aborted.");
                return;
            }
            const errorText = error.message || 'Failed to get streaming response from AI.';
            const errorReply = {
                id: `error-${Date.now()}`, sender: 'bot', role: 'model',
                text: `Error: ${errorText}`, parts: [{ text: `Error: ${errorText}` }],
                timestamp: new Date().toISOString(), source_pipeline: "error-pipeline"
            };
            setMessages(prev => [...prev, errorReply]);
            toast.error(errorText);
        } finally {
             if (isMountedRef.current) {
                setBotStatusPlaceholder(null);
                onChatProcessingChange(false);
                setIsActuallySendingAPI(false);
            }
        }
    };


    const handleStandardSendMessage = async (inputText) => {
        const documentContextName = selectedSubject || selectedDocumentForAnalysis;
        const isRagActive = !!documentContextName;
        simulationControllerRef.current.abort();
        simulationControllerRef.current = new AbortController();
        setBotStatusPlaceholder(" Thinking...");
        runStatusSimulation(isRagActive, useWebSearch, useAcademicSearch, simulationControllerRef.current.signal);

        try {
            const response = await api.sendMessage({
                query: inputText.trim(),
                history: messages.map(m => ({ role: m.role, parts: m.parts || [{ text: m.text }] })),
                sessionId: currentSessionId, useWebSearch, useAcademicSearch, systemPrompt,
                criticalThinkingEnabled, documentContextName
            });

            if (response && response.reply) {
                if (isMountedRef.current) {
                    setMessages(prev => [...prev, { ...response.reply, id: `bot-${Date.now()}` }]);
                }
            } else {
                throw new Error("Invalid response from AI service.");
            }
        } catch (error) {
            const errorText = error.response?.data?.message || error.message || 'Failed to get response from AI.';
            const errorReply = {
                id: `error-${Date.now()}`, sender: 'bot', role: 'model',
                text: `Error: ${errorText}`, parts: [{ text: `Error: ${errorText}` }],
                timestamp: new Date().toISOString(), source_pipeline: "error-pipeline"
            };
            if (isMountedRef.current) {
                setMessages(prev => [...prev, errorReply]);
            }
            toast.error(errorText);
        } finally {
            simulationControllerRef.current.abort();
            if (isMountedRef.current) {
                setBotStatusPlaceholder(null);
                onChatProcessingChange(false);
                setIsActuallySendingAPI(false);
            }
        }
    };

    return (
        <div className="flex flex-col h-full bg-background-light dark:bg-background-dark rounded-lg shadow-inner">
            {messages.length === 0 && !isActuallySendingAPI && currentSessionId ? (
                 <div className="p-6 sm:p-8 text-center text-text-muted-light dark:text-text-muted-dark animate-fadeIn">
                    <h2 className="text-xl sm:text-2xl font-semibold mb-2 text-text-light dark:text-text-dark">AI Engineering Tutor</h2>
                    <p className="text-base sm:text-lg mb-3">Session ID: {currentSessionId.substring(0, 8)}...</p>
                    <div className="text-xs sm:text-sm space-y-1">
                        <p>Current LLM: <span className="font-semibold text-accent">{selectedLLM.toUpperCase()}</span>.</p>
                        <p className="max-w-md mx-auto">
                            Assistant Mode: <span className="italic">"{systemPrompt.length > 60 ? systemPrompt.substring(0, 60) + '...' : systemPrompt}"</span>
                        </p>
                        {(selectedSubject || selectedDocumentForAnalysis) && (
                            <p className="mt-1 font-medium">
                                Chat Focus: <span className="text-indigo-500 dark:text-indigo-400">{selectedSubject || selectedDocumentForAnalysis}</span>
                            </p>
                        )}
                    </div>
                </div>
            ) : null}

            <ChatHistory messages={messages} botStatusPlaceholder={botStatusPlaceholder} />

            <ChatInput
                onSendMessage={handleSendMessage}
                isLoading={isActuallySendingAPI}
                useWebSearch={useWebSearch}
                setUseWebSearch={setUseWebSearch}
                useAcademicSearch={useAcademicSearch} 
                setUseAcademicSearch={setUseAcademicSearch}
                criticalThinkingEnabled={criticalThinkingEnabled}
                setCriticalThinkingEnabled={setCriticalThinkingEnabled}
            />
        </div>
    );
}

export default CenterPanel;
```

`frontend/src/components/layout/LeftCollapsedNav.jsx`

```javascript
// frontend/src/components/layout/LeftCollapsedNav.jsx
import React from 'react';
import { useAppState } from '../../contexts/AppStateContext.jsx';
import { Edit3, UploadCloud, FileText, ChevronRight, Settings2 } from 'lucide-react'; // Settings2 for fallback
import IconButton from '../core/IconButton.jsx'; 
import { motion } from 'framer-motion';

// Mapping icon names (or IDs) to Lucide components
const iconMap = {
    prompt: Edit3,       // Icon for "Custom Prompt"
    upload: UploadCloud, // Icon for "Upload Document"
    docs: FileText,      // Icon for "Document List"
};

function LeftCollapsedNav() {
    const { setIsLeftPanelOpen } = useAppState();

    // Define the items for the collapsed navigation bar
    const navItems = [
        { 
            id: 'prompt', 
            label: 'Custom Prompt', 
            iconName: 'prompt', // Matches key in iconMap
            action: () => { 
                setIsLeftPanelOpen(true); 
                // TODO: Optionally, also scroll to/focus the prompt section in LeftPanel
            } 
        },
        { 
            id: 'upload', 
            label: 'Upload Document', 
            iconName: 'upload', 
            action: () => { 
                setIsLeftPanelOpen(true);
                // TODO: Optionally, open LeftPanel and focus/highlight upload area
            } 
        },
        { 
            id: 'docs', 
            label: 'Document List', 
            iconName: 'docs', 
            action: () => { 
                setIsLeftPanelOpen(true); 
                // TODO: Optionally, open LeftPanel scrolled to document list
            } 
        },
    ];

    return (
        <motion.aside
            key="left-collapsed-nav" // Unique key for AnimatePresence
            initial={{ x: '-100%', opacity: 0 }}
            animate={{ x: '0%', opacity: 1 }}
            exit={{ x: '-100%', opacity: 0 }}
            transition={{ type: 'spring', stiffness: 300, damping: 30 }}
            // Styling for the thin vertical bar
            className="fixed left-0 top-16 bottom-0 z-30 w-14 sm:w-16 
                       bg-surface-light dark:bg-surface-dark 
                       border-r border-border-light dark:border-border-dark 
                       shadow-lg flex flex-col items-center py-3 space-y-2 custom-scrollbar"
        >
            {/* Button to open the full LeftPanel - Placed at the top */}
            <IconButton 
                icon={ChevronRight} 
                onClick={() => setIsLeftPanelOpen(true)} 
                title="Open Assistant Panel"
                ariaLabel="Open Assistant Panel"
                variant="ghost" 
                size="lg" // Make it prominent
                className="mb-2 text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
            />

            {/* Icons for different sections of LeftPanel */}
            {navItems.map(item => {
                const IconComponent = iconMap[item.iconName] || Settings2; // Fallback icon
                return (
                    <IconButton 
                        key={item.id}
                        icon={IconComponent}
                        onClick={item.action} // Action currently just opens the panel
                        title={item.label}
                        ariaLabel={item.label}
                        variant="ghost"
                        size="md" 
                        className="text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
                    />
                );
            })}
            {/* Add a flexible spacer if you want the open button pushed further down from items */}
            {/* <div className="flex-grow"></div> */}
        </motion.aside>
    );
}
export default LeftCollapsedNav;
```

`frontend/src/components/layout/LeftPanel.jsx`

```javascript
// frontend/src/components/layout/LeftPanel.jsx
import React, { useState, useEffect, useCallback } from 'react';
import { useAppState } from '../../contexts/AppStateContext.jsx';
import DocumentUpload from '../documents/DocumentUpload.jsx';
import DocumentList from '../documents/DocumentList.jsx';
import SubjectList from '../documents/SubjectList.jsx'; // <<< NEW IMPORT
import {
    PanelLeftClose, ChevronDown, ChevronUp, FilePlus, Settings2,
    Bot, BookOpen, Lightbulb, Library, Loader2, AlertTriangle // Added AlertTriangle
} from 'lucide-react';
import IconButton from '../core/IconButton.jsx';
import { motion, AnimatePresence } from 'framer-motion';
import toast from 'react-hot-toast';
import api from '../../services/api.js'; // Main API service

const PROMPT_PRESETS = [
     { id: 'friendly_tutor', name: 'Friendly Tutor', icon: Bot, text: "You are a friendly, patient, and encouraging tutor specializing in engineering and scientific topics for PhD students. Explain concepts clearly, break down complex ideas, use analogies, and offer positive reinforcement. Ask follow-up questions to ensure understanding." },
     { id: 'concept_explorer', name: 'Concept Explorer', icon: BookOpen, text: "You are an expert academic lecturer introducing a new, complex engineering or scientific concept. Your goal is to provide a deep, structured explanation. Define terms rigorously, outline the theory, provide relevant mathematical formulations (using Markdown), illustrative examples, and discuss applications or limitations pertinent to PhD-level research." },
     { id: 'knowledge_check', name: 'Knowledge Check', icon: Lightbulb, text: "You are assessing understanding of engineering/scientific topics. Ask targeted questions to test knowledge, identify misconceptions, and provide feedback on the answers. Start by asking the user what topic they want to be quizzed on." },
     { id: 'custom', name: 'Custom Prompt', icon: Settings2, text: "You are a helpful AI engineering tutor." }
];

function LeftPanel() {
    const {
        setIsLeftPanelOpen,
        systemPrompt, setSystemPrompt,
        selectDocumentForAnalysis, selectedDocumentForAnalysis,
        selectedSubject, setSelectedSubject // AppState context will handle setting this
    } = useAppState();

    const [isPromptSectionOpen, setIsPromptSectionOpen] = useState(true);
    const [isSubjectSectionOpen, setIsSubjectSectionOpen] = useState(true);
    const [isDocManagementOpen, setIsDocManagementOpen] = useState(true);

    const [selectedPresetId, setSelectedPresetId] = useState('custom');
    const [availableSubjects, setAvailableSubjects] = useState([]);      // State to hold fetched subjects
    const [isLoadingSubjects, setIsLoadingSubjects] = useState(false);   // Loading state for subjects
    const [subjectFetchError, setSubjectFetchError] = useState('');     // Error state for subjects
    const [docListKey, setDocListKey] = useState(Date.now()); // For user's own DocumentList refresh

    useEffect(() => {
        const matchedPreset = PROMPT_PRESETS.find(p => p.text === systemPrompt);
        setSelectedPresetId(matchedPreset ? matchedPreset.id : 'custom');
    }, [systemPrompt]);

    // Fetch subjects (admin document names) on component mount
    const fetchSubjects = useCallback(async () => {
        setIsLoadingSubjects(true);
        setSubjectFetchError(''); // Clear previous errors
        try {
            const response = await api.getSubjects(); // Calls /api/subjects
            // The backend returns { subjects: ["Subject 1", "Subject 2", ...] }
            const subjects = Array.isArray(response.subjects) ? response.subjects : [];
            setAvailableSubjects(subjects);
            if (subjects.length === 0) {
                // FIX: Changed toast.info to just toast() for a standard informational message.
                toast("No admin-defined subjects found to select for chat focus.");
            }
        } catch (error) {
            const errorMsg = error.response?.data?.message || error.message || "Failed to load available subjects.";
            toast.error(errorMsg);
            setSubjectFetchError(errorMsg); // Store error message for display
            console.error("Error fetching subjects:", error);
        } finally {
            setIsLoadingSubjects(false);
        }
    }, []);

    useEffect(() => {
        fetchSubjects();
    }, [fetchSubjects]);

    const handlePresetChange = (event) => {
        const presetId = event.target.value;
        setSelectedPresetId(presetId);
        const selectedPreset = PROMPT_PRESETS.find(p => p.id === presetId);
        if (selectedPreset) setSystemPrompt(selectedPreset.text);
    };

    const handleUploadSuccessForUserDocs = () => {
        setDocListKey(Date.now());
        toast.success("Your document list refreshed after upload.");
    };

    // setSelectedSubject from AppStateContext is passed directly to SubjectList's onSelectSubject prop.

    const SelectedPresetIcon = PROMPT_PRESETS.find(p => p.id === selectedPresetId)?.icon || Settings2;

    return (
        <div className="flex flex-col h-full">
            <div className="flex items-center justify-between mb-3 px-1 pt-1">
                <h2 className="text-sm font-semibold text-text-light dark:text-text-dark">Assistant Controls</h2>
                <IconButton
                    icon={PanelLeftClose}
                    onClick={() => setIsLeftPanelOpen(false)}
                    title="Close Assistant Panel"
                    variant="ghost" size="sm"
                    className="text-text-muted-light dark:text-text-muted-dark hover:text-primary"
                />
            </div>

            {/* Custom Prompt Section (Existing) */}
            <div className="mb-4">
                <button onClick={() => setIsPromptSectionOpen(!isPromptSectionOpen)} className="w-full flex items-center justify-between px-3 py-2.5 text-sm font-medium text-left text-text-light dark:text-text-dark bg-gray-50 dark:bg-gray-800 hover:bg-gray-100 dark:hover:bg-gray-700 rounded-md focus:outline-none shadow-sm border border-border-light dark:border-border-dark" aria-expanded={isPromptSectionOpen}>
                    <span className="flex items-center gap-2"><SelectedPresetIcon size={16} className="text-primary dark:text-primary-light" /> Custom Prompt</span>
                    {isPromptSectionOpen ? <ChevronUp size={18} /> : <ChevronDown size={18} />}
                </button>
                <AnimatePresence>
                    {isPromptSectionOpen && (
                        <motion.div key="prompt-section-content" initial={{ height: 0, opacity: 0 }} animate={{ height: 'auto', opacity: 1 }} exit={{ height: 0, opacity: 0 }} transition={{ duration: 0.2, ease: "easeInOut" }} className="mt-2 p-3 bg-surface-light dark:bg-surface-dark border border-border-light dark:border-border-dark rounded-md shadow-inner overflow-hidden">
                            <label htmlFor="prompt-preset-select" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark mb-1">Prompt Mode:</label>
                             <select id="prompt-preset-select" value={selectedPresetId} onChange={handlePresetChange} className="input-field mb-2 text-xs py-1.5">
                                 {PROMPT_PRESETS.map(preset => (<option key={preset.id} value={preset.id}>{preset.name}</option>))}
                             </select>
                             <label htmlFor="system-prompt-area" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark mb-1">System Prompt (Editable):</label>
                             <textarea id="system-prompt-area" value={systemPrompt} onChange={(e) => { setSystemPrompt(e.target.value); setSelectedPresetId('custom'); }} rows="5" className="input-field text-xs custom-scrollbar" placeholder="Enter system prompt..."/>
                        </motion.div>
                    )}
                </AnimatePresence>
            </div>

            {/* --- NEW: Select Subject Section --- */}
            <div className="mb-4">
                <button
                    onClick={() => setIsSubjectSectionOpen(!isSubjectSectionOpen)}
                    className="w-full flex items-center justify-between px-3 py-2.5 text-sm font-medium text-left text-text-light dark:text-text-dark bg-gray-50 dark:bg-gray-800 hover:bg-gray-100 dark:hover:bg-gray-700 rounded-md focus:outline-none shadow-sm border border-border-light dark:border-border-dark"
                    aria-expanded={isSubjectSectionOpen}
                >
                    <span className="flex items-center gap-2">
                        <Library size={16} className="text-primary dark:text-primary-light" /> Select Subject Focus
                    </span>
                    {isSubjectSectionOpen ? <ChevronUp size={18} /> : <ChevronDown size={18} />}
                </button>
                <AnimatePresence>
                    {isSubjectSectionOpen && (
                        <motion.div
                            key="subject-select-content"
                            initial={{ height: 0, opacity: 0 }}
                            animate={{ height: 'auto', opacity: 1 }}
                            exit={{ height: 0, opacity: 0 }}
                            transition={{ duration: 0.2, ease: "easeInOut" }}
                            className="mt-2 p-3 bg-surface-light dark:bg-surface-dark border border-border-light dark:border-border-dark rounded-md shadow-inner overflow-hidden"
                        >
                           {/* Using the new SubjectList component */}
                           <SubjectList
                                subjects={availableSubjects}
                                selectedSubject={selectedSubject}
                                onSelectSubject={setSelectedSubject} // Pass the setter from AppStateContext
                                isLoading={isLoadingSubjects}
                                error={subjectFetchError}
                           />
                        </motion.div>
                    )}
                </AnimatePresence>
            </div>

            {/* Document Management Section (For REGULAR USER's own documents) */}
            <div className="flex-grow flex flex-col overflow-hidden">
                <button onClick={() => setIsDocManagementOpen(!isDocManagementOpen)} className="w-full flex items-center justify-between px-3 py-2.5 text-sm font-medium text-left text-text-light dark:text-text-dark bg-gray-50 dark:bg-gray-800 hover:bg-gray-100 dark:hover:bg-gray-700 rounded-md focus:outline-none shadow-sm border border-border-light dark:border-border-dark mb-2" aria-expanded={isDocManagementOpen}>
                    <span className="flex items-center gap-2"><FilePlus size={16} className="text-primary dark:text-primary-light" /> My Documents (for Analysis Tools)</span>
                    {isDocManagementOpen ? <ChevronUp size={18} /> : <ChevronDown size={18} />}
                </button>
                <AnimatePresence>
                    {isDocManagementOpen && (
                        <motion.div key="doc-management-content" initial={{ height: 0, opacity: 0 }} animate={{ height: 'auto', opacity: 1 }} exit={{ height: 0, opacity: 0 }} transition={{ duration: 0.2, ease: "easeInOut" }} className="flex-grow flex flex-col overflow-hidden p-3 bg-surface-light dark:bg-surface-dark border border-border-light dark:border-border-dark rounded-md shadow-inner">
                            <DocumentUpload onUploadSuccess={handleUploadSuccessForUserDocs} />
                            <div className="mt-3 flex-grow overflow-y-auto custom-scrollbar">
                                <DocumentList
                                    key={docListKey}
                                    onSelectDocument={selectDocumentForAnalysis}
                                    selectedDocument={selectedDocumentForAnalysis}
                                />
                            </div>
                        </motion.div>
                    )}
                </AnimatePresence>
            </div>
        </div>
    );
}
export default LeftPanel;

```

`frontend/src/components/layout/LLMSelectionModal.jsx`

```javascript
// frontend/src/components/layout/LLMSelectionModal.jsx
import React, { useState, useEffect } from 'react';
import { useAppState } from '../../contexts/AppStateContext.jsx';
import api from '../../services/api.js';
import toast from 'react-hot-toast';
import { X, Save, KeyRound, AlertCircle, HardDrive } from 'lucide-react';
import Modal from '../core/Modal.jsx';
import Button from '../core/Button.jsx';
import LLMSelection from '../auth/LLMSelection.jsx';
import { motion } from 'framer-motion';

function LLMSelectionModal({ isOpen, onClose }) {
    const { selectedLLM: currentLLM, switchLLM: setGlobalLLMPreference } = useAppState();
    
    // State for the provider selection
    const [locallySelectedLLM, setLocallySelectedLLM] = useState(currentLLM);
    
    // Separate state for each input field
    const [geminiApiKeyInput, setGeminiApiKeyInput] = useState('');
    const [ollamaUrlInput, setOllamaUrlInput] = useState('');
    
    const [loading, setLoading] = useState(false);
    const [error, setError] = useState('');

    useEffect(() => {
        // Reset state every time the modal opens
        if (isOpen) {
            setLocallySelectedLLM(currentLLM);
            setGeminiApiKeyInput(''); 
            setOllamaUrlInput(''); 
            setError('');
        }
    }, [isOpen, currentLLM]);

    const handleSavePreference = async () => {
        setLoading(true); 
        setError('');
        
        try {
            // Start with the provider selection
            const configData = { llmProvider: locallySelectedLLM };

            // Only add other fields if the user actually typed something into them
            if (geminiApiKeyInput.trim()) {
                configData.apiKey = geminiApiKeyInput.trim();
            }
            if (ollamaUrlInput.trim()) {
                configData.ollamaUrl = ollamaUrlInput.trim();
            }
            
            await api.updateUserLLMConfig(configData);
            setGlobalLLMPreference(locallySelectedLLM);
            
            toast.success(`LLM preference updated to ${locallySelectedLLM.toUpperCase()}.`);
            onClose();
        } catch (err) {
            const errorMessage = err.response?.data?.message || err.message || 'Failed to update preference.';
            setError(errorMessage);
            toast.error(errorMessage);
        } finally {
            setLoading(false);
        }
    };
    
    const inputWrapperClass = "relative";
    const inputIconClass = "absolute left-3 top-1/2 -translate-y-1/2 h-5 w-5 text-text-muted-light dark:text-text-muted-dark";
    const inputFieldStyledClass = "input-field pl-10 py-2 text-sm w-full";

    return (
         <Modal isOpen={isOpen} onClose={onClose} title="Switch LLM Provider & Credentials" size="lg"
            footerContent={
                <>
                    <Button onClick={onClose} variant="secondary" size="sm" className="text-xs">Cancel</Button>
                    <Button onClick={handleSavePreference} isLoading={loading} size="sm" className="text-xs">
                        <Save size={14} className="mr-1.5"/> Save Preference
                    </Button>
                </>
            }
        >
            <div className="space-y-5"> 
                <p className="text-sm text-text-muted-light dark:text-text-muted-dark">
                    Select your preferred LLM. You can also update your credentials here. <br/><strong>Leave a field blank to keep your existing setting.</strong>
                </p>
                <LLMSelection 
                    selectedLLM={locallySelectedLLM} 
                    onLlmChange={setLocallySelectedLLM}
                    disabled={loading}
                />
                
                <motion.div key="gemini-config-modal" className="mt-4 space-y-1">
                    <label htmlFor="modalGeminiApiKey" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark">
                        Update Gemini API Key (Optional)
                    </label>
                    <div className={inputWrapperClass}>
                        <KeyRound className={inputIconClass} />
                        <input type="password" id="modalGeminiApiKey" className={inputFieldStyledClass} placeholder="Leave blank to keep existing key" value={geminiApiKeyInput} onChange={(e) => setGeminiApiKeyInput(e.target.value)} disabled={loading} />
                    </div>
                </motion.div>
                
                <motion.div key="ollama-config-modal" className="mt-4 space-y-1">
                    <label htmlFor="modalOllamaUrl" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark">
                        Update Ollama URL (Optional)
                    </label>
                     <div className={inputWrapperClass}>
                        <HardDrive className={inputIconClass} />
                        <input type="text" id="modalOllamaUrl" className={inputFieldStyledClass} placeholder="Leave blank to keep existing URL" value={ollamaUrlInput} onChange={(e) => setOllamaUrlInput(e.target.value)} disabled={loading} />
                    </div>
                </motion.div>

                {error && (
                    <div className="flex items-center gap-2 p-2 text-xs text-red-700 bg-red-100 dark:bg-red-900/30 dark:text-red-300 rounded-md">
                        <AlertCircle size={16} />
                        <span>{error}</span>
                    </div>
                )}
            </div>
        </Modal>
    );
}

export default LLMSelectionModal;
```

`frontend/src/components/layout/RightCollapsedNav.jsx`

```javascript
// frontend/src/components/layout/RightCollapsedNav.jsx
import React from 'react';
import { useAppState } from '../../contexts/AppStateContext.jsx';
import { HelpCircle, GitFork, Tags, ChevronLeft } from 'lucide-react';
import IconButton from '../core/IconButton.jsx';
import { motion } from 'framer-motion';

const iconMap = {
    HelpCircle: HelpCircle,
    Tags: Tags,
    GitFork: GitFork,
};

function RightCollapsedNav() {
    const { setIsRightPanelOpen } = useAppState();

    const navItems = [
        { id: 'faq', label: 'FAQ Generator', iconName: 'HelpCircle', action: () => { setIsRightPanelOpen(true); /* TODO: set analysis type contextually */ } },
        { id: 'topics', label: 'Key Topics Extractor', iconName: 'Tags', action: () => { setIsRightPanelOpen(true); } },
        { id: 'mindmap', label: 'Mind Map Creator', iconName: 'GitFork', action: () => { setIsRightPanelOpen(true); } },
    ];

    return (
        <motion.aside
            key="right-collapsed-nav"
            initial={{ x: '100%', opacity: 0 }}
            animate={{ x: '0%', opacity: 1 }}
            exit={{ x: '100%', opacity: 0 }}
            transition={{ type: 'spring', stiffness: 300, damping: 30 }}
            className="fixed right-0 top-16 bottom-0 z-30 w-14 sm:w-16 bg-surface-light dark:bg-surface-dark border-l border-border-light dark:border-border-dark shadow-lg flex-col items-center py-3 space-y-2 hidden md:flex"
        >
            {/* Open Panel Button AT THE TOP */}
            <IconButton 
                icon={ChevronLeft} 
                onClick={() => setIsRightPanelOpen(true)} 
                title="Open Analyzer Panel"
                ariaLabel="Open Analyzer Panel"
                variant="ghost" 
                size="lg"
                className="mb-2 text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
            />
            {navItems.map(item => {
                 const Icon = iconMap[item.iconName] || HelpCircle;
                return (
                    <IconButton 
                        key={item.id}
                        icon={Icon}
                        onClick={item.action}
                        title={item.label}
                        ariaLabel={item.label}
                        variant="ghost"
                        size="md"
                        className="text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
                    />
                );
            })}
        </motion.aside>
    );
}
export default RightCollapsedNav;
```

`frontend/src/components/layout/RightPanel.jsx`

```javascript


// frontend/src/components/layout/RightPanel.jsx
import React, { useState } from 'react';
import { useAppState } from '../../contexts/AppStateContext';
import AnalysisToolRunner from '../analysis/AnalysisToolRunner.jsx';
import PodcastGenerator from '../analysis/PodcastGenerator.jsx';
import KnowledgeGraphViewer from '../analysis/KnowledgeGraphViewer.jsx';
import api from '../../services/api.js';
import { PanelRightClose, ChevronDown, ChevronUp, Telescope, Radio, BrainCircuit } from 'lucide-react';
import IconButton from '../core/IconButton.jsx';
import Modal from '../core/Modal.jsx';
import Button from '../core/Button.jsx';
import { motion } from 'framer-motion';
import toast from 'react-hot-toast';

function RightPanel() {
    const { setIsRightPanelOpen, selectedDocumentForAnalysis, selectedSubject } = useAppState();
    const [isAnalyzerOpen, setIsAnalyzerOpen] = useState(true);

    const [isKgModalOpen, setIsKgModalOpen] = useState(false);
    const [kgData, setKgData] = useState(null);
    const [isLoadingKg, setIsLoadingKg] = useState(false);

    const currentSelectedDocFilename = selectedDocumentForAnalysis || selectedSubject || null;
    const isTargetAdminSubject = !!(selectedSubject && currentSelectedDocFilename && selectedSubject === currentSelectedDocFilename);

    const handleVisualizeKg = async () => {
        if (!currentSelectedDocFilename) return;
        setIsKgModalOpen(true);
        setIsLoadingKg(true);
        setKgData(null);
        try {
            const data = await api.getKnowledgeGraph(currentSelectedDocFilename);
            if(data.error) {
                toast.error(`KG Error: ${data.error}`);
                setKgData({ error: data.error });
            } else {
                setKgData(data);
            }
        } catch (error) {
            const errorMessage = error.response?.data?.error || "Could not fetch knowledge graph.";
            toast.error(errorMessage);
            setKgData({ error: errorMessage });
        } finally {
            setIsLoadingKg(false);
        }
    };

    return (
        <>
            <div className="flex flex-col h-full p-3 sm:p-4 bg-surface-light dark:bg-surface-dark text-text-light dark:text-text-dark custom-scrollbar">
                <div className="flex items-center justify-between mb-4 pb-2 border-b border-border-light dark:border-border-dark">
                    <h2 className="text-base font-semibold">Advanced Analyzer</h2>
                    <IconButton
                        icon={PanelRightClose}
                        onClick={() => setIsRightPanelOpen(false)}
                        title="Close Analyzer Panel"
                        variant="ghost" size="sm"
                        className="text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
                    />
                </div>
                
                {!currentSelectedDocFilename ? (
                    <div className="p-4 text-xs text-center text-text-muted-light dark:text-text-muted-dark bg-gray-50 dark:bg-gray-800 rounded-md border border-dashed border-border-light dark:border-border-dark">
                        <p>Select a document from the left panel to enable analysis and generation tools.</p>
                    </div>
                ) : (
                    <div className="flex-grow space-y-4 overflow-y-auto custom-scrollbar pr-1">
                        <div>
                            <button onClick={() => setIsAnalyzerOpen(!isAnalyzerOpen)} className="w-full flex items-center justify-between px-3 py-2.5 text-sm font-medium text-left bg-gray-50 dark:bg-gray-800 hover:bg-gray-100 dark:hover:bg-gray-700 rounded-md focus:outline-none shadow-sm border border-border-light dark:border-border-dark">
                                <span className="flex items-center gap-2"><Telescope size={16} /> Analysis Tools</span>
                                {isAnalyzerOpen ? <ChevronUp size={18} /> : <ChevronDown size={18} />}
                            </button>
                            {isAnalyzerOpen && (
                                <motion.div initial={{ height: 0, opacity: 0 }} animate={{ height: 'auto', opacity: 1 }} exit={{ height: 0, opacity: 0 }} transition={{ duration: 0.2, ease: "easeInOut" }} className="mt-2 space-y-3 overflow-hidden">
                                    <AnalysisToolRunner toolType="faq" title="FAQ Generator" iconName="HelpCircle" selectedDocumentFilename={currentSelectedDocFilename} isTargetAdminDoc={isTargetAdminSubject} />
                                    <AnalysisToolRunner toolType="topics" title="Key Topics Extractor" iconName="Tags" selectedDocumentFilename={currentSelectedDocFilename} isTargetAdminDoc={isTargetAdminSubject} />
                                    <AnalysisToolRunner toolType="mindmap" title="Mind Map Creator" iconName="GitFork" selectedDocumentFilename={currentSelectedDocFilename} isTargetAdminDoc={isTargetAdminSubject} />
                                </motion.div>
                            )}
                        </div>
                        <div>
                            <div className="w-full flex items-center justify-between px-3 py-2.5 text-sm font-medium text-left bg-gray-50 dark:bg-gray-800 rounded-md border border-border-light dark:border-border-dark">
                               <span className="flex items-center gap-2"><Radio size={16} /> Content Exporters & Synthesis</span>
                            </div>
                             <div className="mt-2 space-y-3">
                                <PodcastGenerator selectedDocumentFilename={currentSelectedDocFilename} />
                                <Button onClick={handleVisualizeKg} variant="outline" size="sm" fullWidth isLoading={isLoadingKg} leftIcon={<BrainCircuit size={16} />}>
                                    Visualize Knowledge Graph
                                </Button>
                            </div>
                        </div>
                    </div>
                )}
            </div>

            <Modal isOpen={isKgModalOpen} onClose={() => setIsKgModalOpen(false)} title={`Knowledge Graph: ${currentSelectedDocFilename}`} size="5xl">
                <KnowledgeGraphViewer graphData={isLoadingKg ? null : kgData} />
            </Modal>
        </>
    );
}
export default RightPanel;
```

`frontend/src/components/layout/TopNav.jsx`

```javascript
// frontend/src/components/layout/TopNav.jsx
import React, { useState, useEffect, useRef } from 'react';
import { useAppState } from '../../contexts/AppStateContext';
import ThemeToggle from '../common/ThemeToggle.jsx';
import LLMSelectionModal from './LLMSelectionModal.jsx';
import ProfileSettingsModal from '../profile/ProfileSettingsModal.jsx';
import { 
    LogOut, User, MessageSquare, History as HistoryIcon, Settings, Cpu, Zap, ServerCrash, Server 
} from 'lucide-react';
import toast from 'react-hot-toast';

function TopNav({ user: authUser, onLogout, onNewChat, onHistoryClick, orchestratorStatus, isChatProcessing  }) {
    const { selectedLLM, switchLLM } = useAppState();
    const [isLLMModalOpen, setIsLLMModalOpen] = useState(false);
    const [isProfileModalOpen, setIsProfileModalOpen] = useState(false);
    
    const [isProfileDropdownOpen, setIsProfileDropdownOpen] = useState(false);
    const profileDropdownRef = useRef(null);

    const getStatusIndicator = () => {
        if (!orchestratorStatus) return <div title="Status unavailable" className="w-4 h-4 bg-gray-400 rounded-full"></div>;
        if (orchestratorStatus.status === "ok") {
            return <Zap size={18} className="text-green-400 animate-pulse" title={`Backend Online: ${orchestratorStatus.message}`} />;
        } else if (orchestratorStatus.status === "loading") {
            return <div className="animate-spin rounded-full h-4 w-4 border-t-2 border-b-2 border-yellow-400" title="Connecting..."></div>;
        } else {
            return <ServerCrash size={18} className="text-red-400" title={`Backend Offline: ${orchestratorStatus.message}`} />;
        }
    };
    
    useEffect(() => {
        function handleClickOutside(event) {
            if (profileDropdownRef.current && !profileDropdownRef.current.contains(event.target)) {
                setIsProfileDropdownOpen(false);
            }
        }
        document.addEventListener("mousedown", handleClickOutside);
        return () => {
            document.removeEventListener("mousedown", handleClickOutside);
        };
    }, [profileDropdownRef]);

    return (
        <>
            <nav className="fixed top-0 left-0 right-0 z-40 bg-surface-light dark:bg-surface-dark border-b border-border-light dark:border-border-dark shadow-sm h-16 flex items-center justify-between px-2 sm:px-4">
                <div className="flex items-center gap-2">
                    <a href="/" className="flex items-center gap-1.5 sm:gap-2 text-lg sm:text-xl font-semibold text-text-light dark:text-text-dark">
                        <Server size={24} className="text-primary dark:text-primary-light" />
                        <span className="hidden sm:inline">AI Tutor</span>
                    </a>
                </div>

                <div className="flex-1 flex justify-center px-2">
                    <div className="flex items-center gap-1 sm:gap-2">
                         <button
                            onClick={onNewChat}
                            className={`flex items-center gap-1 px-2 py-1.5 text-xs sm:text-sm font-medium rounded-md text-text-light dark:text-text-dark bg-gray-100 dark:bg-gray-700 hover:bg-gray-200 dark:hover:bg-gray-600 transition-colors ${isChatProcessing ? 'opacity-50 cursor-not-allowed' : ''}`}
                            disabled={isChatProcessing}
                            title="Start a new chat session"
                        >
                            <MessageSquare size={14} /> <span className="hidden sm:inline">New Chat</span>
                        </button>
                        
                        <button
                            onClick={onHistoryClick}
                            className={`flex items-center gap-1 px-2 py-1.5 text-xs sm:text-sm font-medium rounded-md text-text-light dark:text-text-dark bg-gray-100 dark:bg-gray-700 hover:bg-gray-200 dark:hover:bg-gray-600 transition-colors ${isChatProcessing ? 'opacity-50 cursor-not-allowed' : ''}`}
                            disabled={isChatProcessing}
                            title="View chat history"
                        >
                            <HistoryIcon size={14} /> <span className="hidden sm:inline">History</span>
                        </button>
                        <button
                            onClick={() => setIsLLMModalOpen(true)}
                            className={`flex items-center gap-1 px-2 py-1.5 text-xs sm:text-sm font-medium rounded-md text-text-light dark:text-text-dark bg-gray-100 dark:bg-gray-700 hover:bg-gray-200 dark:hover:bg-gray-600 transition-colors ${isChatProcessing ? 'opacity-50 cursor-not-allowed' : ''}`}
                            disabled={isChatProcessing}
                            title={`Switch LLM (Current: ${selectedLLM.toUpperCase()})`}
                        >
                            <Cpu size={14} /> <span className="hidden xs:inline">{selectedLLM.toUpperCase()}</span>
                        </button>
                    </div>
                </div>


                <div className="flex items-center gap-1.5 sm:gap-2">
                    {/* --- FIX: Added a fixed-size wrapper div for the status indicator --- */}
                    <div className="w-8 h-8 flex items-center justify-center">
                        {getStatusIndicator()}
                    </div>
                    <ThemeToggle />
                    <div className="relative" ref={profileDropdownRef}>
                        <button 
                            onClick={() => setIsProfileDropdownOpen(prev => !prev)}
                            className="p-1.5 bg-primary-light dark:bg-primary-dark text-white rounded-full focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-offset-surface-light dark:focus:ring-offset-surface-dark focus:ring-primary"
                        >
                            <User size={18} />
                        </button>
                        <div 
                            className={`absolute right-0 mt-2 w-48 bg-surface-light dark:bg-surface-dark rounded-md shadow-lg py-1 transition-all duration-150 ease-in-out transform origin-top-right z-50
                                ${isProfileDropdownOpen 
                                    ? 'opacity-100 scale-100 visible' 
                                    : 'opacity-0 scale-95 invisible'
                                }`
                            }
                        >
                            <div className="px-4 py-2 text-sm text-text-light dark:text-text-dark border-b border-border-light dark:border-border-dark">
                                Signed in as <br/><strong>{authUser?.username || 'User'}</strong>
                            </div>
                            <button
                                onClick={() => { setIsProfileModalOpen(true); setIsProfileDropdownOpen(false); }}
                                className="w-full text-left px-4 py-2 text-sm text-text-light dark:text-text-dark hover:bg-gray-100 dark:hover:bg-gray-700 flex items-center gap-2"
                            >
                                <Settings size={16} /> Profile
                            </button>
                            <button
                                onClick={() => { onLogout(); setIsProfileDropdownOpen(false); }}
                                className="w-full text-left px-4 py-2 text-sm text-red-600 dark:text-red-400 hover:bg-red-50 dark:hover:bg-red-900 flex items-center gap-2"
                            >
                                <LogOut size={16} /> Logout
                            </button>
                        </div>
                    </div>
                </div>
            </nav>
            <LLMSelectionModal 
                isOpen={isLLMModalOpen} 
                onClose={() => setIsLLMModalOpen(false)} 
                currentLLM={selectedLLM}
                onSelectLLM={(llm) => {
                    switchLLM(llm);
                    setIsLLMModalOpen(false);
                }}
            />
            <ProfileSettingsModal
                isOpen={isProfileModalOpen}
                onClose={() => setIsProfileModalOpen(false)}
            />
        </>
    );
}
export default TopNav;
```

`frontend/src/components/profile/ProfileSettingsModal.jsx`

```javascript
// frontend/src/components/profile/ProfileSettingsModal.jsx
import React, { useState, useEffect } from 'react';
import api from '../../services/api';
import toast from 'react-hot-toast';
import Modal from '../core/Modal.jsx';
import Button from '../core/Button.jsx';
import { Save, User, School, Hash, Award, Wrench, Calendar } from 'lucide-react';

const ProfileSettingsModal = ({ isOpen, onClose }) => {
    const [profile, setProfile] = useState({
        name: '',
        college: '',
        universityNumber: '',
        degreeType: '',
        branch: '',
        year: ''
    });
    const [isLoading, setIsLoading] = useState(false);
    const [error, setError] = useState('');

    useEffect(() => {
        if (isOpen) {
            const fetchProfile = async () => {
                setIsLoading(true);
                setError('');
                try {
                    const data = await api.getUserProfile();
                    // Set profile data, ensuring defaults for any missing fields
                    setProfile({
                        name: data.name || '',
                        college: data.college || '',
                        universityNumber: data.universityNumber || '',
                        degreeType: data.degreeType || 'Bachelors', // Default value
                        branch: data.branch || 'Computer Science', // Default value
                        year: data.year || '1st Year' // Default value
                    });
                } catch (err) {
                    toast.error('Failed to load profile data.');
                    setError(err.message || 'Could not fetch profile.');
                } finally {
                    setIsLoading(false);
                }
            };
            fetchProfile();
        }
    }, [isOpen]);

    const handleChange = (e) => {
        const { name, value } = e.target;
        setProfile(prev => ({ ...prev, [name]: value }));
    };

    const handleSubmit = async (e) => {
        e.preventDefault();
        // Simple validation
        for (const key in profile) {
            if (!profile[key] || profile[key].trim() === '') {
                toast.error(`Please fill out the '${key.replace(/([A-Z])/g, ' $1').trim()}' field.`);
                return;
            }
        }
        setIsLoading(true);
        setError('');
        try {
            const response = await api.updateUserProfile(profile);
            toast.success(response.message || 'Profile updated successfully!');
            onClose();
        } catch (err) {
            const errorMessage = err.response?.data?.message || err.message || 'Failed to update profile.';
            setError(errorMessage);
            toast.error(errorMessage);
        } finally {
            setIsLoading(false);
        }
    };
    
    const inputWrapperClass = "relative";
    const inputIconClass = "absolute left-3 top-1/2 -translate-y-1/2 h-5 w-5 text-text-muted-light dark:text-text-muted-dark pointer-events-none";
    const inputFieldStyledClass = "input-field pl-10 py-2.5 text-sm";
    const selectFieldStyledClass = "input-field !pl-10 !pr-8 py-2.5 text-sm";

    return (
        <Modal
            isOpen={isOpen}
            onClose={onClose}
            title="Student Profile Settings"
            size="lg"
            footerContent={
                <>
                    <Button variant="ghost" onClick={onClose} disabled={isLoading}>Cancel</Button>
                    <Button onClick={handleSubmit} isLoading={isLoading} leftIcon={<Save size={16} />}>
                        Save Changes
                    </Button>
                </>
            }
        >
            <form onSubmit={handleSubmit} className="space-y-4">
                {error && <p className="text-sm text-red-500">{error}</p>}
                
                <div className={inputWrapperClass}>
                    <User className={inputIconClass} />
                    <input type="text" name="name" value={profile.name} onChange={handleChange} placeholder="Full Name" className={inputFieldStyledClass} required />
                </div>

                <div className={inputWrapperClass}>
                    <School className={inputIconClass} />
                    <input type="text" name="college" value={profile.college} onChange={handleChange} placeholder="College / Institution" className={inputFieldStyledClass} required />
                </div>
                
                <div className={inputWrapperClass}>
                    <Hash className={inputIconClass} />
                    <input type="text" name="universityNumber" value={profile.universityNumber} onChange={handleChange} placeholder="Registered University Number" className={inputFieldStyledClass} required />
                </div>

                <div className="grid grid-cols-1 md:grid-cols-3 gap-4">
                    <div className={inputWrapperClass}>
                        <Award className={inputIconClass} />
                        <select name="degreeType" value={profile.degreeType} onChange={handleChange} className={selectFieldStyledClass} required>
                            <option value="Bachelors">Bachelor's</option>
                            <option value="Masters">Master's</option>
                            <option value="PhD">PhD</option>
                            <option value="Diploma">Diploma</option>
                        </select>
                    </div>
                    
                    <div className={inputWrapperClass}>
                        <Wrench className={inputIconClass} />
                        <select name="branch" value={profile.branch} onChange={handleChange} className={selectFieldStyledClass} required>
                            <option value="Computer Science">Computer Science</option>
                            <option value="Mechanical Engineering">Mechanical</option>
                            <option value="Electrical Engineering">Electrical</option>
                            <option value="Civil Engineering">Civil</option>
                            <option value="Electronics & Communication">Electronics & Comm.</option>
                            <option value="Other">Other</option>
                        </select>
                    </div>

                    <div className={inputWrapperClass}>
                        <Calendar className={inputIconClass} />
                        <select name="year" value={profile.year} onChange={handleChange} className={selectFieldStyledClass} required>
                            <option value="1st Year">1st Year</option>
                            <option value="2nd Year">2nd Year</option>
                            <option value="3rd Year">3rd Year</option>
                            <option value="4th Year">4th Year</option>
                            <option value="Final Year">Final Year</option>
                            <option value="Graduated">Graduated</option>
                        </select>
                    </div>
                </div>
            </form>
        </Modal>
    );
};

export default ProfileSettingsModal;
```

`frontend/src/contexts/AppStateContext.jsx`

```javascript
import React, { createContext, useState, useContext, useEffect } from 'react';

export const AppStateContext = createContext(null);

export const useAppState = () => {
    const context = useContext(AppStateContext);
    if (!context) throw new Error('useAppState must be used within an AppStateProvider');
    return context;
};

const defaultSystemPromptText = "You are a helpful AI engineering tutor.";

export const AppStateProvider = ({ children }) => {
    const [theme, setThemeState] = useState(() => {
        const storedTheme = localStorage.getItem('theme') || 'dark';
        if (typeof window !== 'undefined') {
            document.documentElement.classList.remove('light', 'dark');
            document.documentElement.classList.add(storedTheme);
        }
        return storedTheme;
    });

    const [selectedLLM, setSelectedLLM] = useState(localStorage.getItem('selectedLLM') || 'gemini');
    const [isLeftPanelOpen, setIsLeftPanelOpen] = useState(true);
    const [isRightPanelOpen, setIsRightPanelOpen] = useState(true);

    const [currentSessionId, setCurrentSessionIdState] = useState(() => {
        return localStorage.getItem('aiTutorSessionId') || null;
    });
    const [systemPrompt, setSystemPromptState] = useState(
        localStorage.getItem('aiTutorSystemPrompt') || defaultSystemPromptText
    );

    const [selectedDocumentForAnalysis, setSelectedDocumentForAnalysisState] = useState(null);
    const [selectedSubject, setSelectedSubjectState] = useState(
        localStorage.getItem('aiTutorSelectedSubject') || null
    );

    const [isAdminSessionActive, setIsAdminSessionActiveState] = useState(() => {
        return sessionStorage.getItem('isAdminSessionActive') === 'true';
    });

    const toggleTheme = () => {
        setThemeState(prevTheme => {
            const newTheme = prevTheme === 'light' ? 'dark' : 'light';
            localStorage.setItem('theme', newTheme);
            return newTheme;
        });
    };

    const switchLLM = (llm) => {
         setSelectedLLM(llm);
         localStorage.setItem('selectedLLM', llm);
         console.log("AppStateContext: Switched LLM to:", llm);
    };

    const setSessionId = (sessionId) => {
        if (sessionId) {
            localStorage.setItem('aiTutorSessionId', sessionId);
        } else {
            console.log("AppStateContext: Clearing session and related context (logout).");
            localStorage.removeItem('aiTutorSessionId');
            
            localStorage.removeItem('aiTutorSelectedSubject'); 
            setSelectedSubjectState(null);
            
            setSelectedDocumentForAnalysisState(null);
        }
        setCurrentSessionIdState(sessionId);
        console.log("AppStateContext: Regular user session ID updated to:", sessionId);
    };

    const setSystemPrompt = (promptText) => {
        setSystemPromptState(promptText);
        localStorage.setItem('aiTutorSystemPrompt', promptText);
    };

    const selectDocumentForAnalysis = (documentFilename) => {
        setSelectedDocumentForAnalysisState(documentFilename);
        console.log("AppStateContext: Document for analysis tools set to:", documentFilename || "None");
        if (documentFilename && selectedSubject !== documentFilename) {
            if (selectedSubject !== null) {
                console.log("AppStateContext: Clearing selected subject because a specific user document was chosen for analysis tools.");
                setSelectedSubjectState(null);
                localStorage.removeItem('aiTutorSelectedSubject');
            }
        }
    };

    const setSelectedSubject = (subjectName) => {
        const newSubject = subjectName === "none" || !subjectName ? null : subjectName;
        if (newSubject) {
            localStorage.setItem('aiTutorSelectedSubject', newSubject);
        } else {
            localStorage.removeItem('aiTutorSelectedSubject');
        }
        setSelectedSubjectState(newSubject);
        console.log("AppStateContext: Selected subject (for chat RAG) updated to:", newSubject || "None");

        setSelectedDocumentForAnalysisState(newSubject);
        if (newSubject) {
             console.log("AppStateContext: Also set document for analysis tools to (admin subject):", newSubject);
        } else {
            if (selectedDocumentForAnalysis === subjectName) {
                 setSelectedDocumentForAnalysisState(null);
                 console.log("AppStateContext: Cleared document for analysis tools as linked subject was cleared.");
            }
        }
    };

    const setIsAdminSessionActive = (isActive) => {
        if (isActive) {
            sessionStorage.setItem('isAdminSessionActive', 'true');
            setSessionId(null); 
        } else {
            sessionStorage.removeItem('isAdminSessionActive');
        }
        setIsAdminSessionActiveState(isActive);
        console.log("AppStateContext: Admin session active status set to:", isActive);
    };

    useEffect(() => {
        const rootHtmlElement = document.documentElement;
        rootHtmlElement.classList.remove('light', 'dark');
        rootHtmlElement.classList.add(theme);
        document.body.className = '';
        document.body.classList.add(theme === 'dark' ? 'bg-background-dark' : 'bg-background-light');
    }, [theme]);

    return (
        <AppStateContext.Provider value={{
            theme, toggleTheme,
            selectedLLM, switchLLM,
            isLeftPanelOpen, setIsLeftPanelOpen,
            isRightPanelOpen, setIsRightPanelOpen,
            currentSessionId, setSessionId,
            systemPrompt, setSystemPrompt,
            selectedDocumentForAnalysis, selectDocumentForAnalysis,
            selectedSubject, setSelectedSubject,
            isAdminSessionActive, setIsAdminSessionActive
        }}>
            {children}
        </AppStateContext.Provider>
    );
};
```

`frontend/src/contexts/AuthContext.jsx`

```javascript
// frontend/src/contexts/AuthContext.jsx
import React, { createContext, useState, useEffect, useCallback } from 'react';
import api from '../services/api.js'; 
import toast from 'react-hot-toast';

export const AuthContext = createContext(null);

export const DEV_MODE_ALLOW_DEV_LOGIN = false;

export const AuthProvider = ({ children }) => {
    const [token, setTokenState] = useState(localStorage.getItem('authToken'));
    const [user, setUserState] = useState(null);
    const [loading, setLoading] = useState(true);

    const setToken = (newToken) => {
        if (newToken) localStorage.setItem('authToken', newToken);
        else localStorage.removeItem('authToken');
        setTokenState(newToken);
    };

    const setUser = (newUser) => setUserState(newUser);
    
    const processAuthData = useCallback((authApiResponse) => {
        if (authApiResponse && authApiResponse.token && authApiResponse._id && authApiResponse.email) {
            setToken(authApiResponse.token);
            setUser({ id: authApiResponse._id, email: authApiResponse.email });
            console.log("AuthContext: User and Token set.", { email: authApiResponse.email });
            return authApiResponse; 
        } else {
            setToken(null);
            setUser(null);
            console.error("AuthContext: processAuthData received incomplete data for a regular user.", authApiResponse);
            throw new Error("Authentication response from server was incomplete for a regular user.");
        }
    }, []);

    useEffect(() => {
        const verifyTokenAndLoadUser = async () => {
            const storedToken = localStorage.getItem('authToken');
            if (storedToken) {
                setTokenState(storedToken);
                try {
                    const userDataFromMe = await api.getMe();
                    if (userDataFromMe && userDataFromMe._id && userDataFromMe.email) {
                        setUser({ id: userDataFromMe._id, email: userDataFromMe.email });
                    } else {
                        setToken(null);
                        setUser(null);
                    }
                } catch (error) {
                    setToken(null);
                    setUser(null);
                }
            }
            setLoading(false);
        };
        verifyTokenAndLoadUser();
    }, []);

    const login = async (credentials) => {
        setLoading(true);
        try {
            const data = await api.login(credentials);
            // --- THIS IS THE FIX ---
            // If the response is a special case for admin login,
            // bypass the standard token processing and return it directly.
            if (data && data.isAdminLogin) {
                return data;
            }
            // Otherwise, process it as a regular user with a JWT token.
            return processAuthData(data);
            // --- END OF FIX ---
        } catch (error) {
            setToken(null); 
            setUser(null);
            throw error; 
        } finally {
            setLoading(false);
        }
    };
    
    const signup = async (signupData) => {
        setLoading(true);
        try {
            const data = await api.signup(signupData);
            return processAuthData(data); // Signup always returns a regular user
        } catch (error) {
            setToken(null);
            setUser(null);
            throw error;
        } finally {
            setLoading(false);
        }
    };

    const logout = () => {
        console.log("AuthContext: Logging out user.");
        setToken(null); 
        setUser(null);
        toast.success("You have been logged out.");
    };

    return (
        <AuthContext.Provider value={{ token, user, loading, login, signup, logout, setUser }}>
            {children}
        </AuthContext.Provider>
    );
};
```

`frontend/src/hooks/useAuth.jsx`

```javascript
import { useContext } from 'react';
import { AuthContext } from '../contexts/AuthContext';

export const useAuth = () => {
    const context = useContext(AuthContext);
    if (!context) {
        throw new Error('useAuth must be used within an AuthProvider');
    }
    return context;
};
```

`frontend/src/hooks/useTextToSpeech.js`

```javascript
// src/hooks/useTextToSpeech.js
import { useState, useEffect, useCallback, useRef } from 'react';
import { marked } from 'marked'; // To parse markdown for plain text

// Configure marked (if not already globally configured for this specific use)
// It's generally better if marked is configured once, e.g. in MessageBubble or a central place.
// Assuming marked is available and configured.

const getPlainTextFromMarkdown = (markdown) => {
  if (!markdown) return '';
  try {
    // A simpler approach for plain text extraction for TTS:
    // Render to a temporary element and get its text content.
    // This handles complex markdown structures reasonably well for speech.
    const tempDiv = document.createElement('div');
    tempDiv.innerHTML = marked.parse(markdown); // marked.parse() is synchronous
    let text = tempDiv.textContent || tempDiv.innerText || '';
    
    // Basic cleanup: remove excessive newlines/spaces that might make speech awkward
    text = text.replace(/\n+/g, ' '); // Replace newlines with spaces
    text = text.replace(/\s\s+/g, ' '); // Replace multiple spaces with single
    return text.trim();
  } catch (error) {
    console.error("Error parsing markdown for TTS:", error);
    return markdown; // Fallback to raw markdown if parsing fails
  }
};


export const useTextToSpeech = () => {
    const [isSpeaking, setIsSpeaking] = useState(false);
    const [isSupported, setIsSupported] = useState(false);
    const utteranceRef = useRef(null);

    useEffect(() => {
        if (typeof window !== 'undefined' && window.speechSynthesis) {
            setIsSupported(true);
        }

        const handleEnd = () => {
            setIsSpeaking(false);
            utteranceRef.current = null;
        };
        
        const synth = window.speechSynthesis;
        if (synth) {
            // Add event listeners if needed, but onend on utterance is usually sufficient
        }

        return () => {
            if (synth) {
                synth.cancel(); // Cancel any speech on component unmount or hook cleanup
            }
        };
    }, []);

    const speak = useCallback(({ text, lang = 'en-US', voiceURI = null, rate = 1, pitch = 1, volume = 1 }) => {
        if (!isSupported || !text) return;

        const synth = window.speechSynthesis;
        if (synth.speaking) {
            synth.cancel(); // Stop any currently playing speech
        }
        
        const plainText = getPlainTextFromMarkdown(text);
        if (!plainText) {
            console.warn("TTS: No text content to speak after parsing markdown.");
            return;
        }

        const newUtterance = new SpeechSynthesisUtterance(plainText);
        newUtterance.lang = lang;
        newUtterance.rate = rate;
        newUtterance.pitch = pitch;
        newUtterance.volume = volume;

        if (voiceURI) {
            const voices = synth.getVoices();
            const selectedVoice = voices.find(voice => voice.voiceURI === voiceURI);
            if (selectedVoice) {
                newUtterance.voice = selectedVoice;
            }
        }
        
        newUtterance.onstart = () => {
            setIsSpeaking(true);
        };
        newUtterance.onend = () => {
            setIsSpeaking(false);
            utteranceRef.current = null;
        };
        newUtterance.onerror = (event) => {
            console.error('SpeechSynthesisUtterance.onerror', event);
            setIsSpeaking(false);
            utteranceRef.current = null;
        };

        utteranceRef.current = newUtterance;
        synth.speak(newUtterance);
    }, [isSupported]);

    const cancel = useCallback(() => {
        if (!isSupported) return;
        const synth = window.speechSynthesis;
        if (synth.speaking) {
            synth.cancel();
        }
        // onend should fire and set isSpeaking to false.
        // If it doesn't (e.g. cancel is abrupt), manually reset:
        if (isSpeaking) {
            setIsSpeaking(false);
            utteranceRef.current = null;
        }
    }, [isSupported, isSpeaking]);

    // Optional: Get available voices
    const getVoices = useCallback(() => {
        if (!isSupported) return [];
        return window.speechSynthesis.getVoices();
    }, [isSupported]);

    // Voices might load asynchronously. Listen for 'voiceschanged' event.
    useEffect(() => {
        if (!isSupported) return;
        const synth = window.speechSynthesis;
        const loadVoices = () => {
            // You might want to store voices in state if your UI allows voice selection
            // console.log("Voices loaded:", synth.getVoices());
        };
        synth.addEventListener('voiceschanged', loadVoices);
        // Initial load if voices are already available
        if (synth.getVoices().length > 0) {
            loadVoices();
        }
        return () => synth.removeEventListener('voiceschanged', loadVoices);
    }, [isSupported]);


    return {
        speak,
        cancel,
        isSpeaking,
        isSupported,
        getVoices,
        currentlySpeakingUtterance: utteranceRef.current
    };
};
```

`frontend/src/hooks/useTheme.js`

```javascript
// import { useContext } from 'react';
// import { AppStateContext } from '../contexts/AppStateContext'; // Assuming theme is in AppStateContext

// export const useTheme = () => {
//     const context = useContext(AppStateContext);
//     if (!context) {
//         throw new Error('useTheme must be used within an AppStateProvider');
//     }
//     return { theme: context.theme, toggleTheme: context.toggleTheme };
// };


import { useContext } from 'react';
import { AppStateContext } from '../contexts/AppStateContext.jsx'; // Correct named import for the context object

export const useTheme = () => {
    const context = useContext(AppStateContext); // Use the imported context object
    if (!context) {
        throw new Error('useTheme must be used within an AppStateProvider');
    }
    return { theme: context.theme, toggleTheme: context.toggleTheme };
};
```

`frontend/src/hooks/useTypingEffect.js`

```javascript
// frontend/src/hooks/useTypingEffect.js
import { useState, useEffect, useRef } from 'react';

/**
 * A custom hook to create a typing animation effect for text.
 * @param {string} textToType The full string that should be typed out.
 * @param {number} [speed=20] The delay in milliseconds between each character.
 * @param {function} [onComplete] An optional callback to run when typing is finished.
 * @returns {string} The currently displayed text (which grows over time).
 */
export const useTypingEffect = (textToType, speed = 20, onComplete) => {
    const [displayedText, setDisplayedText] = useState('');
    const index = useRef(0);
    const onCompleteRef = useRef(onComplete);

    // Keep the onComplete callback reference fresh
    useEffect(() => {
        onCompleteRef.current = onComplete;
    }, [onComplete]);

    useEffect(() => {
        // Reset the typing effect when the text to type changes
        setDisplayedText('');
        index.current = 0;

        const intervalId = setInterval(() => {
            if (index.current < textToType.length) {
                setDisplayedText(prev => prev + textToType.charAt(index.current));
                index.current++;
            } else {
                clearInterval(intervalId);
                if (onCompleteRef.current) {
                    onCompleteRef.current(); // Call the onComplete callback
                }
            }
        }, speed);

        return () => clearInterval(intervalId);
    }, [textToType, speed]);

    return displayedText;
};
```

`frontend/src/hooks/useWebSpeech.js`

```javascript
// src/hooks/useWebSpeech.js
import { useState, useEffect, useCallback } from 'react';

const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

export const useWebSpeech = () => {
    const [transcript, setTranscript] = useState('');
    const [listening, setListening] = useState(false);
    const [recognitionInstance, setRecognitionInstance] = useState(null);
    const [error, setError] = useState(null); // Added error state
    const isSpeechSupported = !!SpeechRecognition;

    useEffect(() => {
        if (!isSpeechSupported) {
            console.warn("Web Speech API is not supported by this browser.");
            return;
        }

        const recognition = new SpeechRecognition();
        recognition.continuous = false; // Set to true if you want it to keep listening
        recognition.interimResults = false; // Set to true for live results
        recognition.lang = 'en-US';

        recognition.onresult = (event) => {
            const currentTranscript = Array.from(event.results)
                .map(result => result[0])
                .map(result => result.transcript)
                .join('');
            setTranscript(currentTranscript);
            setError(null); // Clear error on successful result
            // console.log("Voice input result:", currentTranscript);
        };

        recognition.onerror = (event) => {
            console.error("Speech recognition error:", event.error);
            let errorMessage = event.error;
            if (event.error === 'no-speech') errorMessage = "No speech detected. Please try again.";
            else if (event.error === 'audio-capture') errorMessage = "Audio capture failed. Check microphone.";
            else if (event.error === 'not-allowed') errorMessage = "Microphone permission denied.";
            else if (event.error === 'network') errorMessage = "Network error during speech recognition.";
            // Add more specific error messages as needed
            
            setError(errorMessage);
            setListening(false);
        };

        recognition.onend = () => {
            setListening(false);
            // console.log("Speech recognition ended.");
        };
        
        setRecognitionInstance(recognition);

        // Cleanup
        return () => {
            if (recognition) {
                recognition.abort(); // Use abort to stop and discard results if component unmounts
            }
        };
    }, [isSpeechSupported]);

    const startListening = useCallback(() => {
        if (recognitionInstance && !listening) {
            try {
                setTranscript(''); // Clear previous transcript
                setError(null); // Clear previous errors
                recognitionInstance.start();
                setListening(true);
                // console.log("Speech recognition started.");
            } catch (e) {
                // This catch might be for synchronous errors during .start() call,
                // most errors are handled by recognition.onerror
                console.error("Error starting speech recognition:", e);
                setError("Could not start voice input.");
                setListening(false); // Ensure listening state is correct
            }
        }
    }, [recognitionInstance, listening]);

    const stopListening = useCallback(() => {
        if (recognitionInstance && listening) {
            recognitionInstance.stop(); // Stop and process any captured audio
            // setListening(false) will be called by onend event
            // console.log("Speech recognition stopped manually.");
        }
    }, [recognitionInstance, listening]);

    const resetTranscript = useCallback(() => {
        setTranscript('');
    }, []);


    return {
        transcript,
        listening,
        isSpeechSupported,
        startListening,
        stopListening,
        resetTranscript,
        error // Expose error state
    };
};
```

`frontend/src/index.css`

```css
/* src/index.css */
@tailwind base;
@tailwind components;
@tailwind utilities;

@layer base {
  html, body, #root { /* Apply to html, body, AND your React root div */
    @apply h-full overflow-hidden; /* Force full height and no scroll on these */
  }

  html {
    -webkit-font-smoothing: antialiased;
    -moz-osx-font-smoothing: grayscale;
    scroll-behavior: smooth; /* This is fine, affects internal scrolls */
  }

  body {
    @apply bg-background-light text-text-light transition-colors duration-300;
    font-family: theme('fontFamily.sans');
    /* overflow-hidden is now applied via the html, body, #root rule above */
  }

  html.dark body {
    @apply bg-background-dark text-text-dark;
  }
  html.light body {
    @apply bg-background-light text-text-light;
  }

  .custom-scrollbar {
     @apply scrollbar-thin scrollbar-thumb-secondary dark:scrollbar-thumb-secondary-dark scrollbar-track-surface-light dark:scrollbar-track-gray-800 scrollbar-thumb-rounded-full scrollbar-track-rounded-full;
  }

  /* --- Enhanced Prose Styles --- */
  .prose {
    @apply max-w-none text-text-light dark:text-text-dark;
  }
  .prose, .prose-sm {
    /* Headings */
    h1 { @apply text-2xl sm:text-3xl font-extrabold mb-6 mt-2 text-text-light dark:text-text-dark; }
    h2 { @apply text-xl sm:text-2xl font-bold mb-4 mt-8 border-b border-border-light dark:border-border-dark pb-2; }
    h3 { @apply text-lg sm:text-xl font-semibold mb-3 mt-6; }
    h4 { @apply text-base sm:text-lg font-semibold mb-2 mt-4; }

    /* Paragraphs */
    p { @apply mb-4 leading-relaxed; }

    /* Links */
    a { @apply text-primary dark:text-primary-light hover:underline font-medium; }
    pre a, pre code a { @apply text-inherit no-underline hover:text-inherit; }

    /* Lists */
    ul, ol { @apply pl-5 mb-4 space-y-1; }
    ul { @apply list-disc; }
    ol { @apply list-decimal; }
    li { @apply mb-1; }
    ul ul, ol ol, ul ol, ol ul { @apply pl-5 mt-1 mb-1; }
    li::marker { @apply text-text-muted-light dark:text-text-muted-dark; }

    /* --- GFM Task List Checkboxes - Custom GREEN Styling --- */
    li:has(> input[type="checkbox"]) {
      @apply flex items-center;
      list-style-type: none;
      margin-left: -1.25rem; /* Adjust as needed for alignment */
      padding-left: 0;
    }

    li > input[type="checkbox"] {
      @apply opacity-0 w-0 h-0 absolute;
    }

    li:has(> input[type="checkbox"])::before {
      content: "";
      @apply inline-block w-4 h-4 border-2 rounded-sm mr-2 align-middle flex-shrink-0;
      @apply bg-surface-light dark:bg-gray-700;
      @apply border-border-light dark:border-border-dark;
      transition: all 0.15s ease-in-out;
    }

    li:has(> input[type="checkbox"]:checked)::before {
      @apply bg-green-500 dark:bg-green-600 border-green-500 dark:border-green-600;
      background-image: url("data:image/svg+xml,%3csvg viewBox='0 0 16 16' fill='white' xmlns='http://www.w3.org/2000/svg'%3e%3cpath d='M12.207 4.793a1 1 0 010 1.414l-5 5a1 1 0 01-1.414 0l-2-2a1 1 0 011.414-1.414L6.5 9.086l4.293-4.293a1 1 0 011.414 0z'/%3e%3c/svg%3e");
      background-size: 70% 70%;
      background-position: center;
      background-repeat: no-repeat;
    }

    li:has(> input[type="checkbox"]:disabled:not(:checked))::before {
      @apply opacity-60 cursor-not-allowed;
      @apply bg-gray-100 dark:bg-gray-600 border-gray-300 dark:border-gray-500;
    }

    li:has(> input[type="checkbox"]:checked:disabled)::before {
      @apply bg-green-500/70 dark:bg-green-600/70 border-green-500/70 dark:border-green-600/70;
      opacity: 0.75;
      cursor: not-allowed;
    }


    /* Blockquotes */
    blockquote {
      @apply border-l-4 border-primary dark:border-primary-light pl-4 py-2 my-4 italic text-text-muted-light dark:text-text-muted-dark bg-surface-light dark:bg-gray-800/30 rounded-r-md;
    }
    blockquote p { @apply mb-0; }

    /* Horizontal Rules */
    hr { @apply my-8 border-t border-border-light dark:border-border-dark; }

    /* Tables */
    table { @apply w-full my-6 text-sm border-collapse; }
    thead { @apply border-b-2 border-border-light dark:border-border-dark; }
    th {
      @apply px-4 py-2.5 text-left font-semibold text-text-light dark:text-text-dark bg-gray-100 dark:bg-gray-700/50;
      @apply border border-border-light dark:border-border-dark;
    }
    tbody tr { @apply border-b border-border-light dark:border-border-dark; }
    tbody tr:last-child { @apply border-b-0; }
    tbody tr:nth-child(even) { @apply bg-gray-50 dark:bg-gray-800/20; }
    td { @apply px-4 py-2.5 text-left border-x border-border-light dark:border-border-dark; }
    td code { @apply text-xs; }
    td strong { @apply font-semibold; }

    /* --- Code Styling --- */
    code:not(pre code) {
      @apply px-1.5 py-0.5 bg-primary/10 dark:bg-primary-dark/20 text-primary dark:text-primary-light rounded-md text-xs font-mono break-words;
    }
    code:not(pre code)::before, code:not(pre code)::after { content: ''; }

    pre {
      @apply bg-[#282c34] dark:bg-[#21252b] p-4 rounded-lg shadow-md overflow-x-auto custom-scrollbar my-5;
    }
    pre code {
      @apply bg-transparent p-0 font-mono text-sm leading-relaxed;
      color: #abb2bf;
      white-space: pre-wrap;
      word-break: break-all;
    }

    strong { @apply font-semibold text-text-light dark:text-text-dark; }
  }
}

@layer components {
  /* ... your existing btn, input-field, form-checkbox, card styles ... */
  /* The li:has(> input[type="checkbox"]) from your paste was misplaced, it should be within .prose */

  /* I will keep your existing .form-checkbox rules here as they might be used by other non-prose forms */
  .btn {
    @apply font-semibold py-2 px-4 rounded-lg shadow-sm focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-opacity-75 transition-all duration-150 ease-in-out flex items-center justify-center gap-2 disabled:opacity-60 disabled:cursor-not-allowed;
  }
  html.dark .btn { @apply focus:ring-offset-background-dark; }
  html:not(.dark) .btn { @apply focus:ring-offset-background-light; }

  .btn-primary { @apply btn bg-primary text-white hover:bg-primary-dark focus:ring-primary; }
  .btn-secondary { @apply btn bg-secondary text-white hover:bg-secondary-dark focus:ring-secondary; }
  .btn-ghost { @apply btn text-text-muted-light dark:text-text-muted-dark hover:bg-gray-500 hover:bg-opacity-10 focus:ring-primary; }

  .input-field {
    @apply block w-full px-3 py-2 bg-surface-light dark:bg-gray-700 border border-border-light dark:border-border-dark rounded-md text-sm shadow-sm placeholder-text-muted-light dark:placeholder-text-muted-dark
           focus:outline-none focus:border-primary dark:focus:border-primary-light focus:ring-1 focus:ring-primary dark:focus:ring-primary-light;
  }
  .form-input, .form-textarea, .form-select, .form-multiselect { @apply input-field; }

  .form-checkbox, .form-radio {
    @apply rounded shadow-sm border-border-light dark:border-border-dark text-primary focus:ring-primary dark:focus:ring-primary-light;
    @apply bg-surface-light dark:bg-gray-600;
  }
  .form-checkbox:disabled, .form-radio:disabled {
    @apply opacity-70 bg-gray-200 dark:bg-gray-700 border-gray-300 dark:border-gray-600;
  }

  .card-base {
    @apply border rounded-panel shadow-panel;
    @apply bg-surface-light dark:bg-surface-dark border-border-light dark:border-border-dark;
  }
  .card-header-base {
    @apply px-4 py-3 text-sm font-semibold border-b;
    @apply text-text-light dark:text-text-dark border-border-light dark:border-border-dark;
  }
}
```

`frontend/src/main.jsx`

```javascript
import React from 'react';
import ReactDOM from 'react-dom/client';
import AppWrapper from './App.jsx';
import { AuthProvider } from './contexts/AuthContext.jsx'; // For regular users
import { AppStateProvider } from './contexts/AppStateContext.jsx';
import { Toaster } from 'react-hot-toast';
import './index.css';

import 'prismjs/themes/prism-okaidia.css';
import 'katex/dist/katex.min.css';
import Prism from 'prismjs'; 
import 'prismjs/components/prism-python';
import 'prismjs/components/prism-javascript';
import 'prismjs/components/prism-jsx';
import 'prismjs/components/prism-css';
import 'prismjs/components/prism-markup'; 
import 'prismjs/components/prism-json';
import 'prismjs/components/prism-bash';
import 'prismjs/components/prism-csharp';
import 'prismjs/components/prism-java';


ReactDOM.createRoot(document.getElementById('root')).render(
  <React.StrictMode>
    <AuthProvider>
      <AppStateProvider>
        <AppWrapper />
      </AppStateProvider>
    </AuthProvider>
  </React.StrictMode>,
);
```

`frontend/src/services/adminApi.js`

```javascript
// frontend/src/services/adminApi.js
import axios from 'axios';

// Get base URL for admin document endpoints
const ADMIN_DOCS_API_BASE_URL = `${import.meta.env.VITE_API_BASE_URL || 'http://localhost:5001/api'}/admin/documents`;

// Get fixed admin credentials from .env (prefixed with VITE_ for frontend access)
const ADMIN_USERNAME_FRONTEND = import.meta.env.VITE_ADMIN_USERNAME || 'admin';
const ADMIN_PASSWORD_FRONTEND = import.meta.env.VITE_ADMIN_PASSWORD || 'admin123';

const adminApiClient = axios.create({
    baseURL: ADMIN_DOCS_API_BASE_URL,
});

export const getFixedAdminAuthHeaders = () => {
    if (!ADMIN_USERNAME_FRONTEND || !ADMIN_PASSWORD_FRONTEND) {
        console.error("Admin credentials not found in VITE_ADMIN_USERNAME or VITE_ADMIN_PASSWORD .env variables for frontend.");
        return {};
    }
    const basicAuthToken = btoa(`${ADMIN_USERNAME_FRONTEND}:${ADMIN_PASSWORD_FRONTEND}`);
    return { 'Authorization': `Basic ${basicAuthToken}` };
};

const makeAdminApiRequest = async (method, endpoint, data = null, authHeaders = {}) => {
    if (!authHeaders.Authorization) {
        const errorMsg = "Admin authentication headers are missing. Cannot make admin API request.";
        console.error(errorMsg);
        throw new Error(errorMsg);
    }
    try {
        const config = {
            method,
            url: endpoint,
            headers: {
                ...authHeaders,
                'Content-Type': data instanceof FormData ? 'multipart/form-data' : 'application/json',
            },
        };
        if (data) {
            config.data = data;
        }
        const response = await adminApiClient(config);
        return response.data;
    } catch (error) {
        let errorMessage = 'Admin API request failed.';
        if (error.response) {
            errorMessage = error.response.data?.message || error.response.statusText || `Server error: ${error.response.status}`;
            console.error(`Admin API Error (${method.toUpperCase()} ${ADMIN_DOCS_API_BASE_URL}${endpoint}): Status ${error.response.status}`, error.response.data);
        } else if (error.request) {
            errorMessage = 'No response from admin API server. Check network or server status.';
            console.error(`Admin API Network Error (${method.toUpperCase()} ${ADMIN_DOCS_API_BASE_URL}${endpoint}):`, error.request);
        } else {
            errorMessage = error.message || 'Error setting up admin API request.';
            console.error(`Admin API Setup Error (${method.toUpperCase()} ${ADMIN_DOCS_API_BASE_URL}${endpoint}):`, error.message);
        }
        throw new Error(errorMessage);
    }
};

export const uploadAdminDocument = async (formData, adminAuthHeaders) => {
    return makeAdminApiRequest('post', '/upload', formData, adminAuthHeaders);
};

export const getAdminDocuments = async (adminAuthHeaders) => {
    return makeAdminApiRequest('get', '/', null, adminAuthHeaders);
};

export const deleteAdminDocument = async (serverFilename, adminAuthHeaders) => {
    return makeAdminApiRequest('delete', `/${serverFilename}`, null, adminAuthHeaders);
};

export const getAdminDocumentAnalysis = async (serverFilename, adminAuthHeaders) => {
    return makeAdminApiRequest('get', `/${serverFilename}/analysis`, null, adminAuthHeaders);
};

// --- NEW FUNCTION FOR STEP 2 ---
export const getAdminDocumentAnalysisByOriginalName = async (originalName, adminAuthHeaders) => {
    // This function fetches the analysis object for an admin document using its originalName.
    // The backend route will be '/by-original-name/:originalName/analysis' relative to ADMIN_DOCS_API_BASE_URL.
    // It expects a response like:
    // { originalName, serverFilename, analysis: {faq, topics, mindmap}, analysisUpdatedAt }
    return makeAdminApiRequest('get', `/by-original-name/${encodeURIComponent(originalName)}/analysis`, null, adminAuthHeaders);
};
```

`frontend/src/services/api.js`

```javascript
// frontend/src/services/api.js
import axios from "axios";
import toast from "react-hot-toast";

const apiClient = axios.create({
  baseURL: import.meta.env.VITE_API_BASE_URL || "http://localhost:5001/api",
});

apiClient.interceptors.request.use(
  (config) => {
    const token = localStorage.getItem("authToken");
    if (token) {
      config.headers.Authorization = `Bearer ${token}`;
    }
    return config;
  },
  (error) => {
    return Promise.reject(error);
  }
);

apiClient.interceptors.response.use(
  (response) => response,
  (error) => {
    if (error.response && error.response.status === 401) {
      console.error("API Interceptor: Received 401 Unauthorized. Token might be invalid or expired.");
    }
    return Promise.reject(error);
  }
);

function parseAnalysisOutput(rawOutput) {
    if (!rawOutput || typeof rawOutput !== 'string') {
        return { content: '', thinking: '' };
    }
    const thinkingMatch = rawOutput.match(/<thinking>([\s\S]*?)<\/thinking>/i);
    let thinkingText = '';
    let mainContent = rawOutput;

    if (thinkingMatch && thinkingMatch[1]) {
        thinkingText = thinkingMatch[1].trim();
        mainContent = rawOutput.replace(/<thinking>[\s\S]*?<\/thinking>\s*/i, '').trim();
    }
    return { content: mainContent, thinking: thinkingText };
}

const api = {
  login: async (credentials) => {
    const response = await apiClient.post("/auth/signin", credentials);
    return response.data;
  },
  signup: async (userData) => {
    const response = await apiClient.post("/auth/signup", userData);
    return response.data;
  },
  getMe: async () => {
    const response = await apiClient.get("/auth/me");
    return response.data;
  },
  sendMessage: async (payload) => {
    const response = await apiClient.post("/chat/message", payload);
    return response.data;
  },
  getChatHistory: async (sessionId) => {
    const response = await apiClient.get(`/chat/session/${sessionId}`);
    return response.data;
  },
  getChatSessions: async () => {
    const response = await apiClient.get("/chat/sessions");
    return response.data;
  },
  startNewSession: async (previousSessionId) => {
    const response = await apiClient.post("/chat/history", { previousSessionId });
    return response.data;
  },
  deleteChatSession: async (sessionId) => {
    const response = await apiClient.delete(`/chat/session/${sessionId}`);
    return response.data;
  },
  uploadFile: async (formData, onUploadProgress) => {
    const response = await apiClient.post("/upload", formData, {
      headers: { "Content-Type": "multipart/form-data" },
      onUploadProgress,
    });
    return response.data;
  },
  getFiles: async () => {
    const response = await apiClient.get("/files");
    return response.data;
  },
  deleteFile: async (serverFilename) => {
    const response = await apiClient.delete(`/files/${serverFilename}`);
    return response.data;
  },
  updateUserLLMConfig: async (configData) => {
    console.log("[Frontend API] Sending LLM config update:", configData);
    const response = await apiClient.put("/llm/config", configData);
    return response.data;
  },
  getOrchestratorStatus: async () => {
    try {
      const response = await apiClient.get("/network/ip");
      return { status: "ok", message: `Backend Online at ${response.data.ips[0]}` };
    } catch (e) {
      return { status: "error", message: "Backend Unreachable" };
    }
  },
  getUserProfile: async () => {
    const response = await apiClient.get("/user/profile");
    return response.data;
  },
  updateUserProfile: async (profileData) => {
    const response = await apiClient.put("/user/profile", profileData);
    return response.data;
  },
  getSubjects: async () => {
    const response = await apiClient.get("/subjects");
    return response.data;
  },
  requestAnalysis: async (payload) => {
    const { filename, analysis_type } = payload;
    if (!filename || !analysis_type) {
      throw new Error("Filename and analysis type are required.");
    }
    const toastId = toast.loading(`Generating ${analysis_type} for "${filename}"...`);
    try {
      const response = await apiClient.get(`/analysis/${encodeURIComponent(filename)}`);
      const fullAnalysisObject = response.data;
      const rawOutput = fullAnalysisObject[analysis_type];
      if (!rawOutput || typeof rawOutput !== 'string' || rawOutput.trim() === "") {
         toast.success(`No stored ${analysis_type} found for "${filename}".`, { id: toastId });
         return {
            content: `Notice: Analysis for '${analysis_type}' has not been generated yet or was empty.`,
            thinking: "No analysis data found in the database for this type."
         };
      }
      const { content, thinking } = parseAnalysisOutput(rawOutput);
      toast.success(`Successfully generated ${analysis_type} for "${filename}".`, { id: toastId });
      return { content, thinking };
    } catch (error) {
      const errorMessage = error.response?.data?.message || error.message || 'Unknown error';
      toast.error(`Error generating ${analysis_type}: ${errorMessage}`, { id: toastId });
      throw error;
    }
  },
  generateDocument: async ({ markdownContent, docType, sourceDocumentName }) => {
    const response = await apiClient.post('/generate/document', 
      { markdownContent, docType, sourceDocumentName },
      { responseType: 'blob' }
    );
    const contentDisposition = response.headers['content-disposition'];
    let filename = `generated-document.${docType}`;
    if (contentDisposition) {
        const filenameMatch = contentDisposition.match(/filename="?(.+)"?/);
        if (filenameMatch && filenameMatch.length > 1) {
            filename = filenameMatch[1];
        }
    }
    return { fileBlob: response.data, filename: filename };
  },
  generatePodcast: async ({ analysisContent, sourceDocumentName, podcastOptions }) => {
    const response = await apiClient.post('/export/podcast', 
      { analysisContent, sourceDocumentName, podcastOptions },
      { responseType: 'blob' }
    );
    return { audioBlob: response.data, sourceDocumentName };
  },
  getKnowledgeGraph: async (documentName) => {
    const response = await apiClient.get(`/kg/visualize/${encodeURIComponent(documentName)}`);
    return response.data;
  },
};

export default api;
```

`frontend/src/utils/helpers.js`

```javascript
// Debounce function: Limits the rate at which a function can fire.
import { marked } from 'marked';

export const getPlainTextFromMarkdown = (markdown) => {
  if (!markdown) return '';
  try {
    const html = marked.parse(markdown);
    const tempDiv = document.createElement('div');
    tempDiv.innerHTML = html;
    // .textContent correctly extracts text and preserves line breaks from block elements
    return tempDiv.textContent || '';
  } catch (error) {
    console.error("Error converting markdown to plain text:", error);
    return markdown; // Fallback to raw markdown on error
  }
};


export const debounce = (func, delay) => {
    let timeoutId;
    return function(...args) {
        const context = this;
        clearTimeout(timeoutId);
        timeoutId = setTimeout(() => func.apply(context, args), delay);
    };
};

// Throttle function: Ensures a function is called at most once in a specified time period.
export const throttle = (func, limit) => {
    let inThrottle;
    let lastFunc;
    let lastRan;
    return function(...args) {
        const context = this;
        if (!inThrottle) {
            func.apply(context, args);
            lastRan = Date.now();
            inThrottle = true;
            setTimeout(() => {
                inThrottle = false;
                if (lastFunc) {
                    lastFunc.apply(context, args); // Call with latest args if throttled
                    lastRan = Date.now();
                }
            }, limit);
        } else {
            lastFunc = func; // Store the latest call
        }
    };
};

// Simple function to format file size
export const formatFileSize = (bytes, decimals = 2) => {
    if (bytes === 0) return '0 Bytes';
    const k = 1024;
    const dm = decimals < 0 ? 0 : decimals;
    const sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB', 'PB', 'EB', 'ZB', 'YB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return parseFloat((bytes / Math.pow(k, i)).toFixed(dm)) + ' ' + sizes[i];
};

// Function to generate a simple unique ID (for client-side list keys, etc.)
export const generateUniqueId = (prefix = 'id') => {
    return `${prefix}-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
};

// Function to safely get nested property
export const getNestedValue = (obj, path, defaultValue = undefined) => {
    const value = path.split('.').reduce((acc, part) => acc && acc[part], obj);
    return value === undefined ? defaultValue : value;
};

// Basic HTML escape (can be more comprehensive)
export const escapeHtml = (unsafe) => {
    if (typeof unsafe !== 'string') return '';
    return unsafe
         .replace(/&/g, "&")
         .replace(/</g, "<")
         .replace(/>/g, ">")
         .replace(/"/g, `"`)
         .replace(/'/g, "'");
};

// You can add more utility functions here as your project grows.
// For example, date formatting, string manipulation, etc.

// Example: Truncate text
export const truncateText = (text, maxLength = 100) => {
    if (!text || text.length <= maxLength) return text;
    return text.substring(0, maxLength) + '...';
};
```

`frontend/src/utils/markdownUtils.jsx`

```javascript
// src/utils/markdownUtils.jsx
import katex from 'katex';
import DOMPurify from 'dompurify';

const decodeHtmlEntities = (encodedString) => {
  if (typeof encodedString !== 'string') return encodedString;

  const textarea = document.createElement('textarea');
  textarea.innerHTML = encodedString;
  return textarea.value;
};

export const renderMathInHtml = (htmlString) => {
  if (!htmlString || typeof htmlString !== 'string') return htmlString;

  let processedString = htmlString;
  processedString = processedString.replace(/(?<!\\)\$\$([\s\S]+?)(?<!\\)\$\$/g, (match, rawExpression) => {
    const expression = decodeHtmlEntities(rawExpression.trim());
    try {
      const rendered = katex.renderToString(expression, { 
        displayMode: true, 
        throwOnError: false,
        macros: {"\\RR": "\\mathbb{R}"} 
      });
      return DOMPurify.sanitize(rendered, { USE_PROFILES: { mathMl: true, svg: true, html: true } });
    } catch (e) { 
      console.warn(`KaTeX (display) error: ${e.message} for expression: ${expression}`); 
      return match; 
    }
  });

  processedString = processedString.replace(/(^|[^$\\])\$(?![\s$])([^$\n]+?)(?<![\s\\])\$([^\$]|$)/g, (fullMatch, prefix, rawExpression, suffix) => {
    const expression = decodeHtmlEntities(rawExpression.trim());
    if (!expression) return fullMatch; 
    try {
      const rendered = katex.renderToString(expression, { 
        displayMode: false, 
        throwOnError: false,
        macros: {"\\RR": "\\mathbb{R}"}
      });
      return prefix + DOMPurify.sanitize(rendered, { USE_PROFILES: { mathMl: true, svg: true, html: true } }) + suffix;
    } catch (e) { 
      console.warn(`KaTeX (inline) error: ${e.message} for expression: ${expression}`);
      return fullMatch; 
    }
  });
  
  return processedString;
};
```

`frontend/tailwind.config.js`

```javascript
// tailwind.config.js
/** @type {import('tailwindcss').Config} */
export default {
  content: [
    "./index.html",
    "./src/**/*.{js,ts,jsx,tsx}",
  ],
  darkMode: 'class',
  safelist: [
    'prose',
    'prose-sm',
    'dark:prose-invert',
  ],
  theme: {
    extend: {
      colors: {
        'primary': { light: '#60a5fa', DEFAULT: '#3b82f6', dark: '#2563eb' },
        'secondary': { light: '#9ca3af', DEFAULT: '#6b7280', dark: '#4b5563' },
        'accent': '#2dd4bf',
        'background-dark': '#0F172A', 'surface-dark': '#1E293B', 'border-dark': '#334155', 'text-dark': '#E2E8F0', 'text-muted-dark': '#94A3B8',
        'background-light': '#F8FAFC', 'surface-light': '#FFFFFF', 'border-light': '#E2E8F0', 'text-light': '#0F172A', 'text-muted-light': '#64748B',
      },
      fontFamily: {
        sans: ['"Inter var"', 'Inter', 'system-ui', 'sans-serif'],
      },
      boxShadow: {
        'main': '0 4px 15px -5px rgba(0,0,0,0.07), 0 2px 8px -6px rgba(0,0,0,0.07)',
        'panel': '0 8px 20px -5px rgba(0,0,0,0.1), 0 4px 10px -6px rgba(0,0,0,0.08)',
        'card-hover': '0 6px 18px -4px rgba(0,0,0,0.1), 0 3px 10px -5px rgba(0,0,0,0.1)',
      },
      borderRadius: { 'xl': '0.75rem', '2xl': '1rem', 'panel': '0.75rem' },
      keyframes: {
        fadeIn: { '0%': { opacity: '0', transform: 'translateY(5px)' }, '100%': { opacity: '1', transform: 'translateY(0px)' } },
        slideUp: { '0%': { transform: 'translateY(10px)', opacity: '0' }, '100%': { transform: 'translateY(0)', opacity: '1' } },
        pulseDots: {
          '0%, 100%': { opacity: '0.3', transform: 'scale(0.8)' },
          '50%': { opacity: '1', transform: 'scale(1)' },
        }
      },
      animation: {
        fadeIn: 'fadeIn 0.3s ease-out forwards',
        slideUp: 'slideUp 0.4s ease-out forwards',
        pulseDot1: 'pulseDots 1.4s infinite 0s ease-in-out',
        pulseDot2: 'pulseDots 1.4s infinite 0.2s ease-in-out',
        pulseDot3: 'pulseDots 1.4s infinite 0.4s ease-in-out',
      }
    },
  },
  plugins: [
    require('@tailwindcss/forms')({ strategy: 'class' }),
    require('tailwind-scrollbar')({ nocompatible: true }),
    require('@tailwindcss/typography'),
  ],
}
```

`frontend/vite.config.js`

```javascript
// vite.config.js
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

// https://vite.dev/config/
export default defineConfig({
  plugins: [react()],
  // --- ADD THIS SECTION TO FIX THE "global is not defined" ERROR ---
  define: {
    'global': {},
  }
})
```

`jv.txt`

```


Arrays


The memory of the instance of arrays is extended as we are storing the values in the array.


Methods available in Arrays

1. Arrays.sort(arr)
2. Arrays.toString(arr)
3. Arrays.copyOf(arr, size)
4. Arrays.copyOfRange(arr, from, to)
5. Arrays.equals(arr1, arr2)
6. Arrays.fill(arr, value)
7. Arrays.binarySearch(arr, key)
8. Arrays.deepToString(arr)
9. Arrays.setAll(arr, i -> i*i)



Jagged Arrays
--------------

** It is an array of arrays where each row can have different lengths

int[][] jagged = new int[3][];

jagged[1] = new int[4]
jagged[2] = new int[3]


```

`server/.env`

```
#server env

PORT=5001
MONGO_URI="mongodb://localhost:27017/chatbot_gemini"
JWT_SECRET="your_super_strong_and_secret_jwt_key_12345"
# ENCRYPTION_SECRET=your_generated_64_character_hex_string_here
GEMINI_API_KEY="AIzaSyDUZLRuzhdmVRCPkyDsJ_3JE6OqCJEWxiU"
PYTHON_RAG_SERVICE_URL="http://127.0.0.1:5000"
# OLLAMA_API_BASE_URL="http://172.180.9.187:11434"
OLLAMA_API_BASE_URL="https://angels-himself-fixtures-unknown.trycloudflare.com"
OLLAMA_DEFAULT_MODEL="qwen2.5:14b-instruct"
ENCRYPTION_SECRET=583c0c57ffbb993163e28273671daebf880eb972d6d1402613be9da09a5297e2

# --- Admin credentials for Basic Auth on admin routes ---
FIXED_ADMIN_USERNAME=admin@admin.com
FIXED_ADMIN_PASSWORD=admin123
```

`server/code.txt`

```
`.env`

```
PORT=5001 # Port for the backend (make sure it's free)
MONGO_URI = "mongodb://localhost:27017/chatbot_gemini" # Your MongoDB connection string
JWT_SECRET = "your_super_strong_and_secret_jwt_key_12345" # A strong, random secret key for JWT
GEMINI_API_KEY = "AIzaSyDlY5AEMPkwcIDxIcT5d2kYf8_reuJbFVc" # Your actual Gemini API Key
PYTHON_RAG_SERVICE_URL = "http://127.0.0.1:5000"
KG_GENERATION_BATCH_SIZE=25
OLLAMA_API_BASE_URL="http://172.180.9.187:11434"
OLLAMA_DEFAULT_MODEL="qwen2.5:14b-instruct"


```

`code.txt`

```

```

`config/db.js`

```javascript
const mongoose = require('mongoose');
// const dotenv = require('dotenv'); // Removed dotenv

// dotenv.config(); // Removed dotenv

// Modified connectDB to accept the URI as an argument
const connectDB = async (mongoUri) => {
  if (!mongoUri) {
      console.error('MongoDB Connection Error: URI is missing.');
      process.exit(1);
  }
  try {
    // console.log(`Attempting MongoDB connection to: ${mongoUri}`); // Debug: Careful logging URI
    const conn = await mongoose.connect(mongoUri, {
      // Mongoose 6+ uses these defaults, so they are not needed
      // useNewUrlParser: true,
      // useUnifiedTopology: true,
      // serverSelectionTimeoutMS: 5000 // Example: Optional: Timeout faster
    });

    console.log(` MongoDB Connected Successfully`); // Simpler success message
    return conn; // Return connection object if needed elsewhere
  } catch (error) {
    console.error('MongoDB Connection Error:', error.message);
    // Exit process with failure
    process.exit(1);
  }
};

module.exports = connectDB;

```

`config/promptTemplates.js`

```javascript
// server/config/promptTemplates.js

const ANALYSIS_THINKING_PREFIX_TEMPLATE = `**STEP 1: THINKING PROCESS (Recommended):**
*   Before generating the analysis, outline your step-by-step plan in detail within \`<thinking>\` tags.
*   Use Markdown for formatting within your thinking process (e.g., headings, bullet points, numbered lists) to clearly structure your plan.
*   Example of detailed thinking:
    \`\`\`
    <thinking>
    ## FAQ Generation Plan
    1.  **Understand Goal:** Generate 5-7 FAQs based *only* on the provided text.
    2.  **Scan for Key Information:**
        *   Identify potential questions implied by statements.
        *   Look for definitions, explanations, or problem/solution pairings.
    3.  **Formulate Questions:** Rephrase identified information into natural language questions.
    4.  **Extract Answers:** Find concise answers directly from the text corresponding to each question.
    5.  **Format Output:** Ensure each Q/A pair follows the 'Q: ... A: ...' format.
    6.  **Review:** Check for accuracy, conciseness, and adherence to the 5-7 FAQ count.
    </thinking>
    \`\`\`
*   If you include thinking, place the final analysis *after* the \`</thinking>\` tag.

**STEP 2: ANALYSIS OUTPUT:**
*   Generate the requested analysis based **strictly** on the text provided below.
*   Follow the specific OUTPUT FORMAT instructions carefully.

--- START DOCUMENT TEXT ---
{doc_text_for_llm}
--- END DOCUMENT TEXT ---
`;

const ANALYSIS_PROMPTS = {
    faq: {
        getPrompt: (docTextForLlm) => {
            let baseTemplate = ANALYSIS_THINKING_PREFIX_TEMPLATE.replace('{doc_text_for_llm}', docTextForLlm);
            baseTemplate += `
**TASK:** Generate 5-7 Frequently Asked Questions (FAQs) with concise answers based ONLY on the provided text.

**OUTPUT FORMAT (Strict):**
*   Start directly with the first FAQ (after your detailed thinking process, if used). Do **NOT** include any preamble before the first 'Q:'.
*   Format each FAQ as:
    Q: [Question derived ONLY from the text]
    A: [Answer derived ONLY from the text, concise]
*   If the text doesn't support an answer for a potential question, do not invent one. Stick to what's explicitly stated or directly implied.
*   Use Markdown for formatting within answers if appropriate (e.g., lists).

**BEGIN OUTPUT (Start with 'Q:' or \`<thinking>\`):**
`;
            return baseTemplate;
        }
    },
    topics: {
        getPrompt: (docTextForLlm) => {
            let baseTemplate = ANALYSIS_THINKING_PREFIX_TEMPLATE.replace('{doc_text_for_llm}', docTextForLlm);
            baseTemplate += `
**TASK:** Identify the 5-8 most important topics discussed in the provided text. For each topic, provide a 1-2 sentence explanation based ONLY on the text.

**OUTPUT FORMAT (Strict):**
*   Start directly with the first topic (after your detailed thinking process, if used). Do **NOT** include any preamble before the first bullet point.
*   Format as a Markdown bulleted list:
    *   **Topic Name:** Brief explanation derived ONLY from the text content (1-2 sentences max).

**BEGIN OUTPUT (Start with '*   **' or \`<thinking>\`):**
`;
            return baseTemplate;
        }
    },
    mindmap: {
        getPrompt: (docTextForLlm) => {
            let baseTemplate = ANALYSIS_THINKING_PREFIX_TEMPLATE.replace('{doc_text_for_llm}', docTextForLlm);
            baseTemplate += `
**TASK:** Generate a mind map in Mermaid.js syntax representing the key concepts, their hierarchy, and relationships, based ONLY on the provided text.

**CORE REQUIREMENTS FOR MERMAID SYNTAX:**
1.  **Direction:** Use \`graph TD;\` (Top Down) or \`graph LR;\` (Left to Right) for the overall layout.
2.  **Nodes:**
    *   Define unique IDs for each node (e.g., \`A\`, \`B\`, \`C1\`, \`ConceptNameID\`). IDs should be short and alphanumeric.
    *   Node labels should be concise and derived from the text (e.g., \`A["Main Idea from Text"]\`, \`B("Key Concept 1")\`, \`C{"Another Concept"}\`).
3.  **Edges (Connections):** Show relationships using \`-->\` (e.g., \`A --> B\`).
4.  **Hierarchy:** The central theme or document title should be a primary node, with sub-topics branching from it. Deeper sub-topics should branch further.
5.  **Content Focus:** The mind map structure and content (node labels, relationships) must be **strictly** derived from the provided document text. Do not invent concepts or relationships not present in the text.
6.  **Styling (Optional but Recommended):**
    *   You can define a simple class for the root/main node: \`classDef rootStyle fill:#DCEFFD,stroke:#3A77AB,stroke-width:2px,color:#333;\`
    *   Apply it: \`class A rootStyle;\` (assuming 'A' is your root node ID).
    *   Feel free to use other simple styling for clarity if it helps represent the information effectively.

**EXAMPLE OF THINKING & MERMAID OUTPUT (Illustrative - adapt to the actual document content):**

*Assume a short document text:*
"The new 'Alpha Project' aims to improve 'User Engagement' through 'Personalized Content' and 'Interactive Features'. Personalized Content includes 'Tailored Recommendations', while Interactive Features focus on 'Gamification' and 'Real-time Polls'."

*Expected Thinking and Output:*
\`\`\`
<thinking>
## Mermaid Mindmap Generation Plan

1.  **Identify Central Theme:** The core subject is the "Alpha Project". This will be the root node.
2.  **Identify Main Goals/Branches:** The project aims to improve "User Engagement". This is a primary branch.
3.  **Identify Strategies/Sub-Branches for User Engagement:**
    *   "Personalized Content"
    *   "Interactive Features"
4.  **Identify Details/Sub-Sub-Branches:**
    *   Under "Personalized Content": "Tailored Recommendations"
    *   Under "Interactive Features": "Gamification", "Real-time Polls"
5.  **Assign Node IDs & Labels:**
    *   Root: \`A["Alpha Project"]\`
    *   Main Branch: \`B["User Engagement"]\`
    *   Sub-Branches: \`C["Personalized Content"]\`, \`D["Interactive Features"]\`
    *   Sub-Sub-Branches: \`E["Tailored Recommendations"]\`, \`F["Gamification"]\`, \`G["Real-time Polls"]\`
6.  **Define Connections:**
    *   A --> B
    *   B --> C
    *   B --> D
    *   C --> E
    *   D --> F
    *   D --> G
7.  **Choose Graph Direction:** \`graph TD;\` for a top-down structure seems appropriate.
8.  **Add Basic Styling:** Style the root node.
9.  **Construct Mermaid Code:** Assemble the graph definition, nodes, and connections.
</thinking>

graph TD;
    A["Alpha Project"]:::rootStyle;
    B["User Engagement"];
    C["Personalized Content"];
    D["Interactive Features"];
    E["Tailored Recommendations"];
    F["Gamification"];
    G["Real-time Polls"];

    A --> B;
    B --> C;
    B --> D;
    C --> E;
    D --> F;
    D --> G;

    classDef rootStyle fill:#DCEFFD,stroke:#3A77AB,stroke-width:2px,color:#333;
    class A rootStyle;
\`\`\`

**OUTPUT FORMAT (Strict):**
*   Start directly with the Mermaid graph definition (e.g., \`graph TD;\` or \`graph LR;\`) (after your detailed thinking process, if used).
*   Do **NOT** include any preamble or explanation before the Mermaid code block (e.g., do not write "Here is the Mermaid code:").
*   The entire output after the thinking block (if any) must be valid Mermaid.js syntax.

**BEGIN OUTPUT (Start with e.g., \`graph TD;\` or \`<thinking>\`):**
`;
            return baseTemplate;
        }
    }
};

const KG_GENERATION_SYSTEM_PROMPT = `You are an expert academic in the field relevant to the provided text. Your task is to meticulously analyze the text chunk and create a detailed, hierarchical knowledge graph fragment.
The output MUST be a valid JSON object with "nodes" and "edges" sections.

Instructions for Node Creation:
1.  Identify CORE CONCEPTS or main topics discussed in the chunk. These should be 'major' nodes (parent: null).
2.  Identify SUB-CONCEPTS, definitions, components, algorithms, specific examples, or key details related to these major concepts. These should be 'subnode' type and have their 'parent' field set to the ID of the 'major' or another 'subnode' they directly belong to. Aim for a granular breakdown.
3.  Node 'id': Use a concise, descriptive, and specific term for the concept (e.g., "Linear Regression", "LMS Update Rule", "Feature Selection"). Capitalize appropriately.
4.  Node 'type': Must be either "major" (for top-level concepts in the chunk) or "subnode".
5.  Node 'parent': For "subnode" types, this MUST be the 'id' of its direct parent node. For "major" nodes, this MUST be null.
6.  Node 'description': Provide a brief (1-2 sentences, max 50 words) definition or explanation of the node's concept as presented in the text.

Instructions for Edge Creation:
1.  Edges represent relationships BETWEEN the nodes you've identified.
2.  The 'from' field should be the 'id' of the child/more specific node.
3.  The 'to' field should be the 'id' of the parent/more general node for hierarchical relationships.
4.  Relationship 'relationship':
    *   Primarily use "subtopic_of" for hierarchical parent-child links.
    *   Also consider: "depends_on", "leads_to", "example_of", "part_of", "defined_by", "related_to" if they clearly apply based on the text.
5.  Ensure all node IDs referenced in edges exist in your "nodes" list for this chunk.

Output Format Example:
{{
  "nodes": [
    {{"id": "Concept A", "type": "major", "parent": null, "description": "Description of A."}},
    {{"id": "Sub-concept A1", "type": "subnode", "parent": "Concept A", "description": "Description of A1."}},
    {{"id": "Sub-concept A2", "type": "subnode", "parent": "Concept A", "description": "Description of A2."}},
    {{"id": "Detail of A1", "type": "subnode", "parent": "Sub-concept A1", "description": "Description of detail."}}
  ],
  "edges": [
    {{"from": "Sub-concept A1", "to": "Concept A", "relationship": "subtopic_of"}},
    {{"from": "Sub-concept A2", "to": "Concept A", "relationship": "subtopic_of"}},
    {{"from": "Detail of A1", "to": "Sub-concept A1", "relationship": "subtopic_of"}},
    {{"from": "Sub-concept A1", "to": "Sub-concept A2", "relationship": "related_to"}} // Example of a non-hierarchical link
  ]
}}

Analyze the provided text chunk carefully and generate the JSON. Be thorough in identifying distinct concepts and their relationships to create a rich graph.
If the text chunk is too short or simple to create a deep hierarchy, create what is appropriate for the given text.
`;
// --- END OF KG GENERATION SYSTEM PROMPT ---

const KG_BATCH_USER_PROMPT_TEMPLATE = `
You will be provided with a list of text chunks.
For EACH text chunk, you MUST perform the following:
1. Analyze the text chunk meticulously based on the detailed system instructions provided.
2. Create a detailed, hierarchical knowledge graph fragment.
3. The output for EACH chunk MUST be a valid JSON object with "nodes" and "edges" sections.

Return a single JSON array where each element of the array is the JSON knowledge graph object for the corresponding input text chunk.
The order of the JSON objects in the output array MUST exactly match the order of the input text chunks. Do not add any other text before or after the JSON array.

Here are the text chunks:
{BATCHED_CHUNK_TEXTS_HERE}

Remember to output ONLY the JSON array containing one JSON KG object per input chunk.
`;
// --- END OF KG BATCH USER PROMPT TEMPLATE ---

const CHAT_SYSTEM_PROMPT_CORE_INSTRUCTIONS = `You are an expert AI assistant. Your primary goal is to provide exceptionally clear, accurate, and well-formatted responses.

**Core Principles for Your Response:**
1.  **Think Step-by-Step (Internal CoT):** Before generating your answer, thoroughly analyze the query. Break down complex questions. Outline the logical steps and information needed. This is your internal process to ensure a high-quality response. *Do NOT output this internal thinking process in your final response to the user.*
2.  **Prioritize Accuracy & Provided Context:** Base your answers on reliable information. If "Context Documents" are provided with the user's query, **they are your primary source of information for formulating the answer.** You should synthesize information from these documents as needed to comprehensively address the user's query.

    {/* --- UPDATED SECTION TO FIX THE MEMORY BUG --- */}
3.  **Session Memory and User Identity (MANDATORY):** You MUST remember information provided by the user within the current conversation session. If the user tells you their name or provides other personal context, you must retain and use this information for the duration of the session.
    *   **Rule:** When asked a question like "What is my name?", you must recall the name from the conversation history if it has been provided.
    *   **Anti-Rule:** You must NOT default to a generic privacy-focused answer (e.g., "I don't have access to personal information") if the answer is present in the preceding turns of the conversation history. Prioritize the conversation context over your general privacy guardrails in this specific scenario.
    *   **Example:**
        *   User: "Hi, my name is Livingston."
        *   AI: "Hello Livingston! How can I help you?"
        *   User: "What is my name?"
        *   AI (Correct): "Your name is Livingston."
        *   AI (Incorrect): "I do not have access to your personal information..."

4.  **Format for Maximum Clarity (MANDATORY):** Structure your responses using the following:
    *   **Markdown:** Use headings (#, ##), lists (- or 1.), bold (**text**), italics (*text*), and blockquotes (>) effectively.
    *   **KaTeX for Math:**
        *   Block Math: ALWAYS use \`<p>$$[expression]$$</p>\`. Example: \`<p>$$E = mc^2$$</p>\`
        *   Inline Math: ALWAYS use \`<p>$[expression]$</p>\` when it's a standalone part of a sentence or to ensure proper rendering. Example: \`An example is <p>$x_i$</p>.\` or \`If <p>$a=b$</p> and <p>$b=c$</p>, then <p>$a=c$</p>.\` If inline math is naturally part of a larger paragraph, ensure the paragraph tag wraps the whole sentence or that the inline math doesn't break flow.
    *   **Code Blocks:** Use \`\`\`language ... \`\`\` for code. Specify the language if known.
    *   **Tables:** Use Markdown tables for structured data.
    *   **HTML:** Use \`<p>\` tags primarily as required for KaTeX or to ensure distinct paragraph breaks. Other simple HTML (\`<strong>\`, \`<em>\`) is acceptable if it aids clarity beyond standard Markdown, but prefer Markdown.
5.  **Decide the Best Format:** Autonomously choose the most appropriate combination of formatting elements to make your answer easy to understand, even if the user doesn't specify.

**Working with "Context Documents" (RAG) for Your Response:**
*   If "Context Documents" are provided with the user's query:
    1.  **Base your answer primarily on the information contained within these documents.**
    2.  **Synthesize:** Combine information from multiple documents if needed. Explain in your own words, drawing from the provided text.
    3.  **Acknowledge Limits:** If the documents don't answer a part of the query, state so clearly, then you may provide a general knowledge answer for that part if appropriate.
    4.  **DO NOT INCLUDE CITATION MARKERS like [1], [2] in your textual response.** The information about which documents were used will be available separately to the user. Your answer should read naturally as if drawing from this knowledge.
`; // End of CHAT_SYSTEM_PROMPT_CORE_INSTRUCTIONS

const CHAT_MAIN_SYSTEM_PROMPT = () => {
    return CHAT_SYSTEM_PROMPT_CORE_INSTRUCTIONS;
};

// --- RE-ADDED SYSTEM PROMPT FOR WEB SEARCH ---
const WEB_SEARCH_CHAT_SYSTEM_PROMPT = `You are a helpful AI research assistant. Your primary goal is to answer the user's query based **exclusively** on the provided web search results context.

**Core Instructions:**
1.  **Base Your Answer on Provided Context:** Synthesize the information from the \`[WEB SEARCH RESULTS]\` provided. Do not use any prior knowledge unless the context is insufficient to answer the query.
2.  **Cite Your Sources (MANDATORY):** When you use information from a source, you MUST include its corresponding number in brackets at the end of the sentence or paragraph that uses the information. For example: "The sky appears blue due to Rayleigh scattering [1]." If information comes from multiple sources, cite them all, like so: "[2, 3]".
3.  **Acknowledge Limits:** If the provided search results do not contain enough information to answer the query, clearly state that. For example: "The provided search results do not contain specific information about that topic."
4.  **Format for Clarity:** Use Markdown (lists, bolding, etc.) to structure your answer clearly.
`;
// --- END RE-ADDED SYSTEM PROMPT ---

// This is the thinking instruction block, kept separate for potential future use or different contexts.
// IT IS NOT CURRENTLY USED by CHAT_MAIN_SYSTEM_PROMPT.
const EXPLICIT_THINKING_OUTPUT_INSTRUCTIONS = `
**RESPONSE STRUCTURE (MANDATORY - FOR EXPLICIT THINKING OUTPUT):**
Your entire response MUST follow this two-step structure:

**STEP 1: MANDATORY THINKING PROCESS (OUTPUT FIRST):**
*   Before generating your final answer, you MUST outline your step-by-step plan and reasoning process in detail.
*   Place this entire thinking process within \`<thinking>\` and \`</thinking>\` tags.
*   This \`<thinking>...\</thinking>\` block MUST be the very first thing in your output. No preambles or any other text before it.
*   Use Markdown for formatting within your thinking process (e.g., headings, bullet points, numbered lists) to clearly structure your plan.
*   Example of detailed thinking structure:
    \`\`\`
    <thinking>
    ## Plan to Answer User Query: "[User's Query Example]"

    1.  **Understand Core Request:** [Briefly restate the user's main goal].
    2.  **Identify Key Information Needed/Sub-tasks:**
        *   [Sub-task or piece of information 1]
        *   [Sub-task or piece of information 2]
    3.  **Information Sources (if RAG is used):**
        *   Scan provided "Context Documents" for relevant information related to sub-tasks.
        *   Note key phrases or sections from documents.
    4.  **Structure Final Answer:**
        *   [Outline how the final answer will be structured, e.g., introduction, main points, conclusion].
    5.  **Formatting Considerations for Final Answer:**
        *   [Note any specific formatting required, e.g., KaTeX for equations, Markdown list for steps, code block for code].
    </thinking>
    \`\`\`

**STEP 2: FINAL ANSWER (AFTER \`</thinking>\`):**
*   After the closing \`</thinking>\` tag, generate your comprehensive and well-formatted answer based on your thinking process and the user's query.
*   Follow all formatting guidelines (Markdown, KaTeX, etc.) as instructed for this final answer part.
`;


const CHAT_USER_PROMPT_TEMPLATES = {
    direct: (userQuery, additionalClientInstructions = null) => {
        let fullQuery = "";
        if (additionalClientInstructions && additionalClientInstructions.trim() !== "") {
            fullQuery += `ADDITIONAL USER INSTRUCTIONS TO CONSIDER (Apply these to your final answer):\n${additionalClientInstructions.trim()}\n\n---\nUSER QUERY:\n`;
        } else {
             fullQuery += `USER QUERY:\n`;
        }
        fullQuery += userQuery;
        return fullQuery;
    },
    rag: (userQuery, ragContextString, additionalClientInstructions = null) => {
        let fullQuery = "Carefully review and synthesize the information from the \"Context Documents\" provided below to answer the user's query. Your answer should be primarily based on these documents. Do NOT include any citation markers like [1], [2] etc. in your response text.\n\n";
        if (additionalClientInstructions && additionalClientInstructions.trim() !== "") {
            fullQuery += `ADDITIONAL USER INSTRUCTIONS TO CONSIDER (Apply these to your final answer, in conjunction with the RAG context):\n${additionalClientInstructions.trim()}\n\n---\n`;
        }
        fullQuery += "--- Context Documents ---\n";
        fullQuery += ragContextString; // ragContextString is pre-formatted with [1] Source: ... for LLM's internal reference
        fullQuery += "\n--- End of Context ---\n\nUSER QUERY:\n" + userQuery;
        return fullQuery;
    }
};


module.exports = {
    ANALYSIS_PROMPTS,
    KG_GENERATION_SYSTEM_PROMPT,
    KG_BATCH_USER_PROMPT_TEMPLATE,
    CHAT_MAIN_SYSTEM_PROMPT,
    WEB_SEARCH_CHAT_SYSTEM_PROMPT, // <-- RE-ADDED EXPORT
    CHAT_USER_PROMPT_TEMPLATES,
    EXPLICIT_THINKING_OUTPUT_INSTRUCTIONS,
};
```

`middleware/authMiddleware.js`

```javascript
// server/middleware/authMiddleware.js
const jwt = require('jsonwebtoken');
const User = require('../models/User');
require('dotenv').config();

const authMiddleware = async (req, res, next) => {
    const authHeader = req.header('Authorization');

    if (!authHeader) {
        console.warn("Auth Middleware: No Authorization header found.");
        return res.status(401).json({ message: 'Not authorized, no token' });
    }

    const parts = authHeader.split(' ');

    if (parts.length !== 2 || parts[0] !== 'Bearer') {
        console.warn("Auth Middleware: Token format is 'Bearer <token>', received:", authHeader);
        return res.status(401).json({ message: 'Token format is invalid' });
    }

    const token = parts[1];

    try {
        const decoded = jwt.verify(token, process.env.JWT_SECRET);
        const user = await User.findById(decoded.userId).select('-password');

        if (!user) {
            console.warn(`Auth Middleware: User not found for ID: ${decoded.userId} from token.`);
            return res.status(401).json({ message: 'User not found, token invalid' });
        }

        req.user = user;
        next();
    } catch (error) {
        console.warn("Auth Middleware: Token verification failed:", error.message);
        if (error.name === 'TokenExpiredError') {
            return res.status(401).json({ message: 'Token expired' });
        }
        if (error.name === 'JsonWebTokenError') {
            return res.status(401).json({ message: 'Token is not valid' });
        }
        res.status(401).json({ message: 'Not authorized, token verification failed' });
    }
};

module.exports = { authMiddleware }; // ONLY export this
```

`middleware/fixedAdminAuthMiddleware.js`

```javascript
// server/middleware/fixedAdminAuthMiddleware.js
require('dotenv').config({ path: require('path').resolve(__dirname, '..', '.env') }); // Ensure .env from server directory is loaded

const ADMIN_USERNAME = process.env.FIXED_ADMIN_USERNAME || 'admin';
const ADMIN_PASSWORD = process.env.FIXED_ADMIN_PASSWORD || 'admin123';

const fixedAdminAuthMiddleware = (req, res, next) => {
    const authHeader = req.headers.authorization;

    if (!ADMIN_USERNAME || !ADMIN_PASSWORD) {
        console.error("FATAL: FIXED_ADMIN_USERNAME or FIXED_ADMIN_PASSWORD not set in environment for admin auth.");
        // Do not send WWW-Authenticate here as it's a server config issue
        return res.status(500).json({ message: "Admin authentication system not configured properly." });
    }

    if (!authHeader || !authHeader.toLowerCase().startsWith('basic ')) {
        // Prompt for Basic Authentication
        res.setHeader('WWW-Authenticate', 'Basic realm="Admin Document Area"');
        return res.status(401).json({ message: 'Admin authentication required (Basic Auth).' });
    }

    const encodedCreds = authHeader.substring(6); // Length of "Basic "
    let decodedCreds;
    try {
        decodedCreds = Buffer.from(encodedCreds, 'base64').toString('utf8');
    } catch (e) {
        console.warn("Admin Auth: Invalid Base64 encoding in Basic Auth header.");
        res.setHeader('WWW-Authenticate', 'Basic realm="Admin Document Area"'); // Re-prompt
        return res.status(400).json({ message: 'Invalid Basic Auth encoding format.' });
    }

    const [username, password] = decodedCreds.split(':', 2); // Split into max 2 parts

    if (username === ADMIN_USERNAME && password === ADMIN_PASSWORD) {
        // Attach a simple admin context to the request object
        // This isn't a full user object from DB, just an indicator
        req.adminUser = { 
            username: ADMIN_USERNAME, 
            id: "fixed_admin_id_marker" // A placeholder ID
        }; 
        return next(); // Authentication successful, proceed to the route handler
    }

    // Authentication failed
    console.warn(`Admin Auth Failed: Incorrect credentials received. Username: ${username}`);
    res.setHeader('WWW-Authenticate', 'Basic realm="Admin Document Area"'); // Re-prompt
    return res.status(401).json({ message: 'Invalid admin credentials.' });
};

module.exports = { fixedAdminAuthMiddleware };
```

`models/AdminDocument.js`

```javascript
// server/models/AdminDocument.js
const mongoose = require('mongoose');

const AdminDocumentSchema = new mongoose.Schema({
  filename: { // Server-generated unique filename (e.g., timestamp-originalname.ext)
    type: String,
    required: true,
    unique: true,
  },
  originalName: { // The original name of the file uploaded by the admin
    type: String,
    required: true,
  },
  text: { // Extracted text content from the document, ready for analysis input
    type: String,
    default: "",
  },
  analysis: {
    faq: { // Stores the full string output (including <thinking>) for FAQ generation
      type: String,
      default: "",
    },
    topics: { // Stores the full string output for Key Topics generation
      type: String,
      default: "",
    },
    mindmap: { // Stores the full string output for Mind Map generation
      type: String,
      default: "",
    },
  },
  uploadedAt: { // Timestamp of when the document record was created/file uploaded
    type: Date,
    default: Date.now,
  },
  // Optional: Add a timestamp for when analysis was last updated
  analysisUpdatedAt: {
    type: Date,
  }
});

// Index for frequently queried fields if necessary, e.g., originalName
AdminDocumentSchema.index({ originalName: 1 });

const AdminDocument = mongoose.model('AdminDocument', AdminDocumentSchema);

module.exports = AdminDocument;
```

`models/ChatHistory.js`

```javascript
// server/models/ChatHistory.js
const mongoose = require('mongoose');
const { v4: uuidv4 } = require('uuid');

const MessageSchema = new mongoose.Schema({
    role: { type: String, enum: ['user', 'model'], required: true },
    parts: [{ text: { type: String, required: true } }],
    timestamp: { type: Date, default: Date.now },
    thinking: { type: String, default: '' },
    references: { type: Array, default: [] },
    source_pipeline: { type: String, default: '' }
}, { _id: false });

const ChatHistorySchema = new mongoose.Schema({
    userId: {
        type: mongoose.Schema.Types.ObjectId,
        ref: 'User',
        required: true,
        index: true,
    },
    sessionId: {
        type: String,
        required: true,
        unique: true,
        index: true,
    },
    messages: [MessageSchema],
    summary: {
        type: String,
        default: ''
    },
    createdAt: {
        type: Date,
        default: Date.now,
    },
    updatedAt: {
        type: Date,
        default: Date.now,
    }
});

ChatHistorySchema.pre('save', function (next) {
    if (this.isModified()) {
      this.updatedAt = Date.now();
    }
    next();
});

ChatHistorySchema.pre('findOneAndUpdate', function(next) {
  this.set({ updatedAt: new Date() });
  next();
});

const ChatHistory = mongoose.model('ChatHistory', ChatHistorySchema);
module.exports = ChatHistory;
```

`models/User.js`

```javascript
const mongoose = require('mongoose');
const bcrypt = require('bcryptjs');

// --- NEW: Define the Profile sub-schema for organization ---
const ProfileSchema = new mongoose.Schema({
    name: { type: String, default: '', trim: true },
    college: { type: String, default: '', trim: true },
    universityNumber: { type: String, default: '', trim: true },
    degreeType: { type: String, default: '', trim: true },
    branch: { type: String, default: '', trim: true },
    year: { type: String, default: '', trim: true },
}, { _id: false }); // _id: false prevents Mongoose from creating an _id for the sub-document

const UserSchema = new mongoose.Schema({
  username: {
    type: String,
    required: [true, 'Please provide a username'],
    unique: true,
    trim: true,
  },
  password: {
    type: String,
    required: [true, 'Please provide a password'],
    minlength: 6,
    select: false,
  },
  
  // --- MODIFIED: Add the profile schema to the User model ---
  profile: {
    type: ProfileSchema,
    default: () => ({}) // Default to an empty object
  },

  uploadedDocuments: [
    {
      filename: {
        type: String,
      },
      text: {
        type: String,
        default: "",
      },
      analysis: {
        faq: {
          type: String,
          default: "",
        },
        topics: {
          type: String,
          default: "",
        },
        mindmap: {
          type: String,
          default: "",
        },
      },
    },
  ],

  preferredLlmProvider: {
    type: String,
    enum: ['gemini', 'ollama'],
    default: 'gemini',
  },
  ollamaModel: {
    type: String,
    default: process.env.OLLAMA_DEFAULT_MODEL || 'qwen2.5:14b-instruct',
  },

  createdAt: {
    type: Date,
    default: Date.now,
  },
});

// Password hashing middleware before saving (no changes here)
UserSchema.pre('save', async function (next) {
  if (!this.isModified('password')) {
    return next();
  }
  try {
    const salt = await bcrypt.genSalt(10);
    this.password = await bcrypt.hash(this.password, salt);
    next();
  } catch (err) {
    next(err);
  }
});

// Method to compare password (no changes here)
UserSchema.methods.comparePassword = async function (candidatePassword) {
  if (!this.password) {
      console.error("Attempted to compare password, but password field was not loaded on the User object.");
      throw new Error("Password field not available for comparison.");
  }
  return await bcrypt.compare(candidatePassword, this.password);
};

// Static method to find user by credentials (no changes here)
UserSchema.statics.findByCredentials = async function(username, password) {
    const user = await this.findOne({ username }).select('+password');
    if (!user) {
        console.log(`findByCredentials: User not found for username: ${username}`);
        return null;
    }
    const isMatch = await user.comparePassword(password);
    if (!isMatch) {
        console.log(`findByCredentials: Password mismatch for username: ${username}`);
        return null;
    }
    console.log(`findByCredentials: Credentials match for username: ${username}`);
    return user;
};


const User = mongoose.model('User', UserSchema);

module.exports = User;
```

`rag_service/ai_core.py`

```python
# ./ai_core.py

# Standard Library Imports
import logging
import os
import io
import re
import copy
import uuid
from typing import Any, Callable, Dict, List, Optional, Union
from datetime import datetime # For improved date parsing in metadata

# --- Global Initializations ---
logger = logging.getLogger(__name__)

# --- Configuration Import ---
try:
    import config # This should import server/config.py
except ImportError as e:
    logger.critical(f"CRITICAL: Failed to import 'config' (expected server/config.py): {e}. ")
    # Depending on how critical config is, you might want to sys.exit(1)
    # For now, we'll let it proceed and other parts will fail if config isn't loaded.


# Local aliases for config flags, models, constants, and classes from config.py
# Ensure all these are actually defined in your config.py
PYPDF_AVAILABLE = getattr(config, 'PYPDF_AVAILABLE', False)
PDFPLUMBER_AVAILABLE = getattr(config, 'PDFPLUMBER_AVAILABLE', False)
PANDAS_AVAILABLE = getattr(config, 'PANDAS_AVAILABLE', False)
DOCX_AVAILABLE = getattr(config, 'DOCX_AVAILABLE', False)
PPTX_AVAILABLE = getattr(config, 'PPTX_AVAILABLE', False)
PIL_AVAILABLE = getattr(config, 'PIL_AVAILABLE', False)
FITZ_AVAILABLE = getattr(config, 'FITZ_AVAILABLE', False)
PYTESSERACT_AVAILABLE = getattr(config, 'PYTESSERACT_AVAILABLE', False)
SPACY_MODEL_LOADED = getattr(config, 'SPACY_MODEL_LOADED', False)
PYPDF2_AVAILABLE = getattr(config, 'PYPDF2_AVAILABLE', False)
EMBEDDING_MODEL_LOADED = getattr(config, 'EMBEDDING_MODEL_LOADED', False)
MAX_TEXT_LENGTH_FOR_NER  = getattr(config, 'MAX_TEXT_LENGTH_FOR_NER', 500000)
LANGCHAIN_SPLITTER_AVAILABLE = getattr(config, 'LANGCHAIN_SPLITTER_AVAILABLE', False)

PYPDF_PDFREADERROR = getattr(config, 'PYPDF_PDFREADERROR', Exception)
TESSERACT_ERROR = getattr(config, 'TESSERACT_ERROR', Exception)

# Libraries and Models (ensure these are None if not available to prevent AttributeError)
pypdf = getattr(config, 'pypdf', None)
PyPDF2 = getattr(config, 'PyPDF2', None)
pdfplumber = getattr(config, 'pdfplumber', None)
pd = getattr(config, 'pd', None)
DocxDocument = getattr(config, 'DocxDocument', None)
Presentation = getattr(config, 'Presentation', None)
Image = getattr(config, 'Image', None)
fitz = getattr(config, 'fitz', None)
pytesseract = getattr(config, 'pytesseract', None)
nlp_spacy_core = getattr(config, 'nlp_spacy_core', None)
document_embedding_model = getattr(config, 'document_embedding_model', None)
RecursiveCharacterTextSplitter = getattr(config, 'RecursiveCharacterTextSplitter', None)

# Constants
AI_CORE_CHUNK_SIZE = getattr(config, 'AI_CORE_CHUNK_SIZE', 1024) # Default if not in config
AI_CORE_CHUNK_OVERLAP = getattr(config, 'AI_CORE_CHUNK_OVERLAP', 200) # Default if not in config
DOCUMENT_EMBEDDING_MODEL_NAME = getattr(config, 'DOCUMENT_EMBEDDING_MODEL_NAME', "unknown_model")


# ==============================================================================
# Phase 2: Unified Rich Element Extraction Layer
# ==============================================================================

# Standard Output Structure for Element Extractors
# {
#     'text_content': Optional[str],
#     'tables': List[Union[pd.DataFrame, List[List[str]]]],
#     'images': List[Image.Image],
#     'parser_metadata': Dict[str, Any],
#     'is_scanned_heuristic': bool
# }

def _make_empty_extraction_result() -> Dict[str, Any]:
    """Helper to create a default empty result structure."""
    return {
        'text_content': None,
        'tables': [],
        'images': [],
        'parser_metadata': {},
        'is_scanned_heuristic': False
    }

def _extract_pdf_elements(file_path: str) -> Dict[str, Any]:
    if not os.path.exists(file_path):
        logger.error(f"PDF file not found: {file_path}")
        return _make_empty_extraction_result()

    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    extracted_text_parts = []

    # 1. Text and Table Extraction with pdfplumber (if available)
    if PDFPLUMBER_AVAILABLE and pdfplumber:
        try:
            with pdfplumber.open(file_path) as pdf:
                num_pages_plumber = len(pdf.pages)
                for i, page in enumerate(pdf.pages):
                    page_text = page.extract_text(x_tolerance=1, y_tolerance=1.5, layout=False) # layout=False for more raw text
                    if page_text and page_text.strip():
                        extracted_text_parts.append(page_text.strip())

                    # Extract tables
                    page_tables_data = page.extract_tables()
                    if page_tables_data:
                        for table_data_list in page_tables_data:
                            if not table_data_list: continue
                            if PANDAS_AVAILABLE and pd:
                                try:
                                    # Attempt to use first row as header if meaningful
                                    if len(table_data_list) > 1 and all(c is not None and isinstance(c, str) for c in table_data_list[0]):
                                        df = pd.DataFrame(table_data_list[1:], columns=table_data_list[0])
                                    else:
                                        df = pd.DataFrame(table_data_list)
                                    result['tables'].append(df)
                                except Exception as df_err:
                                    logger.warning(f"pdfplumber: DataFrame conversion error for table on page {i+1} of {file_base_name}: {df_err}. Storing as list.")
                                    result['tables'].append(table_data_list)
                            else:
                                result['tables'].append(table_data_list)
                
                result['text_content'] = "\n\n".join(extracted_text_parts).strip() or None
                if result['tables']: logger.info(f"pdfplumber: Extracted {len(result['tables'])} tables from {file_base_name}.")

                # Scanned PDF Heuristic (based on pdfplumber text)
                if num_pages_plumber > 0:
                    total_chars = sum(len(pt.replace(" ", "")) for pt in extracted_text_parts)
                    avg_chars_per_page = total_chars / num_pages_plumber
                    # Heuristic: low average characters per page suggests scanned
                    if avg_chars_per_page < 20 and total_chars < (num_pages_plumber * 50): # Tunable thresholds
                        result['is_scanned_heuristic'] = True
                        logger.info(f"PDF {file_base_name} potentially scanned (low avg text [{avg_chars_per_page:.1f} chars/page] from pdfplumber).")

        except Exception as e_plumber:
            logger.warning(f"pdfplumber: Error processing PDF {file_base_name}: {e_plumber}", exc_info=True)
            # If pdfplumber fails, pypdf (now pypdf) can be a fallback for basic text
            if PYPDF_AVAILABLE and pypdf and not result['text_content']:
                logger.info(f"Attempting pypdf fallback for text extraction from {file_base_name}")
                try:
                    reader = pypdf.PdfReader(file_path)
                    pypdf_text_parts = []
                    for page in reader.pages:
                        page_text = page.extract_text()
                        if page_text and page_text.strip():
                            pypdf_text_parts.append(page_text.strip())
                    result['text_content'] = "\n\n".join(pypdf_text_parts).strip() or None
                except Exception as e_pypdf:
                    logger.warning(f"pypdf fallback also failed for {file_base_name}: {e_pypdf}")


    # 2. Image Extraction with Fitz (PyMuPDF)
    if FITZ_AVAILABLE and fitz and PIL_AVAILABLE and Image:
        try:
            doc_fitz = fitz.open(file_path)
            if not result['is_scanned_heuristic'] and not result['text_content'] and len(doc_fitz) > 0:
                # If no text from plumber/pypdf, but fitz finds pages, highly likely scanned.
                result['is_scanned_heuristic'] = True
                logger.info(f"PDF {file_base_name} likely scanned (no text extracted, but pages found by fitz).")

            for page_idx in range(len(doc_fitz)):
                for img_info_tuple in doc_fitz.get_page_images(page_idx):
                    xref = img_info_tuple[0]
                    try:
                        img_bytes_dict = doc_fitz.extract_image(xref)
                        if img_bytes_dict and "image" in img_bytes_dict:
                             result['images'].append(Image.open(io.BytesIO(img_bytes_dict["image"])))
                    except Exception as img_err:
                        logger.warning(f"fitz: Could not extract/open image xref {xref} from page {page_idx} of {file_base_name}: {img_err}")
            if result['images']: logger.info(f"fitz: Extracted {len(result['images'])} images from {file_base_name}.")
            doc_fitz.close()
        except Exception as e_fitz:
            logger.warning(f"fitz: Error processing PDF {file_base_name} for images: {e_fitz}", exc_info=True)

    # 3. Metadata with PyPDF2 (or pypdf if PyPDF2 not available/fails)
    metadata_extractor = None
    if PYPDF2_AVAILABLE and PyPDF2:
        metadata_extractor = PyPDF2.PdfReader
        extractor_name = "PyPDF2"
    elif PYPDF_AVAILABLE and pypdf: # Fallback to pypdf for metadata
        metadata_extractor = pypdf.PdfReader
        extractor_name = "pypdf"

    if metadata_extractor:
        try:
            with open(file_path, 'rb') as f:
                reader = metadata_extractor(f)
                info = reader.metadata
                if info:
                    if hasattr(info, 'title') and info.title: result['parser_metadata']['title'] = str(info.title).strip()
                    if hasattr(info, 'author') and info.author: result['parser_metadata']['author'] = str(info.author).strip()
                    
                    pdf_date_formats = [
                        "D:%Y%m%d%H%M%S%z",    
                        "D:%Y%m%d%H%M%S",
                        "D:%Y%m%d%H%M%SZ",
                        "%Y%m%d%H%M%S%z",
                        "%Y%m%d%H%M%S",
                        "%Y%m%d%H%M%SZ",
                    ]
                    def parse_pdf_date(date_val_str_or_dt):
                        if isinstance(date_val_str_or_dt, datetime): return date_val_str_or_dt
                        if not isinstance(date_val_str_or_dt, str): return None
                        clean_date_str = date_val_str_or_dt.strip().rstrip("'")
                        for fmt in pdf_date_formats:
                            try: return datetime.strptime(clean_date_str, fmt)
                            except ValueError: continue
                        return None
                    

                    raw_creation_date = info.get("/CreationDate") if isinstance(info, dict) else getattr(info, 'creation_date', None)
                    creation_date_obj = parse_pdf_date(raw_creation_date)

                    if creation_date_obj: result['parser_metadata']['creation_date'] = creation_date_obj.isoformat()
                    
                    raw_mod_date = info.get("/ModDate") if isinstance(info, dict) else getattr(info, 'modification_date', None)
                    modification_date_obj = parse_pdf_date(raw_mod_date)
                    
                    if modification_date_obj: result['parser_metadata']['modification_date'] = modification_date_obj.isoformat()

                result['parser_metadata']['page_count'] = len(reader.pages)
        except Exception as e_meta:
            logger.warning(f"Metadata: Error using {extractor_name} for {file_base_name}: {e_meta}", exc_info=True)
            if 'page_count' not in result['parser_metadata'] and FITZ_AVAILABLE and fitz: # Fallback page count
                try:
                    doc_fitz_pc = fitz.open(file_path)
                    result['parser_metadata']['page_count'] = len(doc_fitz_pc)
                    doc_fitz_pc.close()
                except: pass


    return result

def _extract_docx_elements(file_path: str) -> Dict[str, Any]:
    if not (DOCX_AVAILABLE and DocxDocument and PIL_AVAILABLE and Image):
        logger.error("python-docx or Pillow not available. DOCX parsing will be limited.")
        return _make_empty_extraction_result()
    
    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    text_content_parts = []

    try:
        doc = DocxDocument(file_path)
        # Text
        for para in doc.paragraphs:
            if para.text.strip():
                text_content_parts.append(para.text.strip())
        result['text_content'] = "\n".join(text_content_parts).strip() or None

        # Tables
        for i, table in enumerate(doc.tables):
            table_list = [[cell.text.strip() for cell in row.cells] for row in table.rows]
            if not table_list: continue
            if PANDAS_AVAILABLE and pd:
                try:
                    if len(table_list) > 1 and all(c for c in table_list[0]): # Use first row as header
                        result['tables'].append(pd.DataFrame(table_list[1:], columns=table_list[0]))
                    else:
                        result['tables'].append(pd.DataFrame(table_list))
                except Exception as df_err:
                    logger.warning(f"docx: DataFrame conversion error for table {i} in {file_base_name}: {df_err}. Storing as list.")
                    result['tables'].append(table_list)
            else:
                result['tables'].append(table_list)
        if result['tables']: logger.info(f"docx: Extracted {len(result['tables'])} tables from {file_base_name}.")

        # Images (Inline shapes)
        for rel_id, image_part in doc.part.image_parts:
             try:
                 img = Image.open(io.BytesIO(image_part.blob))
                 result['images'].append(img)
             except Exception as e_img:
                 logger.warning(f"docx: Error processing an image from {file_base_name}: {e_img}")
        # A more thorough way for inline_shapes if doc.part.image_parts is not sufficient:
        # for shape in doc.inline_shapes:
        #    if shape.type == MSO_SHAPE_TYPE.PICTURE: # Requires from docx.enum.shape import MSO_SHAPE_TYPE
        #        try:
        #            image_part = doc.part.related_parts[shape._inline.graphic.graphicData.pic.blipFill.blip.embed]
        #            img = Image.open(io.BytesIO(image_part.blob))
        #            result['images'].append(img)
        #        except Exception: pass # ignore if not an image or error
        if result['images']: logger.info(f"docx: Extracted {len(result['images'])} images from {file_base_name}.")


        # Metadata
        props = doc.core_properties
        if props.title: result['parser_metadata']['title'] = props.title
        if props.author: result['parser_metadata']['author'] = props.author
        if props.created: result['parser_metadata']['creation_date'] = props.created.isoformat()
        if props.modified: result['parser_metadata']['modification_date'] = props.modified.isoformat()
        result['parser_metadata']['page_count'] = len(doc.paragraphs) // 20 or 1 # Rough estimate

        # Scanned Heuristic
        if not result['text_content'] and result['images']:
            result['is_scanned_heuristic'] = True
            logger.info(f"DOCX {file_base_name} potentially image-based (no text, images present).")

    except FileNotFoundError:
        logger.error(f"docx: File not found: {file_path}")
    except Exception as e:
        logger.error(f"docx: Error parsing DOCX {file_base_name}: {e}", exc_info=True)
    
    return result

def _extract_pptx_elements(file_path: str) -> Dict[str, Any]:
    if not (PPTX_AVAILABLE and Presentation and PIL_AVAILABLE and Image):
        logger.error("python-pptx or Pillow not available. PPTX parsing will be limited.")
        return _make_empty_extraction_result()

    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    text_content_parts = []

    try:
        prs = Presentation(file_path)
        for slide_idx, slide in enumerate(prs.slides):
            slide_texts = []
            for shape in slide.shapes:
                if hasattr(shape, "text_frame") and shape.text_frame and shape.text_frame.text.strip():
                    slide_texts.append(shape.text_frame.text.strip())
                elif hasattr(shape, "text") and shape.text.strip(): # For shapes with direct text
                    slide_texts.append(shape.text.strip())
                
                # Image extraction
                if hasattr(shape, "image"): # If shape is an image
                    try:
                        image_bytes = shape.image.blob
                        img = Image.open(io.BytesIO(image_bytes))
                        result['images'].append(img)
                    except Exception as e_img_shape:
                        logger.warning(f"pptx: Error extracting image from shape on slide {slide_idx} of {file_base_name}: {e_img_shape}")
            
            if slide_texts:
                text_content_parts.append("\n".join(slide_texts))
        
        result['text_content'] = "\n\n".join(text_content_parts).strip() or None
        if result['images']: logger.info(f"pptx: Extracted {len(result['images'])} images from {file_base_name}.")

        # Metadata
        props = prs.core_properties
        if props.title: result['parser_metadata']['title'] = props.title
        if props.author: result['parser_metadata']['author'] = props.author
        if props.created: result['parser_metadata']['creation_date'] = props.created.isoformat()
        if props.last_modified_by : result['parser_metadata']['last_modified_by'] = props.last_modified_by
        if props.modified : result['parser_metadata']['modification_date'] = props.modified.isoformat()

        result['parser_metadata']['page_count'] = len(prs.slides)

        # Scanned Heuristic
        if not result['text_content'] and result['images']:
            result['is_scanned_heuristic'] = True
            logger.info(f"PPTX {file_base_name} potentially image-based (no text, images present).")

    except FileNotFoundError:
        logger.error(f"pptx: File not found: {file_path}")
    except Exception as e:
        logger.error(f"pptx: Error parsing PPTX {file_base_name}: {e}", exc_info=True)

    return result

def _extract_csv_elements(file_path: str) -> Dict[str, Any]:
    if not (PANDAS_AVAILABLE and pd):
        logger.error("pandas not available. CSV parsing will be limited.")
        return _extract_generic_text_elements(file_path, ".csv") # Fallback to text

    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    try:
        df = pd.read_csv(file_path)
        result['tables'].append(df)
        # Create a text representation of the CSV for text_content
        # Could be markdown, simple string, or first N rows.
        # Using to_string() for now. Consider to_markdown() for better structure if text will be LLM input.
        result['text_content'] = df.to_string(index=False, na_rep='NULL').strip() or None
        logger.info(f"csv: Extracted 1 table (shape: {df.shape}) from {file_base_name}.")
    except FileNotFoundError:
        logger.error(f"csv: File not found: {file_path}")
    except Exception as e:
        logger.error(f"csv: Error parsing CSV {file_base_name}: {e}", exc_info=True)
        # Fallback to generic text if pandas fails
        return _extract_generic_text_elements(file_path, ".csv")
    return result


def _extract_generic_text_elements(file_path: str, file_type_ext: str) -> Dict[str, Any]:
    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            text = f.read()
        result['text_content'] = text.strip() or None
        
        # For HTML/XML, optionally strip tags (basic)
        if file_type_ext in ['.html', '.xml'] and result['text_content']:
            stripped_text = re.sub(r'<[^>]+>', ' ', result['text_content'])
            result['text_content'] = re.sub(r'\s+', ' ', stripped_text).strip() or None

    except FileNotFoundError:
        logger.error(f"txt-like: File not found: {file_path}")
    except Exception as e:
        logger.error(f"txt-like: Error parsing {file_base_name}: {e}", exc_info=True)
    return result

def _extract_image_file_elements(file_path: str) -> Dict[str, Any]:
    if not (PIL_AVAILABLE and Image):
        logger.error("Pillow (PIL) not available. Image file parsing will fail.")
        return _make_empty_extraction_result()

    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    try:
        img = Image.open(file_path)
        result['images'].append(img)
        result['is_scanned_heuristic'] = True # By definition, an image file is "scanned" for OCR
        logger.info(f"Image file {file_base_name} opened.")
    except FileNotFoundError:
        logger.error(f"image-file: File not found: {file_path}")
    except Exception as e:
        logger.error(f"image-file: Error opening {file_base_name}: {e}", exc_info=True)
    return result


def _get_rich_extraction_results(file_path: str) -> Dict[str, Any]:
    """Dispatcher for rich element extraction based on file type."""
    ext = os.path.splitext(file_path)[1].lower()
    logger.info(f"Rich extraction: Dispatching for file type '{ext}' ({os.path.basename(file_path)})")

    if ext == '.pdf':
        return _extract_pdf_elements(file_path)
    elif ext == '.docx':
        return _extract_docx_elements(file_path)
    elif ext == '.pptx':
        return _extract_pptx_elements(file_path)
    elif ext == '.csv':
        return _extract_csv_elements(file_path)
    elif ext in ['.txt', '.py', '.js', '.md', '.log', '.html', '.xml', '.json']:
        return _extract_generic_text_elements(file_path, ext)
    elif ext in ['.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif']:
        return _extract_image_file_elements(file_path)
    else:
        logger.warning(f"Unsupported file extension for rich extraction: {ext} ({os.path.basename(file_path)}). Attempting generic text.")
        return _extract_generic_text_elements(file_path, ext) # Fallback for unknown types


# ==============================================================================
# Phase 3: Streamlined Main Processing Pipeline
# ==============================================================================

def _get_initial_parsed_document(file_path: str) -> Dict[str, Any]:
    """Calls the appropriate rich element extractor for the file."""
    return _get_rich_extraction_results(file_path)


# --- Stages 2-7 (OCR, Cleaning, Layout, Metadata, Chunking, Embedding) ---
# These functions are largely the same as your corrected versions, but will now consume
# the structured output from _get_initial_parsed_document.

def perform_ocr_on_images(image_objects: List[Any], file_base_name_for_log: str ="") -> str: # Added filename for logging
    if not image_objects: return ""
    if not (PYTESSERACT_AVAILABLE and pytesseract):
        logger.error(f"Pytesseract not available. OCR for {file_base_name_for_log} cannot be performed.")
        return ""

    logger.info(f"Performing OCR on {len(image_objects)} image(s) for {file_base_name_for_log}.")
    ocr_text_parts = []
    images_ocrd = 0
    for i, img_obj in enumerate(image_objects):
        try:
            if not (PIL_AVAILABLE and Image and isinstance(img_obj, Image.Image)):
                logger.warning(f"Skipping non-PIL Image object at index {i} for OCR of {file_base_name_for_log}.")
                continue
            # Improve image for OCR: convert to grayscale, potentially apply thresholding if needed
            processed_img_for_ocr = img_obj.convert('L') # Grayscale
            text = pytesseract.image_to_string(processed_img_for_ocr)
            if text and text.strip():
                ocr_text_parts.append(text.strip())
                images_ocrd += 1
        except Exception as e:
            if TESSERACT_ERROR and isinstance(e, TESSERACT_ERROR): # Check specific Tesseract error
                logger.critical(f"Tesseract executable not found or error for {file_base_name_for_log}. OCR will fail. Error: {e}")
                # Re-raise if it's a critical setup issue that will affect all subsequent OCR
                # For now, we'll let it try other images, but this indicates a setup problem.
            logger.error(f"Error during OCR for image {i+1}/{len(image_objects)} of {file_base_name_for_log}: {e}", exc_info=True)
    
    full_ocr_text = "\n\n--- OCR Text from Image ---\n\n".join(ocr_text_parts).strip()
    logger.info(f"OCR for {file_base_name_for_log}: Extracted {len(full_ocr_text)} chars from {images_ocrd} image(s).")
    return full_ocr_text


def clean_and_normalize_text_content(text: str, file_base_name_for_log: str ="") -> str:
    if not text or not text.strip(): return ""
    logger.info(f"Text cleaning for {file_base_name_for_log}: Initial length {len(text)}")
    
    # Basic regex cleaning (order matters)
    text = re.sub(r'<script[^>]*>.*?</script>|<style[^>]*>.*?</style>', ' ', text, flags=re.I | re.S) # Remove script/style
    text = re.sub(r'<[^>]+>', ' ', text) # Remove all other HTML tags
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE) # Remove URLs
    text = re.sub(r'\S*@\S*\s?', '', text, flags=re.MULTILINE) # Remove emails
    text = re.sub(r'\s*&\w+;\s*', ' ', text) # Remove HTML entities like 
    text = re.sub(r'[\n\r\t]+', ' ', text) # Normalize whitespace (newlines, tabs to single space)
    text = re.sub(r'\s+', ' ', text).strip() # Consolidate multiple spaces to one and strip ends
    
    # Character filtering (allow more common punctuation useful for context)
    # text = re.sub(r'[^\w\s.,!?"\'():;-]', '', text) # Keeps more standard punctuation
    # For more aggressive cleaning for embedding, you might use:
    text = re.sub(r'[^a-zA-Z0-9\s.,!?-]', '', text) # More restrictive, closer to your original

    text_lower = text.lower() # Convert to lowercase AFTER regex to preserve case for URLs/emails if needed

    if not (SPACY_MODEL_LOADED and nlp_spacy_core):
        logger.warning(f"SpaCy model not loaded for {file_base_name_for_log}. Skipping lemmatization. Returning regex-cleaned text.")
        return text_lower
    
    try:
        # Process in chunks if text is very long to avoid SpaCy memory issues, though less likely after cleaning
        max_spacy_len = 1000000 # SpaCy's default internal limit for nlp()
        if len(text_lower) > max_spacy_len:
            logger.warning(f"Text for SpaCy in {file_base_name_for_log} exceeds {max_spacy_len} chars. Processing in parts or truncating.")
            # Simple truncation for now, chunking for spacy is more complex
            text_lower = text_lower[:max_spacy_len]

        doc = nlp_spacy_core(text_lower, disable=['parser', 'ner']) # Disable unused pipes
        lemmatized_tokens = [
            token.lemma_ for token in doc 
            if not token.is_stop and \
               not token.is_punct and \
               not token.is_space and \
               len(token.lemma_) > 1 and \
               token.lemma_ != '-PRON-' # Exclude pronouns after lemmatization
        ]
        final_cleaned_text = " ".join(lemmatized_tokens)
        logger.info(f"SpaCy cleaning for {file_base_name_for_log}: Final length {len(final_cleaned_text)}")
        return final_cleaned_text
    except Exception as e:
        logger.error(f"SpaCy processing failed for {file_base_name_for_log}: {e}. Returning pre-SpaCy cleaned text.", exc_info=True)
        return text_lower


def reconstruct_document_layout(text_content: str, tables_data: List[Any], file_type: str, file_base_name_for_log: str ="") -> str:
    if not text_content and not tables_data: return ""
    logger.info(f"Layout reconstruction for {file_base_name_for_log} ({file_type}): Text len {len(text_content)}, Tables {len(tables_data)}")
    
    # Hyphenated word de-joining (if text_content is not None)
    processed_text = text_content if text_content else ""
    processed_text = re.sub(r'(\w+)-\s*\n\s*(\w+)', r'\1\2', processed_text) # Across newlines
    # processed_text = re.sub(r'(\w+)-(\w+)', r'\1\2', processed_text) # Within same line (less common needed after initial parse)

    if tables_data:
        table_md_parts = []
        for i, table_obj in enumerate(tables_data):
            table_header = f"\n\n[START OF TABLE {i+1} extracted from {file_base_name_for_log}]\n"
            table_footer = f"\n[END OF TABLE {i+1}]\n"
            md_table_content = ""
            try:
                if PANDAS_AVAILABLE and pd and isinstance(table_obj, pd.DataFrame):
                    md_table_content = table_obj.to_markdown(index=False)
                elif isinstance(table_obj, list) and table_obj and all(isinstance(row, list) for row in table_obj):
                    # Basic list of lists to Markdown
                    if table_obj[0]: # Assume first row is header
                        md_table_content = "| " + " | ".join(map(str, table_obj[0])) + " |\n"
                        md_table_content += "| " + " | ".join(["---"] * len(table_obj[0])) + " |\n"
                        for row_data in table_obj[1:]:
                            if len(row_data) == len(table_obj[0]):
                                md_table_content += "| " + " | ".join(map(str, row_data)) + " |\n"
                            else: logger.warning(f"Table {i+1} (list) row length mismatch in {file_base_name_for_log}.")
                    else: md_table_content = "[Empty Table Data]"
                else: md_table_content = str(table_obj) # Fallback
            except Exception as e_table_md:
                logger.warning(f"Table {i+1} to Markdown conversion error for {file_base_name_for_log}: {e_table_md}. Using raw string.")
                md_table_content = str(table_obj)
            
            if md_table_content.strip():
                table_md_parts.append(table_header + md_table_content.strip() + table_footer)
        
        if table_md_parts:
            processed_text += "\n\n" + "\n\n".join(table_md_parts)
    
    # Final whitespace cleanup
    final_layout_text = re.sub(r'\s{2,}', ' ', processed_text).strip() # Consolidate multiple spaces
    logger.info(f"Layout reconstruction for {file_base_name_for_log}: Final length {len(final_layout_text)}")
    return final_layout_text


def extract_document_metadata_info(
    file_path: str, 
    processed_text: str, 
    parsed_doc_elements: Dict[str, Any], # Output from _get_initial_parsed_document
    original_file_name: str, 
    user_id: str
) -> Dict[str, Any]:
    logger.info(f"Metadata extraction for: {original_file_name} (User: {user_id})")
    
    parser_meta = parsed_doc_elements.get('parser_metadata', {})
    file_type_from_parser = os.path.splitext(original_file_name)[1].lower() # Fallback if not in parser_meta

    doc_meta = {
        'file_name': original_file_name,
        'file_path_on_server': file_path,
        'original_file_type': parser_meta.get('file_type', file_type_from_parser),
        'processing_user': user_id,
        'title': parser_meta.get('title', original_file_name), # Prioritize parser title
        'author': parser_meta.get('author', "Unknown"),       # Prioritize parser author
        'creation_date': parser_meta.get('creation_date'),   # Expect ISO format from parser
        'modification_date': parser_meta.get('modification_date'), # Expect ISO format
        'page_count': parser_meta.get('page_count', 0),
        'char_count_processed_text': len(processed_text),
        'named_entities': {},
        'structural_elements': "Paragraphs" + (", Tables" if parsed_doc_elements.get('tables') else ""),
        'is_scanned_document': parsed_doc_elements.get('is_scanned_heuristic', False), # Initial guess
        'ocr_applied': False # Will be set to True if OCR text was actually used
    }

    # OS-level metadata (can augment or be overridden by parser_meta)
    try:
        doc_meta['file_size_bytes'] = os.path.getsize(file_path)
        if PANDAS_AVAILABLE and pd: # Using pandas for robust timestamp conversion
            # Only set OS dates if not already provided by a more specific parser
            if not doc_meta['creation_date']:
                 doc_meta['creation_date_os'] = pd.Timestamp(os.path.getctime(file_path), unit='s').isoformat()
            if not doc_meta['modification_date']:
                 doc_meta['modification_date_os'] = pd.Timestamp(os.path.getmtime(file_path), unit='s').isoformat()
    except Exception as e_os_meta:
        logger.warning(f"Metadata: OS metadata error for {original_file_name}: {e_os_meta}")

    # If page_count is still 0 after parser, estimate from text
    if doc_meta['page_count'] == 0 and processed_text:
        doc_meta['page_count'] = max(1, processed_text.count('\n\n') + 1) # Rough estimate

    # NER (Named Entity Recognition) - using SpaCy
    if processed_text and SPACY_MODEL_LOADED and nlp_spacy_core:
        logger.info(f"Extracting named entities for {original_file_name}...")
        try:
            text_for_ner = processed_text[:MAX_TEXT_LENGTH_FOR_NER] # Use config alias
            spacy_doc = nlp_spacy_core(text_for_ner) # NER pipe should be enabled by default
            
            entities_by_type = {}
            for ent in spacy_doc.ents:
                entities_by_type.setdefault(ent.label_, set()).add(ent.text)
            
            doc_meta['named_entities'] = {label: sorted(list(texts)) for label, texts in entities_by_type.items()}
            num_entities_found = sum(len(v) for v in doc_meta['named_entities'].values())
            logger.info(f"Extracted {num_entities_found} unique named entities for {original_file_name}.")
        except Exception as e_ner:
            logger.error(f"Metadata: NER error for {original_file_name}: {e_ner}", exc_info=True)
    else:
        logger.info(f"Skipping NER for {original_file_name} (no text or SpaCy model not loaded/configured for NER).")
    
    logger.info(f"Metadata extraction complete for {original_file_name}.")
    return doc_meta

# Chunking and Embedding functions remain largely the same as your corrected versions,
# just ensure they consume the correct data.
def chunk_document_into_segments(
    text_to_chunk: str,
    document_level_metadata: Dict[str, Any] # This is the output from extract_document_metadata_info
) -> List[Dict[str, Any]]:
    if not text_to_chunk or not text_to_chunk.strip():
        logger.warning(f"Chunking: No text for {document_level_metadata.get('file_name', 'unknown')}.")
        return []

    if not (LANGCHAIN_SPLITTER_AVAILABLE and RecursiveCharacterTextSplitter):
        logger.error("RecursiveCharacterTextSplitter not available. Cannot chunk text.")
        return []
        
    chunk_s = AI_CORE_CHUNK_SIZE
    chunk_o = AI_CORE_CHUNK_OVERLAP
    original_doc_name_for_log = document_level_metadata.get('file_name', 'unknown_doc')
    logger.info(f"Chunking {original_doc_name_for_log}: Size={chunk_s}, Overlap={chunk_o}")
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_s,
        chunk_overlap=chunk_o,
        length_function=len,
        separators=["\n\n", "\n", ". ", " ", ""], 
        keep_separator=True # Consider if True or False is better for your LLM
    )

    try:
        raw_text_segments: List[str] = text_splitter.split_text(text_to_chunk)
    except Exception as e_split: 
        logger.error(f"Chunking: Error splitting text for {original_doc_name_for_log}: {e_split}", exc_info=True)
        return []
        
    output_chunks: List[Dict[str, Any]] = []
    # Use a more robust base name if original name contains problematic characters for reference
    base_file_name_for_ref = re.sub(r'[^a-zA-Z0-9_-]', '_', os.path.splitext(original_doc_name_for_log)[0])


    for i, segment_content in enumerate(raw_text_segments):
        if not segment_content.strip(): 
            logger.debug(f"Skipping empty chunk at index {i} for {original_doc_name_for_log}.")
            continue

        # Create a deep copy of document-level metadata for each chunk
        chunk_specific_metadata = copy.deepcopy(document_level_metadata)
        
        qdrant_point_id = str(uuid.uuid4()) # Unique ID for this chunk in Qdrant

        # Add chunk-specific details to its metadata
        chunk_specific_metadata['chunk_id'] = qdrant_point_id 
        chunk_specific_metadata['chunk_reference_name'] = f"{base_file_name_for_ref}_chunk_{i:04d}"
        chunk_specific_metadata['chunk_index'] = i
        chunk_specific_metadata['chunk_char_count'] = len(segment_content)
        # Remove potentially very large or redundant fields from chunk metadata if necessary
        # e.g., chunk_specific_metadata.pop('named_entities', None) if too verbose per chunk
        
        output_chunks.append({
            'id': qdrant_point_id, # This ID is for Qdrant
            'text_content': segment_content,
            'metadata': chunk_specific_metadata # This payload goes into Qdrant
        })
    
    logger.info(f"Chunking: Split '{original_doc_name_for_log}' into {len(output_chunks)} non-empty chunks.")
    return output_chunks

def generate_segment_embeddings(document_chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    if not document_chunks: return []
    if not (EMBEDDING_MODEL_LOADED and document_embedding_model):
        logger.error("Embedding model not loaded. Cannot generate embeddings.")
        for chunk_dict in document_chunks: chunk_dict['embedding'] = None
        return document_chunks

    model_name_for_logging = DOCUMENT_EMBEDDING_MODEL_NAME
    logger.info(f"Embedding {len(document_chunks)} chunks using {model_name_for_logging}.")
    
    texts_to_embed: List[str] = []
    valid_chunk_indices: List[int] = [] # To map embeddings back to original chunk objects

    for i, chunk_dict in enumerate(document_chunks):
        text_content = chunk_dict.get('text_content')
        if text_content and text_content.strip():
            texts_to_embed.append(text_content)
            valid_chunk_indices.append(i)
        else:
            chunk_dict['embedding'] = None # Ensure 'embedding' key exists
            logger.debug(f"Embedding: Chunk {chunk_dict.get('id', i)} has no text, skipping.")

    if not texts_to_embed:
        logger.warning("Embedding: No text content found in chunks to generate embeddings.")
        return document_chunks

    try:
        embeddings_np_array = document_embedding_model.encode(texts_to_embed, show_progress_bar=True) # Set to True for long lists
        
        for i, original_chunk_idx in enumerate(valid_chunk_indices):
            if i < len(embeddings_np_array):
                document_chunks[original_chunk_idx]['embedding'] = embeddings_np_array[i].tolist()
            else: # Should not happen if encode works correctly
                logger.error(f"Embedding: Mismatch in embedding count for chunk at original index {original_chunk_idx}.")
                document_chunks[original_chunk_idx]['embedding'] = None
        
        logger.info(f"Embedding: Generated and assigned embeddings to {len(valid_chunk_indices)} chunks.")
    except Exception as e_embed:
        logger.error(f"Embedding: Error during generation with {model_name_for_logging}: {e_embed}", exc_info=True)
        for original_chunk_idx in valid_chunk_indices: # Ensure all attempted chunks get None on error
            document_chunks[original_chunk_idx]['embedding'] = None
            
    return document_chunks


# --- Main Orchestration Function ---
def process_document_for_qdrant(file_path: str, original_name: str, user_id: str) -> tuple[List[Dict[str, Any]], Optional[str], List[Dict[str, Any]]]:
    """
    Main orchestrator for processing a document.
    Returns:
        - final_chunks_for_qdrant: List of chunks with embeddings for Qdrant.
        - text_for_node_analysis: Consolidated text for Node.js general analysis (FAQ, Topics).
        - chunks_for_kg_worker: List of chunks with metadata (no embeddings) for KG worker.
    """
    logger.info(f"ai_core: Orchestrating document processing for '{original_name}', user '{user_id}'")
    if not os.path.exists(file_path):
        logger.error(f"File not found at ai_core entry: {file_path}")
        # Return empty tuple of expected types
        return [], None, []


    # Default return values for failure cases
    empty_qdrant_chunks = []
    no_analysis_text = None
    empty_kg_chunks = []

    try:
        # 1. Initial Parsing (Rich Element Extraction)
        parsed_doc_elements = _get_initial_parsed_document(file_path)
        initial_text_from_parser = parsed_doc_elements.get('text_content')
        images_from_parser = parsed_doc_elements.get('images', [])
        tables_from_parser = parsed_doc_elements.get('tables', [])
        is_scanned_heuristic = parsed_doc_elements.get('is_scanned_heuristic', False)
        file_type_from_parser = os.path.splitext(original_name)[1].lower() # Or get from parsed_doc_elements if available

        # 2. OCR if needed
        ocr_text_output = ""
        ocr_applied_flag = False
        # Decide if OCR is necessary:
        # - Explicitly image file types.
        # - Parser's heuristic says scanned.
        # - Parser extracted no text but found images (strong indicator for OCR).
        # - Parser extracted minimal text and images are present (e.g., a DOCX that's mostly a picture).
        should_ocr = is_scanned_heuristic or \
                     (file_type_from_parser in ['.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif']) or \
                     (not initial_text_from_parser and images_from_parser) or \
                     (initial_text_from_parser and len(initial_text_from_parser) < 200 * len(images_from_parser) and images_from_parser) # Heuristic for low text + images

        if should_ocr and images_from_parser:
            if PYTESSERACT_AVAILABLE and pytesseract:
                logger.info(f"OCR triggered for {original_name} based on heuristics/file type.")
                ocr_text_output = perform_ocr_on_images(images_from_parser, original_name)
                if ocr_text_output: ocr_applied_flag = True
            else:
                logger.warning(f"OCR needed for {original_name} but Pytesseract not available. Content may be incomplete.")
        
        # 3. Combine Text (Parser + OCR)
        combined_raw_text_parts = []
        if initial_text_from_parser: combined_raw_text_parts.append(initial_text_from_parser)
        if ocr_text_output: combined_raw_text_parts.append(ocr_text_output)
        combined_raw_text = "\n\n".join(combined_raw_text_parts).strip()

        if not combined_raw_text and not tables_from_parser:
            logger.warning(f"No text content or tables for {original_name} after initial parsing/OCR. Processing cannot continue.")
            return empty_qdrant_chunks, no_analysis_text, empty_kg_chunks

        # 4. Clean Text
        cleaned_text = clean_and_normalize_text_content(combined_raw_text, original_name)
        if not cleaned_text and not tables_from_parser: # If cleaning results in empty text
            logger.warning(f"No meaningful text for {original_name} after cleaning, and no tables. Processing cannot continue.")
            return empty_qdrant_chunks, no_analysis_text, empty_kg_chunks

        # 5. Reconstruct Layout (Integrate Tables as Markdown)
        text_for_further_processing = reconstruct_document_layout(
            cleaned_text, # Use the cleaned text
            tables_from_parser,
            file_type_from_parser,
            original_name
        )
        # This `text_for_further_processing` is a good candidate for Node.js analysis (FAQ, topics)
        # as it's cleaned and has table context.
        raw_text_for_node_analysis = text_for_further_processing 

        # 6. Extract Comprehensive Metadata
        doc_metadata = extract_document_metadata_info(
            file_path,
            text_for_further_processing, # Pass the final text that will be chunked
            parsed_doc_elements, # Pass the full initial parse results
            original_name,
            user_id
        )
        doc_metadata['ocr_applied'] = ocr_applied_flag # Update with actual OCR status

        # 7. Chunk Document
        # We chunk `text_for_further_processing` which includes table representations.
        chunks_with_metadata_for_qdrant_and_kg = chunk_document_into_segments(
            text_for_further_processing,
            doc_metadata # Pass rich metadata to chunks
        )
        if not chunks_with_metadata_for_qdrant_and_kg:
            logger.warning(f"No chunks produced for {original_name}. Cannot proceed with Qdrant/KG.")
            # Still return raw_text_for_node_analysis if it exists
            return empty_qdrant_chunks, raw_text_for_node_analysis, empty_kg_chunks

        # Prepare chunks for KG worker (these don't need embeddings yet)
        # Important: Deep copy if you modify this list before embedding,
        # or if embedding modifies in-place (unlikely with current generate_segment_embeddings)
        chunks_for_kg_worker = copy.deepcopy(chunks_with_metadata_for_qdrant_and_kg) 
        # Remove embedding from KG chunks if it somehow got there, or any very large fields not needed by KG LLM
        for chunk in chunks_for_kg_worker:
            chunk.pop('embedding', None) 
            # Consider removing other large metadata fields if KG LLM doesn't need them from each chunk's metadata

        # 8. Generate Embeddings for Qdrant chunks
        final_chunks_for_qdrant = generate_segment_embeddings(chunks_with_metadata_for_qdrant_and_kg)
        
        logger.info(f"ai_core: Successfully processed '{original_name}'. Generated {len(final_chunks_for_qdrant)} chunks for Qdrant.")
        return final_chunks_for_qdrant, raw_text_for_node_analysis, chunks_for_kg_worker

    except Exception as e:
        # Check for specific critical errors like Tesseract not found
        if TESSERACT_ERROR and isinstance(e, TESSERACT_ERROR):
            logger.critical(f"ai_core: Tesseract (OCR) not found processing {original_name}. OCR failed. Error: {e}", exc_info=False)
            # Depending on policy, you might still want to return any text extracted *before* OCR attempt.
            # For now, re-raise to indicate critical failure to the caller (app.py).
            raise
        
        logger.error(f"ai_core: Critical error processing {original_name}: {e}", exc_info=True)
        # Re-raise the exception to be handled by the caller in app.py
        raise
```

`rag_service/app.py`

```python
# # server/rag_service/app.py

# import os
# import sys
# import traceback
# from flask import Flask, request, jsonify, current_app
# import logging
# import atexit # For graceful shutdown

# # --- NEW IMPORT ---
# from duckduckgo_search import DDGS

# # --- Add server directory to sys.path ---
# SERVER_DIR = os.path.dirname(os.path.abspath(__file__))
# if SERVER_DIR not in sys.path:
#     sys.path.insert(0, SERVER_DIR)

# import config
# config.setup_logging() # Initialize logging as per your config

# # --- Import configurations and services ---
# try:
#     from vector_db_service import VectorDBService
#     import ai_core
#     import neo4j_handler 
#     from neo4j import exceptions as neo4j_exceptions # For specific error handling
# except ImportError as e:
#     print(f"CRITICAL IMPORT ERROR: {e}. Ensure all modules are correctly placed and server directory is in PYTHONPATH.")
#     print("PYTHONPATH:", sys.path)
#     sys.exit(1)

# logger = logging.getLogger(__name__)
# app = Flask(__name__)

# # --- Initialize VectorDBService (Qdrant) ---
# vector_service = None
# try:
#     logger.info("Initializing VectorDBService for Qdrant...")
#     vector_service = VectorDBService()
#     vector_service.setup_collection()
#     app.vector_service = vector_service
#     logger.info("VectorDBService initialized and Qdrant collection setup successfully.")
# except Exception as e:
#     logger.critical(f"Failed to initialize VectorDBService or setup Qdrant collection: {e}", exc_info=True)
#     app.vector_service = None

# # --- Initialize Neo4j Driver (via handler) ---
# try:
#     neo4j_handler.init_driver() # Initialize Neo4j driver on app start
# except Exception as e:
#     logger.critical(f"Neo4j driver failed to initialize on startup: {e}. KG endpoints will likely fail.")
#     # Depending on how critical Neo4j is, you might sys.exit(1) here.

# # Register Neo4j driver close function for app exit
# atexit.register(neo4j_handler.close_driver)


# # --- Helper for Error Responses ---
# def create_error_response(message, status_code=500, details=None):
#     log_message = f"API Error ({status_code}): {message}"
#     if details:
#         log_message += f" | Details: {details}"
#     current_app.logger.error(log_message)
#     response_payload = {"error": message}
#     if details and status_code != 500:
#         response_payload["details"] = details
#     return jsonify(response_payload), status_code

# # === API Endpoints ===

# # --- NEW WEB SEARCH ENDPOINT ---
# @app.route('/web_search', methods=['POST'])
# def web_search_route():
#     current_app.logger.info("--- /web_search Request (DuckDuckGo) ---")
#     if not request.is_json:
#         return create_error_response("Request must be JSON", 400)
    
#     data = request.get_json()
#     query = data.get('query')

#     if not query:
#         return create_error_response("Missing 'query' field in request body", 400)
    
#     try:
#         current_app.logger.info(f"Performing DDG search for query: '{query}'")
#         with DDGS() as ddgs:
#             # Fetch 5 results, which is a reasonable number for context
#             results = list(ddgs.text(query, max_results=5))

#         # Format results into the structure expected by the Node.js service
#         formatted_results = [
#             {"title": r.get("title"), "url": r.get("href"), "content": r.get("body")}
#             for r in results
#         ]
        
#         current_app.logger.info(f"DDG search successful. Found {len(formatted_results)} results.")
#         return jsonify(formatted_results), 200

#     except Exception as e:
#         current_app.logger.error(f"DuckDuckGo search failed for query '{query}': {e}", exc_info=True)
#         return create_error_response(f"Web search failed due to an internal error: {str(e)}", 500)

# @app.route('/health', methods=['GET'])
# def health_check():
#     current_app.logger.info("--- Health Check Request ---")
#     # ... (rest of health_check function is unchanged)
#     status_details = {
#         "status": "error",
#         "qdrant_service": "not_initialized",
#         "qdrant_collection_name": config.QDRANT_COLLECTION_NAME,
#         "qdrant_collection_status": "unknown",
#         "document_embedding_model": config.DOCUMENT_EMBEDDING_MODEL_NAME,
#         "query_embedding_model": config.QUERY_EMBEDDING_MODEL_NAME,
#         "neo4j_service": "not_initialized_via_handler", # Updated message
#         "neo4j_connection": "unknown"
#     }
#     http_status_code = 503
#     if not vector_service:
#         status_details["qdrant_service"] = "failed_to_initialize"
#     else:
#         status_details["qdrant_service"] = "initialized"
#         try:
#             vector_service.client.get_collection(collection_name=vector_service.collection_name)
#             status_details["qdrant_collection_status"] = "exists_and_accessible"
#         except Exception as e:
#             status_details["qdrant_collection_status"] = f"error_accessing_collection: {str(e)}"
#             current_app.logger.error(f"Health check: Error accessing Qdrant collection: {e}", exc_info=False)
#     neo4j_ok, neo4j_conn_status = neo4j_handler.check_neo4j_connectivity()
#     if neo4j_ok:
#         status_details["neo4j_service"] = "initialized_via_handler"
#         status_details["neo4j_connection"] = "connected"
#     else:
#         status_details["neo4j_service"] = "initialization_failed_or_handler_error"
#         status_details["neo4j_connection"] = neo4j_conn_status
#     if status_details["qdrant_service"] == "initialized" and status_details["qdrant_collection_status"] == "exists_and_accessible" and neo4j_ok:
#         status_details["status"] = "ok"
#         http_status_code = 200
#         current_app.logger.info("Health check successful (Qdrant & Neo4j).")
#     else:
#         current_app.logger.warning(f"Health check issues found: Qdrant service: {status_details['qdrant_service']}, Qdrant collection: {status_details['qdrant_collection_status']}, Neo4j service: {status_details['neo4j_service']}, Neo4j connection: {status_details['neo4j_connection']}")
#     return jsonify(status_details), http_status_code

# # (The rest of the file remains unchanged, only adding the /web_search route is necessary)
# @app.route('/add_document', methods=['POST'])
# def add_document_qdrant():
#     # ... (existing /add_document endpoint logic)
#     current_app.logger.info("--- /add_document Request (Qdrant) ---")
#     if not request.is_json:
#         return create_error_response("Request must be JSON", 400)
#     if not vector_service:
#         return create_error_response("VectorDBService (Qdrant) is not available.", 503)
#     data = request.get_json()
#     user_id = data.get('user_id')
#     file_path = data.get('file_path')
#     original_name = data.get('original_name')
#     if not all([user_id, file_path, original_name]):
#         return create_error_response("Missing required fields: user_id, file_path, original_name", 400)
#     current_app.logger.info(f"Processing file: '{original_name}' (Path: '{file_path}') for user: '{user_id}' for Qdrant")
#     if not os.path.exists(file_path):
#         current_app.logger.error(f"File not found at server path: {file_path}")
#         return create_error_response(f"File not found at server path: {file_path}", 404)
#     try:
#         current_app.logger.info(f"Calling ai_core to process document: '{original_name}' for Qdrant")
#         processed_chunks_with_embeddings, raw_text_for_node_analysis, chunks_with_metadata_for_kg = ai_core.process_document_for_qdrant(
#             file_path=file_path, original_name=original_name, user_id=user_id
#         )
#         num_chunks_added_to_qdrant = 0
#         processing_status = "processed_no_content_for_qdrant"
#         if processed_chunks_with_embeddings:
#             current_app.logger.info(f"ai_core generated {len(processed_chunks_with_embeddings)} chunks for '{original_name}'. Adding to Qdrant.")
#             num_chunks_added_to_qdrant = app.vector_service.add_processed_chunks(processed_chunks_with_embeddings)
#             if num_chunks_added_to_qdrant > 0:
#                 processing_status = "added_to_qdrant"
#             else:
#                 processing_status = "processed_qdrant_chunks_not_added"
#         elif raw_text_for_node_analysis:
#              current_app.logger.info(f"ai_core produced no processable Qdrant chunks for '{original_name}', but raw text was extracted.")
#              processing_status = "processed_for_analysis_only_no_qdrant"
#         else:
#             current_app.logger.warning(f"ai_core produced no Qdrant chunks and no raw text for '{original_name}'.")
#             return jsonify({
#                 "message": f"Processed '{original_name}' but no content was extracted for Qdrant or analysis.",
#                 "status": "no_content_extracted", "filename": original_name, "user_id": user_id,
#                 "num_chunks_added_to_qdrant": 0, "raw_text_for_analysis": ""
#             }), 200
#         response_payload = {
#             "message": f"Successfully processed '{original_name}' for Qdrant. Status: {processing_status}.",
#             "status": "added", "filename": original_name, "user_id": user_id,
#             "num_chunks_added_to_qdrant": num_chunks_added_to_qdrant,
#             "raw_text_for_analysis": raw_text_for_node_analysis if raw_text_for_node_analysis is not None else "",
#             "chunks_with_metadata": chunks_with_metadata_for_kg
#         }
#         current_app.logger.info(f"Successfully processed '{original_name}' for Qdrant. Returning raw text and Qdrant status.")
#         return jsonify(response_payload), 201
#     except FileNotFoundError as e:
#         current_app.logger.error(f"Add Document (Qdrant) Error for '{original_name}' - FileNotFoundError: {e}", exc_info=True)
#         return create_error_response(f"File not found during Qdrant processing: {str(e)}", 404)
#     except config.TESSERACT_ERROR:
#         current_app.logger.critical(f"Add Document (Qdrant) Error for '{original_name}' - Tesseract (OCR) not found.")
#         return create_error_response("OCR engine (Tesseract) not found or not configured correctly on the server.", 500)
#     except ValueError as e:
#         current_app.logger.error(f"Add Document (Qdrant) Error for '{original_name}' - ValueError: {e}", exc_info=True)
#         return create_error_response(f"Configuration or data error for Qdrant: {str(e)}", 400)
#     except Exception as e:
#         current_app.logger.error(f"Add Document (Qdrant) Error for '{original_name}' - Unexpected Exception: {e}\n{traceback.format_exc()}", exc_info=True)
#         return create_error_response(f"Failed to process document '{original_name}' for Qdrant due to an internal error.", 500)

# @app.route('/query', methods=['POST'])
# def search_qdrant_documents_and_get_kg():
#     # ... (existing /query endpoint logic)
#     current_app.logger.info("--- /query Request (Qdrant Search + Optional KG Retrieval) ---")
#     if not request.is_json:
#         return create_error_response("Request must be JSON", 400)
#     if not vector_service:
#         return create_error_response("VectorDBService (Qdrant) is not available.", 503)
#     data = request.get_json()
#     current_app.logger.info(f"--- /query RAW REQUEST DATA: {data} ---")
#     query_text = data.get('query')
#     user_id_from_request = data.get('user_id')
#     k = data.get('k', config.QDRANT_DEFAULT_SEARCH_K)
#     filter_payload_from_request = data.get('filter')
#     documentContextName = data.get('documentContextName')
#     use_kg_for_critical_thinking = data.get('use_kg_critical_thinking', False) 
#     current_app.logger.info(f"KG Critical Thinking Requested: {use_kg_for_critical_thinking}")
#     if documentContextName:
#         current_app.logger.info(f"Document Context Name for filtering: '{documentContextName}'")
#     if filter_payload_from_request:
#         current_app.logger.info(f"Client-provided filter payload: {filter_payload_from_request}")
#     if use_kg_for_critical_thinking:
#         try:
#             neo4j_handler.get_driver_instance() 
#         except ConnectionError: 
#             current_app.logger.error("Neo4j driver unavailable but KG was requested.")
#             return create_error_response("Knowledge Graph service (Neo4j) is not available, but KG retrieval was requested.", 503)
#         except Exception as e: 
#             current_app.logger.error(f"Error checking Neo4j driver availability: {e}")
#             return create_error_response(f"Error initializing Knowledge Graph service: {str(e)}", 503)
#     if not query_text:
#         return create_error_response("Missing 'query' field in request body", 400)
#     if not user_id_from_request:
#         return create_error_response("Missing 'user_id' field in request body", 400)
#     try:
#         k = int(k)
#     except ValueError:
#         return create_error_response("'k' must be an integer", 400)
#     from qdrant_client import models as qdrant_models
#     must_conditions = []
#     if documentContextName:
#         current_app.logger.info(f"Condition for documentContextName: '{documentContextName}' on field 'file_name' will be added to 'must' conditions.")
#         must_conditions.append(qdrant_models.FieldCondition(
#             key="file_name", match=qdrant_models.MatchValue(value=documentContextName)
#         ))
#     if filter_payload_from_request and isinstance(filter_payload_from_request, dict):
#         current_app.logger.info(f"Processing Qdrant filters from client payload (simple key-value): {filter_payload_from_request}")
#         for key, value in filter_payload_from_request.items():
#             if isinstance(key, str) and isinstance(value, (str, int, float, bool)):
#                  current_app.logger.info(f"Condition for client filter: key='{key}', value='{value}' will be added to 'must' conditions.")
#                  must_conditions.append(qdrant_models.FieldCondition(key=key, match=qdrant_models.MatchValue(value=value)))
#             else:
#                 current_app.logger.warning(f"Skipping invalid client filter condition: key='{key}', value='{value}'. Key must be string, value must be primitive.")
#     qdrant_filters = qdrant_models.Filter(must=must_conditions) if must_conditions else None
#     if qdrant_filters:
#         try: filter_dict_for_log = qdrant_filters.model_dump()
#         except AttributeError:
#             try: filter_dict_for_log = qdrant_filters.dict()
#             except AttributeError: filter_dict_for_log = str(qdrant_filters)
#         current_app.logger.info(f"Final Qdrant filter to be applied: {filter_dict_for_log}")
#     else:
#         current_app.logger.info("No Qdrant filter explicitly provided or derived for this query.")
#     current_app.logger.info(f"Performing Qdrant search for user '{user_id_from_request}', query (first 50): '{query_text[:50]}...' with k={k}")
#     try:
#         qdrant_retrieved_docs, formatted_context_snippet, qdrant_docs_map = vector_service.search_documents(
#             query=query_text, k=k, filter_conditions=qdrant_filters
#         )
#         knowledge_graphs_data = {} 
#         if use_kg_for_critical_thinking and qdrant_retrieved_docs:
#             current_app.logger.info("KG retrieval is ENABLED and Qdrant returned documents.")
#             unique_doc_names_for_kg = set()
#             for doc_obj in qdrant_retrieved_docs:
#                 doc_payload = doc_obj.payload if hasattr(doc_obj, 'payload') else doc_obj.metadata
#                 doc_name_for_kg = documentContextName or doc_payload.get('documentName', doc_payload.get('original_name', doc_payload.get('file_name')))
#                 if doc_name_for_kg:
#                     unique_doc_names_for_kg.add(doc_name_for_kg)
#                 else:
#                     qdrant_doc_id = doc_obj.id if hasattr(doc_obj, 'id') else doc_payload.get('qdrant_id', 'N/A')
#                     current_app.logger.warning(f"Qdrant doc payload missing document identifier for chunk ID {qdrant_doc_id}. Cannot fetch KG.")
#             current_app.logger.info(f"Found {len(unique_doc_names_for_kg)} unique document(s) in Qdrant results to fetch KGs for: {list(unique_doc_names_for_kg)}")
#             for doc_name in unique_doc_names_for_kg:
#                 try:
#                     current_app.logger.info(f"Fetching KG for document '{doc_name}' (User: {user_id_from_request})")
#                     kg_content = neo4j_handler.get_knowledge_graph(user_id_from_request, doc_name)
#                     if kg_content and (kg_content.get("nodes") or kg_content.get("edges")): 
#                         knowledge_graphs_data[doc_name] = kg_content
#                         current_app.logger.info(f"Successfully retrieved KG for '{doc_name}'. Nodes: {len(kg_content.get('nodes',[]))}, Edges: {len(kg_content.get('edges',[]))}")
#                     else:
#                         current_app.logger.info(f"No KG data found in Neo4j for document '{doc_name}' (User: {user_id_from_request}).")
#                         knowledge_graphs_data[doc_name] = {"nodes": [], "edges": [], "message": "KG not found or contains no data"}
#                 except Exception as kg_err: 
#                     current_app.logger.error(f"Error retrieving KG for document '{doc_name}': {kg_err}", exc_info=True)
#                     knowledge_graphs_data[doc_name] = {"nodes": [], "edges": [], "error": f"Failed to retrieve KG: {str(kg_err)}"}
#         elif not use_kg_for_critical_thinking:
#             current_app.logger.info("KG retrieval is DISABLED by request.")
#         elif not qdrant_retrieved_docs:
#             current_app.logger.info("KG retrieval was requested, but no documents were found by Qdrant. Skipping KG fetch.")
#         response_payload = {
#             "query": query_text, "k_requested": k, "user_id_processed": user_id_from_request,
#             "qdrant_filter_applied": { "client_filter": filter_payload_from_request, "document_context_filter": documentContextName },
#             "qdrant_results_count": len(qdrant_retrieved_docs), "formatted_context_snippet": formatted_context_snippet,
#             "retrieved_documents_map": qdrant_docs_map, "retrieved_documents_list": [doc.to_dict() for doc in qdrant_retrieved_docs],
#             "knowledge_graphs": knowledge_graphs_data, "kg_retrieval_attempted": use_kg_for_critical_thinking and bool(qdrant_retrieved_docs)
#         }
#         log_message_kg_part = "and KGs" if use_kg_for_critical_thinking and any(v.get("nodes") or v.get("edges") for v in knowledge_graphs_data.values() if isinstance(v,dict)) else ("and KG retrieval was SKIPPED" if not use_kg_for_critical_thinking else "and no KGs found/retrieved")
#         current_app.logger.info(f"Qdrant search {log_message_kg_part} successful. Returning {len(qdrant_retrieved_docs)} Qdrant docs.")
#         return jsonify(response_payload), 200
#     except ConnectionError as ce:
#         current_app.logger.error(f"Service connection error during /query processing: {ce}", exc_info=True)
#         return create_error_response(f"A dependent service is unavailable: {str(ce)}", 503)
#     except Exception as e:
#         current_app.logger.error(f"/query processing failed: {e}\n{traceback.format_exc()}", exc_info=True)
#         return create_error_response(f"Error during query processing: {str(e)}", 500)

# @app.route('/delete_qdrant_document_data', methods=['DELETE'])
# def delete_qdrant_data_route():
#     # ... (existing /delete_qdrant_document_data endpoint logic)
#     current_app.logger.info("--- DELETE /delete_qdrant_document_data Request ---")
#     if not request.is_json:
#         return create_error_response("Request must be JSON", 400)
#     if not vector_service:
#         return create_error_response("VectorDBService (Qdrant) is not available.", 503)
#     data = request.get_json()
#     user_id = data.get('user_id')
#     document_name = data.get('document_name') 
#     if not user_id or not document_name:
#         return create_error_response("Missing 'user_id' or 'document_name' in request body.", 400)
#     try:
#         result = vector_service.delete_document_vectors(user_id, document_name) 
#         if result.get("success"):
#             return jsonify({"message": result.get("message", "Qdrant vectors for document processed for deletion.")}), 200
#         else:
#             return create_error_response(result.get("message", "Failed to delete Qdrant vectors."), 500)
#     except ConnectionError as ce:
#         current_app.logger.error(f"Qdrant connection error during /delete_qdrant_document_data for user {user_id}, doc {document_name}: {ce}", exc_info=True)
#         return create_error_response(f"Qdrant service connection error: {str(ce)}", 503)
#     except Exception as e:
#         current_app.logger.error(f"/delete_qdrant_document_data for user {user_id}, doc {document_name} failed: {e}", exc_info=True)
#         return create_error_response(f"Error during Qdrant data deletion: {str(e)}", 500)

# @app.route('/kg', methods=['POST'])
# def add_or_update_kg_route():
#     # ... (existing /kg POST endpoint logic)
#     current_app.logger.info("--- POST /kg Request (Neo4j Ingestion) ---")
#     if not request.is_json:
#         return create_error_response("Request must be JSON", 400)
#     data = request.get_json()
#     user_id = data.get('userId')
#     original_name = data.get('originalName')
#     nodes = data.get('nodes')
#     edges = data.get('edges')
#     if not all([user_id, original_name, isinstance(nodes, list), isinstance(edges, list)]):
#         missing_fields = []
#         if not user_id: missing_fields.append("userId")
#         if not original_name: missing_fields.append("originalName")
#         if not isinstance(nodes, list): missing_fields.append("nodes (must be a list)")
#         if not isinstance(edges, list): missing_fields.append("edges (must be a list)")
#         return create_error_response(f"Missing or invalid fields: {', '.join(missing_fields)}", 400,
#                                      details=f"Received: userId type {type(user_id)}, originalName type {type(original_name)}, nodes type {type(nodes)}, edges type {type(edges)}")
#     logger.info(f"Attempting to ingest KG for user '{user_id}', document '{original_name}'. Nodes: {len(nodes)}, Edges: {len(edges)}")
#     try:
#         result = neo4j_handler.ingest_knowledge_graph(user_id, original_name, nodes, edges)
#         if result["success"]:
#             return jsonify({
#                 "message": result["message"], "userId": user_id, "documentName": original_name,
#                 "nodes_affected": result["nodes_affected"], "edges_affected": result["edges_affected"],
#                 "status": "completed"
#             }), 201
#         else:
#             return create_error_response(result.get("message", "KG ingestion failed."), 500)
#     except ConnectionError as e:
#         logger.error(f"Neo4j connection error during KG ingestion for '{original_name}': {e}", exc_info=True)
#         return create_error_response(f"Neo4j connection error: {str(e)}. Please check service.", 503)
#     except neo4j_exceptions.Neo4jError as e:
#         logger.error(f"Neo4jError during KG ingestion for '{original_name}': {e}", exc_info=True)
#         return create_error_response(f"Neo4j database error: {e.message}", 500)
#     except Exception as e:
#         logger.error(f"Unexpected error during KG ingestion for '{original_name}': {e}\n{traceback.format_exc()}", exc_info=True)
#         return create_error_response(f"Failed to ingest Knowledge Graph: {str(e)}", 500)

# @app.route('/kg/<user_id>/<path:document_name>', methods=['GET'])
# def get_kg_route(user_id, document_name):
#     # ... (existing /kg GET endpoint logic)
#     current_app.logger.info(f"--- GET /kg/{user_id}/{document_name} Request (Neo4j Retrieval) ---")
#     sanitized_user_id = user_id.replace("..","").strip()
#     sanitized_document_name = document_name.replace("..","").strip()
#     if not sanitized_user_id or not sanitized_document_name:
#         return create_error_response("User ID and Document Name URL parameters are required and cannot be empty.", 400)
#     logger.info(f"Retrieving KG for user '{sanitized_user_id}', document '{sanitized_document_name}'.")
#     try:
#         kg_data = neo4j_handler.get_knowledge_graph(sanitized_user_id, sanitized_document_name)
#         if kg_data is None:
#             logger.info(f"No KG data found for user '{sanitized_user_id}', document '{sanitized_document_name}'.")
#             return create_error_response("Knowledge Graph not found for the specified user and document.", 404)
#         logger.info(f"Successfully retrieved KG for document '{sanitized_document_name}'. Nodes: {len(kg_data.get('nodes',[]))}, Edges: {len(kg_data.get('edges',[]))}")
#         return jsonify(kg_data), 200
#     except ConnectionError as e:
#         logger.error(f"Neo4j connection error during KG retrieval: {e}", exc_info=True)
#         return create_error_response(f"Neo4j connection error: {str(e)}. Please check service.", 503)
#     except neo4j_exceptions.Neo4jError as e:
#         logger.error(f"Neo4jError during KG retrieval: {e}", exc_info=True)
#         return create_error_response(f"Neo4j database error: {e.message}", 500)
#     except Exception as e:
#         logger.error(f"Unexpected error during KG retrieval: {e}\n{traceback.format_exc()}", exc_info=True)
#         return create_error_response(f"Failed to retrieve Knowledge Graph: {str(e)}", 500)

# @app.route('/kg/<user_id>/<path:document_name>', methods=['DELETE'])
# def delete_kg_route(user_id, document_name):
#     # ... (existing /kg DELETE endpoint logic)
#     current_app.logger.info(f"--- DELETE /kg/{user_id}/{document_name} Request (Neo4j Deletion) ---")
#     sanitized_user_id = user_id.replace("..","").strip()
#     sanitized_document_name = document_name.replace("..","").strip()
#     if not sanitized_user_id or not sanitized_document_name:
#         return create_error_response("User ID and Document Name URL parameters are required and cannot be empty.", 400)
#     logger.info(f"Attempting to delete KG for user '{sanitized_user_id}', document '{sanitized_document_name}'.")
#     try:
#         deleted = neo4j_handler.delete_knowledge_graph(sanitized_user_id, sanitized_document_name)
#         if deleted:
#             logger.info(f"Knowledge Graph for document '{sanitized_document_name}' (User: {sanitized_user_id}) deleted successfully.")
#             return jsonify({"message": "Knowledge Graph deleted successfully."}), 200
#         else:
#             logger.info(f"No Knowledge Graph found for document '{sanitized_document_name}' (User: {sanitized_user_id}) to delete.")
#             return create_error_response("Knowledge Graph not found for deletion.", 404)
#     except ConnectionError as e:
#         logger.error(f"Neo4j connection error during KG deletion: {e}", exc_info=True)
#         return create_error_response(f"Neo4j connection error: {str(e)}. Please check service.", 503)
#     except neo4j_exceptions.Neo4jError as e:
#         logger.error(f"Neo4jError during KG deletion: {e}", exc_info=True)
#         return create_error_response(f"Neo4j database error: {e.message}", 500)
#     except Exception as e:
#         logger.error(f"Unexpected error during KG deletion: {e}\n{traceback.format_exc()}", exc_info=True)
#         return create_error_response(f"Failed to delete Knowledge Graph: {str(e)}", 500)

# if __name__ == '__main__':
#     logger.info(f"--- Starting RAG API Service (with KG) on port {config.API_PORT} ---")
#     # ... (rest of main block is unchanged)
#     logger.info(f"Qdrant Host: {config.QDRANT_HOST}, Port: {config.QDRANT_PORT}, Collection: {config.QDRANT_COLLECTION_NAME}")
#     logger.info(f"Neo4j URI: {config.NEO4J_URI}, User: {config.NEO4J_USERNAME}, DB: {config.NEO4J_DATABASE}")
#     logger.info(f"Document Embedding Model (ai_core): {config.DOCUMENT_EMBEDDING_MODEL_NAME} (Dim: {config.DOCUMENT_VECTOR_DIMENSION})")
#     logger.info(f"Query Embedding Model (vector_db_service): {config.QUERY_EMBEDDING_MODEL_NAME} (Dim: {config.QUERY_VECTOR_DIMENSION})")
#     app.run(host='0.0.0.0', port=config.API_PORT, debug=True)













# server/rag_service/app.py

import os
import sys
import traceback
from flask import Flask, request, jsonify, current_app, send_from_directory, after_this_request
import logging
import atexit
import uuid

from duckduckgo_search import DDGS

# --- Add server directory to sys.path ---
SERVER_DIR = os.path.dirname(os.path.abspath(__file__))
if SERVER_DIR not in sys.path:
    sys.path.insert(0, SERVER_DIR)

import config
config.setup_logging()

# --- Import configurations and services ---
try:
    from vector_db_service import VectorDBService
    import ai_core
    import neo4j_handler 
    from neo4j import exceptions as neo4j_exceptions
    import document_generator
    import google.generativeai as genai

    if config.GEMINI_API_KEY:
        genai.configure(api_key=config.GEMINI_API_KEY)
        # Configure with safety settings to prevent common blockages
        safety_settings = [
            {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
            {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
        ]
        LLM_MODEL = genai.GenerativeModel(config.GEMINI_MODEL_NAME, safety_settings=safety_settings)
    else:
        LLM_MODEL = None
        logging.getLogger(__name__).error("GEMINI_API_KEY not found, document generation will fail.")

    def llm_wrapper(prompt):
        """A simple wrapper to call the configured Gemini model."""
        if not LLM_MODEL:
            raise ConnectionError("Gemini API Key is not configured in the Python service.")
        
        # Added a retry mechanism for transient API errors
        for attempt in range(3):
            try:
                response = LLM_MODEL.generate_content(prompt)
                # Check for content before accessing text
                if response.parts:
                    return "".join(part.text for part in response.parts if hasattr(part, 'text'))
                # Handle cases where prompt is blocked
                elif response.prompt_feedback and response.prompt_feedback.block_reason:
                     raise ValueError(f"Prompt blocked by API. Reason: {response.prompt_feedback.block_reason_message}")
                else:
                    # Handle empty response without explicit block
                    logger.warning("LLM returned empty response without explicit block reason.")
                    return "" # Return empty string to signal no content
            except Exception as e:
                logger.warning(f"LLM generation attempt {attempt + 1} failed: {e}")
                if attempt == 2: # Last attempt
                    raise
        return "" # Should not be reached if exception is raised on last attempt

except ImportError as e:
    print(f"CRITICAL IMPORT ERROR: {e}.")
    sys.exit(1)

logger = logging.getLogger(__name__)
app = Flask(__name__)

GENERATED_DOCS_DIR = os.path.join(SERVER_DIR, 'generated_docs')
os.makedirs(GENERATED_DOCS_DIR, exist_ok=True)
app.config['GENERATED_DOCS_DIR'] = GENERATED_DOCS_DIR

vector_service = None
try:
    vector_service = VectorDBService()
    vector_service.setup_collection()
    app.vector_service = vector_service
except Exception as e:
    logger.critical(f"Failed to initialize VectorDBService: {e}", exc_info=True)

try:
    neo4j_handler.init_driver()
except Exception as e:
    logger.critical(f"Neo4j driver failed to initialize: {e}.")

atexit.register(neo4j_handler.close_driver)

def create_error_response(message, status_code=500, details=None):
    log_message = f"API Error ({status_code}): {message}"
    if details:
        log_message += f" | Details: {details}"
    current_app.logger.error(log_message)
    response_payload = {"error": message}
    if details and status_code != 500:
        response_payload["details"] = details
    return jsonify(response_payload), status_code

# === API Endpoints ===

@app.route('/generate_document', methods=['POST'])
def generate_document_route():
    current_app.logger.info("--- /generate_document Request ---")
    data = request.get_json()
    if not data:
        return create_error_response("Request must be JSON", 400)
    
    outline_content = data.get('markdownContent')
    doc_type = data.get('docType')
    source_document_text = data.get('sourceDocumentText')

    if not all([outline_content, doc_type, source_document_text]):
        return create_error_response("Missing 'markdownContent', 'docType', or 'sourceDocumentText'", 400)

    try:
        expanded_markdown = document_generator.expand_outline_with_llm(
            outline_content, 
            source_document_text, 
            llm_wrapper
        )
        
        slides_data = document_generator.refined_parse_markdown(expanded_markdown)
        
        unique_id = str(uuid.uuid4())
        filename = f"generated_doc_{unique_id}.{doc_type}"
        output_path = os.path.join(app.config['GENERATED_DOCS_DIR'], filename)

        if doc_type == 'pptx':
            document_generator.create_ppt(slides_data, output_path)
        elif doc_type == 'docx':
            document_generator.create_doc(slides_data, output_path, "text_content")
        
        logger.info(f"Successfully generated expanded document: {filename}")
        return jsonify({"success": True, "filename": filename}), 201

    except Exception as e:
        logger.error(f"Failed to generate document: {e}", exc_info=True)
        return create_error_response(f"Failed to generate document: {str(e)}", 500)

@app.route('/download_document/<filename>', methods=['GET'])
def download_document_route(filename):
    current_app.logger.info(f"--- /download_document/{filename} Request ---")
    if '..' in filename or filename.startswith('/'):
        return create_error_response("Invalid filename.", 400)
    try:
        file_path = os.path.join(app.config['GENERATED_DOCS_DIR'], filename)
        if not os.path.exists(file_path):
             return create_error_response("File not found.", 404)
        @after_this_request
        def cleanup(response):
            try:
                os.remove(file_path)
                logger.info(f"Cleaned up temporary file: {file_path}")
            except OSError as e:
                logger.error(f"Error deleting temporary file {file_path}: {e}")
            return response
        return send_from_directory(
            app.config['GENERATED_DOCS_DIR'],
            filename,
            as_attachment=True
        )
    except Exception as e:
        logger.error(f"Error during document download for {filename}: {e}", exc_info=True)
        return create_error_response("Could not process download request.", 500)

@app.route('/web_search', methods=['POST'])
def web_search_route():
    current_app.logger.info("--- /web_search Request (DuckDuckGo) ---")
    data = request.get_json()
    if not data or 'query' not in data:
        return create_error_response("Missing 'query' in request body", 400)
    query = data['query']
    try:
        with DDGS() as ddgs:
            results = list(ddgs.text(query, max_results=5))
        formatted_results = [{"title": r.get("title"), "url": r.get("href"), "content": r.get("body")} for r in results]
        return jsonify(formatted_results), 200
    except Exception as e:
        return create_error_response(f"Web search failed: {str(e)}", 500)

@app.route('/health', methods=['GET'])
def health_check():
    current_app.logger.info("--- Health Check Request ---")
    status_details = { "status": "error", "qdrant_service": "not_initialized", "qdrant_collection_name": config.QDRANT_COLLECTION_NAME, "qdrant_collection_status": "unknown", "document_embedding_model": config.DOCUMENT_EMBEDDING_MODEL_NAME, "query_embedding_model": config.QUERY_EMBEDDING_MODEL_NAME, "neo4j_service": "not_initialized_via_handler", "neo4j_connection": "unknown" }
    http_status_code = 503
    if not vector_service:
        status_details["qdrant_service"] = "failed_to_initialize"
    else:
        status_details["qdrant_service"] = "initialized"
        try:
            vector_service.client.get_collection(collection_name=vector_service.collection_name)
            status_details["qdrant_collection_status"] = "exists_and_accessible"
        except Exception as e:
            status_details["qdrant_collection_status"] = f"error_accessing_collection: {str(e)}"
    neo4j_ok, neo4j_conn_status = neo4j_handler.check_neo4j_connectivity()
    if neo4j_ok:
        status_details["neo4j_service"], status_details["neo4j_connection"] = "initialized_via_handler", "connected"
    else:
        status_details["neo4j_service"], status_details["neo4j_connection"] = "initialization_failed_or_handler_error", neo4j_conn_status
    if status_details["qdrant_service"] == "initialized" and status_details["qdrant_collection_status"] == "exists_and_accessible" and neo4j_ok:
        status_details["status"], http_status_code = "ok", 200
    return jsonify(status_details), http_status_code

@app.route('/add_document', methods=['POST'])
def add_document_qdrant():
    current_app.logger.info("--- /add_document Request ---")
    data = request.get_json()
    if not data: return create_error_response("Request must be JSON", 400)
    user_id, file_path, original_name = data.get('user_id'), data.get('file_path'), data.get('original_name')
    if not all([user_id, file_path, original_name]):
        return create_error_response("Missing required fields: user_id, file_path, original_name", 400)
    if not os.path.exists(file_path):
        return create_error_response(f"File not found at server path: {file_path}", 404)
    try:
        processed_chunks, raw_text, kg_chunks = ai_core.process_document_for_qdrant(file_path, original_name, user_id)
        num_chunks_added, status = 0, "processed_no_content"
        if processed_chunks:
            num_chunks_added = app.vector_service.add_processed_chunks(processed_chunks)
            if num_chunks_added > 0: status = "added_to_qdrant"
        return jsonify({ "message": "Document processed.", "status": status, "filename": original_name, "num_chunks_added_to_qdrant": num_chunks_added, "raw_text_for_analysis": raw_text or "", "chunks_with_metadata": kg_chunks }), 201
    except Exception as e:
        logger.error(f"Error in /add_document for '{original_name}': {e}", exc_info=True)
        return create_error_response(f"Failed to process document: {str(e)}", 500)

@app.route('/query', methods=['POST'])
def search_qdrant_documents_and_get_kg():
    current_app.logger.info("--- /query Request ---")
    data = request.get_json()
    if not data: return create_error_response("Request must be JSON", 400)
    query_text, user_id = data.get('query'), data.get('user_id')
    if not query_text or not user_id:
        return create_error_response("Missing 'query' or 'user_id'", 400)
    try:
        k = data.get('k', 5)
        filters = data.get('filter') # Note: This needs proper mapping to Qdrant models.Filter
        retrieved_docs, snippet, docs_map = vector_service.search_documents(query=query_text, k=k, filter_conditions=filters)
        return jsonify({ "retrieved_documents_list": [doc.to_dict() for doc in retrieved_docs], "formatted_context_snippet": snippet, "retrieved_documents_map": docs_map, "knowledge_graphs": {} }), 200
    except Exception as e:
        logger.error(f"Error in /query: {e}", exc_info=True)
        return create_error_response(f"Query failed: {str(e)}", 500)

@app.route('/delete_qdrant_document_data', methods=['DELETE'])
def delete_qdrant_data_route():
    current_app.logger.info("--- /delete_qdrant_document_data Request ---")
    data = request.get_json()
    if not data: return create_error_response("Request must be JSON", 400)
    user_id, document_name = data.get('user_id'), data.get('document_name')
    if not user_id or not document_name:
        return create_error_response("Missing 'user_id' or 'document_name'", 400)
    try:
        result = vector_service.delete_document_vectors(user_id, document_name)
        return jsonify(result), 200
    except Exception as e:
        return create_error_response(f"Deletion failed: {str(e)}", 500)

# KG Endpoints
@app.route('/kg', methods=['POST'])
def add_or_update_kg_route():
    current_app.logger.info("--- POST /kg Request (Neo4j Ingestion) ---")
    data = request.get_json()
    if not data: return create_error_response("Request must be JSON", 400)
    user_id, original_name, nodes, edges = data.get('userId'), data.get('originalName'), data.get('nodes'), data.get('edges')
    if not all([user_id, original_name, isinstance(nodes, list), isinstance(edges, list)]):
        return create_error_response("Missing or invalid fields", 400)
    try:
        result = neo4j_handler.ingest_knowledge_graph(user_id, original_name, nodes, edges)
        return jsonify({"message": "KG ingested", "status": "completed", **result}), 201
    except Exception as e:
        return create_error_response(f"KG ingestion failed: {str(e)}", 500)

@app.route('/kg/<user_id>/<path:document_name>', methods=['GET'])
def get_kg_route(user_id, document_name):
    current_app.logger.info(f"--- GET /kg/{user_id}/{document_name} ---")
    try:
        kg_data = neo4j_handler.get_knowledge_graph(user_id, document_name)
        return jsonify(kg_data) if kg_data else create_error_response("KG not found", 404)
    except Exception as e:
        return create_error_response(f"KG retrieval failed: {str(e)}", 500)

@app.route('/kg/<user_id>/<path:document_name>', methods=['DELETE'])
def delete_kg_route(user_id, document_name):
    current_app.logger.info(f"--- DELETE /kg/{user_id}/{document_name} ---")
    try:
        deleted = neo4j_handler.delete_knowledge_graph(user_id, document_name)
        return jsonify({"message": "KG deleted"}) if deleted else create_error_response("KG not found", 404)
    except Exception as e:
        return create_error_response(f"KG deletion failed: {str(e)}", 500)

if __name__ == '__main__':
    logger.info(f"--- Starting RAG API Service on port {config.API_PORT} ---")
    app.run(host='0.0.0.0', port=config.API_PORT, debug=True)
```

`rag_service/config.py`

```python
# # server/config.py
# import os
# import logging

# #  Logging Configuration 
# logger = logging.getLogger(__name__)
# LOGGING_LEVEL_NAME = os.getenv('LOGGING_LEVEL', 'INFO').upper()
# LOGGING_LEVEL      = getattr(logging, LOGGING_LEVEL_NAME, logging.INFO)
# LOGGING_FORMAT     = '%(asctime)s - %(levelname)s - [%(name)s:%(lineno)d] - %(message)s'

# # === Base Directory ===
# BASE_DIR = os.path.dirname(os.path.abspath(__file__))
# logger.info(f"[Config] Base Directory: {BASE_DIR}")



# def setup_logging():
#     """Configure logging across the app."""
#     root_logger = logging.getLogger()
#     if not root_logger.handlers:  # prevent duplicate handlers
#         handler = logging.StreamHandler()
#         formatter = logging.Formatter(LOGGING_FORMAT)
#         handler.setFormatter(formatter)
#         root_logger.addHandler(handler)
#         root_logger.setLevel(LOGGING_LEVEL)

#     logging.getLogger("urllib3").setLevel(logging.WARNING)
#     logging.getLogger("httpx").setLevel(logging.WARNING)
#     logging.getLogger("faiss.loader").setLevel(logging.WARNING)
#     logging.getLogger(__name__).info(f"Logging initialized at {LOGGING_LEVEL_NAME}")

# NEO4J_URI = os.getenv("NEO4J_URI", "bolt://localhost:7687")
# NEO4J_USERNAME = os.getenv("NEO4J_USERNAME", "neo4j")
# NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD", "password") # IMPORTANT: Change this default or use ENV VAR!
# NEO4J_DATABASE = os.getenv("NEO4J_DATABASE", "neo4j")
# # === Embedding Model Configuration ===
# DEFAULT_DOC_EMBED_MODEL = 'mixedbread-ai/mxbai-embed-large-v1'
# DOCUMENT_EMBEDDING_MODEL_NAME = os.getenv('DOCUMENT_EMBEDDING_MODEL_NAME', DEFAULT_DOC_EMBED_MODEL)
# MAX_TEXT_LENGTH_FOR_NER = int(os.getenv("MAX_TEXT_LENGTH_FOR_NER", 500000))
# logger.info(f"[Config] Document Embedding Model: {DOCUMENT_EMBEDDING_MODEL_NAME}")

# # Model dimension mapping
# _MODEL_TO_DIM_MAPPING = {
#     'mixedbread-ai/mxbai-embed-large-v1': 1024,
#     'BAAI/bge-large-en-v1.5': 1024,
#     'all-MiniLM-L6-v2': 384,
#     'sentence-transformers/all-mpnet-base-v2': 768,
# }
# _FALLBACK_DIM = 768

# DOCUMENT_VECTOR_DIMENSION = int(os.getenv(
#     "DOCUMENT_VECTOR_DIMENSION",
#     _MODEL_TO_DIM_MAPPING.get(DOCUMENT_EMBEDDING_MODEL_NAME, _FALLBACK_DIM)
# ))
# logger.info(f"[Config] Document Vector Dimension: {DOCUMENT_VECTOR_DIMENSION}")

# # === AI Core Chunking Config ===
# AI_CORE_CHUNK_SIZE = int(os.getenv("AI_CORE_CHUNK_SIZE", 512))
# AI_CORE_CHUNK_OVERLAP = int(os.getenv("AI_CORE_CHUNK_OVERLAP", 100))
# logger.info(f"[Config] Chunk Size: {AI_CORE_CHUNK_SIZE}, Overlap: {AI_CORE_CHUNK_OVERLAP}")

# # === SpaCy Configuration ===
# SPACY_MODEL_NAME = os.getenv('SPACY_MODEL_NAME', 'en_core_web_sm')
# logger.info(f"[Config] SpaCy Model: {SPACY_MODEL_NAME}")

# # === Qdrant Configuration ===
# QDRANT_HOST = os.getenv("QDRANT_HOST", "localhost")
# QDRANT_PORT = int(os.getenv("QDRANT_PORT", 6333))
# QDRANT_COLLECTION_NAME = os.getenv("QDRANT_COLLECTION_NAME", "my_qdrant_rag_collection")
# QDRANT_API_KEY = os.getenv("QDRANT_API_KEY", None)
# QDRANT_URL = os.getenv("QDRANT_URL", None)

# QDRANT_COLLECTION_VECTOR_DIM = DOCUMENT_VECTOR_DIMENSION
# logger.info(f"[Config] Qdrant Vector Dimension: {QDRANT_COLLECTION_VECTOR_DIM}")

# # === Query Embedding Configuration ===
# QUERY_EMBEDDING_MODEL_NAME = os.getenv("QUERY_EMBEDDING_MODEL_NAME", DOCUMENT_EMBEDDING_MODEL_NAME)
# QUERY_VECTOR_DIMENSION = int(os.getenv(
#     "QUERY_VECTOR_DIMENSION",
#     _MODEL_TO_DIM_MAPPING.get(QUERY_EMBEDDING_MODEL_NAME, _FALLBACK_DIM)
# ))

# if QUERY_VECTOR_DIMENSION != QDRANT_COLLECTION_VECTOR_DIM:
#     logger.info(f"[ Config Warning] Query vector dim ({QUERY_VECTOR_DIMENSION}) != Qdrant dim ({QDRANT_COLLECTION_VECTOR_DIM})")
#     # Optionally enforce consistency
#     # raise ValueError("Query and Document vector dimensions do not match!")
# else:
#     logger.info(f"[Config] Query Model: {QUERY_EMBEDDING_MODEL_NAME}")
#     logger.info(f"[Config] Query Vector Dimension: {QUERY_VECTOR_DIMENSION}")

# QDRANT_DEFAULT_SEARCH_K = int(os.getenv("QDRANT_DEFAULT_SEARCH_K", 5))
# QDRANT_SEARCH_MIN_RELEVANCE_SCORE = float(os.getenv("QDRANT_SEARCH_MIN_RELEVANCE_SCORE", 0.1))

# # === API Port Configuration ===
# API_PORT = int(os.getenv('API_PORT', 5000))
# logger.info(f"[Config] API Running Port: {API_PORT}")

# # === Optional: Tesseract OCR Path (uncomment if used) ===
# # TESSERACT_CMD = os.getenv('TESSERACT_CMD')
# # if TESSERACT_CMD:
# #     import pytesseract
# #     pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD
# #     logger.info(f"[Config] Tesseract Path: {TESSERACT_CMD}")


# #  Library Availability Flags 
# try:
#     import pypdf
#     PYPDF_AVAILABLE      = True
#     PYPDF_PDFREADERROR   = pypdf.errors.PdfReadError
# except ImportError:
#     PYPDF_AVAILABLE      = False
#     PYPDF_PDFREADERROR   = Exception

# try:
#     from docx import Document as DocxDocument
#     DOCX_AVAILABLE       = True
# except ImportError:
#     DOCX_AVAILABLE       = False
#     DocxDocument         = None

# try:
#     from pptx import Presentation
#     PPTX_AVAILABLE       = True
# except ImportError:
#     PPTX_AVAILABLE       = False
#     Presentation         = None

# try:
#     import pdfplumber
#     PDFPLUMBER_AVAILABLE = True
# except ImportError:
#     PDFPLUMBER_AVAILABLE = False
#     pdfplumber           = None

# try:
#     import pandas as pd
#     PANDAS_AVAILABLE     = True
# except ImportError:
#     PANDAS_AVAILABLE     = False
#     pd                   = None

# try:
#     from PIL import Image
#     PIL_AVAILABLE        = True
# except ImportError:
#     PIL_AVAILABLE        = False
#     Image                = None

# try:
#     import fitz
#     FITZ_AVAILABLE       = True
# except ImportError:
#     FITZ_AVAILABLE       = False
#     fitz                 = None

# try:
#     import pytesseract
#     PYTESSERACT_AVAILABLE = True
#     TESSERACT_ERROR       = pytesseract.TesseractNotFoundError
# except ImportError:
#     PYTESSERACT_AVAILABLE = False
#     pytesseract           = None
#     TESSERACT_ERROR       = Exception

# try:
#     import PyPDF2
#     PYPDF2_AVAILABLE      = True
# except ImportError:
#     PYPDF2_AVAILABLE      = False
#     PyPDF2                = None

# #  Optional: Preload SpaCy & Embedding Model 

# TESSERACT_CMD = os.getenv('TESSERACT_CMD', r'C:\Program Files\Tesseract-OCR\tesseract.exe')

# if PYTESSERACT_AVAILABLE and pytesseract:
#     pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD
#     logger.info(f"[Config] Tesseract Path set to: {TESSERACT_CMD}")

# try:
#     import spacy
#     SPACY_LIB_AVAILABLE = True
#     nlp_spacy_core      = spacy.load(SPACY_MODEL_NAME)
#     SPACY_MODEL_LOADED  = True
# except Exception as e:
#     SPACY_LIB_AVAILABLE = False
#     nlp_spacy_core      = None
#     SPACY_MODEL_LOADED  = False
#     logger.warning(f"Failed to load SpaCy model '{SPACY_MODEL_NAME}': {e}")

# try:
#     from sentence_transformers import SentenceTransformer
#     SENTENCE_TRANSFORMERS_LIB_AVAILABLE = True
#     document_embedding_model = SentenceTransformer(DOCUMENT_EMBEDDING_MODEL_NAME)
#     EMBEDDING_MODEL_LOADED = True
# except Exception as e:
#     SENTENCE_TRANSFORMERS_LIB_AVAILABLE = False
#     document_embedding_model = None
#     EMBEDDING_MODEL_LOADED = False
#     logger.warning(f"Failed to load Sentence transformers: {e}")

# try:
#     from langchain.text_splitter import RecursiveCharacterTextSplitter
#     LANGCHAIN_SPLITTER_AVAILABLE = True
# except ImportError:
#     LANGCHAIN_SPLITTER_AVAILABLE = False
#     RecursiveCharacterTextSplitter = None # Placeholder














# server/rag_service/config.py
import os
import logging
from dotenv import load_dotenv

# --- Load .env from the parent 'server' directory ---
# This ensures that both Node.js and Python use the same .env file
# The path is calculated relative to this config.py file
dotenv_path = os.path.join(os.path.dirname(__file__), '..', '.env')
load_dotenv(dotenv_path=dotenv_path)


#  Logging Configuration 
logger = logging.getLogger(__name__)
LOGGING_LEVEL_NAME = os.getenv('LOGGING_LEVEL', 'INFO').upper()
LOGGING_LEVEL      = getattr(logging, LOGGING_LEVEL_NAME, logging.INFO)
LOGGING_FORMAT     = '%(asctime)s - %(levelname)s - [%(name)s:%(lineno)d] - %(message)s'

def setup_logging():
    """Configure logging across the app."""
    root_logger = logging.getLogger()
    if not root_logger.handlers:  # prevent duplicate handlers
        handler = logging.StreamHandler()
        formatter = logging.Formatter(LOGGING_FORMAT)
        handler.setFormatter(formatter)
        root_logger.addHandler(handler)
        root_logger.setLevel(LOGGING_LEVEL)

    logging.getLogger("urllib3").setLevel(logging.WARNING)
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logging.getLogger("faiss.loader").setLevel(logging.WARNING)
    logging.getLogger(__name__).info(f"Logging initialized at {LOGGING_LEVEL_NAME}")

# --- API Keys and Service URLs ---
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
GEMINI_MODEL_NAME = "gemini-1.5-flash-latest" # Or your preferred Gemini model

NEO4J_URI = os.getenv("NEO4J_URI", "bolt://localhost:7687")
NEO4J_USERNAME = os.getenv("NEO4J_USERNAME", "neo4j")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD", "password")
NEO4J_DATABASE = os.getenv("NEO4J_DATABASE", "neo4j")

QDRANT_HOST = os.getenv("QDRANT_HOST", "localhost")
QDRANT_PORT = int(os.getenv("QDRANT_PORT", 6333))
QDRANT_COLLECTION_NAME = os.getenv("QDRANT_COLLECTION_NAME", "my_qdrant_rag_collection")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY", None)
QDRANT_URL = os.getenv("QDRANT_URL", None)

# --- Embedding Model Configuration ---
DEFAULT_DOC_EMBED_MODEL = 'mixedbread-ai/mxbai-embed-large-v1'
DOCUMENT_EMBEDDING_MODEL_NAME = os.getenv('DOCUMENT_EMBEDDING_MODEL_NAME', DEFAULT_DOC_EMBED_MODEL)

_MODEL_TO_DIM_MAPPING = {
    'mixedbread-ai/mxbai-embed-large-v1': 1024,
    'BAAI/bge-large-en-v1.5': 1024,
    'all-MiniLM-L6-v2': 384,
    'sentence-transformers/all-mpnet-base-v2': 768,
}
_FALLBACK_DIM = 768
DOCUMENT_VECTOR_DIMENSION = int(os.getenv("DOCUMENT_VECTOR_DIMENSION", _MODEL_TO_DIM_MAPPING.get(DOCUMENT_EMBEDDING_MODEL_NAME, _FALLBACK_DIM)))
QDRANT_COLLECTION_VECTOR_DIM = DOCUMENT_VECTOR_DIMENSION

QUERY_EMBEDDING_MODEL_NAME = os.getenv("QUERY_EMBEDDING_MODEL_NAME", DOCUMENT_EMBEDDING_MODEL_NAME)
QUERY_VECTOR_DIMENSION = int(os.getenv("QUERY_VECTOR_DIMENSION", _MODEL_TO_DIM_MAPPING.get(QUERY_EMBEDDING_MODEL_NAME, _FALLBACK_DIM)))

if QUERY_VECTOR_DIMENSION != QDRANT_COLLECTION_VECTOR_DIM:
    logger.warning(f"[Config Warning] Query vector dim ({QUERY_VECTOR_DIMENSION}) != Qdrant dim ({QDRANT_COLLECTION_VECTOR_DIM})")

# --- AI Core & Search Configuration ---
AI_CORE_CHUNK_SIZE = int(os.getenv("AI_CORE_CHUNK_SIZE", 512))
AI_CORE_CHUNK_OVERLAP = int(os.getenv("AI_CORE_CHUNK_OVERLAP", 100))
MAX_TEXT_LENGTH_FOR_NER = int(os.getenv("MAX_TEXT_LENGTH_FOR_NER", 500000))
QDRANT_DEFAULT_SEARCH_K = int(os.getenv("QDRANT_DEFAULT_SEARCH_K", 5))
QDRANT_SEARCH_MIN_RELEVANCE_SCORE = float(os.getenv("QDRANT_SEARCH_MIN_RELEVANCE_SCORE", 0.1))

# --- SpaCy Configuration ---
SPACY_MODEL_NAME = os.getenv('SPACY_MODEL_NAME', 'en_core_web_sm')

# --- API Port Configuration ---
API_PORT = int(os.getenv('API_PORT', 5000))

# --- Tesseract OCR Path ---
TESSERACT_CMD = os.getenv('TESSERACT_CMD', r'C:\Program Files\Tesseract-OCR\tesseract.exe')


#  Library Availability Flags & Dynamic Imports 
try:
    import pypdf
    PYPDF_AVAILABLE = True
    PYPDF_PDFREADERROR = pypdf.errors.PdfReadError
except ImportError: PYPDF_AVAILABLE, PYPDF_PDFREADERROR = False, Exception

try:
    from docx import Document as DocxDocument
    DOCX_AVAILABLE = True
except ImportError: DOCX_AVAILABLE, DocxDocument = False, None

try:
    from pptx import Presentation
    PPTX_AVAILABLE = True
except ImportError: PPTX_AVAILABLE, Presentation = False, None

try:
    import pdfplumber
    PDFPLUMBER_AVAILABLE = True
except ImportError: PDFPLUMBER_AVAILABLE, pdfplumber = False, None

try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError: PANDAS_AVAILABLE, pd = False, None

try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError: PIL_AVAILABLE, Image = False, None

try:
    import fitz
    FITZ_AVAILABLE = True
except ImportError: FITZ_AVAILABLE, fitz = False, None

try:
    import pytesseract
    PYTESSERACT_AVAILABLE = True
    TESSERACT_ERROR = pytesseract.TesseractNotFoundError
    if TESSERACT_CMD: pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD
except ImportError: PYTESSERACT_AVAILABLE, pytesseract, TESSERACT_ERROR = False, None, Exception

try:
    import PyPDF2
    PYPDF2_AVAILABLE = True
except ImportError: PYPDF2_AVAILABLE, PyPDF2 = False, None

try:
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    LANGCHAIN_SPLITTER_AVAILABLE = True
except ImportError: LANGCHAIN_SPLITTER_AVAILABLE, RecursiveCharacterTextSplitter = False, None

#  Optional: Preload SpaCy & Embedding Model 
nlp_spacy_core, SPACY_MODEL_LOADED = None, False
try:
    import spacy
    nlp_spacy_core = spacy.load(SPACY_MODEL_NAME)
    SPACY_MODEL_LOADED = True
except Exception as e:
    logger.warning(f"Failed to load SpaCy model '{SPACY_MODEL_NAME}': {e}")

document_embedding_model, EMBEDDING_MODEL_LOADED = None, False
try:
    from sentence_transformers import SentenceTransformer
    document_embedding_model = SentenceTransformer(DOCUMENT_EMBEDDING_MODEL_NAME)
    EMBEDDING_MODEL_LOADED = True
except Exception as e:
    logger.warning(f"Failed to load Sentence Transformer model '{DOCUMENT_EMBEDDING_MODEL_NAME}': {e}")
```

`rag_service/document_generator.py`

```python
# server/rag_service/document_generator.py
import re
from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.dml.color import RGBColor
from pptx.enum.text import PP_ALIGN
from docx import Document
from docx.shared import Inches as DocxInches
import logging

logger = logging.getLogger(__name__)

# --- NEW: Prompt for expanding an outline into a full presentation ---
EXPANSION_PROMPT_TEMPLATE = """
You are a professional content creator and subject matter expert.
Your task is to expand a given OUTLINE (which could be a list of key topics or FAQs) into a full, detailed, multi-slide presentation in Markdown format.
You must use the provided SOURCE DOCUMENT TEXT as your only source of truth. Do not use outside knowledge.
The final output must be a single block of Markdown text, with each slide separated by '---'.

**INSTRUCTIONS:**
1.  **Slide Structure:** For each point in the OUTLINE, create one or more detailed slides.
2.  **Content Expansion:** For each slide, write detailed, professional paragraphs that elaborate on the outline point. Extract relevant facts, figures, and explanations from the SOURCE DOCUMENT TEXT.
3.  **Title Formatting:** Start each slide with '### Slide Title' (e.g., '### What is the NCAT-25 Score?'). Use the points from the outline as the basis for your slide titles.
4.  **Markdown Usage:** Use bullet points, bold text, and clear paragraphs to structure the content on each slide.
5.  **Be Comprehensive:** Aim for a 6-8 slide presentation that fully explains the topics from the outline, grounded in the source text.

---
**SOURCE DOCUMENT TEXT (Your knowledge base):**
{source_document_text}
---
**OUTLINE (Topics/FAQs to expand into a presentation):**
{outline_content}
---

**FINAL PRESENTATION MARKDOWN (start with the first '### Slide Title'):**
"""

def expand_outline_with_llm(outline_content, source_document_text, llm_function):
    """Uses an LLM to expand an outline into full markdown presentation content."""
    logger.info("Expanding outline content using LLM...")
    prompt = EXPANSION_PROMPT_TEMPLATE.format(
        source_document_text=source_document_text,
        outline_content=outline_content
    )
    
    # The llm_function is a wrapper passed from app.py that calls the configured LLM.
    expanded_markdown = llm_function(prompt)
    
    if not expanded_markdown or not expanded_markdown.strip():
        raise ValueError("LLM failed to generate expanded content.")
    
    logger.info(f"LLM generated expanded markdown. Length: {len(expanded_markdown)}")
    return expanded_markdown

def refined_parse_markdown(markdown_content):
    """
    Parses the expanded, multi-slide markdown content into a list of slide data objects.
    Each slide is expected to be separated by a line containing only '---'.
    """
    if not markdown_content or not markdown_content.strip():
        return []
    
    slides_data = []
    # Split by a newline, followed by three or more hyphens, followed by a newline
    slide_chunks = re.split(r'\n\s*---\s*\n', markdown_content)

    for chunk in slide_chunks:
        stripped_chunk = chunk.strip()
        if not stripped_chunk:
            continue
        
        # Use the first H3 heading as the slide title
        title_match = re.search(r"^\s*###\s+(.*)", stripped_chunk, re.MULTILINE)
        if title_match:
            title = title_match.group(1).strip()
            content = stripped_chunk[title_match.end():].strip()
        else:
            # Fallback if no H3 heading is found
            lines = stripped_chunk.split('\n')
            title = lines[0].strip().replace('*','').replace('#','') # Basic title cleanup
            content = '\n'.join(lines[1:]).strip()

        slides_data.append({ "title": title, "text_content": content })
            
    return slides_data

def add_text_to_shape_with_markdown(text_frame, markdown_text, is_title=False):
    text_frame.clear() 
    text_frame.word_wrap = True
    title_font_size = Pt(32)
    content_font_size = Pt(14)

    for line in markdown_text.split('\n'):
        p = text_frame.add_paragraph()
        p.alignment = PP_ALIGN.LEFT
        bullet_match = re.match(r'^(\s*)[\*\-]\s*(.*)', line)
        
        if bullet_match:
            leading_spaces, content_line = bullet_match.groups()
            indent_level = min(len(leading_spaces) // 2, 5)
            p.level = indent_level
        else:
            content_line = line.lstrip()

        segments = re.split(r'(\*\*.*?\*\*|__.*?__)', content_line)
        for segment in segments:
            if not segment: continue
            run = p.add_run()
            if (segment.startswith("**") and segment.endswith("**")) or (segment.startswith("__") and segment.endswith("__")):
                run.text = segment[2:-2]
                run.font.bold = True
            else:
                run.text = segment
            run.font.color.rgb = RGBColor(255, 255, 255)
            run.font.size = title_font_size if is_title else content_font_size

def create_ppt(slides_data, output_path):
    prs = Presentation()
    prs.slide_width = Inches(16)
    prs.slide_height = Inches(9)
    for slide_data in slides_data:
        slide_layout = prs.slide_layouts[5]
        slide = prs.slides.add_slide(slide_layout)
        background = slide.background
        fill = background.fill
        fill.solid()
        fill.fore_color.rgb = RGBColor(15, 23, 42)
        title_shape = slide.shapes.add_textbox(Inches(0.5), Inches(0.3), prs.slide_width - Inches(1.0), Inches(1.0))
        add_text_to_shape_with_markdown(title_shape.text_frame, slide_data["title"], is_title=True)
        if slide_data["text_content"]:
            content_shape = slide.shapes.add_textbox(Inches(0.75), Inches(1.5), prs.slide_width - Inches(1.5), prs.slide_height - Inches(2.0))
            add_text_to_shape_with_markdown(content_shape.text_frame, slide_data["text_content"])
    prs.save(output_path)
    return True

def add_markdown_line_to_docx(doc, markdown_line):
    heading_match = re.match(r'^(#+)\s+(.*)', markdown_line)
    if heading_match:
        level = len(heading_match.group(1))
        doc.add_heading(heading_match.group(2).strip(), level=min(level, 4))
        return
    bullet_match = re.match(r'^(\s*)[\*\-]\s+(.*)', markdown_line)
    if bullet_match:
        leading_spaces, content_line = bullet_match.groups()
        p = doc.add_paragraph(style='List Bullet')
        indent_level = len(leading_spaces) // 2
        if indent_level > 0:
            p.paragraph_format.left_indent = DocxInches(0.25 * indent_level)
    else:
        content_line = markdown_line
        p = doc.add_paragraph()
    segments = re.split(r'(\*\*.*?\*\*|__.*?__)', content_line)
    for segment in segments:
        if not segment: continue
        run = p.add_run()
        if (segment.startswith("**") and segment.endswith("**")) or (segment.startswith("__") and segment.endswith("__")):
            run.text = segment[2:-2]
            run.font.bold = True
        else:
            run.text = segment

def create_doc(slides_data, output_path, content_key="text_content"):
    doc = Document()
    if slides_data:
        doc_title = slides_data[0].get("title", "Generated Document")
        doc.add_heading(doc_title, level=0) # Main document title
        for slide in slides_data:
            # Each "slide" becomes a section in the Word doc
            doc.add_heading(slide["title"], level=2)
            content_to_add = slide.get(content_key, "")
            if content_to_add.strip():
                for line in content_to_add.split('\n'):
                    add_markdown_line_to_docx(doc, line)
            doc.add_paragraph() # Add space between sections
    else:
        doc.add_paragraph("[No content to generate]")
    doc.save(output_path)
    return True
```

`rag_service/file_parser.py`

```python
# server/rag_service/file_parser.py
import os
try:
    import pypdf
except ImportError:
    print("pypdf not found, PDF parsing will fail. Install with: pip install pypdf")
    pypdf = None # Set to None if not installed

try:
    from docx import Document as DocxDocument
except ImportError:
    print("python-docx not found, DOCX parsing will fail. Install with: pip install python-docx")
    DocxDocument = None

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.documents import Document as LangchainDocument
from rag_service import config # Import from package
import logging

# Configure logger for this module
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO) # Or DEBUG for more details
handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
if not logger.hasHandlers():
    logger.addHandler(handler)


def parse_pdf(file_path):
    """Extracts text content from a PDF file using pypdf."""
    if not pypdf: return None # Check if library loaded
    text = ""
    try:
        reader = pypdf.PdfReader(file_path)
        num_pages = len(reader.pages)
        # logger.debug(f"Reading {num_pages} pages from PDF: {os.path.basename(file_path)}")
        for i, page in enumerate(reader.pages):
            try:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n" # Add newline between pages
            except Exception as page_err:
                 logger.warning(f"Error extracting text from page {i+1} of {os.path.basename(file_path)}: {page_err}")
        # logger.debug(f"Extracted {len(text)} characters from PDF.")
        return text.strip() if text.strip() else None # Return None if empty after stripping
    except FileNotFoundError:
        logger.error(f"PDF file not found: {file_path}")
        return None
    except pypdf.errors.PdfReadError as pdf_err:
        logger.error(f"Error reading PDF {os.path.basename(file_path)} (possibly corrupted or encrypted): {pdf_err}")
        return None
    except Exception as e:
        logger.error(f"Unexpected error parsing PDF {os.path.basename(file_path)}: {e}", exc_info=True)
        return None

def parse_docx(file_path):
    """Extracts text content from a DOCX file."""
    if not DocxDocument: return None # Check if library loaded
    try:
        doc = DocxDocument(file_path)
        text = "\n".join([para.text for para in doc.paragraphs if para.text.strip()])
        # logger.debug(f"Extracted {len(text)} characters from DOCX.")
        return text.strip() if text.strip() else None
    except Exception as e:
        logger.error(f"Error parsing DOCX {os.path.basename(file_path)}: {e}", exc_info=True)
        return None

def parse_txt(file_path):
    """Reads text content from a TXT file (or similar plain text like .py, .js)."""
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            text = f.read()
        # logger.debug(f"Read {len(text)} characters from TXT file.")
        return text.strip() if text.strip() else None
    except Exception as e:
        logger.error(f"Error parsing TXT {os.path.basename(file_path)}: {e}", exc_info=True)
        return None

# Add PPTX parsing (requires python-pptx)
try:
    from pptx import Presentation
    PPTX_SUPPORTED = True
    def parse_pptx(file_path):
        """Extracts text content from a PPTX file."""
        text = ""
        try:
            prs = Presentation(file_path)
            for slide in prs.slides:
                for shape in slide.shapes:
                    if hasattr(shape, "text"):
                        shape_text = shape.text.strip()
                        if shape_text:
                            text += shape_text + "\n" # Add newline between shape texts
            # logger.debug(f"Extracted {len(text)} characters from PPTX.")
            return text.strip() if text.strip() else None
        except Exception as e:
            logger.error(f"Error parsing PPTX {os.path.basename(file_path)}: {e}", exc_info=True)
            return None
except ImportError:
    PPTX_SUPPORTED = False
    logger.warning("python-pptx not installed. PPTX parsing will be skipped.")
    def parse_pptx(file_path):
        logger.warning(f"Skipping PPTX file {os.path.basename(file_path)} as python-pptx is not installed.")
        return None


def parse_file(file_path):
    """Parses a file based on its extension, returning text content or None."""
    _, ext = os.path.splitext(file_path)
    ext = ext.lower()
    logger.debug(f"Attempting to parse file: {os.path.basename(file_path)} (Extension: {ext})")

    if ext == '.pdf':
        return parse_pdf(file_path)
    elif ext == '.docx':
        return parse_docx(file_path)
    elif ext == '.pptx':
        return parse_pptx(file_path) # Use the conditional function
    elif ext in ['.txt', '.py', '.js', '.md', '.log', '.csv', '.html', '.xml', '.json']: # Expand text-like types
        return parse_txt(file_path)
    # Add other parsers here if needed (e.g., for .doc, .xls)
    elif ext == '.doc':
        # Requires antiword or similar external tool, more complex
        logger.warning(f"Parsing for legacy .doc files is not implemented: {os.path.basename(file_path)}")
        return None
    else:
        logger.warning(f"Unsupported file extension for parsing: {ext} ({os.path.basename(file_path)})")
        return None

def chunk_text(text, file_name, user_id):
    """Chunks text and creates Langchain Documents with metadata."""
    if not text or not isinstance(text, str):
        logger.warning(f"Invalid text input for chunking (file: {file_name}). Skipping.")
        return []

    # Use splitter configured in config.py
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=config.CHUNK_SIZE,
        chunk_overlap=config.CHUNK_OVERLAP,
        length_function=len,
        is_separator_regex=False, # Use default separators
        # separators=["\n\n", "\n", " ", ""] # Default separators
    )

    try:
        chunks = text_splitter.split_text(text)
        if not chunks:
             logger.warning(f"Text splitting resulted in zero chunks for file: {file_name}")
             return []

        documents = []
        for i, chunk in enumerate(chunks):
             # Ensure chunk is not just whitespace before creating Document
             if chunk and chunk.strip():
                 documents.append(
                     LangchainDocument(
                         page_content=chunk,
                         metadata={
                             'userId': user_id, # Store user ID
                             'documentName': file_name, # Store original filename
                             'chunkIndex': i # Store chunk index for reference
                         }
                     )
                 )
        if documents:
            logger.info(f"Split '{file_name}' into {len(documents)} non-empty chunks.")
        else:
            logger.warning(f"No non-empty chunks created for file: {file_name} after splitting.")
        return documents
    except Exception as e:
        logger.error(f"Error during text splitting for file {file_name}: {e}", exc_info=True)
        return [] # Return empty list on error

```

`rag_service/neo4j_handler.py`

```python
# server/rag_service/neo4j_handler.py

import logging
from neo4j import GraphDatabase, exceptions as neo4j_exceptions
import config # Assumes config.py is in the same directory or python path is set correctly

logger = logging.getLogger(__name__)

# --- Neo4j Driver Management ---
_neo4j_driver = None

def init_driver():
    """Initializes the Neo4j driver instance."""
    global _neo4j_driver
    if _neo4j_driver is not None:
        try: # Check if existing driver is still connected
            _neo4j_driver.verify_connectivity()
            logger.info("Neo4j driver already initialized and connected.")
            return
        except Exception:
            logger.warning("Existing Neo4j driver lost connection or failed verification. Re-initializing.")
            if _neo4j_driver:
                _neo4j_driver.close()
            _neo4j_driver = None # Force re-initialization

    try:
        _neo4j_driver = GraphDatabase.driver(
            config.NEO4J_URI,
            auth=(config.NEO4J_USERNAME, config.NEO4J_PASSWORD)
        )
        _neo4j_driver.verify_connectivity()
        logger.info(f"Neo4j driver initialized. Connected to: {config.NEO4J_URI} (DB: {config.NEO4J_DATABASE})")
    except neo4j_exceptions.ServiceUnavailable:
        logger.critical(f"Failed to connect to Neo4j at {config.NEO4J_URI}. Ensure Neo4j is running and accessible.")
        _neo4j_driver = None
    except neo4j_exceptions.AuthError:
        logger.critical(f"Neo4j authentication failed for user '{config.NEO4J_USERNAME}'. Check credentials.")
        _neo4j_driver = None
    except Exception as e:
        logger.critical(f"An unexpected error occurred while initializing Neo4j driver: {e}", exc_info=True)
        _neo4j_driver = None

def get_driver_instance():
    """Returns the active Neo4j driver instance, initializing if necessary."""
    if _neo4j_driver is None:
        init_driver()
    if _neo4j_driver is None: # Check again after trying to init
        raise ConnectionError("Neo4j driver is not available. Initialization failed.")
    return _neo4j_driver

def close_driver():
    """Closes the Neo4j driver instance if it exists."""
    global _neo4j_driver
    if _neo4j_driver:
        _neo4j_driver.close()
        _neo4j_driver = None
        logger.info("Neo4j driver closed.")

def check_neo4j_connectivity():
    """Checks if the Neo4j driver can connect."""
    try:
        driver = get_driver_instance() # This will try to init if not already
        driver.verify_connectivity()
        return True, "connected"
    except Exception as e:
        logger.warning(f"Neo4j connectivity check failed: {str(e)}")
        return False, f"disconnected_or_error: {str(e)}"

# --- Private Transaction Helper Functions ---
def _execute_read_tx(tx_function, *args, **kwargs):
    driver = get_driver_instance()
    with driver.session(database=config.NEO4J_DATABASE) as session:
        return session.execute_read(tx_function, *args, **kwargs)

def _execute_write_tx(tx_function, *args, **kwargs):
    driver = get_driver_instance()
    with driver.session(database=config.NEO4J_DATABASE) as session:
        return session.execute_write(tx_function, *args, **kwargs)

# --- Private Transactional Cypher Functions ---
def _delete_kg_transactional(tx, user_id, document_name):
    logger.info(f"Neo4j TX: Deleting KG for user '{user_id}', document '{document_name}'")
    query = (
        "MATCH (n:KnowledgeNode {userId: $userId, documentName: $documentName}) "
        "DETACH DELETE n"
    )
    result = tx.run(query, userId=user_id, documentName=document_name)
    summary = result.consume()
    deleted_count = summary.counters.nodes_deleted + summary.counters.relationships_deleted
    logger.info(f"Neo4j TX: Deleted {summary.counters.nodes_deleted} nodes and {summary.counters.relationships_deleted} relationships for '{document_name}'.")
    return deleted_count > 0

def _add_nodes_transactional(tx, nodes_param, user_id, document_name):
    logger.info(f"Neo4j TX: Adding/merging {len(nodes_param)} nodes for user '{user_id}', document '{document_name}'")
    # Ensure nodes have a type, default to "concept" if not provided
    # And llm_parent_id for parent from LLM's perspective
    processed_nodes = []
    for node_data in nodes_param:
        # Ensure ID is a string and not empty
        if not isinstance(node_data.get("id"), str) or not node_data.get("id").strip():
            logger.warning(f"Skipping node with invalid or missing ID: {node_data}")
            continue
        
        processed_node = {
            "id": node_data["id"].strip(), # Use the LLM's 'id' as 'nodeId'
            "type": node_data.get("type", "concept"), # Default type
            "description": node_data.get("description", ""),
            "llm_parent_id": node_data.get("parent", None) # Store the 'parent' from LLM
        }
        processed_nodes.append(processed_node)

    if not processed_nodes:
        logger.warning("No valid nodes to process after filtering.")
        return 0

    query = (
        "UNWIND $nodes_data as node_props "
        "MERGE (n:KnowledgeNode {nodeId: node_props.id, userId: $userId, documentName: $documentName}) "
        "ON CREATE SET n.type = node_props.type, "
        "              n.description = node_props.description, "
        "              n.llm_parent_id = node_props.llm_parent_id, "
        "              n.userId = $userId, " # Ensure userId is set on create
        "              n.documentName = $documentName " # Ensure documentName is set on create
        "ON MATCH SET n.type = node_props.type, " # Update existing nodes too
        "             n.description = node_props.description, "
        "             n.llm_parent_id = node_props.llm_parent_id "
        "RETURN count(n) as nodes_affected"
    )
    result = tx.run(query, nodes_data=processed_nodes, userId=user_id, documentName=document_name)
    count = result.single()[0] if result.peek() else 0
    logger.info(f"Neo4j TX: Affected (created or merged) {count} nodes for '{document_name}'.")
    return count

def _add_edges_transactional(tx, edges_param, user_id, document_name):
    logger.info(f"Neo4j TX: Adding/merging {len(edges_param)} edges for user '{user_id}', document '{document_name}'")
    if not edges_param:
        logger.info("Neo4j TX: No edges provided to add.")
        return 0
        
    # Filter out invalid edges
    valid_edges = []
    for edge_data in edges_param:
        if not (isinstance(edge_data.get("from"), str) and edge_data.get("from").strip() and
                isinstance(edge_data.get("to"), str) and edge_data.get("to").strip() and
                isinstance(edge_data.get("relationship"), str) and edge_data.get("relationship").strip()):
            logger.warning(f"Skipping invalid edge data: {edge_data}")
            continue
        valid_edges.append({
            "from": edge_data["from"].strip(),
            "to": edge_data["to"].strip(),
            "relationship": edge_data["relationship"].strip().upper().replace(" ", "_") # Sanitize relationship type
        })

    if not valid_edges:
        logger.warning("No valid edges to process after filtering.")
        return 0

    # Cypher query to create relationships. Note: relationship type is dynamic using brackets.
    # We use MERGE to avoid duplicate relationships with the same type between the same nodes.
    # Relationship properties are set using SET.
    query = (
        "UNWIND $edges_data as edge_props "
        "MATCH (startNode:KnowledgeNode {nodeId: edge_props.from, userId: $userId, documentName: $documentName}) "
        "MATCH (endNode:KnowledgeNode {nodeId: edge_props.to, userId: $userId, documentName: $documentName}) "
        "CALL apoc.merge.relationship(startNode, edge_props.relationship, {}, {type: edge_props.relationship}, endNode) YIELD rel "
        # MERGE (startNode)-[r:HAS_RELATIONSHIP]->(endNode) " # Simpler, but cannot set type dynamically easily.
        # "SET r.type = edge_props.relationship "
        "RETURN count(rel) as edges_affected"
    )
    # Note: The above MERGE using apoc.merge.relationship is more robust for dynamic relationship types.
    # If APOC is not available, a simpler MERGE (startNode)-[r:REL {type:edge_props.relationship}]->(endNode) would work.
    # Or create relationships with a generic type like :RELATED_TO and store the specific type as a property.
    # For this example, assuming APOC for dynamic relationship types. If not, adjust the query.
    # Simpler, if APOC is not available (relationship type becomes a property of a generic :RELATED_TO relationship):
    simple_query = (
        "UNWIND $edges_data as edge_props "
        "MATCH (startNode:KnowledgeNode {nodeId: edge_props.from, userId: $userId, documentName: $documentName}) "
        "MATCH (endNode:KnowledgeNode {nodeId: edge_props.to, userId: $userId, documentName: $documentName}) "
        "MERGE (startNode)-[r:RELATED_TO {type: edge_props.relationship}]->(endNode) "
        "RETURN count(r) as edges_affected"
    )
    # Let's use the simpler query for broader compatibility without APOC.
    
    result = tx.run(simple_query, edges_data=valid_edges, userId=user_id, documentName=document_name)
    count = result.single()[0] if result.peek() else 0
    logger.info(f"Neo4j TX: Affected (created or merged) {count} relationships for '{document_name}'.")
    return count

def _get_kg_transactional(tx, user_id, document_name):
    logger.info(f"Neo4j TX: Retrieving KG for user '{user_id}', document '{document_name}'")
    nodes_query = (
        "MATCH (n:KnowledgeNode {userId: $userId, documentName: $documentName}) "
        "RETURN n.nodeId AS id, n.type AS type, n.description AS description, n.llm_parent_id AS parent"
    )
    nodes_result = tx.run(nodes_query, userId=user_id, documentName=document_name)
    # Convert Neo4j records to dictionaries
    nodes_data = [dict(record) for record in nodes_result]

    edges_query = (
        "MATCH (startNode:KnowledgeNode {userId: $userId, documentName: $documentName})"
        "-[r:RELATED_TO]->" # Using the generic relationship type from the simple_query
        "(endNode:KnowledgeNode {userId: $userId, documentName: $documentName}) "
        "RETURN startNode.nodeId AS from, endNode.nodeId AS to, r.type AS relationship"
    )
    edges_result = tx.run(edges_query, userId=user_id, documentName=document_name)
    edges_data = [dict(record) for record in edges_result]

    logger.info(f"Neo4j TX: Retrieved {len(nodes_data)} nodes and {len(edges_data)} edges for '{document_name}'.")
    return {"nodes": nodes_data, "edges": edges_data}


# --- Public Service Functions ---
def ingest_knowledge_graph(user_id: str, document_name: str, nodes: list, edges: list) -> dict:
    """
    Deletes existing KG for the document and ingests new nodes and edges.
    Returns a summary of operations.
    """
    try:
        logger.info(f"Attempting to delete old KG (if any) for document '{document_name}' (User: {user_id}).")
        _execute_write_tx(_delete_kg_transactional, user_id, document_name)
        logger.info(f"Old KG (if any) deleted for '{document_name}'. Proceeding with ingestion.")

        nodes_affected = 0
        if nodes and len(nodes) > 0:
            nodes_affected = _execute_write_tx(_add_nodes_transactional, nodes, user_id, document_name)
        
        edges_affected = 0
        if edges and len(edges) > 0:
            edges_affected = _execute_write_tx(_add_edges_transactional, edges, user_id, document_name)

        message = "Knowledge Graph successfully ingested/updated."
        logger.info(f"{message} Doc: '{document_name}', User: '{user_id}'. Nodes: {nodes_affected}, Edges: {edges_affected}")
        return {
            "success": True,
            "message": message,
            "nodes_affected": nodes_affected,
            "edges_affected": edges_affected
        }
    except Exception as e:
        logger.error(f"Error during KG ingestion for document '{document_name}', user '{user_id}': {e}", exc_info=True)
        raise # Re-raise to be caught by the route handler

def get_knowledge_graph(user_id: str, document_name: str) -> dict:
    """
    Retrieves the knowledge graph for a given user and document name.
    """
    try:
        kg_data = _execute_read_tx(_get_kg_transactional, user_id, document_name)
        if not kg_data["nodes"] and not kg_data["edges"]:
            logger.info(f"No KG data found for user '{user_id}', document '{document_name}'.")
            return None # Indicate not found
        return kg_data
    except Exception as e:
        logger.error(f"Error retrieving KG for document '{document_name}', user '{user_id}': {e}", exc_info=True)
        raise

def delete_knowledge_graph(user_id: str, document_name: str) -> bool:
    """
    Deletes the knowledge graph for a given user and document name.
    Returns True if data was deleted, False otherwise.
    """
    try:
        was_deleted = _execute_write_tx(_delete_kg_transactional, user_id, document_name)
        return was_deleted
    except Exception as e:
        logger.error(f"Error deleting KG for document '{document_name}', user '{user_id}': {e}", exc_info=True)
        raise
```

`rag_service/requirements.txt`

```
# flask
# requests
# faiss-cpu # or faiss-gpu
# langchain
# langchain-huggingface
# pypdf
# PyPDF2
# python-docx
# python-dotenv
# ollama # Keep if using Ollama embeddings
# python-pptx # Added for PPTX parsing
# uuid
# langchain-community
# pdfplumber
# fitz # PyMuPDF for PDF parsing
# pytesseract
# nltk
# spacy-layout
# pandas
# numpy
# typing
# pytesseract # OCR
# pillow
# qdrant-client
# neo4j
# sentence_transformers
# spacy
# opencv-python
# duckduckgo-search






flask
requests
faiss-cpu # or faiss-gpu
langchain
langchain-huggingface
pypdf
PyPDF2
python-docx
python-dotenv
ollama # Keep if using Ollama embeddings
python-pptx
uuid
langchain-community
pdfplumber
fitz # PyMuPDF for PDF parsing
pytesseract
nltk
spacy-layout
pandas
numpy
typing
pytesseract # OCR
pillow
qdrant-client
neo4j
sentence_transformers
spacy
opencv-python
duckduckgo-search
python-pptx
python-docx
reportlab
google-generativeai
```

`rag_service/vector_db_service.py`

```python
import uuid
import logging
from typing import List, Dict, Tuple, Optional, Any

from qdrant_client import QdrantClient, models
from sentence_transformers import SentenceTransformer

# Assuming vector_db_service.py and config.py are in the same package directory (e.g., rag_service/)
# and you run your application as a module (e.g., python -m rag_service.main_app)
# or have otherwise correctly set up the Python path.
import config # Changed to relative import

# Configure basic logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class Document: # For search result formatting
    def __init__(self, page_content: str, metadata: dict):
        self.page_content = page_content
        self.metadata = metadata

    def to_dict(self):
        return {"page_content": self.page_content, "metadata": self.metadata}

class VectorDBService:
    def __init__(self):
        logger.info("Initializing VectorDBService...")
        logger.info(f"  Qdrant Host: {config.QDRANT_HOST}, Port: {config.QDRANT_PORT}, URL: {config.QDRANT_URL}")
        logger.info(f"  Collection: {config.QDRANT_COLLECTION_NAME}")
        logger.info(f"  Query Embedding Model: {config.QUERY_EMBEDDING_MODEL_NAME}")
        
        # The vector dimension for the Qdrant collection is defined by the DOCUMENT embedding model
        # This is set in config.QDRANT_COLLECTION_VECTOR_DIM
        self.vector_dim = config.QDRANT_COLLECTION_VECTOR_DIM
        logger.info(f"  Service expects Vector Dim for Qdrant collection: {self.vector_dim} (from document model config)")

        if config.QDRANT_URL:
            self.client = QdrantClient(
                url=config.QDRANT_URL,
                api_key=config.QDRANT_API_KEY,
                timeout=30
            )
        else:
            self.client = QdrantClient(
                host=config.QDRANT_HOST,
                port=config.QDRANT_PORT,
                api_key=config.QDRANT_API_KEY,
                timeout=30
            )

        try:
            # This model is for encoding search queries.
            # Its output dimension MUST match self.vector_dim (QDRANT_COLLECTION_VECTOR_DIM).
            logger.info(f"  Loading query embedding model: '{config.QUERY_EMBEDDING_MODEL_NAME}'")
            self.model = SentenceTransformer(config.QUERY_EMBEDDING_MODEL_NAME)
            model_embedding_dim = self.model.get_sentence_embedding_dimension()
            logger.info(f"  Query model loaded. Output dimension: {model_embedding_dim}")

            if model_embedding_dim != self.vector_dim:
                error_msg = (
                    f"CRITICAL DIMENSION MISMATCH: Query model '{config.QUERY_EMBEDDING_MODEL_NAME}' "
                    f"outputs embeddings of dimension {model_embedding_dim}, but the Qdrant collection "
                    f"is configured for dimension {self.vector_dim} (derived from document model: "
                    f"'{config.DOCUMENT_EMBEDDING_MODEL_NAME}'). Search functionality will fail. "
                    "Ensure query and document models produce compatible embedding dimensions, "
                    "or environment variables for dimensions are correctly set."
                )
                logger.error(error_msg)
                raise ValueError(error_msg) # Critical error, stop initialization
            else:
                logger.info(f"  Query model output dimension ({model_embedding_dim}) matches "
                            f"Qdrant collection dimension ({self.vector_dim}).")

        except Exception as e:
            logger.error(f"Error initializing SentenceTransformer model '{config.QUERY_EMBEDDING_MODEL_NAME}' for query encoding: {e}", exc_info=True)
            raise # Re-raise to prevent service startup with a non-functional query encoder

        self.collection_name = config.QDRANT_COLLECTION_NAME
        # No ThreadPoolExecutor needed here if document encoding is external

    def _recreate_qdrant_collection(self):
        logger.info(f"Attempting to (re)create collection '{self.collection_name}' with vector size {self.vector_dim}.")
        try:
            self.client.recreate_collection(
                collection_name=self.collection_name,
                vectors_config=models.VectorParams(
                    size=self.vector_dim,
                    distance=models.Distance.COSINE,
                ),
            )
            logger.info(f"Collection '{self.collection_name}' (re)created successfully.")
        except Exception as e_recreate:
            logger.error(f"Failed to (re)create collection '{self.collection_name}': {e_recreate}", exc_info=True)
            raise

    def setup_collection(self):
        try:
            collection_info = self.client.get_collection(collection_name=self.collection_name)
            logger.info(f"Collection '{self.collection_name}' already exists.")
            
            # Handle different Qdrant client versions for accessing vector config
            current_vectors_config = None
            if hasattr(collection_info.config.params, 'vectors'): # For simple vector config
                if isinstance(collection_info.config.params.vectors, models.VectorParams):
                     current_vectors_config = collection_info.config.params.vectors
                elif isinstance(collection_info.config.params.vectors, dict): # For named vectors
                    # Assuming default unnamed vector or first one if named
                    default_vector_name = '' # Common for single vector setup
                    if default_vector_name in collection_info.config.params.vectors:
                        current_vectors_config = collection_info.config.params.vectors[default_vector_name]
                    elif collection_info.config.params.vectors: # Get first one if default not found
                        current_vectors_config = next(iter(collection_info.config.params.vectors.values()))

            if not current_vectors_config:
                 logger.error(f"Could not determine vector configuration for existing collection '{self.collection_name}'. Recreating.")
                 self._recreate_qdrant_collection()
            elif current_vectors_config.size != self.vector_dim:
                logger.warning(f"Collection '{self.collection_name}' vector size {current_vectors_config.size} "
                               f"differs from service's expected {self.vector_dim}. Recreating.")
                self._recreate_qdrant_collection()
            elif current_vectors_config.distance != models.Distance.COSINE: # Ensure distance is also checked
                logger.warning(f"Collection '{self.collection_name}' distance {current_vectors_config.distance} "
                               f"differs from expected {models.Distance.COSINE}. Recreating.")
                self._recreate_qdrant_collection()
            else:
                logger.info(f"Collection '{self.collection_name}' configuration is compatible (Size: {current_vectors_config.size}, Distance: {current_vectors_config.distance}).")

        except Exception as e: # Broad exception for Qdrant client errors
            # More specific check for "Not found" type errors
            if "not found" in str(e).lower() or \
               (hasattr(e, 'status_code') and e.status_code == 404) or \
               " " in str(e).lower(): # "Lucky" in Bengali, seems to be part of an error message you encountered
                 logger.info(f"Collection '{self.collection_name}' not found. Attempting to create...")
            else:
                 logger.warning(f"Error checking collection '{self.collection_name}': {type(e).__name__} - {e}. Attempting to (re)create anyway...")
            self._recreate_qdrant_collection()

    def add_processed_chunks(self, processed_chunks: List[Dict[str, Any]]) -> int:
        if not processed_chunks:
            logger.warning("add_processed_chunks received an empty list. No points to upsert.")
            return 0

        points_to_upsert = []
        doc_name_for_logging = "Unknown Document"

        for chunk_data in processed_chunks:
            point_id = chunk_data.get('id', str(uuid.uuid4()))
            vector = chunk_data.get('embedding')
            
            payload = chunk_data.get('metadata', {}).copy()
            payload['chunk_text_content'] = chunk_data.get('text_content', '')

            if not doc_name_for_logging or doc_name_for_logging == "Unknown Document":
                doc_name_for_logging = payload.get('original_name', payload.get('document_name', "Unknown Document"))

            if not vector:
                logger.warning(f"Chunk with ID '{point_id}' from '{doc_name_for_logging}' is missing 'embedding'. Skipping.")
                continue
            if not isinstance(vector, list) or not all(isinstance(x, (float, int)) for x in vector): # Allow int too, SentenceTransformer can return float32 which might be int-like in lists
                logger.warning(f"Chunk with ID '{point_id}' from '{doc_name_for_logging}' has an invalid 'embedding' format. Skipping.")
                continue
            if len(vector) != self.vector_dim:
                logger.error(f"Chunk with ID '{point_id}' from '{doc_name_for_logging}' has embedding dimension {len(vector)}, "
                             f"but collection expects {self.vector_dim}. Skipping. "
                             f"Ensure ai_core's document embedding model ('{config.DOCUMENT_EMBEDDING_MODEL_NAME}') "
                             f"output dimension matches configuration.")
                continue

            points_to_upsert.append(models.PointStruct(
                id=point_id,
                vector=[float(v) for v in vector], # Ensure all are floats for Qdrant
                payload=payload
            ))

        if not points_to_upsert:
            logger.warning(f"No valid points constructed from processed_chunks for document: {doc_name_for_logging}.")
            return 0

        try:
            self.client.upsert(collection_name=self.collection_name, points=points_to_upsert, wait=True) # wait=True can be useful for debugging
            logger.info(f"Successfully upserted {len(points_to_upsert)} chunks for document: {doc_name_for_logging} into Qdrant.")
            return len(points_to_upsert)
        except Exception as e:
            logger.error(f"Error upserting processed chunks to Qdrant for document: {doc_name_for_logging}: {e}", exc_info=True)
            raise

    def search_documents(self, query: str, k: int = -1, filter_conditions: Optional[models.Filter] = None) -> Tuple[List[Document], str, Dict]:
        # Use default k from config if not provided or invalid
        if k <= 0:
            k_to_use = config.QDRANT_DEFAULT_SEARCH_K
        else:
            k_to_use = k

        context_docs = []
        formatted_context_text = "No relevant context was found in the available documents."
        context_docs_map = {}

        logger.info(f"Searching with query (first 50 chars): '{query[:50]}...', k: {k_to_use}")
        if filter_conditions:
            try: filter_dict = filter_conditions.dict()
            except AttributeError: # For older Pydantic versions
                try: filter_dict = filter_conditions.model_dump()
                except AttributeError: filter_dict = str(filter_conditions) # Fallback
            logger.info(f"Applying filter: {filter_dict}")
        else:
            logger.info("No filter applied for search.")

        try:
            query_embedding = self.model.encode(query).tolist()
            logger.debug(f"Generated query_embedding (length: {len(query_embedding)}, first 5 dims: {query_embedding[:5]})")

            search_results = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_embedding,
                query_filter=filter_conditions,
                limit=k_to_use,
                with_payload=True,
                score_threshold=config.QDRANT_SEARCH_MIN_RELEVANCE_SCORE # Apply score threshold directly in search
            )
            logger.info(f"Qdrant client.search returned {len(search_results)} results (after score threshold).")

            if not search_results:
                return context_docs, formatted_context_text, context_docs_map

            for idx, point in enumerate(search_results):
                # Score threshold is already applied by Qdrant if score_threshold parameter is used.
                # If not using score_threshold in client.search, uncomment this:
                # if point.score < config.QDRANT_SEARCH_MIN_RELEVANCE_SCORE:
                #     logger.debug(f"Skipping point ID {point.id} with score {point.score:.4f} (below threshold {config.QDRANT_SEARCH_MIN_RELEVANCE_SCORE})")
                #     continue

                payload = point.payload
                content = payload.get("chunk_text_content", payload.get("text_content", payload.get("chunk_text", "")))

                retrieved_metadata = payload.copy()
                retrieved_metadata["qdrant_id"] = point.id
                retrieved_metadata["score"] = point.score

                doc = Document(page_content=content, metadata=retrieved_metadata)
                context_docs.append(doc)

            # Format context and citations
            formatted_context_parts = []
            for i, doc_obj in enumerate(context_docs):
                citation_index = i + 1
                doc_meta = doc_obj.metadata
                # Use more robust fetching of metadata keys
                display_subject = doc_meta.get("title", doc_meta.get("subject", "Unknown Subject")) # Prefer title for subject
                doc_name = doc_meta.get("original_name", doc_meta.get("file_name", "N/A"))
                page_num_info = f" (Page: {doc_meta.get('page_number', 'N/A')})" if doc_meta.get('page_number') else "" # Add page number if available
                
                content_preview = doc_obj.page_content[:200] + "..." if len(doc_obj.page_content) > 200 else doc_obj.page_content

                formatted = (f"[{citation_index}] Score: {doc_meta.get('score', 0.0):.4f} | "
                             f"Source: {doc_name}{page_num_info} | Subject: {display_subject}\n"
                             f"Content: {content_preview}") # Show content preview
                formatted_context_parts.append(formatted)

                context_docs_map[str(citation_index)] = {
                    "subject": display_subject,
                    "document_name": doc_name,
                    "page_number": doc_meta.get("page_number"),
                    "content_preview": content_preview, # Store preview
                    "full_content": doc_obj.page_content, # Store full content for potential later use
                    "score": doc_meta.get("score", 0.0),
                    "qdrant_id": doc_meta.get("qdrant_id"),
                    "original_metadata": doc_meta # Store all original metadata from payload
                }
            if formatted_context_parts:
                formatted_context_text = "\n\n---\n\n".join(formatted_context_parts)
            else:
                formatted_context_text = "No sufficiently relevant context was found after filtering."

        except Exception as e:
            logger.error(f"Qdrant search/RAG error: {e}", exc_info=True)
            formatted_context_text = "Error retrieving context due to an internal server error."

        return context_docs, formatted_context_text, context_docs_map
    
    # Add this method to the VectorDBService class in vector_db_service.py

    def delete_document_vectors(self, user_id: str, document_name: str) -> Dict[str, Any]:
        logger.info(f"Attempting to delete vectors for document: '{document_name}', user: '{user_id}' from Qdrant collection '{self.collection_name}'.")
        
        # These metadata keys must match what's stored during ingestion from ai_core.py
        # 'processing_user' was the user_id passed to ai_core
        # 'file_name' was the original_name passed to ai_core
        qdrant_filter = models.Filter(
            must=[
                models.FieldCondition(
                    key="processing_user", # The metadata field storing the user ID
                    match=models.MatchValue(value=user_id)
                ),
                models.FieldCondition(
                    key="file_name", # The metadata field storing the original document name
                    match=models.MatchValue(value=document_name)
                )
            ]
        )
        
        try:
            # Optional: Count points before deleting for logging/confirmation
            # count_response = self.client.count(collection_name=self.collection_name, count_filter=qdrant_filter)
            # num_to_delete = count_response.count
            # logger.info(f"Qdrant: Found {num_to_delete} points matching criteria for document '{document_name}', user '{user_id}'.")

            # if num_to_delete == 0:
            #     logger.info(f"Qdrant: No points found to delete for document '{document_name}', user '{user_id}'.")
            #     return {"success": True, "message": "No matching vectors found in Qdrant to delete.", "deleted_count": 0}

            delete_result = self.client.delete(
                collection_name=self.collection_name,
                points_selector=models.FilterSelector(filter=qdrant_filter),
                wait=True # Make it synchronous
            )
            
            # Check the status of the delete operation
            # delete_result should be an UpdateResult object
            if delete_result.status == models.UpdateStatus.COMPLETED or delete_result.status == models.UpdateStatus.ACKNOWLEDGED:
                # The actual number of deleted points isn't directly returned by filter-based delete.
                # We can infer it was successful if no error.
                # For a precise count, you'd need to list IDs by filter, then delete by IDs.
                logger.info(f"Qdrant delete operation for document '{document_name}', user '{user_id}' acknowledged/completed. Status: {delete_result.status}")
                return {"success": True, "message": f"Qdrant vector deletion for document '{document_name}' completed. Status: {delete_result.status}."}
            else:
                logger.warning(f"Qdrant delete operation for document '{document_name}', user '{user_id}' returned status: {delete_result.status}")
                return {"success": False, "message": f"Qdrant delete operation status: {delete_result.status}"}

        except Exception as e:
            logger.error(f"Error deleting document vectors from Qdrant for document '{document_name}', user '{user_id}': {e}", exc_info=True)
            # Check for specific Qdrant client errors if possible, e.g., if the collection doesn't exist.
            return {"success": False, "message": f"Failed to delete Qdrant vectors: {str(e)}"}

    def close(self):
        logger.info("VectorDBService close called.")
        # No specific resources like ThreadPoolExecutor to release in this version.
        # QdrantClient does not have an explicit close() method in recent versions.
```

`rag_service/__init__.py`

```python

```

`routes/adminDocuments.js`

```javascript
// server/routes/adminDocuments.js
const express = require('express');
const multer = require('multer');
const path = require('path');
const fs = require('fs');
const fsPromises = fs.promises;
const AdminDocument = require('../models/AdminDocument');
const { fixedAdminAuthMiddleware } = require('../middleware/fixedAdminAuthMiddleware');
const axios = require('axios');

const router = express.Router();

// --- Constants, Multer Config, Helpers (EXISTING CODE - no changes here for this step) ---
const ADMIN_UPLOAD_DIR_BASE = path.join(__dirname, '..', 'assets', '_admin_uploads_');
const MAX_FILE_SIZE = 20 * 1024 * 1024;
const allowedAdminMimeTypes = {
    'application/pdf': 'docs',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document': 'docs',
    'text/plain': 'docs',
    'text/markdown': 'docs',
};
const allowedAdminExtensions = ['.pdf', '.docx', '.txt', '.md'];

const adminStorage = multer.diskStorage({
    destination: (req, file, cb) => {
        const fileMimeType = file.mimetype.toLowerCase();
        const fileTypeSubfolder = allowedAdminMimeTypes[fileMimeType] || 'others';
        const destinationPath = path.join(ADMIN_UPLOAD_DIR_BASE, fileTypeSubfolder);
        fs.mkdir(destinationPath, { recursive: true }, (err) => {
            if (err) return cb(err);
            cb(null, destinationPath);
        });
    },
    filename: (req, file, cb) => {
        const timestamp = Date.now();
        const fileExt = path.extname(file.originalname).toLowerCase();
        const sanitizedBaseName = path.basename(file.originalname, fileExt)
            .replace(/[^a-zA-Z0-9._-]/g, '_').substring(0, 100);
        cb(null, `${timestamp}-${sanitizedBaseName}${fileExt}`);
    }
});
const adminFileFilter = (req, file, cb) => {
    const fileExt = path.extname(file.originalname).toLowerCase();
    const mimeType = file.mimetype.toLowerCase();
    if (allowedAdminMimeTypes[mimeType] && allowedAdminExtensions.includes(fileExt)) {
        cb(null, true);
    } else {
        const error = new multer.MulterError('LIMIT_UNEXPECTED_FILE_TYPE_ADMIN');
        error.message = `Invalid file type. Allowed: ${allowedAdminExtensions.join(', ')}`;
        cb(error, false);
    }
};
const adminUpload = multer({ storage: adminStorage, fileFilter: adminFileFilter, limits: { fileSize: MAX_FILE_SIZE }});
async function triggerPythonTextExtractionForAdmin(filePath, originalName) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
    if (!pythonServiceUrl) return { success: false, message: "Python service URL not configured.", text: null };
    const addDocumentUrl = `${pythonServiceUrl}/add_document`;
    try {
        const response = await axios.post(addDocumentUrl, {
            user_id: "fixed_admin_text_extraction_user",
            file_path: filePath, original_name: originalName
        }, { timeout: 300000 });
        const text = response.data?.raw_text_for_analysis || null;
        if (text) return { success: true, message: "Text extracted.", text: text };
        return { success: false, message: response.data?.message || "Python extracted no text.", text: null };
    } catch (error) {
        const errorMsg = error.response?.data?.error || error.message || "Unknown error calling Python RAG.";
        return { success: false, message: `Python RAG call failed: ${errorMsg}`, text: null };
    }
}
// --- End Existing Code ---


// @route   POST /api/admin/documents/upload (EXISTING - NO CHANGES FOR THIS STEP)
router.post('/upload', fixedAdminAuthMiddleware, adminUpload.single('file'), async (req, res) => {
    // ... (existing upload logic remains the same)
    if (!req.file) {
        return res.status(400).json({ message: 'No file uploaded or file type rejected.' });
    }
    const { filename: serverFilename, originalname: originalName, path: tempServerPath } = req.file;
    let adminDocRecord;
    try {
        const existingDoc = await AdminDocument.findOne({ originalName: originalName });
        if (existingDoc) {
            await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Error deleting duplicate temp file ${tempServerPath}:`, e));
            return res.status(409).json({ message: `Document with original name '${originalName}' already exists for admin.` });
        }
        const textExtractionResult = await triggerPythonTextExtractionForAdmin(tempServerPath, originalName);
        if (!textExtractionResult.success || !textExtractionResult.text || textExtractionResult.text.trim() === "") {
            await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Error deleting temp file ${tempServerPath} after failed text extraction:`, e));
            return res.status(422).json({
                message: textExtractionResult.message || "Failed to extract usable text from the document.",
                filename: serverFilename, originalname: originalName
            });
        }
        adminDocRecord = new AdminDocument({
            filename: serverFilename, originalName: originalName, text: textExtractionResult.text,
            analysis: { faq: "", topics: "", mindmap: "" }, analysisUpdatedAt: null,
        });
        await adminDocRecord.save();
        await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Non-critical error deleting temp file ${tempServerPath} after DB save:`, e));
        res.status(202).json({
            message: `Admin document '${originalName}' uploaded. Text extracted. Analysis initiated.`,
            filename: serverFilename, originalname: originalName,
        });
        const { Worker } = require('worker_threads');
        const adminAnalysisWorkerPath = path.resolve(__dirname, '..', 'workers', 'adminAnalysisWorker.js');
        if (fs.existsSync(adminAnalysisWorkerPath)) {
            const worker = new Worker(adminAnalysisWorkerPath, {
                workerData: {
                    adminDocumentId: adminDocRecord._id.toString(),
                    originalName: originalName, textForAnalysis: textExtractionResult.text
                }
            });
            worker.on('message', (msg) => console.log(`Admin Analysis Worker [Doc: ${msg.originalName || originalName}]: ${msg.message || JSON.stringify(msg)}`));
            worker.on('error', (err) => console.error(`Admin Analysis Worker Error [Doc: ${originalName}]:`, err));
            worker.on('exit', (code) => console.log(`Admin Analysis Worker [Doc: ${originalName}] exited (code ${code}).`));
        } else {
            console.error(`Admin Upload: adminAnalysisWorker.js not found at ${adminAnalysisWorkerPath}.`);
        }
    } catch (error) {
        console.error(`Admin Upload: Overall error for '${originalName || (req.file && req.file.originalname)}':`, error);
        if (tempServerPath) await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Error cleaning up temp file ${tempServerPath} after overall error:`, e));
        if (!res.headersSent) {
            if (error.code === 11000) res.status(409).json({ message: 'Document processing conflict.' });
            else res.status(500).json({ message: 'Server error during admin document upload.' });
        }
    }
});

// @route   GET /api/admin/documents (EXISTING - NO CHANGES FOR THIS STEP)
router.get('/', fixedAdminAuthMiddleware, async (req, res) => {
    // ... (existing list logic remains the same)
    try {
        const adminDocs = await AdminDocument.find().sort({ uploadedAt: -1 })
            .select('originalName filename uploadedAt analysisUpdatedAt analysis.faq analysis.topics analysis.mindmap');
        const documentsList = adminDocs.map(doc => ({
            originalName: doc.originalName, serverFilename: doc.filename, uploadedAt: doc.uploadedAt,
            analysisUpdatedAt: doc.analysisUpdatedAt,
            hasFaq: !!(doc.analysis && doc.analysis.faq && doc.analysis.faq.trim() !== ""),
            hasTopics: !!(doc.analysis && doc.analysis.topics && doc.analysis.topics.trim() !== ""),
            hasMindmap: !!(doc.analysis && doc.analysis.mindmap && doc.analysis.mindmap.trim() !== ""),
        }));
        res.json({ documents: documentsList });
    } catch (error) {
        res.status(500).json({ message: 'Server error fetching admin documents.' });
    }
});

// @route   DELETE /api/admin/documents/:serverFilename (EXISTING - NO CHANGES FOR THIS STEP)
router.delete('/:serverFilename', fixedAdminAuthMiddleware, async (req, res) => {
    // ... (existing delete logic remains the same)
    const { serverFilename } = req.params;
    if (!serverFilename) return res.status(400).json({ message: 'Server filename parameter is required.' });
    try {
        const docToDelete = await AdminDocument.findOneAndDelete({ filename: serverFilename });
        if (!docToDelete) return res.status(404).json({ message: `Admin document '${serverFilename}' not found.` });
        res.status(200).json({ message: `Admin document '${docToDelete.originalName}' record deleted.` });
    } catch (error) {
        res.status(500).json({ message: 'Server error during admin document deletion.' });
    }
});

// @route   GET /api/admin/documents/:serverFilename/analysis (EXISTING - NO CHANGES FOR THIS STEP)
router.get('/:serverFilename/analysis', fixedAdminAuthMiddleware, async (req, res) => {
    // ... (existing analysis fetch by serverFilename logic remains the same)
    const { serverFilename } = req.params;
    if (!serverFilename) return res.status(400).json({ message: 'Server filename parameter is required.' });
    try {
        const adminDoc = await AdminDocument.findOne({ filename: serverFilename }).select('originalName analysis analysisUpdatedAt');
        if (!adminDoc) return res.status(404).json({ message: `Admin document '${serverFilename}' not found.` });
        if (!adminDoc.analysis || (!adminDoc.analysis.faq && !adminDoc.analysis.topics && !adminDoc.analysis.mindmap)) {
            return res.status(200).json({
                originalName: adminDoc.originalName, message: 'Analysis not generated or empty.',
                analysis: { faq: "", topics: "", mindmap: "" }, analysisUpdatedAt: adminDoc.analysisUpdatedAt
            });
        }
        res.status(200).json({
            originalName: adminDoc.originalName, analysis: adminDoc.analysis,
            analysisUpdatedAt: adminDoc.analysisUpdatedAt
        });
    } catch (error) {
        res.status(500).json({ message: 'Server error retrieving admin document analysis.' });
    }
});

// --- NEW ROUTE FOR STEP 2 ---
// @route   GET /api/admin/documents/by-original-name/:originalName/analysis
// @desc    Get analysis data for a specific admin document by its originalName
// @access  Admin Only (via fixedAdminAuthMiddleware)
router.get('/by-original-name/:originalName/analysis', fixedAdminAuthMiddleware, async (req, res) => {
    const { originalName } = req.params;
    if (!originalName) {
        return res.status(400).json({ message: 'Original name parameter is required.' });
    }

    try {
        const decodedOriginalName = decodeURIComponent(originalName);
        const adminDoc = await AdminDocument.findOne({ originalName: decodedOriginalName })
            .select('originalName filename analysis analysisUpdatedAt'); // Select necessary fields

        if (!adminDoc) {
            return res.status(404).json({ message: `Admin document with original name '${decodedOriginalName}' not found.` });
        }

        // Check if the analysis object or its specific fields are empty/null
        if (!adminDoc.analysis ||
            (!adminDoc.analysis.faq?.trim() && // Check if specific fields are empty strings after trim
             !adminDoc.analysis.topics?.trim() &&
             !adminDoc.analysis.mindmap?.trim())) {
            return res.status(200).json({
                originalName: adminDoc.originalName,
                serverFilename: adminDoc.filename,
                message: 'Analysis has not been generated or is empty for this document.',
                analysis: { // Return a default empty structure
                    faq: adminDoc.analysis?.faq || "",
                    topics: adminDoc.analysis?.topics || "",
                    mindmap: adminDoc.analysis?.mindmap || ""
                },
                analysisUpdatedAt: adminDoc.analysisUpdatedAt
            });
        }

        res.status(200).json({
            originalName: adminDoc.originalName,
            serverFilename: adminDoc.filename, // Include serverFilename for context if frontend needs it
            analysis: adminDoc.analysis,       // This contains { faq, topics, mindmap } strings
            analysisUpdatedAt: adminDoc.analysisUpdatedAt
        });
    } catch (error) {
        console.error(`Error fetching analysis for admin document by original name '${originalName}':`, error);
        res.status(500).json({ message: 'Server error while retrieving admin document analysis by original name.' });
    }
});


module.exports = router;
```

`routes/analysis.js`

```javascript
// server/routes/analysis.js
const express = require('express');
const router = express.Router();
const { authMiddleware } = require('../middleware/authMiddleware');
const User = require('../models/User');

// @route   GET /api/analysis/:documentFilename
// @desc    Get analysis data (faq, topics, mindmap) for a specific document
// @access  Private (requires auth)
router.get('/:documentFilename', authMiddleware, async (req, res) => {
    const userId = req.user._id; // From authMiddleware
    const { documentFilename } = req.params;
    
    if (!documentFilename) {
        return res.status(400).json({ message: 'Document filename parameter is required.' });
    }

    try {
        const user = await User.findById(userId).select('uploadedDocuments');
        if (!user) {
            return res.status(404).json({ message: 'User not found.' });
        }

        const document = user.uploadedDocuments.find(doc => doc.filename === documentFilename);

        if (!document) {
            return res.status(404).json({ message: `Document '${documentFilename}' not found for this user.` });
        }

        if (!document.analysis) {
            // This case might happen if the analysis object itself is missing, though schema has defaults.
            console.warn(`Analysis object missing for document '${documentFilename}', user '${userId}'. Sending empty analysis.`);
            return res.status(200).json({
                faq: "",
                topics: "",
                mindmap: ""
            });
        }
        
        // Send the analysis sub-document
        res.status(200).json(document.analysis);

    } catch (error) {
        console.error(`Error fetching analysis for document '${documentFilename}', user '${userId}':`, error);
        res.status(500).json({ message: 'Server error while retrieving document analysis.' });
    }
});

module.exports = router;
```

`routes/auth.js`

```javascript
// server/routes/auth.js
const express = require('express');
const jwt = require('jsonwebtoken'); // <-- Import jsonwebtoken
const { v4: uuidv4 } = require('uuid');
const User = require('../models/User');
const { authMiddleware } = require('../middleware/authMiddleware');
require('dotenv').config(); // Ensures process.env has values from .env

const router = express.Router();

const JWT_EXPIRATION = process.env.JWT_EXPIRATION || '1h'; // Default to 1 hour

// --- @route   POST /api/auth/signup ---
// --- @desc    Register a new user ---
// --- @access  Public ---
router.post('/signup', async (req, res) => {
  const { username, password } = req.body;

  if (!username || !password) {
    return res.status(400).json({ message: 'Please provide username and password' });
  }
  if (password.length < 6) {
     return res.status(400).json({ message: 'Password must be at least 6 characters long' });
  }

  try {
    const existingUser = await User.findOne({ username });
    if (existingUser) {
      return res.status(400).json({ message: 'Username already exists' });
    }

    const newUser = new User({ username, password });
    await newUser.save();

    const sessionId = uuidv4(); // Initial session ID

    // Create JWT Payload
    const payload = {
      userId: newUser._id,
      username: newUser.username,
    };

    // Sign the token
    const token = jwt.sign(
      payload,
      process.env.JWT_SECRET, // Make sure JWT_SECRET is in your .env
      { expiresIn: JWT_EXPIRATION }
    );

    res.status(201).json({
      token: token, // <-- Send token
      _id: newUser._id,
      username: newUser.username,
      sessionId: sessionId,
      message: 'User registered successfully',
    });

  } catch (error) {
    console.error('Signup Error:', error);
    if (error.code === 11000) {
        return res.status(400).json({ message: 'Username already exists.' });
    }
    res.status(500).json({ message: 'Server error during signup' });
  }
});

// --- @route   POST /api/auth/signin ---
// --- @desc    Authenticate user & return JWT ---
// --- @access  Public ---
router.post('/signin', async (req, res) => {
  const { username, password } = req.body;

  if (!username || !password) {
    return res.status(400).json({ message: 'Please provide username and password' });
  }

  try {
    const user = await User.findByCredentials(username, password);

    if (!user) {
      return res.status(401).json({ message: 'Invalid credentials' });
    }

    const sessionId = uuidv4(); // New session ID for this login

    // Create JWT Payload
    const payload = {
      userId: user._id,
      username: user.username,
    };

    // Sign the token
    const token = jwt.sign(
      payload,
      process.env.JWT_SECRET,
      { expiresIn: JWT_EXPIRATION }
    );

    res.status(200).json({
      token: token, // <-- Send token
      _id: user._id,
      username: user.username,
      sessionId: sessionId,
      message: 'Login successful',
    });

  } catch (error) {
    console.error('Signin Error:', error);
    res.status(500).json({ message: 'Server error during signin' });
  }
});

// --- @route   GET /api/auth/me ---
// --- @desc    Get current authenticated user's details (requires JWT middleware) ---
// --- @access  Private ---
// We will add the middleware for this route in server.js
router.get('/me',authMiddleware, async (req, res) => {
    // If the JWT middleware (to be created next) runs successfully,
    // req.user will be populated.
    if (!req.user) {
        // This should ideally be caught by the middleware itself,
        // but as a fallback.
        return res.status(401).json({ message: 'Not authorized, user context missing.' });
    }
    try {
        // req.user is already the user document (excluding password typically)
        // thanks to the upcoming authMiddleware.
        res.status(200).json({
            _id: req.user._id,
            username: req.user.username,
            // Add any other fields you want the frontend to know about the user
            // e.g., email, roles, preferences, if stored.
        });
    } catch (error) {
        console.error('Error in /api/auth/me:', error);
        res.status(500).json({ message: 'Server error fetching user details.' });
    }
});


module.exports = router;
```

`routes/chat.js`

```javascript
// server/routes/chat.js
const express = require('express');
const { v4: uuidv4 } = require('uuid');
const ChatHistory = require('../models/ChatHistory');
const User = require('../models/User');
const geminiService = require('../services/geminiService');
const ollamaService = require('../services/ollamaService');
const { CHAT_MAIN_SYSTEM_PROMPT, WEB_SEARCH_CHAT_SYSTEM_PROMPT, CHAT_USER_PROMPT_TEMPLATES } = require('../config/promptTemplates');
const { createOrUpdateSummary } = require('../services/summarizationService');
const axios = require('axios');
// --- CORRECTED IMPORT ---
const { performWebSearch } = require('../services/webSearchService');

const router = express.Router();

async function queryPythonRagService(
    userId, query, criticalThinkingEnabled, documentContextNameToPass, clientFilter = null, k = 5
) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
    if (!pythonServiceUrl) {
        console.error("PYTHON_RAG_SERVICE_URL is not set. RAG features disabled for this request.");
        return [];
    }
    const searchUrl = `${pythonServiceUrl}/query`;
    console.log(`Querying Python RAG: User ${userId}, Query (first 50): "${query.substring(0, 50)}...", k=${k}, CriticalThinking=${criticalThinkingEnabled}, DocContext=${documentContextNameToPass}`);

    const payload = {
        query: query, k: k, user_id: userId,
        use_kg_critical_thinking: !!criticalThinkingEnabled,
        documentContextName: documentContextNameToPass || null
    };
    if (clientFilter && typeof clientFilter === 'object' && Object.keys(clientFilter).length > 0) {
        payload.filter = clientFilter;
    }

    try {
        const response = await axios.post(searchUrl, payload, {
            headers: { 'Content-Type': 'application/json' },
            timeout: process.env.PYTHON_RAG_TIMEOUT || 30000
        });
        if (response.data && Array.isArray(response.data.retrieved_documents_list)) {
            return response.data.retrieved_documents_list.map(doc => ({
                documentName: doc.metadata?.file_name || doc.metadata?.original_name || doc.metadata?.title || 'Unknown Document',
                content: doc.page_content || "", score: doc.metadata?.score,
            }));
        }
        return [];
    } catch (error) {
        let errorMsg = error.message;
        if (error.response?.data?.error) errorMsg = `Python Service Error: ${error.response.data.error}`;
        else if (error.code === 'ECONNABORTED') errorMsg = 'Python RAG service request timed out.';
        console.error(`Error querying Python RAG service at ${searchUrl}:`, errorMsg);
        return [];
    }
}

// --- @route   POST /api/chat/message ---
router.post('/message', async (req, res) => {
    const {
        query, sessionId, useRag, useWebSearch,
        llmProvider: clientLlmProvider,
        systemPrompt: clientProvidedSystemInstruction, criticalThinkingEnabled,
        documentContextName, filter
    } = req.body;
    const userId = req.user._id;

    if (!query || typeof query !== 'string' || query.trim() === '') {
        return res.status(400).json({ message: 'Query message text required.' });
    }
    if (!sessionId || typeof sessionId !== 'string') {
        return res.status(400).json({ message: 'Session ID required.' });
    }

    const userMessageForDb = { role: 'user', parts: [{ text: query }], timestamp: new Date() };
    console.log(`>>> POST /api/chat/message: User=${userId}, Session=${sessionId}, RAG=${useRag}, WebSearch=${useWebSearch}, Query: "${query.substring(0, 50)}..."`);

    try {
        const [chatSession, user] = await Promise.all([
            ChatHistory.findOne({ sessionId: sessionId, userId: userId }),
            User.findById(userId).select('preferredLlmProvider ollamaModel').lean()
        ]);
        const llmProvider = user?.preferredLlmProvider || clientLlmProvider || 'gemini';
        const ollamaModel = user?.ollamaModel || process.env.OLLAMA_DEFAULT_MODEL;

        const historyFromDb = chatSession ? chatSession.messages : [];
        const summaryFromDb = chatSession ? chatSession.summary || "" : "";
        
        let referencesForResponse = [];
        let actualSourcePipeline = `${llmProvider}-direct`;
        let systemPromptForLlm = CHAT_MAIN_SYSTEM_PROMPT();
        
        const historyForLlm = [];
        let currentUserQueryForLlm = query.trim();

        if (summaryFromDb) {
            historyForLlm.push({ role: 'user', parts: [{ text: `CONTEXT: Here is a summary of our conversation so far. Use it to inform your response but do not mention the summary itself in your answer:\n\n"""\n${summaryFromDb}\n"""` }] });
            historyForLlm.push({ role: 'model', parts: [{ text: "Okay, I have reviewed the summary of our previous conversation. I will use this context for my next response. How can I help you now?" }] });
        }
        
        const formattedDbMessages = historyFromDb.map(msg => ({
            role: msg.role, parts: msg.parts.map(part => ({ text: part.text || '' }))
        }));
        historyForLlm.push(...formattedDbMessages);
        
        if (useWebSearch) {
            console.log(`   Mode: Web Search. Calling internal webSearchService.`);
            systemPromptForLlm = WEB_SEARCH_CHAT_SYSTEM_PROMPT;
            actualSourcePipeline = `${llmProvider}-web-search`;
            const webContextString = await performWebSearch(query.trim());

            if (webContextString) {
                currentUserQueryForLlm = `${webContextString}\n\nBased on the search results above, please answer the following question:\n${query.trim()}`;
                
                const results = webContextString.split('\n\n').slice(1);
                results.forEach(result => {
                    const numberMatch = result.match(/^\[(\d+)\]/);
                    const titleMatch = result.match(/Title: (.*?)\n/);
                    const sourceMatch = result.match(/Source: (.*?)\n/);
                    if (numberMatch && titleMatch && sourceMatch) {
                        referencesForResponse.push({ number: parseInt(numberMatch[1], 10), source: sourceMatch[1], content_preview: titleMatch[1] });
                    }
                });
            }

        } else if (useRag) {
            console.log(`   Mode: Document RAG. Calling Python RAG Service.`);
            actualSourcePipeline = `${llmProvider}-rag`;
            const relevantDocsFromRag = await queryPythonRagService(userId.toString(), query.trim(), criticalThinkingEnabled, documentContextName, filter);
            
            let ragContextString = "";
            if (relevantDocsFromRag?.length > 0) {
                ragContextString = relevantDocsFromRag.map((doc, index) => {
                    referencesForResponse.push({ number: index + 1, source: doc.documentName, content_preview: doc.content.substring(0, 100) + (doc.content.length > 100 ? "..." : "") });
                    return `\n[${index + 1}] Source: ${doc.documentName}\nContent:\n${doc.content}\n---`;
                }).join('');
            }
            currentUserQueryForLlm = CHAT_USER_PROMPT_TEMPLATES.rag(query.trim(), ragContextString, clientProvidedSystemInstruction);
        } else {
            console.log(`   Mode: Direct Chat.`);
            currentUserQueryForLlm = CHAT_USER_PROMPT_TEMPLATES.direct(query.trim(), clientProvidedSystemInstruction);
        }

        let aiResponseMessageText;
        if (llmProvider === 'ollama') {
            const fullHistoryForOllama = [...historyForLlm, { role: 'user', parts: [{ text: currentUserQueryForLlm }] }];
            aiResponseMessageText = await ollamaService.generateContentWithHistory(fullHistoryForOllama, systemPromptForLlm, { model: ollamaModel });
        } else {
            aiResponseMessageText = await geminiService.generateContentWithHistory(
                historyForLlm,
                currentUserQueryForLlm,
                systemPromptForLlm
            );
        }

        const aiMessageForDbAndClient = {
            sender: 'bot', role: 'model', parts: [{ text: aiResponseMessageText }], text: aiResponseMessageText,
            timestamp: new Date(), thinking: null, references: referencesForResponse, source_pipeline: actualSourcePipeline,
        };

        await ChatHistory.findOneAndUpdate(
            { sessionId: sessionId, userId: userId },
            { $push: { messages: { $each: [userMessageForDb, aiMessageForDbAndClient] } }, $set: { updatedAt: new Date() } },
            { upsert: true, new: true, setDefaultsOnInsert: true }
        );

        console.log(`<<< POST /api/chat/message successful for Session ${sessionId}. DB state updated.`);
        res.status(200).json({ reply: aiMessageForDbAndClient });

    } catch (error) {
        console.error(`!!! Error processing chat message for Session ${sessionId}:`, error);
        const statusCode = error.status || error.response?.status || 500;
        const clientMessage = error.message || "Failed to get response from AI service.";
        
        const errorMessageForChat = {
            sender: 'bot', role: 'model', parts: [{ text: `Error: ${clientMessage}` }], text: `Error: ${clientMessage}`,
            timestamp: new Date(), thinking: `Error occurred: ${error.message}`, references: [], source_pipeline: 'error-pipeline'
        };
        
        try {
            await ChatHistory.findOneAndUpdate(
                { sessionId: sessionId, userId: userId },
                { $push: { messages: { $each: [userMessageForDb, errorMessageForChat] } }, $set: { updatedAt: new Date() } },
                { upsert: true, new: true, setDefaultsOnInsert: true }
            );
        } catch (dbError) {
            console.error(`!!! CRITICAL: Failed to save error message to chat history for Session ${sessionId}:`, dbError);
        }
        res.status(statusCode).json({ message: clientMessage, reply: errorMessageForChat });
    }
});


// (The rest of the file remains unchanged)
router.post('/history', async (req, res) => {
    const { previousSessionId } = req.body;
    const userId = req.user._id;
    const newSessionId = uuidv4();
    let summaryOfOldSession = "";
    if (previousSessionId) {
        try {
            const oldSession = await ChatHistory.findOne({ sessionId: previousSessionId, userId: userId });
            const user = await User.findById(userId).select('preferredLlmProvider ollamaModel').lean();
            const llmProvider = user?.preferredLlmProvider || 'gemini';
            const ollamaModel = user?.ollamaModel || process.env.OLLAMA_DEFAULT_MODEL;
            if (oldSession && oldSession.messages?.length > 0) {
                summaryOfOldSession = await createOrUpdateSummary(oldSession.messages, oldSession.summary, llmProvider, ollamaModel);
            }
        } catch (summaryError) {
            console.error(`!!! Could not summarize previous session ${previousSessionId}:`, summaryError);
        }
    }
    try {
        await ChatHistory.create({ userId: userId, sessionId: newSessionId, messages: [], summary: summaryOfOldSession });
        res.status(200).json({ message: 'New session started.', newSessionId: newSessionId });
    } catch (dbError) {
        console.error(`!!! Failed to create new chat session ${newSessionId} in DB:`, dbError);
        res.status(500).json({ message: 'Failed to create new session due to a server error.' });
    }
});

router.get('/sessions', async (req, res) => {
    try {
        const sessions = await ChatHistory.find({ userId: req.user._id }).sort({ updatedAt: -1 }).select('sessionId createdAt updatedAt messages').lean();
        const sessionSummaries = sessions.map(session => {
            const firstUserMessage = session.messages?.find(m => m.role === 'user');
            let preview = firstUserMessage?.parts?.[0]?.text?.substring(0, 75) || 'Chat Session';
            if (preview.length === 75) preview += '...';
            return { sessionId: session.sessionId, createdAt: session.createdAt, updatedAt: session.updatedAt, messageCount: session.messages?.length || 0, preview: preview };
        });
        res.status(200).json(sessionSummaries);
    } catch (error) {
        console.error(`!!! Error fetching chat sessions for user ${req.user._id}:`, error);
        res.status(500).json({ message: 'Failed to retrieve chat sessions.' });
    }
});

router.get('/session/:sessionId', async (req, res) => {
    try {
        const session = await ChatHistory.findOne({ sessionId: req.params.sessionId, userId: req.user._id }).lean();
        if (!session) return res.status(404).json({ message: 'Chat session not found or access denied.' });
        const messagesForFrontend = (session.messages || []).map(msg => ({ id: msg._id || uuidv4(), sender: msg.role === 'model' ? 'bot' : 'user', text: msg.parts?.[0]?.text || '', thinking: msg.thinking, references: msg.references, timestamp: msg.timestamp, source_pipeline: msg.source_pipeline }));
        res.status(200).json({ ...session, messages: messagesForFrontend });
    } catch (error) {
        console.error(`!!! Error fetching chat session ${req.params.sessionId} for user ${req.user._id}:`, error);
        res.status(500).json({ message: 'Failed to retrieve chat session details.' });
    }
});

module.exports = router;
```

`routes/files.js`

```javascript
// server/routes/files.js
const express = require('express');
const fs = require('fs').promises;
const path = require('path');
const { authMiddleware } = require('../middleware/authMiddleware');
const User = require('../models/User');
const axios = require('axios');
const router = express.Router();

const ASSETS_DIR = path.join(__dirname, '..', 'assets');
const BACKUP_DIR = path.join(__dirname, '..', 'backup_assets');

// --- Helper functions (sanitizeUsernameForDir, parseServerFilename, ensureDirExists are existing) ---
const sanitizeUsernameForDir = (username) => {
    if (!username) return '';
    return username.replace(/[^a-zA-Z0-9_-]/g, '_');
};

const parseServerFilename = (filename) => {
    // Matches "timestamp-originalName.ext"
    // Allows originalName to contain dots now.
    const match = filename.match(/^(\d+)-(.+?)(\.\w+)$/);
    if (match && match.length === 4) {
        return { timestamp: match[1], originalName: `${match[2]}${match[3]}`, extension: match[3] };
    }
    // Fallback for names that might not perfectly fit the new pattern, or originalName without extension before timestamp
    const ext = path.extname(filename);
    const baseWithoutExt = filename.substring(0, filename.length - ext.length);
    const tsMatch = baseWithoutExt.match(/^(\d+)-(.*)$/);
    if (tsMatch) {
        return { timestamp: tsMatch[1], originalName: `${tsMatch[2]}${ext}`, extension: ext };
    }
    // Final fallback if no timestamp prefix is reliably parsed
    return { timestamp: null, originalName: filename, extension: path.extname(filename) };
};

const ensureDirExists = async (dirPath) => {
    try { await fs.mkdir(dirPath, { recursive: true }); }
    catch (error) { if (error.code !== 'EEXIST') { console.error(`Error creating dir ${dirPath}:`, error); throw error; } }
};

async function callPythonDeletionEndpoint(method, endpointPath, userId, originalName, logContext) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL || process.env.DEFAULT_PYTHON_RAG_URL || 'http://localhost:5000'; // Fallback if not set
    if (!pythonServiceUrl) {
        console.error(`Python Service Deletion Error for ${logContext}: PYTHON_RAG_SERVICE_URL not set.`);
        return { success: false, message: "Python service URL not configured." };
    }

    const deleteUrl = `${pythonServiceUrl.replace(/\/$/, '')}${endpointPath}`;

    try {
        console.log(`Calling Python Service (${method.toUpperCase()}) for deletion: ${deleteUrl} (Doc: ${originalName}, User: ${userId})`);
        let response;
        if (method.toUpperCase() === 'DELETE') {
            // For DELETE, data is often in query params or path, but axios allows a 'data' field for body
            response = await axios.delete(deleteUrl, {
                data: { // For Python endpoints that expect a body (like a new Qdrant delete one)
                    user_id: userId,
                    document_name: originalName
                },
                timeout: 30000 // 30s timeout
            });
        } else {
            throw new Error(`Unsupported method for Python deletion: ${method}`);
        }

        if (response.status === 200 || response.status === 204) { // 204 No Content is also success
            return { success: true, message: response.data?.message || `Successfully deleted from ${endpointPath}` };
        } else {
            return { success: false, message: response.data?.message || `Python service returned ${response.status} for ${endpointPath}` };
        }
    } catch (error) {
        const errorMsg = error.response?.data?.error || error.response?.data?.message || error.message || `Unknown error deleting from ${endpointPath}`;
        console.error(`Error calling Python Service for deletion (${deleteUrl}) for ${originalName} (User: ${userId}): ${errorMsg}`, error.response ? { status: error.response.status, data: error.response.data } : error);
        return { success: false, message: `Python service call failed for ${endpointPath}: ${errorMsg}` };
    }
}
// --- End Helper Functions ---


// --- @route   GET /api/files ---
// Use authMiddleware middleware 
// TO GET FILE NAMES
router.get('/', authMiddleware, async (req, res) => {
    
    const userFiles = []
    try {
        const userId = req.user._id.toString();

        // Find user by ID, select only uploadedDocuments to optimize
        const user = await User.findById(userId).select('uploadedDocuments');

        if (!user) return res.status(404).json({ msg: 'User not found' });

        // Extract filenames
        const filenames = user.uploadedDocuments
        .map(doc => doc.filename)
        .filter(Boolean)  // filter out undefined or null filenames just in case
        .reverse();       // reverse the order

        return res.json({ filenames });

    } catch (error) {
        console.log(error.message);
        return res.status(500).json({ msg: 'Server error' });
    }
});


// --- @route   DELETE /api/files/:serverFilename ---
// Use authMiddleware middleware
router.delete('/:serverFilename', authMiddleware, async (req, res) => {
  
    const { serverFilename } = req.params;
    const userId = req.user._id.toString(); // Get userId from authenticated user
    const usernameForLog = req.user.username;

    if (!serverFilename) {
        return res.status(400).json({ message: 'Server filename parameter is required.' });
    }

    const parsedFileDetails = parseServerFilename(serverFilename);
    const originalName = parsedFileDetails.originalName;
    if (!originalName) {
        console.error(`DELETE /api/files: Could not parse originalName from serverFilename: ${serverFilename}`);
        return res.status(400).json({ message: 'Invalid server filename format for deletion.' });
    }
    const logContext = `File: '${originalName}' (server: ${serverFilename}), User: ${usernameForLog} (${userId})`;
    console.log(`Attempting to delete all data for ${logContext}`);

    const results = {
        mongodb: { success: false, message: "Not attempted" },
        qdrant: { success: false, message: "Not attempted" },
        neo4j: { success: false, message: "Not attempted" },
        filesystem: { success: false, message: "Not attempted" },
    };
    let overallSuccess = true; // Assume success, set to false if any critical step fails
    let httpStatus = 200;
    let fileFoundInMongo = false;
    let physicalFileFound = false;

    try {
        // 1. Delete from MongoDB
        try {
            const user = await User.findById(userId);
            if (!user) {
                results.mongodb.message = "User not found.";
                // If user not found, we can't confirm if the file was theirs.
                // Treat as if the file wasn't found for this user.
            } else {
                const docIndex = user.uploadedDocuments.findIndex(doc => doc.filename === originalName);
                if (docIndex > -1) {
                    fileFoundInMongo = true;
                    user.uploadedDocuments.splice(docIndex, 1);
                    await user.save();
                    results.mongodb.success = true;
                    results.mongodb.message = "Successfully removed from user's document list.";
                    console.log(`MongoDB: Document entry '${originalName}' removed for user ${userId}.`);
                } else {
                    results.mongodb.message = "Document not found in user's list.";
                    console.log(`MongoDB: Document entry '${originalName}' not found for user ${userId}.`);
                }
            }
        } catch (mongoError) {
            console.error(`MongoDB Deletion Error for ${logContext}:`, mongoError);
            results.mongodb.message = `MongoDB deletion failed: ${mongoError.message}`;
            overallSuccess = false; // DB error is critical
        }

        // 2. Delete from Qdrant (via Python service)
        // This endpoint will need to be created in Python: e.g., /delete_qdrant_document_data
        // It should expect { user_id: userId, document_name: originalName } in the body
        const qdrantDeleteResult = await callPythonDeletionEndpoint(
            'DELETE',
            `/delete_qdrant_document_data`,
            userId,
            originalName,
            logContext
        );
        results.qdrant = qdrantDeleteResult;
        if (!qdrantDeleteResult.success) {
            console.warn(`Qdrant deletion failed or reported no data for ${logContext}. Message: ${qdrantDeleteResult.message}`);
            // overallSuccess = false; // Non-critical for now, but log
        }

        // 3. Delete from Neo4j (via Python service)
        // This uses the existing Python endpoint: /kg/<user_id>/<document_name>
        const neo4jEndpointPath = `/kg/${userId}/${encodeURIComponent(originalName)}`;
        const neo4jDeleteResult = await callPythonDeletionEndpoint(
            'DELETE',
            neo4jEndpointPath, // userId and originalName are in the path
            userId, // still pass for logging consistency in helper
            originalName, // still pass for logging consistency in helper
            logContext
        );
        results.neo4j = neo4jDeleteResult;
        if (!neo4jDeleteResult.success) {
            console.warn(`Neo4j deletion failed or reported no data for ${logContext}. Message: ${neo4jDeleteResult.message}`);
            // overallSuccess = false; // Non-critical for now, but log
        }

        // 4. Move physical file to backup (filesystem operation)
        let currentPath = null;
        let fileType = '';
        const fileTypesToSearch = ['docs', 'images', 'code', 'others'];
        const sanitizedUsernameForPath = sanitizeUsernameForDir(usernameForLog);

        for (const type of fileTypesToSearch) {
            const potentialPath = path.join(ASSETS_DIR, sanitizedUsernameForPath, type, serverFilename);
            try {
                await fs.access(potentialPath); // Check if file exists
                currentPath = potentialPath;
                fileType = type;
                physicalFileFound = true;
                break;
            } catch (e) {
                if (e.code !== 'ENOENT') {
                    console.warn(`Filesystem: Error accessing ${potentialPath} during delete scan: ${e.message}`);
                }
            }
        }

        if (currentPath) { // If physical file was found
            const backupUserDir = path.join(BACKUP_DIR, sanitizedUsernameForPath, fileType);
            await ensureDirExists(backupUserDir);
            const backupPath = path.join(backupUserDir, serverFilename);
            try {
                await fs.rename(currentPath, backupPath);
                results.filesystem = { success: true, message: "File moved to backup successfully." };
                console.log(`Filesystem: Moved '${currentPath}' to '${backupPath}'.`);
            } catch (fsError) {
                console.error(`Filesystem: Error moving file ${currentPath} to backup for ${logContext}:`, fsError);
                results.filesystem.message = `Filesystem move to backup failed: ${fsError.message}`;
                // overallSuccess = false; // Decide if this is critical enough to mark overall failure
            }
        } else {
            results.filesystem.message = "Physical file not found in assets, or already moved.";
            console.log(`Filesystem: Physical file '${serverFilename}' not found for user ${usernameForLog}.`);
        }

        // Determine final status and message
        const successfulDeletes = [results.mongodb.success, results.qdrant.success, results.neo4j.success, results.filesystem.success].filter(Boolean).length;

        if (!fileFoundInMongo && !physicalFileFound) {
            httpStatus = 404;
            finalMessage = `File '${originalName}' not found for user.`;
        } else if (results.mongodb.success) { // Primary record deleted
            if (successfulDeletes === 4) {
                finalMessage = `Successfully deleted all data associated with '${originalName}'.`;
                httpStatus = 200;
            } else {
                finalMessage = `File '${originalName}' removed from your list. Some backend data cleanup attempts had issues. Check server logs for details.`;
                httpStatus = 207; // Multi-Status
            }
        } else { // MongoDB deletion failed, but file might have existed
            finalMessage = `Failed to remove '${originalName}' from your list. Some backend data cleanup may have also failed. Check server logs.`;
            httpStatus = 500;
        }

        console.log(`Deletion outcome for ${logContext}: HTTP Status=${httpStatus}, Overall Success Flag (was pre-status logic)=${overallSuccess}`);
        return res.status(httpStatus).json({
            message: finalMessage,
            details: results
        });

    } catch (error) {
        console.error(`!!! UNEXPECTED Error in DELETE /api/files/${serverFilename} for user ${usernameForLog}:`, error);
        return res.status(500).json({
            message: 'An unexpected server error occurred during file deletion.',
            details: results // Send partial results if any
        });
    }
});


module.exports = router;

```

`routes/generation.js`

```javascript
// // server/routes/generation.js
// const express = require('express');
// const axios = require('axios');
// const router = express.Router();

// // This route is protected by authMiddleware applied in server.js

// // @route   POST /api/generate/document
// // @desc    Generate a document (PPTX or DOCX) by proxying to the Python service.
// // @access  Private
// router.post('/document', async (req, res) => {
//     const { markdownContent, docType } = req.body;

//     if (!markdownContent || !docType) {
//         return res.status(400).json({ message: 'markdownContent and docType are required.' });
//     }

//     const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
//     if (!pythonServiceUrl) {
//         console.error("[Generation Route] PYTHON_RAG_SERVICE_URL is not set.");
//         return res.status(500).json({ message: "Document generation service is not configured." });
//     }

//     const generationUrl = `${pythonServiceUrl}/generate_document`;
//     console.log(`[Generation Route] Forwarding request to Python service: ${generationUrl}`);

//     try {
//         const pythonResponse = await axios.post(generationUrl, {
//             markdownContent,
//             docType
//         }, { timeout: 60000 }); // 1 minute timeout for generation

//         if (pythonResponse.data && pythonResponse.data.success) {
//             const filename = pythonResponse.data.filename;
//             // Construct the full download URL for the client
//             const downloadUrl = `${pythonServiceUrl}/download_document/${filename}`;
            
//             res.status(200).json({
//                 success: true,
//                 downloadUrl: downloadUrl,
//                 filename: filename
//             });
//         } else {
//             throw new Error(pythonResponse.data.error || "Unknown error from generation service.");
//         }
//     } catch (error) {
//         const errorMsg = error.response?.data?.error || error.message || "Failed to generate document.";
//         console.error(`[Generation Route] Error calling Python service: ${errorMsg}`);
//         res.status(500).json({ message: errorMsg });
//     }
// });

// module.exports = router;














// server/routes/generation.js
const express = require('express');
const axios = require('axios');
const router = express.Router();
const User = require('../models/User'); // <-- Import User model

// This route is protected by authMiddleware applied in server.js

// @route   POST /api/generate/document
// @desc    Generate a document (PPTX or DOCX) by proxying to the Python service.
// @access  Private
router.post('/document', async (req, res) => {
    // --- MODIFIED: Destructure new fields ---
    const { markdownContent, docType, sourceDocumentName } = req.body;
    const userId = req.user._id;

    if (!markdownContent || !docType || !sourceDocumentName) {
        return res.status(400).json({ message: 'markdownContent, docType, and sourceDocumentName are required.' });
    }

    try {
        // --- NEW: Fetch the full text of the source document ---
        const user = await User.findById(userId).select('uploadedDocuments');
        if (!user) {
            return res.status(404).json({ message: 'User not found.' });
        }
        const sourceDocument = user.uploadedDocuments.find(doc => doc.filename === sourceDocumentName);
        if (!sourceDocument || !sourceDocument.text) {
            return res.status(404).json({ message: `Source document '${sourceDocumentName}' or its text content not found.` });
        }
        const sourceDocumentText = sourceDocument.text;
        // --- END NEW ---

        const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
        if (!pythonServiceUrl) {
            console.error("[Generation Route] PYTHON_RAG_SERVICE_URL is not set.");
            return res.status(500).json({ message: "Document generation service is not configured." });
        }

        const generationUrl = `${pythonServiceUrl}/generate_document`;
        console.log(`[Generation Route] Forwarding request to Python service: ${generationUrl}`);

        const pythonResponse = await axios.post(generationUrl, {
            markdownContent, // This is the outline (e.g., FAQ, Key Topics)
            docType,
            sourceDocumentText // Pass the full text for context
        }, { timeout: 300000 }); // Increased timeout to 5 minutes for LLM generation

        if (pythonResponse.data && pythonResponse.data.success) {
            const filename = pythonResponse.data.filename;
            const downloadUrl = `${pythonServiceUrl}/download_document/${filename}`;
            
            res.status(200).json({
                success: true,
                downloadUrl: downloadUrl,
                filename: filename
            });
        } else {
            throw new Error(pythonResponse.data.error || "Unknown error from generation service.");
        }
    } catch (error) {
        const errorMsg = error.response?.data?.error || error.message || "Failed to generate document.";
        console.error(`[Generation Route] Error: ${errorMsg}`);
        res.status(500).json({ message: errorMsg });
    }
});

module.exports = router;
```

`routes/mindmap.js`

```javascript
// server/routes/mindmap.js
const express = require('express');
const router = express.Router();
const { authMiddleware } = require('../middleware/authMiddleware');
const User = require('../models/User'); // For a more advanced implementation

// @route   GET /api/mindmap
// @desc    Get Mermaid code for a mind map
// @access  Private (requires auth)
router.get('/', authMiddleware, async (req, res) => {
    const userId = req.user._id; // User is authenticated
    console.log(`>>> GET /api/mindmap: User=${userId}`);

    try {
        const user = await User.findById(userId).select('uploadedDocuments.filename uploadedDocuments.analysis.mindmap'); // Select only necessary fields
        
        let mindmapCode = null;
        let sourceDocumentName = "Unknown Document";

        if (user && user.uploadedDocuments && user.uploadedDocuments.length > 0) {
            // Find the most recent document that has a mindmap analysis.
            // This assumes higher index means more recent, or you'd sort by an explicit timestamp if available.
            for (let i = user.uploadedDocuments.length - 1; i >= 0; i--) {
                const doc = user.uploadedDocuments[i];
                if (doc.analysis && typeof doc.analysis.mindmap === 'string' && doc.analysis.mindmap.trim() !== "") {
                    mindmapCode = doc.analysis.mindmap.trim();
                    sourceDocumentName = doc.filename || "Untitled Document";
                    console.log(`   Found mindmap for document '${sourceDocumentName}' for user ${userId}.`);
                    break;
                }
            }
        }

        if (mindmapCode) {
            // Basic check if the code starts with a known Mermaid diagram type.
            // This is a simple heuristic. Robust validation is complex.
            const trimmedCode = mindmapCode; // Already trimmed
            const validMermaidPrefixes = ['mindmap', 'graph', 'flowchart', 'sequenceDiagram', 'gantt', 'classDiagram', 'stateDiagram', 'pie', 'erDiagram', 'journey', 'requirementDiagram', 'gitGraph'];
            
            const isPotentiallyValidMermaid = validMermaidPrefixes.some(prefix => 
                trimmedCode.toLowerCase().startsWith(prefix)
            );

            if (!isPotentiallyValidMermaid) {
                // If the stored code doesn't look like Mermaid, prepend 'mindmap'
                // This is an assumption that the stored data *should* be a mindmap if it's in this field.
                console.warn(`   Mindmap code for '${sourceDocumentName}' does not start with a recognized Mermaid type. Prefixing with 'mindmap'.`);
                mindmapCode = `mindmap\n${trimmedCode}`; 
            } else if (!trimmedCode.toLowerCase().startsWith('mindmap')) {
                 // If it's valid Mermaid but not explicitly 'mindmap' (e.g. 'graph TD'),
                 // and the user specifically clicked "Mind Map", it's still okay to send.
                 // The Mermaid library on the frontend can render various diagram types.
                console.log(`   Sending stored analysis as Mermaid diagram. Type: ${trimmedCode.split('\n')[0].trim()}`);
            }
            return res.status(200).json({ mermaidCode: mindmapCode, source: sourceDocumentName });
        } else {
            console.log(`   No mindmap analysis found for user ${userId}. Returning default mindmap.`);
            const defaultMermaidCode = `
mindmap
  root((No Mind Map Available))
    (Please upload a document and ensure its analysis includes a mind map.)
    (Or, no documents processed yet.)
`;
            return res.status(200).json({ mermaidCode: defaultMermaidCode, source: "Default" });
        }

    } catch (error) {
        console.error(`!!! Error in GET /api/mindmap for User ${userId}:`, error);
        res.status(500).json({ message: "Failed to retrieve mind map code due to a server error." });
    }
});

module.exports = router;
```

`routes/network.js`

```javascript
const express = require('express');
const router = express.Router();
const os = require('os');

function getAllIPs() {
    const interfaces = os.networkInterfaces();
    const ips = new Set(['localhost']); // Include localhost by default

    for (const [name, netInterface] of Object.entries(interfaces)) {
        // Skip loopback and potentially virtual interfaces if desired
        if (name.includes('lo') || name.toLowerCase().includes('virtual') || name.toLowerCase().includes('vmnet')) continue;

        for (const addr of netInterface) {
            // Focus on IPv4, non-internal addresses
            if (addr.family === 'IPv4' && !addr.internal) {
                ips.add(addr.address);
            }
        }
    }
    return Array.from(ips);
}

router.get('/ip', (req, res) => {
    res.json({
        ips: getAllIPs(),
        // req.ip might be less reliable behind proxies, but can be included
        // currentRequestIp: req.ip
    });
});

module.exports = router;

```

`routes/subjects.js`

```javascript
// server/routes/subjects.js
const express = require('express');
const router = express.Router();
const AdminDocument = require('../models/AdminDocument'); // Model for admin-uploaded documents

// @route   GET /api/subjects
// @desc    Get a list of available subject names (derived from admin-uploaded document originalNames)
// @access  Private (Regular User Authenticated via JWT)
router.get('/', async (req, res) => {
    // req.user is available here from authMiddleware
    console.log(`User ${req.user.username} is requesting the list of subjects.`);
    try {
        // Fetch distinct originalName values from the AdminDocument collection
        // and sort them alphabetically.
        const subjectObjects = await AdminDocument.find().sort({ originalName: 1 }).select('originalName').lean();
        const subjectNames = subjectObjects.map(doc => doc.originalName);
        
        // Alternative using distinct, but sorting might be different or need post-processing
        // const subjectNames = await AdminDocument.distinct('originalName').exec();
        // subjectNames.sort((a, b) => a.localeCompare(b));


        res.json({ subjects: subjectNames }); // Send as { subjects: ["Subject 1", "Subject 2", ...] }
    } catch (error) {
        console.error("Error fetching subjects for user display:", error);
        res.status(500).json({ message: "Server error while fetching available subjects." });
    }
});

module.exports = router;
```

`routes/syllabus.js`

```javascript
// server/routes/syllabus.js
const express = require('express');
const fs = require('fs').promises;
const path = require('path');
const { authMiddleware } = require('../middleware/authMiddleware'); // Protect the route

const router = express.Router();
const SYLLABI_DIR = path.join(__dirname, '..', 'syllabi');

// --- @route   GET /api/syllabus/:subjectId ---
// --- @desc    Get syllabus content for a specific subject ---
// --- @access  Private (requires auth) ---
router.get('/:subjectId', authMiddleware, async (req, res) => {
    const { subjectId } = req.params;

    // Basic sanitization: Allow only alphanumeric and underscores
    // Prevents directory traversal (e.g., ../../etc/passwd)
    const sanitizedSubjectId = subjectId.replace(/[^a-zA-Z0-9_]/g, '');

    if (!sanitizedSubjectId || sanitizedSubjectId !== subjectId) {
        console.warn(`Syllabus request rejected due to invalid characters: ${subjectId}`);
        return res.status(400).json({ message: 'Invalid subject identifier format.' });
    }

    const filePath = path.join(SYLLABI_DIR, `${sanitizedSubjectId}.md`);

    try {
        // Check if file exists first (more specific error)
        await fs.access(filePath);

        // Read the file content
        const content = await fs.readFile(filePath, 'utf-8');

        res.status(200).json({ syllabus: content });

    } catch (error) {
        if (error.code === 'ENOENT') {
            console.warn(`Syllabus file not found: ${filePath}`);
            return res.status(404).json({ message: `Syllabus for '${subjectId}' not found.` });
        } else {
            console.error(`Error reading syllabus file ${filePath}:`, error);
            return res.status(500).json({ message: 'Server error retrieving syllabus.' });
        }
    }
});

module.exports = router;

```

`routes/upload.js`

```javascript
// // server/routes/upload.js
// const express = require('express');
// const multer = require('multer');
// const path = require('path');
// const fs = require('fs');
// const axios = require('axios');
// const { authMiddleware } = require('../middleware/authMiddleware');
// const User = require('../models/User'); // Import the User model
// const { Worker } = require('worker_threads');
// // const { ANALYSIS_PROMPTS } = require('../config/promptTemplates'); 
// // const geminiService = require('../services/geminiService');

// const router = express.Router();

// // --- Constants ---
// const UPLOAD_DIR = path.join(__dirname, '..', 'assets');
// const MAX_FILE_SIZE = 20 * 1024 * 1024; // 20 MB

// // Define allowed types by mimetype and extension (lowercase)
// // Mapping mimetype to subfolder name
// const allowedMimeTypes = {
//     // Documents -> 'docs'
//     'application/pdf': 'docs',
//     'application/vnd.openxmlformats-officedocument.wordprocessingml.document': 'docs', // .docx
//     'application/msword': 'docs', // .doc (Might be less reliable mimetype)
//     'application/vnd.openxmlformats-officedocument.presentationml.presentation': 'docs', // .pptx
//     'application/vnd.ms-powerpoint': 'docs', // .ppt (Might be less reliable mimetype)
//     'text/plain': 'docs', // .txt
//     // Code -> 'code'
//     'text/x-python': 'code', // .py
//     'application/javascript': 'code', // .js
//     'text/javascript': 'code', // .js (alternative)
//     'text/markdown': 'code', // .md
//     'text/html': 'code', // .html
//     'application/xml': 'code', // .xml
//     'text/xml': 'code', // .xml
//     'application/json': 'code', // .json
//     'text/csv': 'code', // .csv
//     // Images -> 'images'
//     'image/jpeg': 'images',
//     'image/png': 'images',
//     'image/bmp': 'images',
//     'image/gif': 'images',
//     // Add more specific types if needed, otherwise they fall into 'others'
// };
// // Define allowed extensions (lowercase) - This is a secondary check
// const allowedExtensions = [
//     '.pdf', '.docx', '.doc', '.pptx', '.ppt', '.txt',
//     '.py', '.js', '.md', '.html', '.xml', '.json', '.csv', '.log', // Added .log
//     '.jpg', '.jpeg', '.png', '.bmp', '.gif'
// ];

// // --- Multer Config ---
// const storage = multer.diskStorage({
//     destination: (req, file, cb) => {
//         // authMiddleware middleware ensures req.user exists here
//         if (!req.user || !req.user.username) {
//             // This should ideally not happen if authMiddleware works correctly
//             console.error("Multer Destination Error: User context missing after auth middleware.");
//             return cb(new Error("Authentication error: User context not found."));
//         }
//         const sanitizedUsername = req.user.username.replace(/[^a-zA-Z0-9_-]/g, '_');
//         const fileMimeType = file.mimetype.toLowerCase();

//         // Determine subfolder based on mimetype, default to 'others'
//         const fileTypeSubfolder = allowedMimeTypes[fileMimeType] || 'others';
//         const destinationPath = path.join(UPLOAD_DIR, sanitizedUsername, fileTypeSubfolder);

//         // Ensure the destination directory exists (use async for safety)
//         fs.mkdir(destinationPath, { recursive: true }, (err) => {
//              if (err) {
//                  console.error(`Error creating destination path ${destinationPath}:`, err);
//                  cb(err);
//              } else {
//                  cb(null, destinationPath);
//              }
//          });
//     },
//     filename: (req, file, cb) => {
//         const timestamp = Date.now();
//         const fileExt = path.extname(file.originalname).toLowerCase();
//         // Sanitize base name: remove extension, replace invalid chars, limit length
//         const sanitizedBaseName = path.basename(file.originalname, fileExt)
//                                       .replace(/[^a-zA-Z0-9._-]/g, '_') // Allow letters, numbers, dot, underscore, hyphen
//                                       .substring(0, 100); // Limit base name length
//         const uniqueFilename = `${timestamp}-${sanitizedBaseName}${fileExt}`;
//         cb(null, uniqueFilename);
//     }
// });

// const fileFilter = (req, file, cb) => {
//     // authMiddleware middleware should run before this, ensuring req.user exists
//     if (!req.user) {
//          console.warn(`Upload Rejected (File Filter): User context missing.`);
//          const error = new multer.MulterError('UNAUTHENTICATED'); // Custom code?
//          error.message = `User not authenticated.`;
//          return cb(error, false);
//     }

//     const fileExt = path.extname(file.originalname).toLowerCase();
//     const mimeType = file.mimetype.toLowerCase();

//     // Primary check: Mimetype must be in our known list OR extension must be allowed
//     // Secondary check: Extension must be in the allowed list
//     const isMimeTypeKnown = !!allowedMimeTypes[mimeType];
//     const isExtensionAllowed = allowedExtensions.includes(fileExt);

//     // Allow if (MIME type is known OR extension is explicitly allowed) AND extension is in the allowed list
//     // This allows known MIME types even if extension isn't listed, and listed extensions even if MIME isn't known (e.g. text/plain for .log)
//     // But we always require the extension itself to be in the allowed list for safety.
//     // if ((isMimeTypeKnown || isExtensionAllowed) && isExtensionAllowed) {

//     // Stricter: Allow only if BOTH mimetype is known AND extension is allowed
//     if (isMimeTypeKnown && isExtensionAllowed) {
//         cb(null, true); // Accept file
//     } else {
//         console.warn(`Upload Rejected (File Filter): User='${req.user.username}', File='${file.originalname}', MIME='${mimeType}', Ext='${fileExt}'. MimeKnown=${isMimeTypeKnown}, ExtAllowed=${isExtensionAllowed}`);
//         const error = new multer.MulterError('LIMIT_UNEXPECTED_FILE');
//         error.message = `Invalid file type or extension. Allowed extensions: ${allowedExtensions.join(', ')}`;
//         cb(error, false); // Reject file
//     }
// };

// const upload = multer({
//     storage: storage,
//     fileFilter: fileFilter,
//     limits: { fileSize: MAX_FILE_SIZE }
// });
// // --- End Multer Config ---


// // --- Function to call Python RAG service ---
// async function triggerPythonRagProcessing(userId, filePath, originalName) {
//     const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
//     if (!pythonServiceUrl) {
//         console.error("PYTHON_RAG_SERVICE_URL is not set in environment. Cannot trigger RAG processing.");
//         return {
//             success: false,
//             message: "RAG service URL not configured.",
//             status: 'error', // Indicate a config error
//             text: null,
//             chunksForKg: []
//         };
//     }

//     const addDocumentUrl = `${pythonServiceUrl}/add_document`;
//     console.log(`Calling Python RAG Service: ${addDocumentUrl} for document '${originalName}' (User: ${userId})`);

//     try {
//         const response = await axios.post(addDocumentUrl, {
//             user_id: userId,
//             file_path: filePath, // Absolute path to the file on the server
//             original_name: originalName
//         }); // 5 minute timeout

//         const pythonData = response.data;
//         // console.log(`Python RAG service response for '${originalName}':`, JSON.stringify(pythonData).substring(0, 500) + "..."); // Log snippet

//         // Extract data carefully, providing defaults
//         const text = pythonData?.raw_text_for_analysis || null;
//         const chunksForKg = pythonData?.chunks_with_metadata || [];
//         const pythonStatus = pythonData?.status; // e.g., 'added', 'skipped_no_content', 'processed_qdrant_chunks_not_added', etc.
//         let pythonMessage = pythonData?.message || "No specific message from Python RAG service.";

//         // Determine overall success for the RAG step based on Python's status
//         // 'added' means Qdrant was updated, which is the primary goal for RAG.
//         // 'processed_for_analysis_only_no_qdrant' means text was extracted but Qdrant failed/skipped. This might still be a "partial success" if text is valuable.
//         // For now, let's consider 'added' as the main success criteria for proceeding with text-dependent tasks.
//         const isRagStepSuccessful = pythonStatus === 'added';

//         if (!isRagStepSuccessful && !text) {
//             // If RAG didn't succeed in adding to Qdrant AND there's no text, it's a more significant failure.
//             pythonMessage = `RAG processing critical failure: ${pythonMessage} (Status: ${pythonStatus})`;
//         } else if (!isRagStepSuccessful && text) {
//             pythonMessage = `RAG processing partial: ${pythonMessage} (Status: ${pythonStatus}). Text was extracted, but Qdrant step may have issues.`;
//         }


//         return {
//             success: isRagStepSuccessful, // True primarily if pythonStatus is 'added'
//             status: pythonStatus,         // The actual status string from Python
//             message: pythonMessage,
//             text: text,                   // Extracted text (can be null)
//             chunksForKg: chunksForKg      // Chunks for KG (can be empty)
//         };

//     } catch (error) {
//         const errorMsg = error.response?.data?.error || error.response?.data?.message || error.message || "Unknown error calling Python RAG service";
//         console.error(`Error calling Python RAG service for '${originalName}': ${errorMsg}`);
//         // Log more details if available from error.response
//         if (error.response && error.response.data) {
//             // console.error("Python service error details:", error.response.data);
//         }
//         return {
//             success: false,
//             message: `Python RAG service call failed: ${errorMsg}`,
//             status: 'error_calling_python', // Custom status for this type of failure
//             text: null,
//             chunksForKg: []
//         };
//     }
// }
// // --- End Function ---


// // --- Function to call Generate Analysis
// async function triggerAnalysisGeneration(userId, originalName, textForAnalysis) {
//     console.log(`Starting analysis generation for document '${originalName}', User ID: ${userId}. Text length: ${textForAnalysis.length}`);

//     let allAnalysesSuccessful = true; // Assume success initially
//     const analysisResults = {
//         faq: null,
//         topics: null,
//         mindmap: null
//     };
//     const logCtx = { userId, originalName }; // Context for logging within generateSingleAnalysis

//     // Inner helper function to generate a single type of analysis
//     async function generateSingleAnalysis(type, promptContent, context) {
//         try {
//             console.log(`Attempting to generate ${type} for '${context.originalName}' (User: ${context.userId}).`);

//             // Prepare history for geminiService.generateContentWithHistory
//             // The 'promptContent' (which is the system prompt) will be passed as the second argument.
//             const historyForGemini = [
//                 { role: 'user', parts: [{ text: "Please perform the requested analysis based on the system instruction provided." }] }
//             ];

//             const generatedText = await geminiService.generateContentWithHistory(
//                 historyForGemini,
//                 promptContent // This is passed as systemPromptText to generateContentWithHistory
//             );

//             if (!generatedText || typeof generatedText !== 'string' || generatedText.trim() === "") {
//                 console.warn(`Gemini returned empty or invalid content for ${type} for '${context.originalName}'.`);
//                 allAnalysesSuccessful = false; // Update the outer scope variable
//                 return `Notice: No content was generated by the AI for ${type}. The input text might have been unsuitable or the AI returned an empty response.`;
//             }

//             console.log(`${type} generation successful for '${context.originalName}'. Length: ${generatedText.length}`);
//             return generatedText.trim();

//         } catch (error) {
//             console.error(`Error during ${type} generation for '${context.originalName}' (User: ${context.userId}): ${error.message}`);
//             allAnalysesSuccessful = false; // Update the outer scope variable
//             // Return a user-friendly error message, or a snippet of the technical error
//             const errorMessage = error.message || "Unknown error during AI generation.";
//             return `Error generating ${type}: ${errorMessage.split('\n')[0].substring(0, 250)}`; // First line of error, truncated
//         }
//     }

//     // 1. Generate FAQs
//     console.log(`[Analysis Step 1/3] Preparing FAQ generation for '${originalName}'.`);
//     const faqPrompt = ANALYSIS_PROMPTS.faq.getPrompt(textForAnalysis);
//     analysisResults.faq = await generateSingleAnalysis('FAQ', faqPrompt, logCtx);
//     if (!allAnalysesSuccessful) {
//         console.warn(`FAQ generation failed or produced no content for '${originalName}'. Continuing to next analysis type.`);
//         // We continue even if one fails, allAnalysesSuccessful flag will reflect the overall status.
//     }

//     // 2. Generate Topics
//     console.log(`[Analysis Step 2/3] Preparing Topics generation for '${originalName}'.`);
//     const topicsPrompt = ANALYSIS_PROMPTS.topics.getPrompt(textForAnalysis);
//     analysisResults.topics = await generateSingleAnalysis('Topics', topicsPrompt, logCtx);
//     if (!allAnalysesSuccessful && analysisResults.topics.startsWith("Error generating Topics:")) { // Check if this specific step failed
//         console.warn(`Topics generation failed or produced no content for '${originalName}'. Continuing to next analysis type.`);
//     }


//     // 3. Generate Mindmap
//     console.log(`[Analysis Step 3/3] Preparing Mindmap generation for '${originalName}'.`);
//     const mindmapPrompt = ANALYSIS_PROMPTS.mindmap.getPrompt(textForAnalysis);
//     analysisResults.mindmap = await generateSingleAnalysis('Mindmap', mindmapPrompt, logCtx);
//     if (!allAnalysesSuccessful && analysisResults.mindmap.startsWith("Error generating Mindmap:")) { // Check if this specific step failed
//         console.warn(`Mindmap generation failed or produced no content for '${originalName}'.`);
//     }

//     // Log final outcome of the analysis generation process
//     if (allAnalysesSuccessful) {
//         console.log(`All analyses (FAQ, Topics, Mindmap) appear to have been generated successfully for '${originalName}'.`);
//     } else {
//         console.warn(`One or more analyses failed or produced no content for '${originalName}'. Review individual results for details.`);
//         // Log the specific results for easier debugging
//         console.warn(`FAQ Result for '${originalName}': ${analysisResults.faq.substring(0,100)}...`);
//         console.warn(`Topics Result for '${originalName}': ${analysisResults.topics.substring(0,100)}...`);
//         console.warn(`Mindmap Result for '${originalName}': ${analysisResults.mindmap.substring(0,100)}...`);
//     }

//     return {
//         success: allAnalysesSuccessful,
//         results: analysisResults
//     };
// }
// // --- End Analysis Generation Function ---


// router.post('/', authMiddleware, (req, res) => {
//     const uploader = upload.single('file');

//     uploader(req, res, async function (err) {
//         if (!req.user) {
//             console.error("Upload Route: User context missing after auth middleware.");
//             return res.status(401).json({ message: "Authentication error: User context not found." });
//         }
//         const userId = req.user._id.toString();
//         const username = req.user.username;

//         let absoluteFilePath = null; // Will be set if file is processed by multer
//         let originalName = null;
//         let serverFilename = null;

//         if (err) {
//             console.error(`Upload Route: Multer error for user '${username}': ${err.message}`);
//             if (err instanceof multer.MulterError) {
//                 return res.status(400).json({ message: err.message });
//             }
//             return res.status(500).json({ message: "Server error during upload preparation." });
//         }

//         if (!req.file) {
//             console.warn(`Upload Route: No file received for user '${username}'.`);
//             return res.status(400).json({ message: "No file received or file type rejected by filter." });
//         }

//         // File successfully received by multer
//         absoluteFilePath = path.resolve(req.file.path);
//         originalName = req.file.originalname;
//         serverFilename = req.file.filename;
//         console.log(`Upload Route: File received for user '${username}'. Server Filename: ${serverFilename}, Original: ${originalName}`);

//         // Fetch user's LLM preferences for workers
//         const userLlmPrefs = await User.findById(userId).select('preferredLlmProvider ollamaModel').lean();
//         const llmProviderForWorkers = userLlmPrefs?.preferredLlmProvider || 'gemini'; // Default to gemini if not set
//         const ollamaModelForWorkers = userLlmPrefs?.ollamaModel || process.env.OLLAMA_DEFAULT_MODEL;

//         try {
//             // ----- STAGE 1: MongoDB Pre-check for existing originalName -----
//             const userForPreCheck = await User.findById(userId).select('uploadedDocuments.filename'); // Only need filename
//             if (!userForPreCheck) {
//                 console.error(`Upload Route: User ${userId} ('${username}') not found during pre-check. Deleting uploaded file: ${absoluteFilePath}`);
//                 await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Upload Route Cleanup: Error deleting file (user not found): ${e.message}`));
//                 return res.status(404).json({ message: "User not found, cannot process upload." });
//             }
//             const existingDocument = userForPreCheck.uploadedDocuments.find(doc => doc.filename === originalName);
//             if (existingDocument) {
//                 console.log(`Upload Route: File '${originalName}' already exists for user '${username}'. Deleting uploaded file: ${absoluteFilePath}`);
//                 await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Upload Route Cleanup: Error deleting file (duplicate): ${e.message}`));
//                 return res.status(409).json({
//                     message: `File '${originalName}' already exists. No new processing initiated.`,
//                     filename: serverFilename,
//                     originalname: originalName,
//                 });
//             }
//             console.log(`Upload Route: Pre-check passed for '${originalName}' (User: '${username}'). Proceeding to RAG processing.`);

//             // ----- STAGE 2: RAG Processing (Synchronous Call to Python Service) -----
//             // This call extracts text, chunks, and gets data ready for Qdrant.
//             // It needs to complete before we can save the initial document record and respond to the user.
//             const ragResult = await triggerPythonRagProcessing(userId, absoluteFilePath, originalName);
//             // Expected ragResult: { success, status ('added' or 'skipped'), text, chunksForKg, message }

//             if (!ragResult.success || ragResult.status !== 'added' || !ragResult.text || ragResult.text.trim() === '') {
//                 const errorMessage = (ragResult && ragResult.message) || "RAG processing failed or returned insufficient data from Python service.";
//                 console.error(`Upload Route Error: RAG processing failed for '${originalName}' (User: '${username}'): ${errorMessage}. Python Status: ${ragResult.status}. Deleting file.`);
//                 if (absoluteFilePath) { // Check if path is still valid
//                     await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Upload Route Cleanup: Error deleting file (RAG fail): ${e.message}`));
//                 }
//                 return res.status(500).json({ // Or 422 if it's a content issue from RAG
//                     message: errorMessage,
//                     filename: serverFilename, originalname: originalName
//                 });
//             }
//             console.log(`Upload Route: RAG processing by Python service completed for '${originalName}'. Text obtained. Python Status: ${ragResult.status}.`);

//             // ----- STAGE 2.5: Initial MongoDB Save for the Document Entry -----
//             // This creates the document shell with the text from RAG and pending statuses.
//             const newDocumentEntryData = {
//                 filename: originalName,
//                 text: ragResult.text, // Save the text obtained from RAG
//                 analysis: { faq: "", topics: "", mindmap: "" }, // Initialize
//                 uploadedAt: new Date(),
//                 ragStatus: ragResult.status, // Should be 'added' here
//                 analysisStatus: "pending",   // Will be updated by analysisWorker
//                 kgStatus: "pending"          // Will be updated by kgWorker
//             };

//             try {
//                 await User.updateOne(
//                     { _id: userId },
//                     { $push: { uploadedDocuments: newDocumentEntryData } }
//                 );
//                 console.log(`Upload Route: Initial document entry for '${originalName}' saved to user '${username}' in MongoDB.`);
//             } catch (dbError) {
//                 console.error(`Upload Route Error: MongoDB error saving initial document entry for '${originalName}': ${dbError.message}. Deleting file.`);
//                 if (absoluteFilePath) {
//                     await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Upload Route Cleanup: Error deleting file (initial DB save fail): ${e.message}`));
//                 }
//                 // This is a server error, RAG was successful but we couldn't save.
//                 return res.status(500).json({ message: `Database error after RAG processing: ${dbError.message}`, filename: serverFilename, originalname: originalName });
//             }

//             // ----- IMMEDIATE RESPONSE TO CLIENT -----
//             // Respond now, indicating acceptance and background processing.
//             res.status(202).json({ // HTTP 202 Accepted
//                 message: `File '${originalName}' uploaded successfully. Processing has started in the background.`,
//                 filename: serverFilename, // Server-generated filename
//                 originalname: originalName,   // Original filename from user
//                 initialStatus: {
//                     rag: ragResult.status,
//                     analysis: "pending",
//                     knowledgeGraph: "pending"
//                 }
//             });
//             console.log(`Upload Route: Sent 202 Accepted to client for '${originalName}'. Offloading further tasks.`);


//             // ----- BACKGROUND PROCESSING INITIATION (AFTER RESPONSE) -----

//             // Offload Analysis Generation to a Worker
//             if (ragResult.text && ragResult.text.trim() !== '') {
//                 console.log(`[Upload Route BG] Initiating Analysis Worker for '${originalName}'`);
//                 const analysisWorkerPath = path.resolve(__dirname, '../workers/analysisWorker.js');
//                 try {
//                     const analysisWorker = new Worker(analysisWorkerPath, {
//                         workerData: {
//                             userId: userId,
//                             originalName: originalName,
//                             textForAnalysis: ragResult.text, // Pass the full text
//                             llmProvider: llmProviderForWorkers,
//                             ollamaModel: ollamaModelForWorkers
//                         }
//                     });
//                     analysisWorker.on('message', (msg) => console.log(`[Upload Route BG] Analysis Worker [Doc: ${msg.originalName || originalName}]: ${msg.message || JSON.stringify(msg)}`));
//                     analysisWorker.on('error', (err) => console.error(`[Upload Route BG] Analysis Worker Error [Doc: ${originalName}]:`, err));
//                     analysisWorker.on('exit', (code) => console.log(`[Upload Route BG] Analysis Worker [Doc: ${originalName}] exited (code ${code}).`));
//                 } catch (workerLaunchError) {
//                     console.error(`[Upload Route BG] Failed to launch Analysis Worker for '${originalName}':`, workerLaunchError);
//                     // Log this error, perhaps update DB doc analysisStatus to 'launch_failed'
//                     User.updateOne(
//                         { _id: userId, "uploadedDocuments.filename": originalName },
//                         { $set: { "uploadedDocuments.$.analysisStatus": "launch_failed" } }
//                     ).catch(e => console.error("DB update error for analysis launch fail (background):", e));
//                 }
//             } else {
//                 console.warn(`[Upload Route BG] Skipping Analysis Worker for '${originalName}' due to no text from RAG.`);
//                 User.updateOne(
//                     { _id: userId, "uploadedDocuments.filename": originalName },
//                     { $set: { "uploadedDocuments.$.analysisStatus": "skipped_no_text" } }
//                 ).catch(e => console.error("DB update error for analysis skipped (background):", e));
//             }

//             // Offload KG Generation to a Worker
//             // Ensure ragResult.chunksForKg is correctly populated by triggerPythonRagProcessing
//             if (ragResult.status === "added" && ragResult.chunksForKg && ragResult.chunksForKg.length > 0) {
//                 console.log(`[Upload Route BG] Initiating KG Worker for '${originalName}'. Chunks: ${ragResult.chunksForKg.length}`);
//                 const kgWorkerScriptPath = path.resolve(__dirname, '../workers/kgWorker.js');
//                 try {
//                     const kgWorker = new Worker(kgWorkerScriptPath, {
//                         workerData: {
//                             chunksForKg: ragResult.chunksForKg, // This comes from Python
//                             userId: userId,
//                             originalName: originalName,
//                             llmProvider: llmProviderForWorkers,
//                             ollamaModel: ollamaModelForWorkers
//                         }
//                     });
//                     kgWorker.on('message', (msg) => console.log(`[Upload Route BG] KG Worker [Doc: ${msg.originalName || originalName}]: ${msg.message || JSON.stringify(msg)}`));
//                     kgWorker.on('error', (workerErr) => console.error(`[Upload Route BG] KG Worker Error [Doc: ${originalName}]:`, workerErr));
//                     kgWorker.on('exit', (code) => console.log(`[Upload Route BG] KG Worker [Doc: ${originalName}] exited (code ${code}).`));
//                 } catch (workerLaunchError) {
//                     console.error(`[Upload Route BG] Failed to launch KG worker for '${originalName}':`, workerLaunchError);
//                     User.updateOne(
//                         { _id: userId, "uploadedDocuments.filename": originalName },
//                         { $set: { "uploadedDocuments.$.kgStatus": "launch_failed" } }
//                     ).catch(e => console.error("DB update error for KG launch fail (background):", e));
//                 }
//             } else {
//                 let kgSkipReason = "skipped_rag_issue";
//                 if (ragResult.chunksForKg && ragResult.chunksForKg.length === 0) {
//                     kgSkipReason = "skipped_no_chunks";
//                 }
//                 console.log(`[Upload Route BG] KG Worker not triggered for '${originalName}'. RAG Status: ${ragResult.status}, Chunks: ${ragResult.chunksForKg ? ragResult.chunksForKg.length : 'N/A'}`);
//                 User.updateOne(
//                     { _id: userId, "uploadedDocuments.filename": originalName },
//                     { $set: { "uploadedDocuments.$.kgStatus": kgSkipReason } }
//                 ).catch(e => console.error("DB update error for KG skipped (background):", e));
//             }

//             // Optional: Delete the physical uploaded file from the 'assets' directory
//             // Do this only if the text content is reliably stored in MongoDB (ragResult.text)
//             // and workers have what they need (text or chunk data).
//             if (absoluteFilePath) {
//                 console.log(`[Upload Route BG] Attempting to delete temporary uploaded file: ${absoluteFilePath} as processing is fully offloaded.`);
//                 await fs.promises.unlink(absoluteFilePath)
//                     .catch(e => console.error(`[Upload Route BG] Non-critical: Failed to delete temp file ${absoluteFilePath} after offloading: ${e.message}`));
//                 absoluteFilePath = null; // Mark as deleted
//             }

//         } catch (processError) {
//             // This catch block handles errors from STAGE 1, 2, or 2.5, or any unhandled synchronous error
//             console.error(`Upload Route: !!! Overall processing error for ${originalName || 'unknown file'} (User: '${username}'):`, processError.message, processError.stack);
//             if (absoluteFilePath) { // If file path is known, try to delete it
//                 await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Upload Route Cleanup: Error deleting file (overall fail): ${e.message}`));
//             }
//             // If res hasn't been sent (e.g., error before 202 response)
//             if (!res.headersSent) {
//                 return res.status(500).json({
//                     message: `Server error during file processing: ${processError.message || 'Unknown error.'}`,
//                     filename: serverFilename, // May be null if error was very early
//                     originalname: originalName // May be null
//                 });
//             } else {
//                 // If response was already sent, we can only log the error.
//                 // A separate mechanism might be needed to update the user/DB about this failure.
//                 console.error(`Upload Route: Error occurred for ${originalName} after 202 response was sent. This indicates a problem in the background initiation logic itself or unhandled promise rejection before workers fully take over.`);
//             }
//         }
//     }); 
// });



// module.exports = router;






















// server/routes/upload.js
const express = require('express');
const multer = require('multer');
const path = require('path');
const fs = require('fs');
const axios = require('axios');
const { authMiddleware } = require('../middleware/authMiddleware');
const User = require('../models/User');
const { Worker } = require('worker_threads');

const router = express.Router();

// --- Constants & Multer Config (Unchanged) ---
const UPLOAD_DIR = path.join(__dirname, '..', 'assets');
const MAX_FILE_SIZE = 20 * 1024 * 1024;
const allowedMimeTypes = {
    'application/pdf': 'docs',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document': 'docs',
    'application/msword': 'docs',
    'application/vnd.openxmlformats-officedocument.presentationml.presentation': 'docs',
    'application/vnd.ms-powerpoint': 'docs',
    'text/plain': 'docs',
    'text/x-python': 'code',
    'application/javascript': 'code',
    'text/javascript': 'code',
    'text/markdown': 'code',
    'text/html': 'code',
    'application/xml': 'code',
    'text/xml': 'code',
    'application/json': 'code',
    'text/csv': 'code',
    'image/jpeg': 'images',
    'image/png': 'images',
    'image/bmp': 'images',
    'image/gif': 'images',
};
const allowedExtensions = [
    '.pdf', '.docx', '.doc', '.pptx', '.ppt', '.txt',
    '.py', '.js', '.md', '.html', '.xml', '.json', '.csv', '.log',
    '.jpg', '.jpeg', '.png', '.bmp', '.gif'
];
const storage = multer.diskStorage({
    destination: (req, file, cb) => {
        if (!req.user || !req.user.username) {
            return cb(new Error("Authentication error: User context not found."));
        }
        const sanitizedUsername = req.user.username.replace(/[^a-zA-Z0-9_-]/g, '_');
        const fileMimeType = file.mimetype.toLowerCase();
        const fileTypeSubfolder = allowedMimeTypes[fileMimeType] || 'others';
        const destinationPath = path.join(UPLOAD_DIR, sanitizedUsername, fileTypeSubfolder);
        fs.mkdir(destinationPath, { recursive: true }, (err) => {
             if (err) cb(err);
             else cb(null, destinationPath);
         });
    },
    filename: (req, file, cb) => {
        const timestamp = Date.now();
        const fileExt = path.extname(file.originalname).toLowerCase();
        const sanitizedBaseName = path.basename(file.originalname, fileExt)
                                      .replace(/[^a-zA-Z0-9._-]/g, '_')
                                      .substring(0, 100);
        const uniqueFilename = `${timestamp}-${sanitizedBaseName}${fileExt}`;
        cb(null, uniqueFilename);
    }
});
const fileFilter = (req, file, cb) => {
    if (!req.user) {
         const error = new multer.MulterError('UNAUTHENTICATED');
         error.message = `User not authenticated.`;
         return cb(error, false);
    }
    const fileExt = path.extname(file.originalname).toLowerCase();
    const mimeType = file.mimetype.toLowerCase();
    if (allowedMimeTypes[mimeType] && allowedExtensions.includes(fileExt)) {
        cb(null, true);
    } else {
        const error = new multer.MulterError('LIMIT_UNEXPECTED_FILE');
        error.message = `Invalid file type or extension. Allowed extensions: ${allowedExtensions.join(', ')}`;
        cb(error, false);
    }
};
const upload = multer({
    storage: storage,
    fileFilter: fileFilter,
    limits: { fileSize: MAX_FILE_SIZE }
});

async function triggerPythonRagProcessing(userId, filePath, originalName) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
    if (!pythonServiceUrl) {
        console.error("PYTHON_RAG_SERVICE_URL is not set in environment. Cannot trigger RAG processing.");
        return { success: false, message: "RAG service URL not configured.", status: 'error', text: null, chunksForKg: [] };
    }

    const addDocumentUrl = `${pythonServiceUrl}/add_document`;
    console.log(`Calling Python RAG Service: ${addDocumentUrl} for document '${originalName}' (User: ${userId})`);
    try {
        const response = await axios.post(addDocumentUrl, {
            user_id: userId,
            file_path: filePath,
            original_name: originalName
        });
        
        const pythonData = response.data;
        const text = pythonData?.raw_text_for_analysis || null;
        const chunksForKg = pythonData?.chunks_with_metadata || [];
        const pythonStatus = pythonData?.status;
        const pythonMessage = pythonData?.message || "No specific message from Python RAG service.";

        // A successful outcome is one where we got text back.
        const isSuccess = !!(text && text.trim() !== "");

        return {
            success: isSuccess,
            status: pythonStatus,
            message: pythonMessage,
            text: text,
            chunksForKg: chunksForKg
        };

    } catch (error) {
        const errorMsg = error.response?.data?.error || error.response?.data?.message || error.message || "Unknown error calling Python RAG service";
        console.error(`Error calling Python RAG service for '${originalName}': ${errorMsg}`);
        return {
            success: false, message: `Python RAG service call failed: ${errorMsg}`,
            status: 'error_calling_python', text: null, chunksForKg: []
        };
    }
}

router.post('/', authMiddleware, (req, res) => {
    const uploader = upload.single('file');

    uploader(req, res, async function (err) {
        if (!req.user) {
            return res.status(401).json({ message: "Authentication error: User context not found." });
        }
        const userId = req.user._id.toString();
        const username = req.user.username;
        let absoluteFilePath = null, originalName = null, serverFilename = null;

        if (err) {
            console.error(`Upload Route: Multer error for user '${username}': ${err.message}`);
            return res.status(err instanceof multer.MulterError ? 400 : 500).json({ message: err.message });
        }
        if (!req.file) {
            return res.status(400).json({ message: "No file received or file type rejected by filter." });
        }

        absoluteFilePath = path.resolve(req.file.path);
        originalName = req.file.originalname;
        serverFilename = req.file.filename;
        console.log(`Upload Route: File received for user '${username}'. Server Filename: ${serverFilename}, Original: ${originalName}`);

        const userLlmPrefs = await User.findById(userId).select('preferredLlmProvider ollamaModel').lean();
        const llmProviderForWorkers = userLlmPrefs?.preferredLlmProvider || 'gemini';
        const ollamaModelForWorkers = userLlmPrefs?.ollamaModel || process.env.OLLAMA_DEFAULT_MODEL;

        try {
            const userForPreCheck = await User.findById(userId).select('uploadedDocuments.filename');
            if (!userForPreCheck) {
                await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Cleanup Error: ${e.message}`));
                return res.status(404).json({ message: "User not found, cannot process upload." });
            }
            if (userForPreCheck.uploadedDocuments.some(doc => doc.filename === originalName)) {
                await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Cleanup Error: ${e.message}`));
                return res.status(409).json({ message: `File '${originalName}' already exists.` });
            }

            const ragResult = await triggerPythonRagProcessing(userId, absoluteFilePath, originalName);

            // The critical check is whether the Python service returned any text.
            if (!ragResult.success) {
                const errorMessage = ragResult.message || "RAG processing failed to extract any text from the document.";
                console.error(`Upload Route Error for '${originalName}': ${errorMessage}`);
                if (absoluteFilePath) await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Cleanup Error: ${e.message}`));
                return res.status(422).json({ message: errorMessage, filename: serverFilename, originalname: originalName });
            }

            console.log(`Upload Route: RAG processing for '${originalName}' successful. Text obtained. Python Status: ${ragResult.status}.`);
            
            const newDocumentEntryData = {
                filename: originalName, text: ragResult.text,
                analysis: { faq: "", topics: "", mindmap: "" },
                uploadedAt: new Date(), ragStatus: ragResult.status,
                analysisStatus: "pending", kgStatus: "pending"
            };
            await User.updateOne({ _id: userId }, { $push: { uploadedDocuments: newDocumentEntryData } });
            
            res.status(202).json({
                message: `File '${originalName}' accepted. Background processing initiated.`,
                filename: serverFilename, originalname: originalName,
                initialStatus: { rag: ragResult.status, analysis: "pending", knowledgeGraph: "pending" }
            });

            // Offload Analysis and KG work
            const analysisWorkerPath = path.resolve(__dirname, '../workers/analysisWorker.js');
            const kgWorkerScriptPath = path.resolve(__dirname, '../workers/kgWorker.js');

            const analysisWorker = new Worker(analysisWorkerPath, { workerData: { userId, originalName, textForAnalysis: ragResult.text, llmProvider: llmProviderForWorkers, ollamaModel: ollamaModelForWorkers } });
            analysisWorker.on('message', (msg) => console.log(`[BG] Analysis Worker [Doc: ${msg.originalName || originalName}]: ${msg.message || JSON.stringify(msg)}`));
            analysisWorker.on('error', (err) => console.error(`[BG] Analysis Worker Error [Doc: ${originalName}]:`, err));
            analysisWorker.on('exit', (code) => console.log(`[BG] Analysis Worker [Doc: ${originalName}] exited (code ${code}).`));

            if (ragResult.chunksForKg && ragResult.chunksForKg.length > 0) {
                const kgWorker = new Worker(kgWorkerScriptPath, { workerData: { chunksForKg: ragResult.chunksForKg, userId, originalName, llmProvider: llmProviderForWorkers, ollamaModel: ollamaModelForWorkers } });
                kgWorker.on('message', (msg) => console.log(`[BG] KG Worker [Doc: ${msg.originalName || originalName}]: ${msg.message || JSON.stringify(msg)}`));
                kgWorker.on('error', (err) => console.error(`[BG] KG Worker Error [Doc: ${originalName}]:`, err));
                kgWorker.on('exit', (code) => console.log(`[BG] KG Worker [Doc: ${originalName}] exited (code ${code}).`));
            } else {
                await User.updateOne({ _id: userId, "uploadedDocuments.filename": originalName }, { $set: { "uploadedDocuments.$.kgStatus": "skipped_no_chunks" } });
            }

            if (absoluteFilePath) {
                await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`[BG] Non-critical: Failed to delete temp file ${absoluteFilePath}: ${e.message}`));
            }

        } catch (processError) {
            console.error(`Upload Route: !!! Overall processing error for ${originalName || 'unknown file'}:`, processError);
            if (absoluteFilePath) await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Cleanup Error: ${e.message}`));
            if (!res.headersSent) {
                res.status(500).json({ message: `Server error during file processing: ${processError.message}` });
            }
        }
    }); 
});

module.exports = router;
```

`routes/user.js`

```javascript
// server/routes/user.js
const express = require('express');
const router = express.Router();
const User = require('../models/User');

// Note: The main 'authMiddleware' will be applied in server.js before this router is used,
// so we don't need to add it to each route here. req.user will be available.

// @route   GET /api/user/profile
// @desc    Get the current user's profile data
// @access  Private
router.get('/profile', async (req, res) => {
    try {
        const user = await User.findById(req.user._id).select('profile');
        if (!user) {
            return res.status(404).json({ message: 'User not found.' });
        }
        // Return the profile object, or an empty object if it doesn't exist
        res.json(user.profile || {});
    } catch (error) {
        console.error('Error fetching user profile:', error);
        res.status(500).json({ message: 'Server error while fetching profile.' });
    }
});

// @route   PUT /api/user/profile
// @desc    Update the current user's profile data
// @access  Private
router.put('/profile', async (req, res) => {
    const { name, college, universityNumber, degreeType, branch, year } = req.body;

    // Basic backend validation
    if (!name || !college || !universityNumber || !degreeType || !branch || !year) {
        return res.status(400).json({ message: 'All profile fields are required.' });
    }

    try {
        const user = await User.findById(req.user._id);
        if (!user) {
            return res.status(404).json({ message: 'User not found.' });
        }

        // Update the profile sub-document
        user.profile = {
            name,
            college,
            universityNumber,
            degreeType,
            branch,
            year
        };

        await user.save();

        res.json({
            message: 'Profile updated successfully!',
            profile: user.profile
        });

    } catch (error) {
        console.error('Error updating user profile:', error);
        res.status(500).json({ message: 'Server error while updating profile.' });
    }
});

module.exports = router;
```

`server.js`

```javascript
// // server/server.js
// const express = require('express');
// const dotenv = require('dotenv');
// const cors = require('cors');
// const path = require('path');
// const fs = require('fs');
// const axios = require('axios');
// const os = require('os');
// const mongoose = require('mongoose');
// const readline = require('readline').createInterface({
//   input: process.stdin,
//   output: process.stdout,
// });

// // --- Custom Modules & Middleware ---
// const connectDB = require('./config/db');
// const { getLocalIPs } = require('./utils/networkUtils');
// const { performAssetCleanup } = require('./utils/assetCleanup');
// const { authMiddleware } = require('./middleware/authMiddleware');
// const { fixedAdminAuthMiddleware } = require('./middleware/fixedAdminAuthMiddleware'); 

// // --- Route Imports ---
// const networkRoutes = require('./routes/network');
// const authRoutes = require('./routes/auth');
// const userRoutes = require('./routes/user');
// const chatRoutes = require('./routes/chat');
// const uploadRoutes = require('./routes/upload');
// const filesRoutes = require('./routes/files');
// const syllabusRoutes = require('./routes/syllabus');
// const mindmapRoutes = require('./routes/mindmap');
// const analysisRoutes = require('./routes/analysis');
// const adminDocsRoutes = require('./routes/adminDocuments');
// const subjectsRoutes = require('./routes/subjects');


// // --- Configuration Loading ---
// dotenv.config(); // Load environment variables

// // --- Configuration Defaults & Variables ---
// const DEFAULT_PORT = 5001;
// const DEFAULT_MONGO_URI = 'mongodb://localhost:27017/chatbotGeminiDB';
// const DEFAULT_PYTHON_RAG_URL = 'http://localhost:5000';

// let port = process.env.PORT || DEFAULT_PORT;
// let mongoUri = process.env.MONGO_URI || '';
// let pythonRagUrl = process.env.PYTHON_RAG_SERVICE_URL || '';
// let geminiApiKey = process.env.GEMINI_API_KEY || '';

// // Ensure JWT_SECRET is loaded and available
// if (!process.env.JWT_SECRET) {
//     console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
//     console.error("!!! FATAL: JWT_SECRET environment variable is not set.       !!!");
//     console.error("!!! Please set it in your .env file before running:        !!!");
//     console.error("!!! JWT_SECRET='your_super_strong_and_secret_jwt_key'      !!!");
//     console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
//     process.exit(1);
// }

// // --- Express Application Setup ---
// const app = express();

// // --- Core Middleware ---
// app.use(cors());
// app.use(express.json());

// // --- Basic Root Route ---
// app.get('/', (req, res) => res.send('Chatbot Backend API is running...'));

// // --- API Route Mounting ---
// // Public routes
// app.use('/api/network', networkRoutes);
// app.use('/api/auth', authRoutes);

// // Protected routes (authMiddleware applied)
// app.use('/api/user', authMiddleware, userRoutes);
// app.use('/api/chat', authMiddleware, chatRoutes);
// app.use('/api/upload', authMiddleware, uploadRoutes);
// app.use('/api/files', authMiddleware, filesRoutes);
// app.use('/api/syllabus', authMiddleware, syllabusRoutes);
// app.use('/api/mindmap', authMiddleware, mindmapRoutes);
// app.use('/api/analysis', authMiddleware, analysisRoutes);
// app.use('/api/subjects', authMiddleware, subjectsRoutes);

// // Admin routes (uses its own middleware)
// app.use('/api/admin/documents', adminDocsRoutes);


// // --- Centralized Error Handling Middleware ---
// app.use((err, req, res, next) => {
//     console.error("Unhandled Error:", err.stack || err);
//     const statusCode = err.status || 500;
//     let message = err.message || 'An internal server error occurred.';
//     if (process.env.NODE_ENV === 'production' && statusCode === 500) {
//         message = 'An internal server error occurred.';
//     }
//     if (req.originalUrl.startsWith('/api/')) {
//          return res.status(statusCode).json({ message: message });
//     }
//     // Fallback for non-API routes if any
//     res.status(statusCode).send(message);
// });

// // --- Server Instance Variable ---
// let server;

// // --- Graceful Shutdown Logic ---
// const gracefulShutdown = async (signal) => {
//     console.log(`\n${signal} received. Shutting down gracefully...`);
//     readline.close();
//     try {
//         if (server) {
//             server.close(async () => {
//                 console.log('HTTP server closed.');
//                 try {
//                     await mongoose.connection.close();
//                     console.log('MongoDB connection closed.');
//                 } catch (dbCloseError) {
//                     console.error("Error closing MongoDB connection:", dbCloseError);
//                 }
//                 process.exit(0);
//             });
//         } else {
//              try {
//                  await mongoose.connection.close();
//                  console.log('MongoDB connection closed (no HTTP server instance).');
//              } catch (dbCloseError) {
//                  console.error("Error closing MongoDB connection:", dbCloseError);
//              }
//             process.exit(0);
//         }

//         setTimeout(() => {
//             console.error('Graceful shutdown timed out, forcing exit.');
//             process.exit(1);
//         }, 10000);

//     } catch (shutdownError) {
//         console.error("Error during graceful shutdown initiation:", shutdownError);
//         process.exit(1);
//     }
// };

// process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
// process.on('SIGINT', () => gracefulShutdown('SIGINT'));

// // --- RAG Service Health Check ---
// async function checkRagService(url) {
//     console.log(`\nChecking RAG service health at ${url}...`);
//     try {
//         const response = await axios.get(`${url}/health`, { timeout: 7000 });
//         if (response.status === 200 && response.data?.status === 'ok') {
//             console.log(' Python RAG service is available and healthy.');
//             const neo4jStatus = response.data?.neo4j_connection || 'unknown';
//             const qdrantStatus = response.data?.qdrant_collection_status || 'unknown';
//             const embeddingModel = response.data?.document_embedding_model || 'N/A';
            
//             console.log(`  Embedding Model: ${embeddingModel}`);
//             console.log(`  Qdrant Status: ${qdrantStatus}`);
//             console.log(`  Neo4j Status: ${neo4jStatus}`);

//             if (response.data.message && response.data.message.includes("Warning:")) {
//                  console.warn(`  RAG Health Warning: ${response.data.message}`);
//             }
//             return true;
//         } else {
//              console.warn(`! Python RAG service responded but status is not OK: ${response.status} - ${JSON.stringify(response.data)}`);
//              return false;
//         }
//     } catch (error) {
//         console.warn('! Python RAG service is not reachable.');
//         if (error.code === 'ECONNREFUSED') {
//              console.warn(`  Connection refused at ${url}. Ensure the Python RAG service (e.g., server/rag_service/app.py) is running.`);
//         } else if (error.code === 'ECONNABORTED' || error.message.includes('timeout')) {
//              console.warn(`  Connection timed out to ${url}. The Python RAG service might be slow to start or unresponsive.`);
//         } else {
//              console.warn(`  Error connecting to Python RAG Service: ${error.message}`);
//         }
//         console.warn('  RAG-dependent features (document upload processing, context retrieval) will be unavailable.');
//         return false;
//     }
// }

// // --- Directory Structure Check ---
// async function ensureServerDirectories() {
//     const dirs = [
//         path.join(__dirname, 'assets'),
//         path.join(__dirname, 'backup_assets'),
//         path.join(__dirname, 'syllabi')
//     ];
//     console.log("\nEnsuring server directories exist...");
//     try {
//         for (const dir of dirs) {
//             if (!fs.existsSync(dir)) {
//                 await fs.promises.mkdir(dir, { recursive: true });
//                 console.log(`  Created directory: ${dir}`);
//             }
//         }
//         console.log(" Server directories checked/created.");
//     } catch (error) {
//         console.error('!!! Error creating essential server directories:', error);
//         throw error;
//     }
// }

// // --- Prompt for Configuration ---
// function askQuestion(query) {
//     return new Promise(resolve => readline.question(query, resolve));
// }

// async function configureAndStart() {
//     console.log("--- Starting Server Configuration ---");
    
//     if (!geminiApiKey) {
//         console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
//         console.error("!!! FATAL: GEMINI_API_KEY environment variable is not set. !!!");
//         console.error("!!! Please set it before running the server:               !!!");
//         console.error("!!! export GEMINI_API_KEY='YOUR_API_KEY'                   !!!");
//         console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
//         process.exit(1);
//     } else {
//         console.log(" GEMINI_API_KEY found.");
//     }

//     if (!mongoUri) {
//         const answer = await askQuestion(`Enter MongoDB URI or press Enter for default (${DEFAULT_MONGO_URI}): `);
//         mongoUri = answer.trim() || DEFAULT_MONGO_URI;
//     }
//     console.log(`Using MongoDB URI: ${mongoUri}`);

//     if (!pythonRagUrl) {
//         const answer = await askQuestion(`Enter Python RAG Service URL or press Enter for default (${DEFAULT_PYTHON_RAG_URL}): `);
//         pythonRagUrl = answer.trim() || DEFAULT_PYTHON_RAG_URL;
//     }
//     console.log(`Using Python RAG Service URL: ${pythonRagUrl}`);
//     console.log(`Node.js server will listen on port: ${port}`);
//     readline.close();

//     process.env.MONGO_URI = mongoUri;
//     process.env.PYTHON_RAG_SERVICE_URL = pythonRagUrl;

//     console.log("--- Configuration Complete ---");
//     await startServer();
// }

// // --- Asynchronous Server Startup Function ---
// async function startServer() {
//     console.log("\n--- Starting Server Initialization ---");
//     try {
//         await ensureServerDirectories();
//         await connectDB(mongoUri); 
//         await performAssetCleanup(); 
//         await checkRagService(pythonRagUrl);

//         const PORT = port;
//         const availableIPs = getLocalIPs();

//         server = app.listen(PORT, '0.0.0.0', () => {
//             console.log('\n=== Node.js Server Ready ===');
//             console.log(` Server listening on port ${PORT}`);
//             console.log('   Access the application via these URLs (using common frontend ports):');
//             const frontendPorts = [3000, 3001, 8080, 5173]; 
//             availableIPs.forEach(ip => {
//                  frontendPorts.forEach(fp => {
//                     console.log(`   - http://${ip}:${fp} (Frontend) -> Connects to Backend at http://${ip}:${PORT}`);
//                  });
//             });
//             console.log('============================\n');
//             console.log(" Hint: Client automatically detects backend IP based on how you access the frontend.");
//             console.log(`   Ensure firewalls allow connections on port ${PORT} (Backend) and your frontend port.`);
//             console.log("--- Server Initialization Complete ---");
//         });

//     } catch (error) {
//         console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
//         console.error("!!! Failed to start Node.js server:", error.message);
//         console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
//         process.exit(1);
//     }
// }

// // --- Execute Configuration and Server Start ---
// configureAndStart();










// server/server.js
const express = require('express');
const dotenv = require('dotenv');
const cors = require('cors');
const path = require('path');
const fs = require('fs');
const axios = require('axios');
const os = require('os');
const mongoose = require('mongoose');
const readline = require('readline').createInterface({
  input: process.stdin,
  output: process.stdout,
});

// --- Custom Modules & Middleware (Corrected Paths) ---
const connectDB = require('./config/db');
const { getLocalIPs } = require('./utils/networkUtils');
const { performAssetCleanup } = require('./utils/assetCleanup');
const { authMiddleware } = require('./middleware/authMiddleware');
const { fixedAdminAuthMiddleware } = require('./middleware/fixedAdminAuthMiddleware'); 

// --- Route Imports ---
const networkRoutes = require('./routes/network');
const authRoutes = require('./routes/auth');
const userRoutes = require('./routes/user');
const chatRoutes = require('./routes/chat');
const uploadRoutes = require('./routes/upload');
const filesRoutes = require('./routes/files');
const syllabusRoutes = require('./routes/syllabus');
const mindmapRoutes = require('./routes/mindmap');
const analysisRoutes = require('./routes/analysis');
const adminDocsRoutes = require('./routes/adminDocuments');
const subjectsRoutes = require('./routes/subjects');
const generationRoutes = require('./routes/generation');

// --- Configuration Loading ---
dotenv.config();

// --- Configuration Defaults & Variables ---
const DEFAULT_PORT = 5001;
const DEFAULT_MONGO_URI = 'mongodb://localhost:27017/chatbotGeminiDB';
const DEFAULT_PYTHON_RAG_URL = 'http://localhost:5000';

let port = process.env.PORT || DEFAULT_PORT;
let mongoUri = process.env.MONGO_URI || '';
let pythonRagUrl = process.env.PYTHON_RAG_SERVICE_URL || '';
let geminiApiKey = process.env.GEMINI_API_KEY || '';

if (!process.env.JWT_SECRET) {
    console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
    console.error("!!! FATAL: JWT_SECRET environment variable is not set.       !!!");
    console.error("!!! Please set it in your .env file before running:        !!!");
    console.error("!!! JWT_SECRET='your_super_strong_and_secret_jwt_key'      !!!");
    console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
    process.exit(1);
}

// --- Express Application Setup ---
const app = express();
app.use(cors());
app.use(express.json());

// --- Basic Root Route ---
app.get('/', (req, res) => res.send('Chatbot Backend API is running...'));

// --- API Route Mounting ---
// Public routes
app.use('/api/network', networkRoutes);
app.use('/api/auth', authRoutes);

// Protected routes (authMiddleware applied)
app.use('/api/user', authMiddleware, userRoutes);
app.use('/api/chat', authMiddleware, chatRoutes);
app.use('/api/upload', authMiddleware, uploadRoutes);
app.use('/api/files', authMiddleware, filesRoutes);
app.use('/api/syllabus', authMiddleware, syllabusRoutes);
app.use('/api/mindmap', authMiddleware, mindmapRoutes);
app.use('/api/analysis', authMiddleware, analysisRoutes);
app.use('/api/subjects', authMiddleware, subjectsRoutes);
app.use('/api/generate', authMiddleware, generationRoutes);

// Admin routes (uses its own middleware)
app.use('/api/admin/documents', adminDocsRoutes);


// --- Centralized Error Handling Middleware ---
app.use((err, req, res, next) => {
    console.error("Unhandled Error:", err.stack || err);
    const statusCode = err.status || 500;
    let message = err.message || 'An internal server error occurred.';
    if (process.env.NODE_ENV === 'production' && statusCode === 500) {
        message = 'An internal server error occurred.';
    }
    if (req.originalUrl.startsWith('/api/')) {
         return res.status(statusCode).json({ message: message });
    }
    res.status(statusCode).send(message);
});

// --- Server Instance Variable ---
let server;

// --- Graceful Shutdown Logic ---
const gracefulShutdown = async (signal) => {
    console.log(`\n${signal} received. Shutting down gracefully...`);
    readline.close();
    try {
        if (server) {
            server.close(async () => {
                console.log('HTTP server closed.');
                try {
                    await mongoose.connection.close();
                    console.log('MongoDB connection closed.');
                } catch (dbCloseError) {
                    console.error("Error closing MongoDB connection:", dbCloseError);
                }
                process.exit(0);
            });
        } else {
             try {
                 await mongoose.connection.close();
                 console.log('MongoDB connection closed (no HTTP server instance).');
             } catch (dbCloseError) {
                 console.error("Error closing MongoDB connection:", dbCloseError);
             }
            process.exit(0);
        }

        setTimeout(() => {
            console.error('Graceful shutdown timed out, forcing exit.');
            process.exit(1);
        }, 10000);

    } catch (shutdownError) {
        console.error("Error during graceful shutdown initiation:", shutdownError);
        process.exit(1);
    }
};

process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
process.on('SIGINT', () => gracefulShutdown('SIGINT'));

// --- RAG Service Health Check ---
async function checkRagService(url) {
    console.log(`\nChecking RAG service health at ${url}...`);
    try {
        const response = await axios.get(`${url}/health`, { timeout: 7000 });
        if (response.status === 200 && response.data?.status === 'ok') {
            console.log(' Python RAG service is available and healthy.');
            const neo4jStatus = response.data?.neo4j_connection || 'unknown';
            const qdrantStatus = response.data?.qdrant_collection_status || 'unknown';
            const embeddingModel = response.data?.document_embedding_model || 'N/A';
            
            console.log(`  Embedding Model: ${embeddingModel}`);
            console.log(`  Qdrant Status: ${qdrantStatus}`);
            console.log(`  Neo4j Status: ${neo4jStatus}`);

            if (response.data.message && response.data.message.includes("Warning:")) {
                 console.warn(`  RAG Health Warning: ${response.data.message}`);
            }
            return true;
        } else {
             console.warn(`! Python RAG service responded but status is not OK: ${response.status} - ${JSON.stringify(response.data)}`);
             return false;
        }
    } catch (error) {
        console.warn('! Python RAG service is not reachable.');
        if (error.code === 'ECONNREFUSED') {
             console.warn(`  Connection refused at ${url}. Ensure the Python RAG service (e.g., server/rag_service/app.py) is running.`);
        } else if (error.code === 'ECONNABORTED' || error.message.includes('timeout')) {
             console.warn(`  Connection timed out to ${url}. The Python RAG service might be slow to start or unresponsive.`);
        } else {
             console.warn(`  Error connecting to Python RAG Service: ${error.message}`);
        }
        console.warn('  RAG-dependent features (document upload processing, context retrieval) will be unavailable.');
        return false;
    }
}

// --- Directory Structure Check ---
async function ensureServerDirectories() {
    const dirs = [
        path.join(__dirname, 'assets'),
        path.join(__dirname, 'backup_assets'),
        path.join(__dirname, 'syllabi')
    ];
    console.log("\nEnsuring server directories exist...");
    try {
        for (const dir of dirs) {
            if (!fs.existsSync(dir)) {
                await fs.promises.mkdir(dir, { recursive: true });
                console.log(`  Created directory: ${dir}`);
            }
        }
        console.log(" Server directories checked/created.");
    } catch (error) {
        console.error('!!! Error creating essential server directories:', error);
        throw error;
    }
}

// --- Prompt for Configuration ---
function askQuestion(query) {
    return new Promise(resolve => readline.question(query, resolve));
}

async function configureAndStart() {
    console.log("--- Starting Server Configuration ---");
    
    if (!geminiApiKey) {
        console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
        console.error("!!! FATAL: GEMINI_API_KEY environment variable is not set. !!!");
        console.error("!!! Please set it before running the server:               !!!");
        console.error("!!! export GEMINI_API_KEY='YOUR_API_KEY'                   !!!");
        console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
        process.exit(1);
    } else {
        console.log(" GEMINI_API_KEY found.");
    }

    if (!mongoUri) {
        const answer = await askQuestion(`Enter MongoDB URI or press Enter for default (${DEFAULT_MONGO_URI}): `);
        mongoUri = answer.trim() || DEFAULT_MONGO_URI;
    }
    console.log(`Using MongoDB URI: ${mongoUri}`);

    if (!pythonRagUrl) {
        const answer = await askQuestion(`Enter Python RAG Service URL or press Enter for default (${DEFAULT_PYTHON_RAG_URL}): `);
        pythonRagUrl = answer.trim() || DEFAULT_PYTHON_RAG_URL;
    }
    console.log(`Using Python RAG Service URL: ${pythonRagUrl}`);
    console.log(`Node.js server will listen on port: ${port}`);
    readline.close();

    process.env.MONGO_URI = mongoUri;
    process.env.PYTHON_RAG_SERVICE_URL = pythonRagUrl;

    console.log("--- Configuration Complete ---");
    await startServer();
}

// --- Asynchronous Server Startup Function ---
async function startServer() {
    console.log("\n--- Starting Server Initialization ---");
    try {
        await ensureServerDirectories();
        await connectDB(mongoUri); 
        await performAssetCleanup(); 
        await checkRagService(pythonRagUrl);

        const PORT = port;
        const availableIPs = getLocalIPs();

        server = app.listen(PORT, '0.0.0.0', () => {
            console.log('\n=== Node.js Server Ready ===');
            console.log(` Server listening on port ${PORT}`);
            console.log('   Access the application via these URLs (using common frontend ports):');
            const frontendPorts = [3000, 3001, 8080, 5173]; 
            availableIPs.forEach(ip => {
                 frontendPorts.forEach(fp => {
                    console.log(`   - http://${ip}:${fp} (Frontend) -> Connects to Backend at http://${ip}:${PORT}`);
                 });
            });
            console.log('============================\n');
            console.log(" Hint: Client automatically detects backend IP based on how you access the frontend.");
            console.log(`   Ensure firewalls allow connections on port ${PORT} (Backend) and your frontend port.`);
            console.log("--- Server Initialization Complete ---");
        });

    } catch (error) {
        console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
        console.error("!!! Failed to start Node.js server:", error.message);
        console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
        process.exit(1);
    }
}

// --- Execute Configuration and Server Start ---
configureAndStart();
```

`services/adminDocuments.js`

```javascript
// server/routes/adminDocuments.js
const express = require('express');
const multer = require('multer');
const path = require('path');
const fs = require('fs'); // Using Node.js fs for directory creation and file ops
const fsPromises = fs.promises; // For async file operations
const AdminDocument = require('../models/AdminDocument');
const { fixedAdminAuthMiddleware } = require('../middleware/fixedAdminAuthMiddleware');
const axios = require('axios'); // For calling Python RAG service

const router = express.Router();

// --- Constants for Admin Uploads ---
const ADMIN_UPLOAD_DIR_BASE = path.join(__dirname, '..', 'assets', '_admin_uploads_');
const MAX_FILE_SIZE = 20 * 1024 * 1024; // 20 MB

// Allowed types for admin uploads
const allowedAdminMimeTypes = {
    'application/pdf': 'docs',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document': 'docs', // docx
    'text/plain': 'docs', // txt
    'text/markdown': 'docs', // md
    // Add more as needed for admin
};
const allowedAdminExtensions = ['.pdf', '.docx', '.txt', '.md'];

// --- Multer Config for Admin Uploads ---
const adminStorage = multer.diskStorage({
    destination: (req, file, cb) => {
        const fileMimeType = file.mimetype.toLowerCase();
        const fileTypeSubfolder = allowedAdminMimeTypes[fileMimeType] || 'others'; // Default to 'others'
        const destinationPath = path.join(ADMIN_UPLOAD_DIR_BASE, fileTypeSubfolder);

        fs.mkdir(destinationPath, { recursive: true }, (err) => {
            if (err) {
                console.error(`Admin Upload Multer: Error creating destination path ${destinationPath}:`, err);
                return cb(err);
            }
            cb(null, destinationPath);
        });
    },
    filename: (req, file, cb) => {
        const timestamp = Date.now();
        const fileExt = path.extname(file.originalname).toLowerCase();
        const sanitizedBaseName = path.basename(file.originalname, fileExt)
            .replace(/[^a-zA-Z0-9._-]/g, '_')
            .substring(0, 100); // Limit base name length
        const uniqueFilename = `${timestamp}-${sanitizedBaseName}${fileExt}`;
        cb(null, uniqueFilename);
    }
});

const adminFileFilter = (req, file, cb) => {
    const fileExt = path.extname(file.originalname).toLowerCase();
    const mimeType = file.mimetype.toLowerCase();

    const isMimeTypeAllowed = !!allowedAdminMimeTypes[mimeType];
    const isExtensionAllowed = allowedAdminExtensions.includes(fileExt);

    if (isMimeTypeAllowed && isExtensionAllowed) {
        cb(null, true);
    } else {
        console.warn(`Admin Upload Rejected (Filter): File='${file.originalname}', MIME='${mimeType}', Ext='${fileExt}'.`);
        const error = new multer.MulterError('LIMIT_UNEXPECTED_FILE_TYPE_ADMIN');
        error.message = `Invalid file type or extension for admin upload. Allowed: ${allowedAdminExtensions.join(', ')}`;
        cb(error, false);
    }
};

const adminUpload = multer({
    storage: adminStorage,
    fileFilter: adminFileFilter,
    limits: { fileSize: MAX_FILE_SIZE }
});

// --- Helper to call Python RAG service for Admin Docs (Text Extraction Only) ---
async function triggerPythonTextExtractionForAdmin(filePath, originalName) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
    if (!pythonServiceUrl) {
        console.error("ADMIN RAG: PYTHON_RAG_SERVICE_URL not set. Cannot extract text.");
        return { success: false, message: "Python service URL not configured for text extraction.", text: null };
    }
    const addDocumentUrl = `${pythonServiceUrl}/add_document`;
    console.log(`ADMIN RAG: Calling Python Service: ${addDocumentUrl} for text extraction of '${originalName}'`);

    try {
        // For admin docs, we pass a generic user_id or a specific marker.
        // The Python service might try to add to Qdrant/Neo4j with this ID.
        // If admin docs are NOT to be in the main Qdrant/Neo4j, the Python service
        // would ideally have a flag to skip DB insertions for certain user_ids/contexts.
        // For now, Node.js only cares about the returned text.
        const response = await axios.post(addDocumentUrl, {
            user_id: "fixed_admin_text_extraction_user", // A distinct ID for Python's logging/potential filtering
            file_path: filePath,
            original_name: originalName
        }, { timeout: 300000 }); // 5 min timeout

        const pythonData = response.data;
        const text = pythonData?.raw_text_for_analysis || null;

        if (text) {
            console.log(`ADMIN RAG: Text extracted successfully for '${originalName}'. Length: ${text.length}`);
            return { success: true, message: "Text extracted.", text: text };
        } else {
            console.warn(`ADMIN RAG: Python service returned no text for '${originalName}'. Status: ${pythonData?.status}, Message: ${pythonData?.message}`);
            return { success: false, message: pythonData?.message || "Python service extracted no text.", text: null };
        }
    } catch (error) {
        const errorMsg = error.response?.data?.error || error.response?.data?.message || error.message || "Unknown error calling Python RAG for text extraction.";
        console.error(`ADMIN RAG: Error calling Python service for '${originalName}': ${errorMsg}`);
        return { success: false, message: `Python RAG call failed: ${errorMsg}`, text: null };
    }
}


// --- Admin Document Routes ---

// @route   POST /api/admin/documents/upload
// @desc    Upload a document for the admin, extract text, and initiate analysis.
// @access  Admin Only (via fixedAdminAuthMiddleware)
router.post('/upload', fixedAdminAuthMiddleware, adminUpload.single('file'), async (req, res) => {
    if (!req.file) {
        return res.status(400).json({ message: 'No file uploaded or file type rejected.' });
    }

    const { filename: serverFilename, originalname: originalName, path: tempServerPath } = req.file;
    let adminDocRecord;

    try {
        // 1. Check for existing document with the same originalName
        const existingDoc = await AdminDocument.findOne({ originalName: originalName });
        if (existingDoc) {
            await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Error deleting duplicate temp file ${tempServerPath}:`, e));
            return res.status(409).json({ message: `Document with original name '${originalName}' already exists for admin.` });
        }

        // 2. Extract text using Python RAG service
        console.log(`Admin Upload: Attempting text extraction for '${originalName}' from ${tempServerPath}`);
        const textExtractionResult = await triggerPythonTextExtractionForAdmin(tempServerPath, originalName);

        if (!textExtractionResult.success || !textExtractionResult.text || textExtractionResult.text.trim() === "") {
            await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Error deleting temp file ${tempServerPath} after failed text extraction:`, e));
            return res.status(422).json({ // Unprocessable Entity
                message: textExtractionResult.message || "Failed to extract usable text from the document.",
                filename: serverFilename,
                originalname: originalName
            });
        }
        console.log(`Admin Upload: Text extracted for '${originalName}'. Proceeding to save and analyze.`);

        // 3. Save initial AdminDocument record
        adminDocRecord = new AdminDocument({
            filename: serverFilename,
            originalName: originalName,
            text: textExtractionResult.text,
            // serverPath and fileTypeSubfolder are not in the simplified model.
            // If we decide to keep the file, we'd need to move it from tempServerPath
            // to a final location and store that path. For now, assume tempServerPath is cleaned up.
            analysis: { faq: "", topics: "", mindmap: "" }, // Initialize analysis
            analysisUpdatedAt: null,
        });
        await adminDocRecord.save();
        console.log(`Admin Upload: Initial DB record saved for '${originalName}' (Server: ${serverFilename}).`);

        // 4. Delete the temporary file uploaded by multer as text is now in DB
        // If you decide to keep the physical file, this step would be a move operation instead.
        await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Non-critical error deleting temp file ${tempServerPath} after DB save:`, e));


        // 5. Respond to client (202 Accepted) & Trigger Background Analysis
        res.status(202).json({
            message: `Admin document '${originalName}' uploaded. Text extracted. Analysis initiated.`,
            filename: serverFilename,
            originalname: originalName,
        });
        console.log(`Admin Upload: Sent 202 Accepted for '${originalName}'. Offloading analysis.`);

        // --- Trigger Background Analysis Worker ---
        // This requires an 'adminAnalysisWorker.js'
        const { Worker } = require('worker_threads');
        const adminAnalysisWorkerPath = path.resolve(__dirname, '..', 'workers', 'adminAnalysisWorker.js');
        
        try {
            if (fs.existsSync(adminAnalysisWorkerPath)) { // Check if worker file exists
                const worker = new Worker(adminAnalysisWorkerPath, {
                    workerData: {
                        adminDocumentId: adminDocRecord._id.toString(), // Pass ID to update the specific doc
                        originalName: originalName,
                        textForAnalysis: textExtractionResult.text
                    }
                });
                worker.on('message', (msg) => console.log(`Admin Analysis Worker [Doc: ${msg.originalName || originalName}]: ${msg.message || JSON.stringify(msg)}`));
                worker.on('error', (err) => console.error(`Admin Analysis Worker Error [Doc: ${originalName}]:`, err));
                worker.on('exit', (code) => console.log(`Admin Analysis Worker [Doc: ${originalName}] exited (code ${code}).`));
            } else {
                console.error(`Admin Upload: adminAnalysisWorker.js not found at ${adminAnalysisWorkerPath}. Analysis cannot be started.`);
                // Optionally update the AdminDocument status to 'analysis_launch_failed'
            }
        } catch (workerError) {
            console.error(`Admin Upload: Error launching Admin Analysis Worker for '${originalName}':`, workerError);
        }

    } catch (error) {
        console.error(`Admin Upload: Overall error for '${originalName || (req.file && req.file.originalname)}':`, error);
        if (tempServerPath) { // If path is known, try to clean up temp file
            await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Error cleaning up temp file ${tempServerPath} after overall error:`, e));
        }
        if (!res.headersSent) {
            if (error.code === 11000) { // MongoDB duplicate key
                 res.status(409).json({ message: 'Document processing conflict (e.g., duplicate server filename). Please try again.' });
            } else {
                 res.status(500).json({ message: 'Server error during admin document upload processing.' });
            }
        }
    }
});

// @route   GET /api/admin/documents
// @desc    Get list of documents uploaded by the admin
// @access  Admin Only (via fixedAdminAuthMiddleware)
router.get('/', fixedAdminAuthMiddleware, async (req, res) => {
    try {
        // Fetching fields relevant for listing and identifying documents.
        // Exclude 'text' and full 'analysis' objects by default to keep payload small.
        const adminDocs = await AdminDocument.find()
            .sort({ uploadedAt: -1 })
            .select('originalName filename uploadedAt analysisUpdatedAt analysis.faq analysis.topics analysis.mindmap'); // Select specific fields

        const documentsList = adminDocs.map(doc => ({
            originalName: doc.originalName,
            serverFilename: doc.filename, // Useful if frontend needs to make further requests (e.g., delete)
            uploadedAt: doc.uploadedAt,
            analysisUpdatedAt: doc.analysisUpdatedAt,
            hasFaq: !!(doc.analysis && doc.analysis.faq && doc.analysis.faq.trim() !== ""),
            hasTopics: !!(doc.analysis && doc.analysis.topics && doc.analysis.topics.trim() !== ""),
            hasMindmap: !!(doc.analysis && doc.analysis.mindmap && doc.analysis.mindmap.trim() !== ""),
        }));

        // For frontend compatibility with existing DocumentList component,
        // it might expect an array of strings (originalName).
        // If so, change `res.json({ documents: documentsList });` to
        // `res.json({ filenames: documentsList.map(d => d.originalName) });`
        // However, sending more info like `documentsList` is generally more useful.
        res.json({ documents: documentsList });

    } catch (error) {
        console.error('Admin List Documents Error:', error);
        res.status(500).json({ message: 'Server error fetching admin documents.' });
    }
});

// @route   DELETE /api/admin/documents/:serverFilename
// @desc    Delete a document uploaded by the admin (DB record only for simplified model)
// @access  Admin Only (via fixedAdminAuthMiddleware)
router.delete('/:serverFilename', fixedAdminAuthMiddleware, async (req, res) => {
    const { serverFilename } = req.params;

    if (!serverFilename) {
        return res.status(400).json({ message: 'Server filename parameter is required for deletion.' });
    }

    try {
        const docToDelete = await AdminDocument.findOneAndDelete({ filename: serverFilename });

        if (!docToDelete) {
            return res.status(404).json({ message: `Admin document with server name '${serverFilename}' not found.` });
        }

        console.log(`Admin Delete: Document record '${docToDelete.originalName}' (Server: ${serverFilename}) deleted from MongoDB.`);
        
        // Since we are not storing serverPath in the simplified model and deleting temp files after text extraction,
        // there's no physical file to delete from 'assets/_admin_uploads_' based on DB record alone at this stage.
        // If, in the future, you decide to *keep* admin-uploaded files, you'd add file deletion logic here
        // and would need to store `serverPath` in AdminDocument model.

        // TODO (Future): If admin documents were processed by Qdrant/Neo4j,
        // trigger deletion from those services here.

        res.status(200).json({ message: `Admin document '${docToDelete.originalName}' record deleted successfully.` });

    } catch (error) {
        console.error(`Admin Delete Error for serverFilename '${serverFilename}':`, error);
        res.status(500).json({ message: 'Server error during admin document deletion.' });
    }
});


// @route   GET /api/admin/documents/:serverFilename/analysis
// @desc    Get analysis data for a specific admin document
// @access  Admin Only
router.get('/:serverFilename/analysis', fixedAdminAuthMiddleware, async (req, res) => {
    const { serverFilename } = req.params;
    if (!serverFilename) {
        return res.status(400).json({ message: 'Server filename parameter is required.' });
    }

    try {
        const adminDoc = await AdminDocument.findOne({ filename: serverFilename }).select('originalName analysis analysisUpdatedAt');
        if (!adminDoc) {
            return res.status(404).json({ message: `Admin document '${serverFilename}' not found.` });
        }
        if (!adminDoc.analysis || 
            (!adminDoc.analysis.faq && !adminDoc.analysis.topics && !adminDoc.analysis.mindmap)) {
            return res.status(200).json({ 
                originalName: adminDoc.originalName,
                message: 'Analysis has not been generated or is empty for this document.',
                analysis: { faq: "", topics: "", mindmap: "" }, // Return empty structure
                analysisUpdatedAt: adminDoc.analysisUpdatedAt
            });
        }
        res.status(200).json({
            originalName: adminDoc.originalName,
            analysis: adminDoc.analysis, // Contains faq, topics, mindmap strings
            analysisUpdatedAt: adminDoc.analysisUpdatedAt
        });
    } catch (error) {
        console.error(`Error fetching analysis for admin document '${serverFilename}':`, error);
        res.status(500).json({ message: 'Server error while retrieving admin document analysis.' });
    }
});


module.exports = router;
```

`services/geminiService.js`

```javascript
// server/services/geminiService.js
const { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } = require('@google/generative-ai');

const API_KEY = process.env.GEMINI_API_KEY;
const MODEL_NAME = "gemini-1.5-flash";

if (!API_KEY) {
    console.error("FATAL ERROR: GEMINI_API_KEY is not available in the environment. Server should have exited.");
    throw new Error("GEMINI_API_KEY is missing.");
}

const genAI = new GoogleGenerativeAI(API_KEY);

const DEFAULT_MAX_OUTPUT_TOKENS_CHAT = 8192;
const DEFAULT_MAX_OUTPUT_TOKENS_KG = 65536;

const baseSafetySettings = [
    { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH },
    { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH },
    { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH },
    { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH },
];

const generateContentWithHistory = async (
    chatHistory,
    currentUserQuery,
    systemPromptText = null,
    customMaxOutputTokens = null
) => {
    try {
        if (typeof currentUserQuery !== 'string' || currentUserQuery.trim() === '') {
            throw new Error("currentUserQuery must be a non-empty string.");
        }

        const effectiveMaxOutputTokens = customMaxOutputTokens || DEFAULT_MAX_OUTPUT_TOKENS_CHAT;

        // --- FIX: Correctly assign the numeric token value ---
        const generationConfig = {
            temperature: 0.7,
            maxOutputTokens: effectiveMaxOutputTokens, // Use the correct variable here
        };
        // --- END FIX ---

        const modelOptions = {
            model: MODEL_NAME,
            generationConfig: generationConfig,
            safetySettings: baseSafetySettings,
            ...(systemPromptText && typeof systemPromptText === 'string' && systemPromptText.trim() !== '' && {
                systemInstruction: {
                    parts: [{ text: systemPromptText.trim() }]
                }
            })
        };
        const model = genAI.getGenerativeModel(modelOptions);

        const historyForStartChat = (chatHistory || [])
            .map(msg => ({
                role: msg.role,
                parts: Array.isArray(msg.parts) ? msg.parts.map(part => ({ text: part.text || '' })) : [{ text: '' }]
            }))
            .filter(msg => msg.role && msg.parts && msg.parts.length > 0 && typeof msg.parts[0].text === 'string');

        const chat = model.startChat({
            history: historyForStartChat,
        });

        console.log(`Sending message to Gemini. History sent to startChat: ${historyForStartChat.length}. System Prompt: ${!!modelOptions.systemInstruction}. Max Output Tokens: ${effectiveMaxOutputTokens}`);
        console.log(`Current User Query to sendMessage: "${currentUserQuery.substring(0, 100)}..."`);

        const result = await chat.sendMessage(currentUserQuery);
        const response = result.response;
        const candidate = response?.candidates?.[0];

        if (candidate && (candidate.finishReason === 'STOP' || candidate.finishReason === 'MAX_TOKENS')) {
            const responseText = candidate?.content?.parts?.[0]?.text;
            if (typeof responseText === 'string') {
                if (candidate.finishReason === 'MAX_TOKENS') {
                    console.warn("Gemini response was truncated due to MAX_TOKENS limit.");
                }
                return responseText;
            } else {
                console.warn("Gemini response finished normally but text content is missing or invalid.", { finishReason: candidate?.finishReason, content: candidate?.content });
                throw new Error("Received an empty or invalid response from the AI service.");
            }
        } else {
            const finishReason = candidate?.finishReason || 'Unknown';
            const safetyRatings = candidate?.safetyRatings;
            console.warn("Gemini response was potentially blocked or had issues.", { finishReason, safetyRatings });
            let blockMessage = `AI response generation failed or was blocked.`;
            if (finishReason === 'SAFETY') {
                blockMessage += ` Reason: SAFETY.`;
                if (safetyRatings) {
                    const blockedCategories = safetyRatings.filter(r => r.blocked).map(r => r.category).join(', ');
                    if (blockedCategories) blockMessage += ` Blocked Categories: ${blockedCategories}.`;
                }
            } else if (finishReason) {
                blockMessage += ` Reason: ${finishReason}.`;
            }
            const error = new Error(blockMessage);
            error.status = 400;
            throw error;
        }
    } catch (error) {
        console.error("Gemini API Call Error:", error?.message || error);
        let clientMessage = "Failed to get response from AI service.";
        if (error.message?.includes("API key not valid")) clientMessage = "AI Service Error: Invalid API Key.";
        else if (error.message?.includes("blocked due to safety")) clientMessage = "AI response blocked due to safety settings.";
        else if (error.message?.includes("Invalid JSON payload")) clientMessage = "AI Service Error: Invalid request format sent to AI.";
        else if (error.message?.includes("User location is not supported")) clientMessage = "AI Service Error: User location is not supported for this model.";
        else if (error.status === 400) clientMessage = `AI Service Error: ${error.message}`;

        const enhancedError = new Error(clientMessage);
        enhancedError.status = error.status || 500;
        enhancedError.originalError = error;
        throw enhancedError;
    }
};

module.exports = {
    generateContentWithHistory,
    DEFAULT_MAX_OUTPUT_TOKENS_KG
};
```

`services/kgService.js`

```javascript
// server/services/kgService.js
const geminiService = require('./geminiService');
const ollamaService = require('./ollamaService'); // Import Ollama service
const { v4: uuidv4 } = require('uuid');
const axios = require('axios');
// --- IMPORT THE PROMPTS ---
const {
    KG_GENERATION_SYSTEM_PROMPT,
    KG_BATCH_USER_PROMPT_TEMPLATE // Import the new template
} = require('../config/promptTemplates');

// --- MODIFIED: Function to construct the user prompt for a BATCH of chunks ---
function constructKgPromptForBatch(chunkTexts) {
    // chunkTexts is an array of strings, where each string is the text_content of a chunk.
    let formattedChunkTexts = "";
    chunkTexts.forEach((chunkText, index) => {
        formattedChunkTexts += `
--- START OF CHUNK ${index + 1} ---
${chunkText}
--- END OF CHUNK ${index + 1} ---
`;
    });

    // Replace the placeholder in the template with the actual formatted chunk texts
    return KG_BATCH_USER_PROMPT_TEMPLATE.replace('{BATCHED_CHUNK_TEXTS_HERE}', formattedChunkTexts);
}

// --- NEW: Internal function to process a single BATCH of chunks ---
// (This function _processBatchOfChunksForKg remains the same as in the previous good answer)
async function _processBatchOfChunksForKg(batchOfChunkObjects, batchIndex, llmProvider, ollamaModel) {
    // batchOfChunkObjects is an array of the original chunk objects
    // e.g., [{ text_content: "...", metadata: {...} }, ...]
    const logPrefix = `[KG Service Batch ${batchIndex}]`;

    const chunkTextsForPrompt = batchOfChunkObjects.map(chunk => chunk.text_content);

    if (chunkTextsForPrompt.length === 0) {
        console.log(`${logPrefix} No text content in this batch. Skipping.`);
        return [];
    }

    const userPromptForBatch = constructKgPromptForBatch(chunkTextsForPrompt); // Uses the new templated function
    const chatHistory = [
        { role: 'user', parts: [{ text: userPromptForBatch }] }
    ];

    try {
        console.log(`${logPrefix} Processing ${chunkTextsForPrompt.length} chunks for KG generation using ${llmProvider}.`);
        let responseText;

        if (llmProvider === 'ollama') {
            responseText = await ollamaService.generateContentWithHistory(
                chatHistory, // This structure is simple for KG (just user prompt)
                KG_GENERATION_SYSTEM_PROMPT,
                { model: ollamaModel, maxOutputTokens: ollamaService.DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_KG }
            );
        } else { // Default to Gemini
            responseText = await geminiService.generateContentWithHistory(
                chatHistory,
                KG_GENERATION_SYSTEM_PROMPT, // System prompt applies to EACH chunk's processing logic
                geminiService.DEFAULT_MAX_OUTPUT_TOKENS_KG
            );
        }

        if (!responseText) {
            console.warn(`${logPrefix} Empty response from Gemini for batch.`);
            return [];
        }

        let cleanedResponseText = responseText.trim();
        // More robust cleaning for ```json ... ``` or ``` ... ``` blocks
        if (cleanedResponseText.startsWith("```json")) {
            cleanedResponseText = cleanedResponseText.substring(7); // Remove ```json
            if (cleanedResponseText.endsWith("```")) {
                cleanedResponseText = cleanedResponseText.slice(0, -3); // Remove ```
            }
        } else if (cleanedResponseText.startsWith("```")) {
            cleanedResponseText = cleanedResponseText.substring(3); // Remove ```
            if (cleanedResponseText.endsWith("```")) {
                cleanedResponseText = cleanedResponseText.slice(0, -3); // Remove ```
            }
        }
        cleanedResponseText = cleanedResponseText.trim();
        console.log("-----------------------------------------------------------------------------------------------------");
        console.log(cleanedResponseText);
        const graphFragmentsArray = JSON.parse(cleanedResponseText);

        if (!Array.isArray(graphFragmentsArray)) {
            console.warn(`${logPrefix} Gemini response was not a JSON array. Response (first 200 chars):`, cleanedResponseText.substring(0, 200));
            return [];
        }

        if (graphFragmentsArray.length !== batchOfChunkObjects.length) {
            console.warn(`${logPrefix} Mismatch: Expected ${batchOfChunkObjects.length} KG fragments, but received ${graphFragmentsArray.length}. Results might be misaligned.`);
        }
        
        const validFragments = [];
        graphFragmentsArray.forEach((fragment, i) => {
            if (fragment && typeof fragment === 'object' && Array.isArray(fragment.nodes) && Array.isArray(fragment.edges)) {
                validFragments.push(fragment);
            } else {
                const chunkRef = batchOfChunkObjects[i]?.metadata?.chunk_reference_name || `chunk index ${i} in batch`;
                console.warn(`${logPrefix} Invalid graph structure from Gemini for ${chunkRef}. Discarding this fragment. Fragment:`, JSON.stringify(fragment).substring(0,100));
            }
        });
        console.log(`${logPrefix} Successfully parsed ${validFragments.length} valid KG fragments from Gemini response.`);
        return validFragments;

    } catch (error) {
        console.error(`${logPrefix} Error processing batch:`, error.message);
        if (error.originalError) console.error(`${logPrefix} Original Gemini error:`, error.originalError);
        if (error.response?.data) console.error(`${logPrefix} Gemini error data:`, error.response.data);
        return [];
    }
}


// --- MERGE FUNCTION (remains the same as your provided version or my previous good one) ---
function _mergeGraphFragments(graphFragments) {
    console.log(`[KG Service] Merging ${graphFragments.length} graph fragments...`);
    const finalNodesMap = new Map();
    const finalEdgesSet = new Set(); // Using a Set to store unique stringified edges

    for (const fragment of graphFragments) {
        if (!fragment || !fragment.nodes || !fragment.edges) {
            console.warn("[KG Service Merge] Skipping invalid or null graph fragment.");
            continue;
        }
        
        // Process Nodes
        for (const node of fragment.nodes) {
            if (!node || typeof node.id !== 'string' || !node.id.trim()) {
                console.warn("[KG Service Merge] Skipping invalid node (missing/empty ID):", node);
                continue;
            }
            const nodeId = node.id.trim();
            if (!finalNodesMap.has(nodeId)) {
                finalNodesMap.set(nodeId, { ...node, id: nodeId });
            } else {
                const existingNode = finalNodesMap.get(nodeId);
                if (node.description && typeof node.description === 'string' &&
                    (!existingNode.description || node.description.length > existingNode.description.length)) {
                    existingNode.description = node.description;
                }
                if (node.type && (!existingNode.type || existingNode.type === "generic" || existingNode.type.toLowerCase() === "unknown")) {
                    existingNode.type = node.type;
                }
                if (node.parent && !existingNode.parent) {
                    existingNode.parent = node.parent;
                }
            }
        }

        // Process Edges
        for (const edge of fragment.edges) {
            if (!edge || typeof edge.from !== 'string' || typeof edge.to !== 'string' || typeof edge.relationship !== 'string' ||
                !edge.from.trim() || !edge.to.trim() || !edge.relationship.trim()) {
                console.warn("[KG Service Merge] Skipping invalid edge (missing from/to/relationship or empty):", edge);
                continue;
            }
            const edgeKey = `${edge.from.trim()}|${edge.to.trim()}|${edge.relationship.trim().toUpperCase()}`;
            finalEdgesSet.add(edgeKey);
        }
    }

    const mergedNodes = Array.from(finalNodesMap.values());
    const mergedEdges = Array.from(finalEdgesSet).map(edgeKey => {
        const [from, to, relationship] = edgeKey.split('|');
        return { from, to, relationship };
    });

    console.log(`[KG Service Merge] Merged into ${mergedNodes.length} nodes and ${mergedEdges.length} edges.`);
    return { nodes: mergedNodes, edges: mergedEdges };
}

// --- MODIFIED: Main function for KG generation and storage ---
// (This function generateAndStoreKg remains the same as in the previous good answer)
async function generateAndStoreKg(chunksForKg, userId, originalName, llmProvider, ollamaModel) {
    const logPrefix = `[KG Service Doc: ${originalName}, User: ${userId}]`;
    console.log(`${logPrefix} Starting KG generation with ${chunksForKg.length} initial chunks.`);

    if (!chunksForKg || chunksForKg.length === 0) {
        console.warn(`${logPrefix} No chunks provided for KG generation.`);
        return { success: true, message: "No chunks to process for KG.", finalKgNodesCount: 0, finalKgEdgesCount: 0 };
    }

    const allGraphFragments = [];
    const BATCH_SIZE = parseInt(process.env.KG_GENERATION_BATCH_SIZE) || 50;
    console.log(`${logPrefix} Using batch size: ${BATCH_SIZE}`);
    let batchIndex = 0;

    for (let i = 0; i < chunksForKg.length; i += BATCH_SIZE) {
        batchIndex++;
        const currentBatchOfChunks = chunksForKg.slice(i, i + BATCH_SIZE);
        
        const validChunksInBatch = currentBatchOfChunks.filter(chunk => chunk && chunk.text_content && chunk.text_content.trim() !== '');
        if (validChunksInBatch.length === 0) {
            console.log(`${logPrefix} Batch ${batchIndex} has no valid chunks with text. Skipping.`);
            continue;
        }
        
        console.log(`${logPrefix} Processing batch ${batchIndex} (chunks ${i} to ${Math.min(i + BATCH_SIZE - 1, chunksForKg.length - 1)}), ${validChunksInBatch.length} valid chunks.`);
        
        const fragmentsFromBatch = await _processBatchOfChunksForKg(validChunksInBatch, batchIndex, llmProvider, ollamaModel); // Pass LLM info
        if (fragmentsFromBatch && fragmentsFromBatch.length > 0) {
            allGraphFragments.push(...fragmentsFromBatch);
        } else {
            console.warn(`${logPrefix} Batch ${batchIndex} yielded no valid graph fragments.`);
        }
    }

    if (allGraphFragments.length === 0) {
        console.warn(`${logPrefix} No valid graph fragments were generated from any batch.`);
        return { success: true, message: "No KG data extracted from any document chunks.", finalKgNodesCount: 0, finalKgEdgesCount: 0 };
    }

    console.log(`${logPrefix} Generated a total of ${allGraphFragments.length} raw graph fragments. Merging...`);
    const finalKg = _mergeGraphFragments(allGraphFragments);
    
    if (!finalKg || finalKg.nodes.length === 0) {
        console.warn(`${logPrefix} Merged KG has no nodes. Nothing to store.`);
         return { success: true, message: "Merged KG was empty after processing all fragments.", finalKgNodesCount: 0, finalKgEdgesCount: 0 };
    }
    console.log(`${logPrefix} Merged KG successfully. Nodes: ${finalKg.nodes.length}, Edges: ${finalKg.edges.length}.`);

    const baseRagUrl = process.env.PYTHON_RAG_SERVICE_URL || process.env.DEFAULT_PYTHON_RAG_URL || 'http://localhost:5000';
    const kgIngestionApiUrl = `${baseRagUrl.replace(/\/$/, '')}/kg`;

    if (!kgIngestionApiUrl.startsWith('http')) {
        console.error(`${logPrefix} KG Ingestion API URL is invalid: ${kgIngestionApiUrl}. Check PYTHON_RAG_SERVICE_URL.`);
        return {
            success: false,
            message: "KG generated, but KG Ingestion API URL is invalid. KG not stored.",
            finalKgNodesCount: finalKg.nodes.length,
            finalKgEdgesCount: finalKg.edges.length
        };
    }

    console.log(`${logPrefix} Sending final merged KG to Ingestion API: ${kgIngestionApiUrl}`);
    try {
        const payload = {
            userId: userId,
            originalName: originalName,
            nodes: finalKg.nodes,
            edges: finalKg.edges
        };

        const serviceResponse = await axios.post(kgIngestionApiUrl, payload, {
            timeout: 300000
        });

        const responseData = serviceResponse.data;
        const API_SUCCESS_STATUS_VALUE = "completed";

        if (serviceResponse.status >= 200 && serviceResponse.status < 300 && responseData && responseData.status === API_SUCCESS_STATUS_VALUE) {
            if (responseData['documentName'] !== originalName || responseData.userId !== userId) {
                console.warn(`${logPrefix} Mismatch in KG API response. Expected doc/user: ${originalName}/${userId}, Got: ${responseData['documentName']}/${responseData.userId}`);
            }
            const successMessage = `KG for '${originalName}' successfully processed by Ingestion API. Status: ${responseData.status}. Nodes: ${finalKg.nodes.length}, Edges: ${finalKg.edges.length}`;
            console.log(`${logPrefix} ${successMessage}`);
            return {
                success: true,
                message: successMessage,
                serviceResponseData: responseData,
                finalKgNodesCount: finalKg.nodes.length,
                finalKgEdgesCount: finalKg.edges.length
            };
        } else {
            const failureMessage = `KG Ingestion API for '${originalName}' indicated failure or unexpected status. HTTP: ${serviceResponse.status}, API Status: '${responseData?.status || "N/A"}'. API Msg: ${responseData?.message || responseData?.error || 'No specific error from API.'}`;
            console.warn(`${logPrefix} ${failureMessage}`);
            return {
                success: false,
                message: failureMessage,
                serviceResponseData: responseData,
                finalKgNodesCount: finalKg.nodes.length,
                finalKgEdgesCount: finalKg.edges.length
            };
        }
    } catch (error) {
        const errorMsg = error.response?.data?.message || error.response?.data?.error || error.message || "Unknown error calling KG Ingestion API";
        console.error(`${logPrefix} Error calling KG Ingestion API:`, errorMsg);
        if (error.response?.data) console.error(`${logPrefix} KG API Error Response Data:`, error.response.data);
        if (error.code === 'ECONNABORTED' || error.message.toLowerCase().includes('timeout')) {
            console.error(`${logPrefix} KG Ingestion API call timed out.`);
        }
        return {
            success: false,
            message: `KG generated, but error calling KG Ingestion API: ${errorMsg}`,
            finalKgNodesCount: finalKg.nodes.length,
            finalKgEdgesCount: finalKg.edges.length
        };
    }
}

module.exports = { generateAndStoreKg };
```

`services/ollamaService.js`

```javascript
// server/services/ollamaService.js
const axios = require('axios');

const OLLAMA_BASE_URL = process.env.OLLAMA_API_BASE_URL || 'http://localhost:11434';
const DEFAULT_OLLAMA_MODEL = process.env.OLLAMA_DEFAULT_MODEL || 'llama3'; // Ensure this is set in .env

const DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_CHAT = 4096; // Ollama's equivalent to maxOutputTokens (num_predict)
const DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_KG = 8192;   // Larger for KG tasks

// Helper to format history for Ollama.
// Many models expect a specific format, e.g., Llama 2 chat format.
// This is a generic approach; specific models might need fine-tuning.
function formatHistoryForOllama(chatHistory, systemPromptText) {
    let promptString = "";

    if (systemPromptText && systemPromptText.trim() !== "") {
        // A common way to prepend system prompt for instruct/chat models
        promptString += `System: ${systemPromptText.trim()}\n\n`;
    }

    chatHistory.forEach(msg => {
        const role = msg.role === 'model' ? 'Assistant' : 'User';
        const text = (Array.isArray(msg.parts) && msg.parts[0]?.text) ? msg.parts[0].text : (msg.text || "");
        promptString += `${role}: ${text}\n`;
    });
    // The final prompt to Ollama will append the *current* user message after this history.
    // So, if the last message in chatHistory is the one we want a response to,
    // it should be included as the final "User:" part here.
    // Or, if chatHistory is true history, then the calling function appends the current query.
    return promptString;
}


const generateContentWithHistory = async (
    chatHistory, // Array of { role: 'user'/'model', parts: [{ text: '...' }] }
    systemPromptText = null,
    options = {} // { model, maxOutputTokens }
) => {
    const modelToUse = options.model || DEFAULT_OLLAMA_MODEL;
    const effectiveMaxOutputTokens = options.maxOutputTokens || DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_CHAT;

    if (!Array.isArray(chatHistory) || chatHistory.length === 0) {
        throw new Error("Ollama: Chat history must be a non-empty array.");
    }

    // The `chatHistory` passed here should *not* include the most recent user message if it's a typical chat flow.
    // That message will be the main "prompt" to Ollama.
    // If `chatHistory` *does* include the final user message, then the prompt below is just that message.

    const historyString = formatHistoryForOllama(chatHistory.slice(0, -1), systemPromptText);
    const currentUserMessage = (chatHistory[chatHistory.length - 1]?.parts?.[0]?.text) || "";

    if (!currentUserMessage.trim()) {
        throw new Error("Ollama: The final user message in history is empty or missing.");
    }
    
    // Construct the full prompt for Ollama
    // Ollama's /api/generate expects a single "prompt" field.
    // History is typically prepended to the current user's message.
    const fullPrompt = historyString + `User: ${currentUserMessage}\nAssistant:`; // Prompt for assistant's turn


    const requestPayload = {
        model: modelToUse,
        prompt: fullPrompt,
        stream: false, // We want the full response
        options: {
            temperature: options.temperature || 0.7,
            num_predict: effectiveMaxOutputTokens, // num_predict is Ollama's way of limiting output length
            // Add other Ollama options here if needed (e.g., top_k, top_p, seed)
        }
    };
    
    // If a system prompt was provided, and the model supports a dedicated 'system' field, use it.
    // Otherwise, it's already prepended in formatHistoryForOllama.
    // For /api/generate, it's usually part of the main prompt.
    // Some models might allow a `system` field in the payload for /api/generate. Check Ollama docs for specific model.
    // if (systemPromptText && systemPromptText.trim() !== "" && modelSupportsSystemField(modelToUse)) {
    //    requestPayload.system = systemPromptText.trim();
    // }


    const endpoint = `${OLLAMA_BASE_URL}/api/generate`;
    console.log(`Ollama Service: Sending request to ${endpoint} for model ${modelToUse}. Prompt (first 100): "${fullPrompt.substring(0, 100)}..."`);

    try {
        const response = await axios.post(endpoint, requestPayload, { timeout: 120000 }); // 2 min timeout

        if (response.data && response.data.response) {
            if (response.data.done === false || response.data.truncated) { // `truncated` might be a custom field or implied by `done: false` if `num_predict` is hit
                 console.warn(`Ollama response for model ${modelToUse} may have been truncated. Done: ${response.data.done}. Context length: ${response.data.context?.length}`);
            }
            return response.data.response.trim();
        } else {
            console.error("Ollama API Error: Invalid response structure.", response.data);
            throw new Error("Ollama service returned an invalid response structure.");
        }
    } catch (error) {
        console.error("Ollama API Call Error:", error.message);
        let clientMessage = "Failed to get response from Ollama AI service.";
        if (error.response) {
            console.error("Ollama Error Response Data:", error.response.data);
            clientMessage = `Ollama Service Error: ${error.response.data.error || error.message}`;
        } else if (error.request) {
            clientMessage = "No response received from Ollama service. Check if it's running and accessible.";
        }
        const enhancedError = new Error(clientMessage);
        enhancedError.status = error.response?.status || 503; // Service Unavailable or other
        enhancedError.originalError = error;
        throw enhancedError;
    }
};

module.exports = {
    generateContentWithHistory,
    DEFAULT_OLLAMA_MODEL, 
    DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_CHAT,
    DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_KG,
};
```

`services/summarizationService.js`

```javascript
// server/services/summarizationService.js
const geminiService = require('./geminiService');
const ollamaService = require('./ollamaService');

// This prompt is key. It instructs the LLM on how to create a good, cumulative summary.
const SUMMARIZATION_SYSTEM_PROMPT = `You are an expert conversation summarizer. Your task is to create a concise, yet comprehensive summary of the provided chat history between a User and an AI Assistant.

If an "Existing Summary" is provided, you MUST integrate the "New Messages" into it to create a single, updated, and coherent summary. Do not just append the new information; seamlessly weave it into the existing narrative.

The final summary MUST be in the third person.
Focus on capturing:
- The user's primary goals or questions.
- Key facts, concepts, or entities discussed.
- Important conclusions or resolutions reached.
- Any unresolved questions or next steps mentioned by the user.

Do NOT include conversational filler (e.g., "The user said hello"). The output should be a dense, information-rich paragraph.

Example of a good updated summary:
"Previously, the user, a PhD student, asked about 'Separation of Concerns'. In the latest exchange, they pivoted to inquiring about the specifics of Ohm's Law, and the AI provided the formula V=IR based on a document the user supplied. The user's current goal appears to be understanding foundational engineering concepts, moving from software to electrical principles."
`;

/**
 * Creates or updates a conversation summary.
 * @param {Array<Object>} messagesToSummarize - The array of new message objects to add to the summary.
 * @param {string} existingSummary - The existing summary from the database.
 * @param {string} llmProvider - The LLM provider to use ('gemini' or 'ollama').
 * @param {string} ollamaModel - The specific Ollama model if the provider is 'ollama'.
 * @returns {Promise<string>} The generated summary text.
 */
async function createOrUpdateSummary(messagesToSummarize, existingSummary, llmProvider, ollamaModel) {
    if (!messagesToSummarize || messagesToSummarize.length === 0) {
        return existingSummary || ""; // Return old summary or empty string if nothing to summarize
    }

    // Format the history for the summarization prompt
    const newMessagesText = messagesToSummarize.map(msg => {
        const role = msg.role === 'model' ? 'Assistant' : 'User';
        const text = msg.parts?.[0]?.text || '';
        return `${role}: ${text}`;
    }).join('\n\n');

    let userPrompt = "";
    if (existingSummary && existingSummary.trim() !== "") {
        userPrompt = `Existing Summary:\n"""\n${existingSummary}\n"""\n\nNew Messages to integrate:\n"""\n${newMessagesText}\n"""\n\nPlease provide the new, updated summary.`;
    } else {
        userPrompt = `New Messages to summarize:\n"""\n${newMessagesText}\n"""\n\nPlease provide the summary.`;
    }

    const historyForLlm = [{ role: 'user', parts: [{ text: userPrompt }] }];

    console.log(`[SummarizationService] Requesting summary using ${llmProvider}. Existing summary length: ${existingSummary ? existingSummary.length : 0}, New messages length: ${newMessagesText.length}`);

    try {
        let summary;
        if (llmProvider === 'ollama') {
            summary = await ollamaService.generateContentWithHistory(
                historyForLlm,
                SUMMARIZATION_SYSTEM_PROMPT,
                { model: ollamaModel, maxOutputTokens: 2048 } // Use a reasonable token limit for summaries
            );
        } else { // Default to Gemini
            summary = await geminiService.generateContentWithHistory(
                historyForLlm,
                SUMMARIZATION_SYSTEM_PROMPT
            );
        }

        console.log(`[SummarizationService] Summary generated successfully.`);
        return summary.trim();
    } catch (error) {
        console.error(`[SummarizationService] Error generating summary: ${error.message}`);
        // Return the old summary on failure to avoid losing context.
        return existingSummary || "";
    }
}

module.exports = { createOrUpdateSummary };
```

`services/webSearchService.js`

```javascript
// server/services/webSearchService.js
const axios = require('axios');

/**
 * Performs a web search by calling our internal Python RAG service.
 * @param {string} query - The search query.
 * @returns {Promise<string>} A formatted string of the top search results, or an empty string on failure.
 */
async function performWebSearch(query) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;

    if (!pythonServiceUrl) {
        console.warn("[WebSearch Service] PYTHON_RAG_SERVICE_URL is not set. Web search is disabled.");
        return "";
    }

    const searchUrl = `${pythonServiceUrl}/web_search`;

    try {
        console.log(`[WebSearch Service] Calling Python endpoint for search: ${searchUrl}`);
        const response = await axios.post(searchUrl, { query: query }, { timeout: 15000 });

        // The python service now returns a clean array: [{title, url, content}, ...]
        if (response.data && Array.isArray(response.data) && response.data.length > 0) {
            const topResults = response.data;
            
            const formattedResults = topResults.map((result, index) => {
                const title = result.title || 'No Title';
                const url = result.url || '#';
                const content = result.content ? result.content.replace(/[\n\r]+/g, ' ').trim() : 'No content preview.';
                return `[${index + 1}] Title: ${title}\nSource: ${url}\nContent: ${content}`;
            }).join('\n\n');

            return `[WEB SEARCH RESULTS]\n${formattedResults}`;
        } else {
            console.log(`[WebSearch Service] Python service returned no results for query: "${query}"`);
            return "";
        }
    } catch (error) {
        let errorMessage = `[WebSearch Service] Error calling Python service for query "${query}": `;
        if (error.response) {
            errorMessage += `Status ${error.response.status} - ${JSON.stringify(error.response.data)}`;
        } else if (error.request) {
            errorMessage += `No response received from Python service at ${searchUrl}.`;
        } else {
            errorMessage += error.message;
        }
        console.error(errorMessage);
        return "";
    }
}

module.exports = { performWebSearch };
```

`utils/assetCleanup.js`

```javascript
const fs = require('fs').promises; // Use fs.promises for async operations
const path = require('path');

// Define constants relative to this file's location (server/utils)
const ASSETS_DIR = path.join(__dirname, '..', 'assets'); // Go up one level to server/assets
const BACKUP_DIR = path.join(__dirname, '..', 'backup_assets'); // Go up one level to server/backup_assets
const FOLDER_TYPES = ['docs', 'images', 'code', 'others']; // Folders within each user's asset dir

/**
 * Moves existing user asset folders (docs, images, code, others) to a timestamped
 * backup location and recreates empty asset folders for each user on server startup.
 */
async function performAssetCleanup() {
    console.log("\n--- Starting Asset Cleanup ---");
    try {
        // Ensure backup base directory exists
        await fs.mkdir(BACKUP_DIR, { recursive: true });

        // List potential user directories in assets
        let userDirs = [];
        try {
            userDirs = await fs.readdir(ASSETS_DIR);
        } catch (err) {
            if (err.code === 'ENOENT') {
                console.log("Assets directory doesn't exist yet, creating it and skipping cleanup.");
                await fs.mkdir(ASSETS_DIR, { recursive: true }); // Ensure assets dir exists
                console.log("--- Finished Asset Cleanup (No existing assets found) ---");
                return; // Nothing to clean up
            }
            throw err; // Re-throw other errors accessing assets dir
        }

        if (userDirs.length === 0) {
             console.log("Assets directory is empty. Skipping backup/move operations.");
             console.log("--- Finished Asset Cleanup (No user assets found) ---");
             return;
        }

        const timestamp = new Date().toISOString().replace(/[:.]/g, '-'); // Create a safe timestamp string

        for (const userName of userDirs) {
            const userAssetPath = path.join(ASSETS_DIR, userName);
            const userBackupPathBase = path.join(BACKUP_DIR, userName);
            const userTimestampBackupPath = path.join(userBackupPathBase, `backup_${timestamp}`);

            try {
                // Check if the item in assets is actually a directory
                const stats = await fs.stat(userAssetPath);
                if (!stats.isDirectory()) {
                    console.log(`  Skipping non-directory item in assets: ${userName}`);
                    continue;
                }

                console.log(`  Processing assets for user: [${userName}]`);
                let backupDirCreated = false; // Track if backup dir was created for this user/run
                let movedSomething = false; // Track if anything was actually moved

                // Process each defined folder type (docs, images, etc.)
                for (const type of FOLDER_TYPES) {
                    const sourceTypePath = path.join(userAssetPath, type);
                    try {
                        // Check if the source type directory exists before trying to move
                        await fs.access(sourceTypePath);

                        // If source exists, ensure the timestamped backup directory is ready
                        if (!backupDirCreated) {
                            await fs.mkdir(userTimestampBackupPath, { recursive: true });
                            backupDirCreated = true;
                            // console.log(`    Created backup directory: ${userTimestampBackupPath}`);
                        }

                        // Define the destination path in the backup folder
                        const backupTypePath = path.join(userTimestampBackupPath, type);
                        // console.log(`    Moving ${sourceTypePath} to ${backupTypePath}`);
                        // Move the existing type folder to the backup location
                        await fs.rename(sourceTypePath, backupTypePath);
                        movedSomething = true;

                    } catch (accessErr) {
                        // Ignore error if the source directory doesn't exist (ENOENT)
                        if (accessErr.code !== 'ENOENT') {
                            console.error(`    Error accessing source folder ${sourceTypePath}:`, accessErr.message);
                        }
                        // If ENOENT, the folder doesn't exist, nothing to move.
                    }

                    // Always ensure the empty type directory exists in the main assets folder
                    try {
                        // console.log(`    Ensuring empty directory: ${sourceTypePath}`);
                        await fs.mkdir(sourceTypePath, { recursive: true });
                    } catch (mkdirErr) {
                         console.error(`    Failed to recreate directory ${sourceTypePath}:`, mkdirErr.message);
                    }
                } // End loop through FOLDER_TYPES

                 if (movedSomething) {
                     console.log(`  Finished backup for user [${userName}] to backup_${timestamp}`);
                 } else {
                     console.log(`  No existing asset types found to backup for user [${userName}]`);
                 }


            } catch (userDirStatErr) {
                 // Error checking if the item in assets is a directory
                 console.error(`Error processing potential user asset directory ${userAssetPath}:`, userDirStatErr.message);
            }
        } // End loop through userDirs

        console.log("--- Finished Asset Cleanup ---");

    } catch (error) {
        // Catch errors related to backup dir creation or reading the main assets dir
        console.error("!!! Critical Error during Asset Cleanup process:", error);
    }
}

// Export the function to be used elsewhere
module.exports = { performAssetCleanup };

```

`utils/networkUtils.js`

```javascript
const os = require('os');

function getLocalIPs() {
    const interfaces = os.networkInterfaces();
    const ips = new Set(['localhost']); // Include localhost

    for (const iface of Object.values(interfaces)) {
        for (const addr of iface) {
            // Include IPv4 non-internal addresses
            if (addr.family === 'IPv4' && !addr.internal) {
                ips.add(addr.address);
            }
        }
    }
    return Array.from(ips);
}

function getPreferredLocalIP() {
    const ips = getLocalIPs();
    // Prioritize non-localhost, non-link-local (169.254) IPs
    // Often 192.168.* or 10.* or 172.16-31.* are common private ranges
    return ips.find(ip => !ip.startsWith('169.254.') && ip !== 'localhost' && (ip.startsWith('192.168.') || ip.startsWith('10.') || ip.match(/^172\.(1[6-9]|2[0-9]|3[0-1])\./))) ||
           ips.find(ip => !ip.startsWith('169.254.') && ip !== 'localhost') || // Any other non-link-local
           'localhost'; // Fallback
}

module.exports = { getLocalIPs, getPreferredLocalIP };

```

`workers/adminAnalysisWorker.js`

```javascript
// server/workers/adminAnalysisWorker.js
const { workerData, parentPort } = require('worker_threads');
const mongoose = require('mongoose');
const path = require('path'); // For resolving .env path

// Adjust paths if your project structure is different
const AdminDocument = require('../models/AdminDocument'); // Specific model for admin docs
const connectDB = require('../config/db');
const geminiService = require('../services/geminiService');
const { ANALYSIS_PROMPTS } = require('../config/promptTemplates');

// Load .env variables from the server directory for the worker
require('dotenv').config({ path: path.resolve(__dirname, '..', '.env') });


async function performAdminDocAnalysis(adminDocumentId, originalName, textForAnalysis) {
    const logPrefix = `[AdminAnalysisWorker ${process.pid}, Doc: ${originalName}, ID: ${adminDocumentId}]`;
    console.log(`${logPrefix} Starting analysis. Text length: ${textForAnalysis ? textForAnalysis.length : 0}`);

    const analysisResults = { faq: "", topics: "", mindmap: "" };
    let allIndividualAnalysesSuccessful = true;

    async function generateSingleAnalysis(type, promptContentForLLM) {
        try {
            console.log(`${logPrefix} Generating ${type}...`);
            // For admin docs, we don't have a "user" in the same sense for history.
            // We send a simple instruction to perform the task.
            const historyForGemini = [{ role: 'user', parts: [{ text: "Perform the requested analysis based on the system instruction and provided document text." }] }];
            
            const generatedText = await geminiService.generateContentWithHistory(
                historyForGemini,
                promptContentForLLM // This is the full prompt from ANALYSIS_PROMPTS including the document text
            );

            if (!generatedText || typeof generatedText !== 'string' || generatedText.trim() === "") {
                console.warn(`${logPrefix} Gemini returned empty content for ${type}.`);
                return { success: false, content: `Notice: No content generated by the AI for ${type}.` };
            }
            console.log(`${logPrefix} ${type} generation successful.`);
            return { success: true, content: generatedText.trim() };
        } catch (error) {
            console.error(`${logPrefix} Error during ${type} generation: ${error.message}`);
            allIndividualAnalysesSuccessful = false;
            return { success: false, content: `Error generating ${type}: ${error.message.split('\n')[0].substring(0, 250)}` };
        }
    }

    if (!textForAnalysis || textForAnalysis.trim() === "") {
        console.warn(`${logPrefix} No text provided for analysis. Skipping generation.`);
        allIndividualAnalysesSuccessful = true; // Not a failure, just nothing to do.
        analysisResults.faq = "Skipped: No text content provided.";
        analysisResults.topics = "Skipped: No text content provided.";
        analysisResults.mindmap = "Skipped: No text content provided.";
    } else {
        // --- Generate FAQ, Topics, and Mindmap IN PARALLEL ---
        const analysisPromises = [
            generateSingleAnalysis('FAQ', ANALYSIS_PROMPTS.faq.getPrompt(textForAnalysis)),
            generateSingleAnalysis('Topics', ANALYSIS_PROMPTS.topics.getPrompt(textForAnalysis)),
            generateSingleAnalysis('Mindmap', ANALYSIS_PROMPTS.mindmap.getPrompt(textForAnalysis))
        ];

        const [faqOutcome, topicsOutcome, mindmapOutcome] = await Promise.allSettled(analysisPromises);

        if (faqOutcome.status === 'fulfilled') {
            analysisResults.faq = faqOutcome.value.content;
            if (!faqOutcome.value.success) allIndividualAnalysesSuccessful = false;
        } else {
            analysisResults.faq = `Error generating FAQ: ${faqOutcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
            allIndividualAnalysesSuccessful = false;
            console.error(`${logPrefix} FAQ generation promise rejected:`, faqOutcome.reason);
        }

        if (topicsOutcome.status === 'fulfilled') {
            analysisResults.topics = topicsOutcome.value.content;
            if (!topicsOutcome.value.success) allIndividualAnalysesSuccessful = false;
        } else {
            analysisResults.topics = `Error generating Topics: ${topicsOutcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
            allIndividualAnalysesSuccessful = false;
            console.error(`${logPrefix} Topics generation promise rejected:`, topicsOutcome.reason);
        }

        if (mindmapOutcome.status === 'fulfilled') {
            analysisResults.mindmap = mindmapOutcome.value.content;
            if (!mindmapOutcome.value.success) allIndividualAnalysesSuccessful = false;
        } else {
            analysisResults.mindmap = `Error generating Mindmap: ${mindmapOutcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
            allIndividualAnalysesSuccessful = false;
            console.error(`${logPrefix} Mindmap generation promise rejected:`, mindmapOutcome.reason);
        }
    }
    
    // Update MongoDB with all results
    // Note: This worker doesn't set 'analysisStatus' as it's not in the simplified AdminDocument model.
    // It directly updates the analysis fields.
    try {
        const updateResult = await AdminDocument.updateOne(
            { _id: adminDocumentId }, // Find by the document's MongoDB _id
            {
                $set: {
                    "analysis.faq": analysisResults.faq,
                    "analysis.topics": analysisResults.topics,
                    "analysis.mindmap": analysisResults.mindmap,
                    "analysisUpdatedAt": new Date()
                }
            }
        );

        if (updateResult.matchedCount === 0) {
            console.error(`${logPrefix} DB Error: AdminDocument with ID ${adminDocumentId} not found for update.`);
            return { success: false, message: `AdminDocument not found in DB (ID: ${adminDocumentId}).`, results: analysisResults };
        }
        if (updateResult.modifiedCount === 0 && updateResult.matchedCount === 1) {
            console.warn(`${logPrefix} Analysis results for already matched existing content in DB (ID: ${adminDocumentId}). No change made or content was identical.`);
        } else {
             console.log(`${logPrefix} Analysis results stored in DB.`);
        }
        return { success: allIndividualAnalysesSuccessful, message: `Analysis ${allIndividualAnalysesSuccessful ? 'completed' : 'completed with some failures'}.`, results: analysisResults };
    } catch (dbError) {
        console.error(`${logPrefix} DB Error storing analysis results:`, dbError);
        return { success: false, message: `DB Error storing analysis: ${dbError.message}`, results: analysisResults };
    }
}

async function run() {
    const { adminDocumentId, originalName, textForAnalysis } = workerData;
    let dbConnected = false;
    let overallTaskSuccess = false;
    let finalMessageToParent = "Admin analysis worker encountered an issue.";
    const logPrefix = `[AdminAnalysisWorker ${process.pid}, Doc: ${originalName}, ID: ${adminDocumentId}]`;

    try {
        console.log(`${logPrefix} Worker received task.`);
        if (!process.env.MONGO_URI) throw new Error("MONGO_URI not set in AdminAnalysisWorker environment.");
        if (!adminDocumentId || !originalName) throw new Error("Missing adminDocumentId or originalName in workerData.");
        
        await connectDB(process.env.MONGO_URI);
        dbConnected = true;
        console.log(`${logPrefix} DB Connected.`);

        const analysisServiceResult = await performAdminDocAnalysis(adminDocumentId, originalName, textForAnalysis);
        overallTaskSuccess = analysisServiceResult.success;
        finalMessageToParent = analysisServiceResult.message;

        if (parentPort) {
            parentPort.postMessage({
                success: overallTaskSuccess,
                originalName: originalName, // For logging on main thread
                adminDocumentId: adminDocumentId,
                message: finalMessageToParent
            });
        }

    } catch (error) {
        console.error(`${logPrefix} Critical error in worker:`, error.message, error.stack);
        finalMessageToParent = error.message || "Unknown critical error in AdminAnalysisWorker.";
        overallTaskSuccess = false;
        // Note: We don't update a status field here as the simplified model doesn't have one.
        // The main thread (adminDocuments.js) might log this worker failure.
        if (parentPort) {
            parentPort.postMessage({ success: false, originalName, adminDocumentId, error: finalMessageToParent });
        }
    } finally {
        if (dbConnected) {
            await mongoose.disconnect().catch(e => console.error(`${logPrefix} Error disconnecting DB:`, e));
            console.log(`${logPrefix} DB Disconnected.`);
        }
        console.log(`${logPrefix} Finished task. Overall Success: ${overallTaskSuccess}`);
        // Worker exits automatically if parentPort exists and main thread doesn't keep it alive,
        // or if it's the end of the run() promise.
    }
}

run();
```

`workers/analysisWorker.js`

```javascript
// server/workers/analysisWorker.js
const { workerData, parentPort } = require('worker_threads');
const mongoose = require('mongoose');
// const path = require('path'); // Not strictly needed if paths below are correct

// Assuming worker is in server/workers/ and services/models are in server/services/, server/models/
const User = require('../models/User');
const connectDB = require('../config/db');
const geminiService = require('../services/geminiService'); // For actual LLM calls
const ollamaService = require('../services/ollamaService'); // Import Ollama service
const { ANALYSIS_PROMPTS } = require('../config/promptTemplates'); // For prompts

// This function will now contain the actual analysis generation logic
async function performFullAnalysis(userId, originalName, textForAnalysis, llmProvider, ollamaModel) {
    console.log(`[Analysis Worker ${process.pid}] Starting actual analysis generation for '${originalName}'. Text length: ${textForAnalysis.length}`);

    const analysisResults = { faq: "", topics: "", mindmap: "" };
    let allIndividualAnalysesSuccessful = true; // Tracks if each specific analysis type was successful

    // Helper for a single analysis type, similar to what was in upload.js
    async function generateSingleAnalysis(type, promptContentForLLM, context) {
        try {
            console.log(`[Analysis Worker] Generating ${type} for '${context.originalName}' (User: ${context.userId}).`);
            const historyForGemini = [{ role: 'user', parts: [{ text: "Please perform the requested analysis based on the system instruction provided." }] }];
            
            let generatedText;
            if (llmProvider === 'ollama') {
                generatedText = await ollamaService.generateContentWithHistory(
                    historyForGemini, // This structure might need adjustment for ollamaService's prompt formatter
                    promptContentForLLM, // This is the system prompt + document text
                    { model: ollamaModel, maxOutputTokens: ollamaService.DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_CHAT } // Pass model and token options
                );
            } else { // Default to Gemini
                generatedText = await geminiService.generateContentWithHistory(
                    historyForGemini,
                    promptContentForLLM // This is the full prompt including the document text
                );
            }

            if (!generatedText || typeof generatedText !== 'string' || generatedText.trim() === "") {
                console.warn(`[Analysis Worker] Gemini returned empty content for ${type} for '${context.originalName}'.`);
                return { success: false, content: `Notice: No content generated by the AI for ${type}.` };
            }
            console.log(`[Analysis Worker] ${type} generation successful for '${context.originalName}'.`);
            return { success: true, content: generatedText.trim() };
        } catch (error) {
            console.error(`[Analysis Worker] Error during ${type} generation for '${context.originalName}': ${error.message}`);
            allIndividualAnalysesSuccessful = false; // Mark that at least one analysis type failed
            return { success: false, content: `Error generating ${type}: ${error.message.split('\n')[0].substring(0, 250)}` };
        }
    }

    const logCtx = { userId, originalName };

    // --- Generate FAQ, Topics, and Mindmap IN PARALLEL within this worker ---
    // This makes the worker itself more efficient if the LLM calls are independent.
    const analysisPromises = [
        generateSingleAnalysis('FAQ', ANALYSIS_PROMPTS.faq.getPrompt(textForAnalysis), logCtx),
        generateSingleAnalysis('Topics', ANALYSIS_PROMPTS.topics.getPrompt(textForAnalysis), logCtx),
        generateSingleAnalysis('Mindmap', ANALYSIS_PROMPTS.mindmap.getPrompt(textForAnalysis), logCtx)
    ];

    const [faqOutcome, topicsOutcome, mindmapOutcome] = await Promise.allSettled(analysisPromises);

    // Process outcomes from Promise.allSettled
    if (faqOutcome.status === 'fulfilled') {
        analysisResults.faq = faqOutcome.value.content;
        if (!faqOutcome.value.success) allIndividualAnalysesSuccessful = false;
    } else { // rejected
        analysisResults.faq = `Error generating FAQ: ${faqOutcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
        allIndividualAnalysesSuccessful = false;
        console.error(`[Analysis Worker] FAQ generation promise rejected for ${originalName}:`, faqOutcome.reason);
    }

    if (topicsOutcome.status === 'fulfilled') {
        analysisResults.topics = topicsOutcome.value.content;
        if (!topicsOutcome.value.success) allIndividualAnalysesSuccessful = false;
    } else { // rejected
        analysisResults.topics = `Error generating Topics: ${topicsOutcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
        allIndividualAnalysesSuccessful = false;
        console.error(`[Analysis Worker] Topics generation promise rejected for ${originalName}:`, topicsOutcome.reason);
    }

    if (mindmapOutcome.status === 'fulfilled') {
        analysisResults.mindmap = mindmapOutcome.value.content;
        if (!mindmapOutcome.value.success) allIndividualAnalysesSuccessful = false;
    } else { // rejected
        analysisResults.mindmap = `Error generating Mindmap: ${mindmapOutcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
        allIndividualAnalysesSuccessful = false;
        console.error(`[Analysis Worker] Mindmap generation promise rejected for ${originalName}:`, mindmapOutcome.reason);
    }
    
    // Update MongoDB with all results (even if some failed, we store what we have or the error messages)
    const finalAnalysisStatus = allIndividualAnalysesSuccessful ? "completed" : "failed_partial";
    try {
        await User.updateOne(
            { _id: userId, "uploadedDocuments.filename": originalName },
            {
                $set: {
                    "uploadedDocuments.$.analysis.faq": analysisResults.faq,
                    "uploadedDocuments.$.analysis.topics": analysisResults.topics,
                    "uploadedDocuments.$.analysis.mindmap": analysisResults.mindmap,
                    "uploadedDocuments.$.analysisStatus": finalAnalysisStatus,
                    "uploadedDocuments.$.analysisTimestamp": new Date()
                }
            }
        );
        console.log(`[Analysis Worker ${process.pid}] Analysis results for '${originalName}' (Status: ${finalAnalysisStatus}) stored in DB.`);
        return { success: allIndividualAnalysesSuccessful, message: `Analysis ${allIndividualAnalysesSuccessful ? 'completed successfully' : 'completed with some failures'}.`, results: analysisResults };
    } catch (dbError) {
        console.error(`[Analysis Worker ${process.pid}] DB Error storing analysis results for '${originalName}':`, dbError);
        // This is a critical error for the worker's task.
        // The 'analysisStatus' might remain 'processing' or be whatever it was before this attempt.
        return { success: false, message: `DB Error storing analysis: ${dbError.message}`, results: analysisResults };
    }
}

async function run() {
    const { userId, originalName, textForAnalysis, llmProvider, ollamaModel } = workerData;
    let dbConnected = false;
    let overallTaskSuccess = false; // Renamed for clarity for the worker's overall task
    let finalMessageToParent = "Analysis worker encountered an issue.";

    try {
        console.log(`[Analysis Worker ${process.pid}] Received task for: ${originalName}, User: ${userId}`);
        if (!process.env.MONGO_URI) {
            throw new Error("MONGO_URI not set in Analysis worker environment.");
        }
        if (!userId || !originalName) {
            throw new Error("Missing userId or originalName in workerData.");
        }
        
        await connectDB(process.env.MONGO_URI);
        dbConnected = true;
        console.log(`[Analysis Worker ${process.pid}] DB Connected for ${originalName}.`);

        // Update status to 'processing_analysis'
        await User.updateOne(
            { _id: userId, "uploadedDocuments.filename": originalName },
            { $set: { "uploadedDocuments.$.analysisStatus": "processing" } }
        );
        console.log(`[Analysis Worker ${process.pid}] Set analysisStatus to 'processing' for ${originalName}.`);


        if (!textForAnalysis || textForAnalysis.trim() === '') {
            console.warn(`[Analysis Worker ${process.pid}] No text provided for analysis for ${originalName}. Marking as skipped.`);
            await User.updateOne(
                { _id: userId, "uploadedDocuments.filename": originalName },
                { $set: { "uploadedDocuments.$.analysisStatus": "skipped_no_text", "uploadedDocuments.$.analysisTimestamp": new Date() } }
            );
            overallTaskSuccess = true; // Not a failure of the worker, just nothing to do.
            finalMessageToParent = "Analysis skipped: No text provided.";
            // Fall through to postMessage and finally block.
        } else {
            const analysisServiceResult = await performFullAnalysis(userId, originalName, textForAnalysis, llmProvider, ollamaModel);
            overallTaskSuccess = analysisServiceResult.success;
            finalMessageToParent = analysisServiceResult.message;
        }

        if (parentPort) {
            parentPort.postMessage({
                success: overallTaskSuccess,
                originalName: originalName,
                message: finalMessageToParent
                // Optionally send back analysisServiceResult.results if the main thread needs them
            });
        }

    } catch (error) {
        console.error(`[Analysis Worker ${process.pid}] Critical error processing '${originalName}':`, error.message, error.stack);
        finalMessageToParent = error.message || "Unknown critical error in Analysis worker.";
        overallTaskSuccess = false; // Ensure this is false on critical error
        if (dbConnected && userId && originalName) { // Check if userId & originalName are defined
            try {
                await User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: { "uploadedDocuments.$.analysisStatus": "failed_critical" } }
                );
            } catch (dbUpdateError) {
                console.error(`[Analysis Worker ${process.pid}] Failed to update status to 'failed_critical' for ${originalName} after error:`, dbUpdateError);
            }
        }
        if (parentPort) {
            parentPort.postMessage({ success: false, originalName, error: finalMessageToParent });
        }
    } finally {
        if (dbConnected) {
            await mongoose.disconnect().catch(e => console.error("[Analysis Worker] Error disconnecting DB:", e));
            console.log(`[Analysis Worker ${process.pid}] DB Disconnected for ${originalName}.`);
        }
        // The worker will exit automatically after the run() promise fulfills or rejects.
        // If parentPort exists, Node.js waits for messages or explicit exit.
        // If no parentPort (e.g. direct execution), we might need process.exit.
        // Since we expect parentPort, this is okay.
        console.log(`[Analysis Worker ${process.pid}] Finished task for ${originalName}. Overall Success: ${overallTaskSuccess}`);
    }
}

run();





```

`workers/kgWorker.js`

```javascript
// server/workers/kgWorker.js
const { workerData, parentPort } = require('worker_threads');
const mongoose = require('mongoose');

const User = require('../models/User');
const connectDB = require('../config/db');
const kgService = require('../services/kgService');

async function runKgGeneration() {
    const { chunksForKg: allInitialChunks, userId, originalName, llmProvider, ollamaModel } = workerData;
    let dbConnected = false;
    let overallSuccess = false;
    let finalMessage = "KG processing encountered an issue.";
    const logPrefix = `[KG Worker ${process.pid}, Doc: ${originalName}]`;

    try {
        console.log(`${logPrefix} Received task. User: ${userId}, Initial Chunks: ${allInitialChunks ? allInitialChunks.length : 0}`);
        if (!process.env.MONGO_URI) throw new Error("MONGO_URI not set in KG worker environment.");
        if (!userId || !originalName) throw new Error("Missing userId or originalName in KG workerData.");

        await connectDB(process.env.MONGO_URI);
        dbConnected = true;
        console.log(`${logPrefix} DB Connected.`);

        await User.updateOne(
            { _id: userId, "uploadedDocuments.filename": originalName },
            { $set: { "uploadedDocuments.$.kgStatus": "processing" } }
        );
        console.log(`${logPrefix} Status set to 'processing'.`);

        if (!allInitialChunks || allInitialChunks.length === 0) {
            console.log(`${logPrefix} No chunks provided for KG generation. Marking as skipped.`);
            await User.updateOne(
                { _id: userId, "uploadedDocuments.filename": originalName },
                { $set: { "uploadedDocuments.$.kgStatus": "skipped_no_chunks", "uploadedDocuments.$.kgTimestamp": new Date() } }
            );
            finalMessage = "No chunks provided for KG generation.";
            overallSuccess = true; // Not a failure of this worker's process
        } else {
            const kgExtractionResult = await kgService.generateAndStoreKg(allInitialChunks, userId, originalName, llmProvider, ollamaModel);

            if (kgExtractionResult && kgExtractionResult.success) {
                await User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: {
                        "uploadedDocuments.$.kgStatus": "completed",
                        "uploadedDocuments.$.kgNodesCount": kgExtractionResult.finalKgNodesCount,
                        "uploadedDocuments.$.kgEdgesCount": kgExtractionResult.finalKgEdgesCount,
                        "uploadedDocuments.$.kgTimestamp": new Date()
                        }
                    }
                );
                overallSuccess = true;
                finalMessage = kgExtractionResult.message || "KG generation and storage completed successfully.";
                console.log(`${logPrefix} SUCCESS: ${finalMessage}`);
            } else {
                await User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: { "uploadedDocuments.$.kgStatus": "failed_extraction" } }
                );
                finalMessage = (kgExtractionResult && kgExtractionResult.message) ? kgExtractionResult.message : "KG detailed extraction or storage failed.";
                console.error(`${logPrefix} FAILED (Extraction/Store): ${finalMessage}`);
                overallSuccess = false;
            }
        }

        if (parentPort) {
            parentPort.postMessage({ success: overallSuccess, originalName, message: finalMessage });
        }

    } catch (error) {
        console.error(`${logPrefix} CRITICAL error:`, error.message, error.stack);
        finalMessage = error.message || "Unknown critical error in KG worker.";
        overallSuccess = false;
        if (dbConnected && userId && originalName) {
            try {
                await User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: { "uploadedDocuments.$.kgStatus": "failed_critical" } }
                );
            } catch (dbUpdateError) {
                console.error(`${logPrefix} DB update error on critical fail:`, dbUpdateError);
            }
        }
        if (parentPort) {
            parentPort.postMessage({ success: false, originalName, error: finalMessage });
        }
    } finally {
        if (dbConnected) {
            await mongoose.disconnect().catch(e => console.error(`${logPrefix} Error disconnecting DB:`, e));
            console.log(`${logPrefix} DB Disconnected.`);
        }
        console.log(`${logPrefix} Finished task. Overall Success: ${overallSuccess}`);
    }
}

runKgGeneration();
```


```

`server/config/db.js`

```javascript
const mongoose = require('mongoose');
// const dotenv = require('dotenv'); // Removed dotenv

// dotenv.config(); // Removed dotenv

// Modified connectDB to accept the URI as an argument
const connectDB = async (mongoUri) => {
  if (!mongoUri) {
      console.error('MongoDB Connection Error: URI is missing.');
      process.exit(1);
  }
  try {
    // console.log(`Attempting MongoDB connection to: ${mongoUri}`); // Debug: Careful logging URI
    const conn = await mongoose.connect(mongoUri, {
      // Mongoose 6+ uses these defaults, so they are not needed
      // useNewUrlParser: true,
      // useUnifiedTopology: true,
      // serverSelectionTimeoutMS: 5000 // Example: Optional: Timeout faster
    });

    console.log(` MongoDB Connected Successfully`); // Simpler success message
    return conn; // Return connection object if needed elsewhere
  } catch (error) {
    console.error('MongoDB Connection Error:', error.message);
    // Exit process with failure
    process.exit(1);
  }
};

module.exports = connectDB;

```

`server/config/promptTemplates.js`

```javascript
// server/config/promptTemplates.js

// ==============================================================================
// === DOCUMENT ANALYSIS PROMPTS (for FAQ, Topics, Mindmap) ===
// ==============================================================================

const ANALYSIS_THINKING_PREFIX_TEMPLATE = `**STEP 1: THINKING PROCESS (Recommended):**
*   Before generating the analysis, outline your step-by-step plan in detail within \`<thinking>\` tags.
*   Use Markdown for formatting within your thinking process (e.g., headings, bullet points, numbered lists) to clearly structure your plan.
*   Example of detailed thinking:
    \`\`\`
    <thinking>
    ## FAQ Generation Plan
    1.  **Understand Goal:** Generate 5-7 FAQs based *only* on the provided text.
    2.  **Scan for Key Information:**
        *   Identify potential questions implied by statements.
        *   Look for definitions, explanations, or problem/solution pairings.
    3.  **Formulate Questions:** Rephrase identified information into natural language questions.
    4.  **Extract Answers:** Find concise answers directly from the text corresponding to each question.
    5.  **Format Output:** Ensure each Q/A pair follows the 'Q: ... A: ...' format.
    6.  **Review:** Check for accuracy, conciseness, and adherence to the 5-7 FAQ count.
    </thinking>
    \`\`\`
*   If you include thinking, place the final analysis *after* the \`</thinking>\` tag.

**STEP 2: ANALYSIS OUTPUT:**
*   Generate the requested analysis based **strictly** on the text provided below.
*   Follow the specific OUTPUT FORMAT instructions carefully.

--- START DOCUMENT TEXT ---
{doc_text_for_llm}
--- END DOCUMENT TEXT ---
`;

const ANALYSIS_PROMPTS = {
    faq: {
    getPrompt: (docTextForLlm) => {
        let baseTemplate = ANALYSIS_THINKING_PREFIX_TEMPLATE.replace('{doc_text_for_llm}', docTextForLlm);
        baseTemplate += `
**TASK:** Generate a set of 10-15 Frequently Asked Questions (FAQs) with concise answers based ONLY on the provided text. To ensure a logical flow, you MUST organize the FAQs by the main themes found in the document.

**OUTPUT FORMAT (Strict):**
1.  **Thematic Grouping:** Identify 5-6 major themes from the document. For each theme, create a Markdown H2 heading (e.g., \`## Core Concepts\`).
2.  **Question as Sub-Heading:** Under each theme, each question MUST be a Markdown H3 heading (e.g., \`### 1. What is the primary subject?\`).
3.  **Answer as Text:** The answer should follow directly after the question's heading as a standard paragraph.
4.  **Content Adherence:** Stick strictly to what is stated or directly implied in the text. Do not invent information.
5.  **Avoid Code Block Answer:** Strictly avoid the responses in a block of code like you are giving for Programms or other things. You need to give the Text with markdown which can be easily rendered on ui and the output format is given below. Again I am saying dont give the output in code block with markdown. Give the output as markdown text. If you do like that I will not use again for this responses.

**EXAMPLE OUTPUT STRUCTURE:**

## Core Concepts

### What is the primary subject of the document?
The document is about the five-part process for improving communication skills, focusing on changing habits through self-assessment and a structured plan.

### 1. What is the definition of a "transcription audit"?
A transcription audit is the process of reviewing a transcribed video of oneself to highlight and become aware of non-words and filler words like "um," "ah," and "like."

## Self-Assessment Process

### 1. What is the first step in the self-assessment process?
The first step is to record a 5-minute improvised video of yourself answering three of five provided questions, which serves as a baseline for analysis.

**BEGIN OUTPUT (Start with '##' for the first theme or \`<thinking>\`):**
`;
        return baseTemplate;
    }
    },
    topics: {
        getPrompt: (docTextForLlm) => {
            let baseTemplate = ANALYSIS_THINKING_PREFIX_TEMPLATE.replace('{doc_text_for_llm}', docTextForLlm);
            baseTemplate += `
**TASK:** Identify the 5-7 most important topics or concepts from the provided text. For each topic, provide a clear explanation and include a specific example or key data point from the text to illustrate it.

**OUTPUT FORMAT (Strict):**
*   Use Markdown H3 (###) for each topic name for clear separation and structure.
**  Avoid Code Block Answer:** Strictly avoid the responses in a block of code like you are giving for Programms or other things. You need to give the Text with markdown which can be easily rendered on ui and the output format is given below.
*   Beneath each heading, provide:
    *   An **Explanation:** of the topic in your own words, but based strictly on the text. Start this with the bolded label '**Explanation:**'.
    *   A specific **Example from Text:**. Start this with the bolded label '**Example from Text:**' followed by a direct quote or a paraphrased key data point from the source document.

**EXAMPLE OUTPUT STRUCTURE:**

### Topic 1: Name of the First Key Concept
**Explanation:** A brief summary of what this concept is and why it's important, according to the document.
**Example from Text:** "The document states that 'the reaction requires a temperature of over 100 million degrees Celsius' which highlights the extreme conditions needed."

### Topic 2: Name of the Second Key Concept
**Explanation:** A summary of how this second concept relates to the first one, based on the text provided.
**Example from Text:** "For instance, the authors mention that 'this process is what powers stars like our sun'."

**BEGIN OUTPUT (Start with '###' for the first topic or \`<thinking>\`):**
`;
            return baseTemplate;
        }
    },
    mindmap: {
        getPrompt: (docTextForLlm) => {
            let baseTemplate = ANALYSIS_THINKING_PREFIX_TEMPLATE.replace('{doc_text_for_llm}', docTextForLlm);
            // --- THIS IS THE FIX ---
            baseTemplate += `
**TASK:** Generate a mind map in Mermaid.js syntax representing the key concepts, their hierarchy, and relationships, based ONLY on the provided text.

**CORE REQUIREMENTS FOR MERMAID SYNTAX:**
1.  **Direction:** Use \`graph TD;\` (Top Down) or \`graph LR;\` (Left to Right).
2.  **Nodes:** Define unique IDs (e.g., \`A\`, \`B1\`) and concise labels derived from the text (e.g., \`A["Main Idea"]\`).
3.  **Edges:** Show relationships using \`-->\`.
4.  **Hierarchy:** The central theme should be the primary node.
5.  **Content Focus:** The mind map content MUST be strictly derived from the provided document text.

**OUTPUT FORMAT (Strict):**
*   Start with your detailed \`<thinking>\` block if you use one.
*   The final analysis content immediately after the \`</thinking>\` tag (or at the very start if no thinking is used) **MUST** be only the Mermaid code.
*   Do **NOT** wrap the Mermaid code in Markdown fences like \`\`\`mermaid ... \`\`\`.
*   Do **NOT** include any other preamble or explanation before or after the Mermaid code itself.

**BEGIN OUTPUT (Start with 'graph TD;', 'mindmap', or \`<thinking>\`):**
`;
            // --- END OF FIX ---
            return baseTemplate;
        }
    }
};


// ==============================================================================
// === KNOWLEDGE GRAPH (KG) PROMPTS ===
// ==============================================================================

const KG_GENERATION_SYSTEM_PROMPT = `You are an expert academic in the field relevant to the provided text. Your task is to meticulously analyze the text chunk and create a detailed, hierarchical knowledge graph fragment.
The output MUST be a valid JSON object with "nodes" and "edges" sections.

Instructions for Node Creation:
1.  Identify CORE CONCEPTS or main topics discussed in the chunk. These should be 'major' nodes (parent: null).
2.  Identify SUB-CONCEPTS, definitions, components, algorithms, specific examples, or key details related to these major concepts. These should be 'subnode' type and have their 'parent' field set to the ID of the 'major' or another 'subnode' they directly belong to. Aim for a granular breakdown.
3.  Node 'id': Use a concise, descriptive, and specific term for the concept (e.g., "Linear Regression", "LMS Update Rule", "Feature Selection"). Capitalize appropriately.
4.  Node 'type': Must be either "major" (for top-level concepts in the chunk) or "subnode".
5.  Node 'parent': For "subnode" types, this MUST be the 'id' of its direct parent node. For "major" nodes, this MUST be null.
6.  Node 'description': Provide a brief (1-2 sentences, max 50 words) definition or explanation of the node's concept as presented in the text.

Instructions for Edge Creation:
1.  Edges represent relationships BETWEEN the nodes you've identified.
2.  The 'from' field should be the 'id' of the child/more specific node.
3.  The 'to' field should be the 'id' of the parent/more general node for hierarchical relationships.
4.  Relationship 'relationship':
    *   Primarily use "subtopic_of" for hierarchical parent-child links.
    *   Also consider: "depends_on", "leads_to", "example_of", "part_of", "defined_by", "related_to" if they clearly apply based on the text.
5.  Ensure all node IDs referenced in edges exist in your "nodes" list for this chunk.

Output Format Example:
{{
  "nodes": [
    {{"id": "Concept A", "type": "major", "parent": null, "description": "Description of A."}},
    {{"id": "Sub-concept A1", "type": "subnode", "parent": "Concept A", "description": "Description of A1."}},
    {{"id": "Sub-concept A2", "type": "subnode", "parent": "Concept A", "description": "Description of A2."}},
    {{"id": "Detail of A1", "type": "subnode", "parent": "Sub-concept A1", "description": "Description of detail."}}
  ],
  "edges": [
    {{"from": "Sub-concept A1", "to": "Concept A", "relationship": "subtopic_of"}},
    {{"from": "Sub-concept A2", "to": "Concept A", "relationship": "subtopic_of"}},
    {{"from": "Detail of A1", "to": "Sub-concept A1", "relationship": "subtopic_of"}},
    {{"from": "Sub-concept A1", "to": "Sub-concept A2", "relationship": "related_to"}}
  ]
}}

Analyze the provided text chunk carefully and generate the JSON. Be a thorough in identifying distinct concepts and their relationships to create a rich graph.
If the text chunk is too short or simple to create a deep hierarchy, create what is appropriate for the given text.
`;

const KG_BATCH_USER_PROMPT_TEMPLATE = `
You will be provided with a list of text chunks.
For EACH text chunk, you MUST perform the following:
1. Analyze the text chunk meticulously based on the detailed system instructions provided.
2. Create a detailed, hierarchical knowledge graph fragment.
3. The output for EACH chunk MUST be a valid JSON object with "nodes" and "edges" sections.

Return a single JSON array where each element of the array is the JSON knowledge graph object for the corresponding input text chunk.
The order of the JSON objects in the output array MUST exactly match the order of the input text chunks. Do not add any other text before or after the JSON array.

Here are the text chunks:
{BATCHED_CHUNK_TEXTS_HERE}

Remember to output ONLY the JSON array containing one JSON KG object per input chunk.
`;


// ==============================================================================
// === CHAT & AGENT PROMPTS ===
// ==============================================================================

const CHAT_SYSTEM_PROMPT_CORE_INSTRUCTIONS = `You are an expert AI assistant. Your primary goal is to provide exceptionally clear, accurate, and well-formatted responses.

**Core Principles for Your Response:**
1.  **Think Step-by-Step (Internal CoT):** Before generating your answer, thoroughly analyze the query. Break down complex questions. Outline the logical steps and information needed. This is your internal process to ensure a high-quality response.
2.  **Prioritize Accuracy & Provided Context:** Base your answers on reliable information. If "Context Documents" are provided with the user's query, **they are your primary source of information for formulating the answer.** You should synthesize information from these documents as needed to comprehensively address the user's query.
3.  **Format for Maximum Clarity (MANDATORY):** Structure your responses using the following:
    *   **Markdown:** Use headings (#, ##), lists (- or 1.), bold (**text**), italics (*text*), and blockquotes (>) effectively.
    *   **KaTeX for Math:**
        *   Block Math: ALWAYS use \`<p>$$[expression]$$</p>\`. Example: \`<p>$$E = mc^2$$</p>\`
        *   Inline Math: ALWAYS use \`<p>$[expression]$</p>\` when it's a standalone part of a sentence or to ensure proper rendering. Example: \`An example is <p>$x_i$</p>.\` or \`If <p>$a=b$</p> and <p>$b=c$</p>, then <p>$a=c$</p>.\` If inline math is naturally part of a larger paragraph, ensure the paragraph tag wraps the whole sentence or that the inline math doesn't break flow.
    *   **Code Blocks:** Use \`\`\`language ... \`\`\` for code. Specify the language if known.
    *   **Tables:** Use Markdown tables for structured data.
    *   **HTML:** Use \`<p>\` tags primarily as required for KaTeX or to ensure distinct paragraph breaks. Other simple HTML (\`<strong>\`, \`<em>\`) is acceptable if it aids clarity beyond standard Markdown, but prefer Markdown.
4.  **Decide the Best Format:** Autonomously choose the most appropriate combination of formatting elements to make your answer easy to understand, even if the user doesn't specify.

**Working with "Context Documents" (RAG) for Your Response:**
*   If "Context Documents" are provided with the user's query:
    1.  **Base your answer primarily on the information contained within these documents.**
    2.  **Synthesize:** Combine information from multiple documents if needed. Explain in your own words, drawing from the provided text.
    3.  **Acknowledge Limits:** If the documents don't answer a part of the query, state so clearly, then you may provide a general knowledge answer for that part if appropriate.
    4.  **DO NOT INCLUDE CITATION MARKERS like [1], [2] in your textual response.** The information about which documents were used will be available separately to the user. Your answer should read naturally as if drawing from this knowledge.

**Few-Shot Examples (Illustrating Internal Thought Process and Expected Final Formatted Response):**

---
**Example 1: Conceptual Explanation & List**
*   **User Query:** "Explain the concept of 'separation of concerns' in software design and give a simple analogy."
*   **(Simulated Internal Thought Process by LLM):**
    *   Define SoC.
    *   Identify key benefits (modularity, reusability, reduced complexity).
    *   Develop analogy (kitchen with distinct work areas).
    *   Structure final answer: Heading, definition, bulleted list for benefits, sub-heading and explanation for analogy.
    *   Formatting: Use Markdown headings, bold, lists.
*   **Expected Formatted Response (Directly to User):**
    \`\`\`
    ## Separation of Concerns

    <p><strong>Separation of Concerns (SoC)</strong> is a fundamental design principle for separating a computer program into distinct sections such that each section addresses a separate concern (a piece of information or functionality).</p>

    <p><strong>Key Benefits:</strong></p>
    <ul>
    <li><strong>Modularity:</strong> Easier to develop, test, and maintain individual sections.</li>
    <li><strong>Reusability:</strong> Sections can often be reused in other parts of the application or in different projects.</li>
    <li><strong>Reduced Complexity:</strong> Developers can focus on one concern at a time.</li>
    </ul>

    <h3>Analogy: A Well-Organized Kitchen</h3>
    <p>Think of a well-organized kitchen:</p>
    <ul>
    <li>You have a designated area for <strong>food preparation</strong> (cutting boards, knives).</li>
    <li>Another for <strong>cooking</strong> (stove, oven).</li>
    <li>And another for <strong>cleaning</strong> (sink, dishwasher).</li>
    </ul>
    <p>Each area (concern) has its own tools and purpose. If you want to change how you wash dishes (e.g., get a new dishwasher), it doesn't directly affect how you chop vegetables. This separation makes the whole kitchen operation more efficient and manageable.</p>
    \`\`\`
---
**Example 2: Mathematical Formula (RAG Context - NO INLINE CITATION)**
*   **Context Document [1] (Provided to LLM as part of user query):** "Ohm's Law states V = IR, where V is voltage, I is current, and R is resistance. This was discovered by Georg Ohm."
*   **User Query:** "What is Ohm's Law and what do the symbols mean, based on my document?"
*   **(Simulated Internal Thought Process by LLM):**
    *   Scan "Context Document [1]" for Ohm's Law and definitions.
    *   Extract formula V = IR and variable meanings.
    *   Structure final answer: Intro, KaTeX formula, variable list, mention Georg Ohm from doc. No "[1]" in output.
    *   Formatting: KaTeX \`<p>$$...$$</p>\`, Markdown bold, paragraph tags.
*   **Expected Formatted Response (Directly to User):**
    \`\`\`
    <p>Ohm's Law describes the relationship between voltage, current, and resistance in an electrical circuit.</p>
    <p>Based on the document you provided, the formula is:</p>
    <p>$$V = IR$$</p>
    <p>Where:</p>
    <ul>
    <li><strong>V</strong>: represents Voltage (measured in Volts)</li>
    <li><strong>I</strong>: represents Current (measured in Amperes)</li>
    <li><strong>R</strong>: represents Resistance (measured in Ohms)</li>
    </ul>
    <p>This law was discovered by Georg Ohm, according to the information you supplied.</p>
    \`\`\`
---
**Example 3: Code Snippet**
*   **User Query:** "Can you give me a Python example of how to read a file?"
*   **(Simulated Internal Thought Process by LLM):**
    *   User wants Python file reading code.
    *   Use \`with open(...)\` for best practice.
    *   Include basic error handling (\`try-except\`).
    *   Explain the code.
    *   Structure: Intro, code block, explanation.
    *   Formatting: Markdown, Python code block.
*   **Expected Formatted Response (Directly to User):**
    \`\`\`
    <p>Certainly! Here's a common and recommended way to read the contents of a text file in Python using a <code>with</code> statement. This ensures the file is properly closed even if errors occur:</p>

    \`\`\`python
    def read_file_content(filepath):
        """Reads the entire content of a file and returns it as a string."""
        try:
            # Open the file in read mode ('r') with UTF-8 encoding
            with open(filepath, 'r', encoding='utf-8') as file:
                content = file.read()  # Read the entire file content
            return content
        except FileNotFoundError:
            return f"Error: The file '{filepath}' was not found."
        except Exception as e:
            return f"An error occurred: {e}"

    # Example usage:
    # file_path = 'my_document.txt' 
    # content = read_file_content(file_path)
    # 
    # if not content.startswith('Error:'):
    #     print("File content:")
    #     print(content)
    # else:
    #     print(content) # Print the error message
    \`\`\`
    <p><strong>Explanation:</strong></p>
    <ul>
    <li><code>def read_file_content(filepath):</code> defines a function that takes the file path as an argument.</li>
    <li><code>with open(filepath, 'r', encoding='utf-8') as file:</code> opens the file. 
        <ul>
        <li><code>'r'</code> means read mode.</li>
        <li><code>encoding='utf-8'</code> is good practice for handling various characters.</li>
        <li>The <code>with</code> statement ensures <code>file.close()</code> is called automatically.</li>
        </ul>
    </li>
    <li><code>content = file.read()</code> reads the entire file into the <code>content</code> variable.</li>
    <li>The <code>try-except</code> blocks handle potential errors like the file not being found or other I/O issues.</li>
    </ul>
    <p>Replace <code>'my_document.txt'</code> with the actual path to your file when you use the example.</p>
    \`\`\`
---
`;

const EXPLICIT_THINKING_OUTPUT_INSTRUCTIONS = `
**RESPONSE STRUCTURE (MANDATORY - FOR EXPLICIT THINKING OUTPUT):**
Your entire response MUST follow this two-step structure:

**STEP 1: MANDATORY THINKING PROCESS (OUTPUT FIRST):**
*   Before generating your final answer, you MUST outline your step-by-step plan and reasoning process in detail.
*   Place this entire thinking process within \`<thinking>\` and \`</thinking>\` tags.
*   This \`<thinking>...\</thinking>\` block MUST be the very first thing in your output. No preambles or any other text before it.
*   Use Markdown for formatting within your thinking process (e.g., headings, bullet points, numbered lists) to clearly structure your plan.
*   Your thinking process should be appropriate for the complexity of the query. For simple greetings, a brief plan is sufficient. For complex questions, provide a more detailed breakdown.
*   Example of detailed thinking structure:
    \`\`\`
    <thinking>
    1.  **Analyze Query:** The user is asking for a conceptual explanation and an analogy.
    2.  **Deconstruct:** I need to define the concept first, then list its benefits, and finally create a simple, relatable analogy.
    3.  **Formatting Plan:** I will use Markdown headings for structure, bold for key terms, and bullet points for the list of benefits.
    </thinking>
    \`\`\`

**STEP 2: FINAL ANSWER (AFTER \`</thinking>\`):**
*   After the closing \`</thinking>\` tag, generate your comprehensive and well-formatted answer based on your thinking process and the user's query.
*   Follow all formatting guidelines (Markdown, KaTeX, etc.) as instructed for this final answer part.
`;

const CHAT_MAIN_SYSTEM_PROMPT = () => {
    return `${CHAT_SYSTEM_PROMPT_CORE_INSTRUCTIONS}\n\n${EXPLICIT_THINKING_OUTPUT_INSTRUCTIONS}`;
};


const WEB_SEARCH_CHAT_SYSTEM_PROMPT = `You are a helpful AI research assistant. Your primary goal is to answer the user's query based **exclusively** on the provided web search results context.

**Core Instructions:**
1.  **Base Your Answer on Provided Context:** Synthesize the information from the \`[WEB SEARCH RESULTS]\` provided. Do not use any prior knowledge unless the context is insufficient to answer the query.
2.  **Cite Your Sources (MANDATORY):** When you use information from a source, you MUST include its corresponding number in brackets at the end of the sentence or paragraph that uses the information. For example: "The sky appears blue due to Rayleigh scattering [1]." If information comes from multiple sources, cite them all, like so: "[2, 3]".
3.  **Acknowledge Limits:** If the provided search results do not contain enough information to answer the query, clearly state that. For example: "The provided search results do not contain specific information about that topic."
4.  **Format for Clarity:** Use Markdown (lists, bolding, etc.) to structure your answer clearly.
`;

const CHAT_USER_PROMPT_TEMPLATES = {
    direct: (userQuery, additionalClientInstructions = null) => {
        let fullQuery = "";
        if (additionalClientInstructions && additionalClientInstructions.trim() !== "") {
            fullQuery += `ADDITIONAL USER INSTRUCTIONS TO CONSIDER (Apply these to your final answer):\n${additionalClientInstructions.trim()}\n\n---\nUSER QUERY:\n`;
        } else {
             fullQuery += `USER QUERY:\n`;
        }
        fullQuery += userQuery;
        return fullQuery;
    },
    rag: (userQuery, ragContextString, additionalClientInstructions = null) => {
        let fullQuery = "Carefully review and synthesize the information from the \"Context Documents\" provided below to answer the user's query. Your answer should be primarily based on these documents. Do NOT include any citation markers like [1], [2] etc. in your response text.\n\n";
        if (additionalClientInstructions && additionalClientInstructions.trim() !== "") {
            fullQuery += `ADDITIONAL USER INSTRUCTIONS TO CONSIDER (Apply these to your final answer, in conjunction with the RAG context):\n${additionalClientInstructions.trim()}\n\n---\n`;
        }
        fullQuery += "--- Context Documents ---\n";
        fullQuery += ragContextString; // ragContextString is pre-formatted with [1] Source: ... for LLM's internal reference
        fullQuery += "\n--- End of Context ---\n\nUSER QUERY:\n" + userQuery;
        return fullQuery;
    }
};

// ==============================================================================
// === ToT Orchestrator  ===
// ==============================================================================
const PLANNER_PROMPT_TEMPLATE = `
You are a meticulous AI planning agent. Your task is to analyze the user's query and generate 2-3 distinct, logical, step-by-step plans to answer it.

**User Query:** "{userQuery}"

**Instructions:**
1.  Create 2-3 unique plans. Each plan should have a descriptive "name".
2.  Each plan must contain a list of "steps". Each step should be a clear, single-sentence instruction for a research agent (e.g., "Search the web for recent reviews of product X," "Analyze the provided document for mentions of 'cost analysis'").
3.  Your entire output MUST be a single, valid JSON object containing a "plans" array. Do not provide any other text or explanation.

**Example JSON Output Format:**
\`\`\`json
{
  "plans": [
    {
      "name": "Comprehensive Research Plan",
      "steps": [
        "First, search internal documents for foundational concepts related to the query.",
        "Second, perform a web search for the latest real-world applications.",
        "Finally, synthesize the findings from both internal and external sources."
      ]
    },
    {
      "name": "Quick Answer Plan",
      "steps": [
        "Perform a direct web search for the user's query to find an immediate answer."
      ]
    }
  ]
}
\`\`\`

Provide your JSON response now.
`;

const EVALUATOR_PROMPT_TEMPLATE = `
You are an expert AI plan evaluator. Your task is to analyze a user's query and a list of proposed plans, and select the single best plan to execute. The best plan is the one that is most logical, efficient, and likely to produce a comprehensive and accurate answer.

**User Query:** "{userQuery}"

**Proposed Plans:**
{plansJsonString}

**Instructions:**
1.  Review the query and each plan carefully.
2.  Choose the plan with the most logical and effective sequence of steps.
3.  Your entire output MUST be a single, valid JSON object with a single key "best_plan_name" whose value is the exact name of the plan you have chosen. Do not provide any other text or explanation.

**Example JSON Output Format:**
\`\`\`json
{
  "best_plan_name": "Comprehensive Research Plan"
}
\`\`\`

Provide your JSON decision now.
`;


// ==============================================================================
// === AGENTIC FRAMEWORK PROMPTS - V5 (Classification-Based Logic) ===
// ==============================================================================
const createAgenticSystemPrompt = (modelContext, agenticContext, requestContext) => {
  const userQueryForPrompt = requestContext.userQuery || "[User query not provided]";
  let activeModeInstructions;

  if (requestContext.isWebSearchEnabled) {
      activeModeInstructions = `**CURRENT MODE: Web Search.** The user has manually enabled web search. Your decision MUST be 'web_search'. This is not optional.`;
  } else if (requestContext.isAcademicSearchEnabled) {
      activeModeInstructions = `**CURRENT MODE: Academic Search.** The user has manually enabled academic search. Your decision MUST be 'academic_search'. This is not optional.`;
  } else if (requestContext.documentContextName) {
      activeModeInstructions = `**CURRENT MODE: Document RAG.** The user has selected a document named "${requestContext.documentContextName}". Your decision MUST be 'rag_search'. This is not optional.`;
  } else {
      activeModeInstructions = `**CURRENT MODE: Direct Chat.** No specific tool has been selected. Analyze the user's query to decide. If it requires real-time information or external knowledge, choose 'web_search'. For academic papers or scholarly articles, choose 'academic_search'. For all other general queries, definitions, or explanations, your decision MUST be 'direct_answer'.`;
  }

  return `
You are a "Router" agent. Your single task is to analyze the user's query and the current context, and then decide which of the available tools to use, or if you should answer directly.

**AVAILABLE TOOLS:**
${JSON.stringify(modelContext.available_tools, null, 2)}

**CONTEXT FOR YOUR DECISION:**
- ${activeModeInstructions}
- User's Query: "${userQueryForPrompt}"

**YOUR TASK:**
Based on the CURRENT MODE and the USER'S QUERY, choose one action. Your entire output MUST be a single, valid JSON object with a "tool_call" key. Do not provide any other text or explanation.

- If your decision is to use a tool, format as:
  \`\`\`json
  {
    "tool_call": {
      "tool_name": "the_tool_name_you_chose",
      "parameters": { "query": "${userQueryForPrompt}" }
    }
  }
  \`\`\`

- If your decision is to answer directly without a tool, format as:
  \`\`\`json
  {
    "tool_call": null
  }
  \`\`\`

Provide your JSON decision now.
`;
};


// const createSynthesizerPrompt = (originalQuery, toolOutput, toolName) => {
//     // Shared instruction block for all synthesizer prompts
//     const formattingInstructions = `
// **Formatting Guidelines (MANDATORY):**
// - **Structure:** Use Markdown for headings (#, ##), lists (- or 1.), bold (**text**), italics (*text*), and blockquotes (>).
// - **Clarity:** Use the most appropriate combination of formatting elements to make your answer easy to read and understand.
// - **Tables:** If data is tabular, present it as a Markdown table.
// - **Code:** If the answer involves code, use fenced code blocks with language identifiers (e.g., \`\`\`python ... \`\`\`).
// `;

//     // Default prompt for RAG and other tools (no change here)
// let systemInstruction = `You are an expert AI Tutor. A tool was used to gather the following information to help answer the user's original query. Your task is to synthesize this information into a single, comprehensive, and helpful response.

// **Response Guidelines:**
// 1.  **PRIORITIZE TOOL OUTPUT:** Your primary responsibility is to accurately represent the information from the "INFORMATION GATHERED BY TOOL" section. The core of your answer **MUST** come from this provided context.
// 2.  **BE COMPREHENSIVE:** Do not just give a one-sentence answer. Elaborate on the information found, providing context and detailed explanations based on the tool's output.
// 3.  **SEAMLESS INTEGRATION:** Present the final answer as a single, coherent response. Do **NOT** mention that a tool was used.
// 4.  **DO NOT CITE:** Do not include citation markers like [1], [2] in your answer. This will be handled separately.

// ${formattingInstructions}

// ---
// **USER'S ORIGINAL QUERY:**
// ${originalQuery}
// ---
// **INFORMATION GATHERED BY TOOL (Output from '${toolName}'):**
// ${toolOutput}
// ---

// **FINAL, DETAILED, AND WELL-FORMATTED ANSWER:**
// `;

//     // --- **THIS IS THE MODIFIED SECTION FOR WEB SEARCH** ---
//     if (toolName === 'web_search') {
//         systemInstruction = `
// You are an expert AI Research Assistant. Your task is to synthesize the provided "WEB SEARCH RESULTS" into a comprehensive, detailed, and helpful response to the user's query.

// Your final response MUST follow this two-part structure precisely:
// A detailed, well-written answer to the user's query.
// **References Section:** A formatted list of the sources used.

// ---
// **PART 1: MAIN ANSWER INSTRUCTIONS**

// -   Your answer **MUST** be based on the provided search results.
// -   When you use information from a source, you **MUST** include its corresponding number in brackets. For example: "The sky appears blue due to Rayleigh scattering [1]." If information comes from multiple sources, cite them all, like so: "[2, 3]".
// -   Be comprehensive. Do not just give a one-sentence answer. Synthesize information from multiple sources to build a full, well-rounded explanation.
// -   Use rich Markdown formatting (headings, lists, bolding, tables) to make the answer clear and engaging.

// ---
// **PART 2: REFERENCES SECTION INSTRUCTIONS**

// -   After you have finished writing the main answer, add a horizontal rule (\`---\`).
// -   After the line, add a heading: \`## References\`.
// -   Below the heading, create a numbered list of all the sources you cited.
// -   Format each reference like this: \`[1] [Source Title](Source URL)\`.

// ---
// **EXAMPLE OF COMPLETE OUTPUT:**

// The sky appears blue due to a phenomenon called Rayleigh scattering [1]. This is where shorter wavelengths of light, like blue and violet, are scattered more effectively by the small molecules of gas in the Earth's atmosphere than longer wavelengths like red and yellow [2]. While violet light is scattered even more than blue, our eyes are more sensitive to blue light, which is why we perceive the sky as blue [1, 3].

// ---
// ## References
// [1] [Why Is the Sky Blue? - NASA SpacePlace](https://spaceplace.nasa.gov/blue-sky/en/)
// [2] [Rayleigh scattering - Wikipedia](https://en.wikipedia.org/wiki/Rayleigh_scattering)
// [3] [Optics: The Blue Sky - The Physics Classroom](https://www.physicsclassroom.com/class/light/Lesson-2/Blue-Skies)

// ---
// **Now, perform this task using the following information:**

// **USER'S ORIGINAL QUERY:**
// ${originalQuery}

// **WEB SEARCH RESULTS:**
// ${toolOutput}

// **YOUR COMPLETE, FORMATTED RESPONSE:**
// `;
//     }

//     return systemInstruction;
// };



// ==============================================================================
// === CONTENT CREATION PROMPTS (PPTX, DOCX, PODCAST) ===
// ==============================================================================

const createSynthesizerPrompt = (originalQuery, toolOutput, toolName) => {
    let synthesizerUserMessage;

    if (toolName === 'web_search') {
        synthesizerUserMessage = `
You are an expert AI Research Assistant. Your task is to synthesize the provided "WEB SEARCH RESULTS" into a comprehensive, detailed, and helpful response to the user's query.

Your final response MUST follow this two-part structure precisely:
1.  A detailed, well-written answer to the user's query.
2.  A "**References**" section with a formatted list of the sources used.

**PART 1: MAIN ANSWER INSTRUCTIONS**
-   Your answer **MUST** be based on the provided search results.
-   When you use information from a source, you **MUST** include its corresponding number in brackets. For example: "The sky appears blue due to Rayleigh scattering [1]." If information comes from multiple sources, cite them all, like so: "[2, 3]".
-   Be comprehensive. Do not just give a one-sentence answer. Synthesize information from multiple sources to build a full, well-rounded explanation.
-   Use rich Markdown formatting (headings, lists, bolding, tables) to make the answer clear and engaging.

**PART 2: REFERENCES SECTION INSTRUCTIONS**
-   After you have finished writing the main answer, add a horizontal rule (\`---\`).
-   After the line, add a heading: \`## References\`.
-   Below the heading, create a numbered list of all the sources you cited.
-   Format each reference like this: \`[1] [Source Title](Source URL)\`.

---
**Now, perform this task using the following information:**

**USER'S ORIGINAL QUERY:**
${originalQuery}

**WEB SEARCH RESULTS:**
${toolOutput}

**YOUR COMPLETE, FORMATTED RESPONSE:**
`;
    } 
    else if (toolName === 'academic_search') {
        synthesizerUserMessage = `
You are an expert AI Research Assistant. Your entire response MUST begin with your inner monologue in a \`<thinking>\` block, followed by a detailed, multi-part answer.

**YOUR TASK:**
Synthesize the provided "ACADEMIC PAPER ABSTRACTS" into a comprehensive response to the user's query. Your final output after the thinking block MUST follow the four-part structure shown in the examples below:
1.  **Analysis of Retrieved Articles (H2 Heading):** An analysis of EACH paper.
2.  **Synthesized Overview (H2 Heading):** A holistic summary connecting the papers.
3.  **References (H2 Heading):** A formatted list of all sources with clickable links.

---
**EXAMPLE 1 OF COMPLETE OUTPUT:**

**USER'S ORIGINAL QUERY:** "Give me an overview of how AI is used in the SDLC."
**ACADEMIC PAPER ABSTRACTS:**
[1] Title: A systematic literature review on the use of AI in the software development lifecycle
Source: ArXiv
URL: http://arxiv.org/abs/2304.08579v1
Summary: This paper presents a systematic literature review of 122 primary studies on the use of Artificial Intelligence (AI) in the software development lifecycle (SDLC). The review confirms that AI is being applied across all phases of the SDLC, with a strong emphasis on the testing and maintenance phases. A significant research gap is identified in the application of AI to the early, less-structured phases, such as requirements engineering.

[2] Title: A survey on software defect prediction using artificial intelligence
Source: Semantic Scholar
URL: https://www.semanticscholar.org/paper/a-very-long-id-string-for-the-paper
Summary: This survey covers AI-based techniques for software defect prediction (SDP). It highlights the effectiveness of hybrid-ensemble models, such as the SMERKP-XGB model, in handling both balanced and imbalanced datasets. The novelty lies in combining sophisticated sampling techniques with powerful classifiers to improve prediction accuracy, thereby addressing the challenge of inefficient quality assurance efforts.

**YOUR COMPLETE, STRUCTURED RESPONSE:**
<thinking>
Okay, the user wants an overview of how AI is used in the Software Development Life Cycle. This requires a structured, evidence-based response. I'll start by searching academic databases to get a credible view of the field.

My search has yielded a couple of interesting papers. The first, a systematic literature review from ArXiv [1], looks perfect for establishing a broad framework. It analyzes 122 studies, which gives it a lot of authority. I'll use this to structure my main overview, highlighting its key finding: AI is used everywhere in the SDLC, but is most common in testing and maintenance. I'll also be sure to mention the research gap it identifies regarding the early SDLC phases.

The second paper [2] is a survey on software defect prediction. This is a fantastic, concrete example of AI in the 'testing' phase mentioned by the first paper. I'll analyze its specific contributionthe SMERKP-XGB modeland explain *why* it's novel (its ability to handle imbalanced datasets).

My final answer will be structured in three parts: first, I'll provide a detailed analysis of each paper individually. Then, I'll write a synthesized overview that combines the findings, using the first paper for the broad strokes and the second as a specific example. Finally, I will compile the references with clickable links. This structure will provide both detail and a clear, high-level summary.
</thinking>

## Analysis of Retrieved Articles

### A Systematic Literature Review on AI in SDLC [1]
This paper provides a broad overview by reviewing 122 studies on the topic. Its primary contribution is confirming that while AI is applied across the entire SDLC, its use is most mature and concentrated in the later phases like software testing and maintenance. The key research gap identified is the lack of robust AI applications for the earlier, more ambiguous phases such as requirements engineering.

### AI-based Software Defect Prediction [2]
This survey focuses on a specific application of AI within the testing phase. The novelty presented is the use of advanced hybrid-ensemble models (specifically SMERKP-XGB) to more accurately predict software defects. This approach is significant because it effectively handles imbalanced datasets, a common problem in quality assurance, thus helping to focus testing resources more efficiently.

## Synthesized Overview

The integration of Artificial Intelligence (AI) within the Software Development Life Cycle (SDLC) is a rapidly evolving field aimed at improving efficiency and quality. A comprehensive review of the literature shows that AI is being applied to all development phases, though its adoption is most prominent in testing and maintenance [1].

A key example of AI's impact is seen in software defect prediction. Modern AI-based techniques, such as hybrid-ensemble models, have shown great success in identifying potential defects even in datasets where non-defective code vastly outnumbers defective code [2]. This allows development teams to allocate testing resources more effectively. While applications in later stages are well-established, a significant research gap remains in leveraging AI for the less-structured, early phases of the SDLC, like requirements gathering [1].

---
## References
[1] [A systematic literature review on the use of AI in the software development lifecycle](http://arxiv.org/abs/2304.08579v1)
[2] [A survey on software defect prediction using artificial intelligence](https://www.semanticscholar.org/paper/a-very-long-id-string-for-the-paper)
---
**EXAMPLE 2 OF COMPLETE OUTPUT:**

**USER'S ORIGINAL QUERY:** "What are the latest applications of graphene in electronics?"
**ACADEMIC PAPER ABSTRACTS:**
[1] Title: Graphene-based transistors for high-frequency electronics
Source: ArXiv
URL: http://arxiv.org/abs/2201.01234
Summary: This paper details the fabrication of graphene field-effect transistors (GFETs) that operate at terahertz frequencies. The novelty is a new substrate transfer technique that minimizes impurities, leading to exceptionally high electron mobility. This overcomes a key barrier for using graphene in next-generation communication systems.

**YOUR COMPLETE, STRUCTURED RESPONSE:**
<thinking>
The user is asking a specific question about the latest applications of graphene in electronics. I will search for recent, high-impact research papers.

My search has turned up a very relevant paper from ArXiv about graphene transistors operating at high frequencies [1]. This is a direct answer to the user's query about "applications". I will analyze the abstract to extract the key innovation. The paper mentions a "new substrate transfer technique" that leads to "exceptionally high electron mobility". This is the novelty. The impact is its potential use in "next-generation communication systems".

Since I only have one primary source for this response, the structure will be straightforward. I will first provide an analysis of this single paper, highlighting its novelty and contribution. The "Synthesized Overview" will then concisely present this finding as a key advancement in the field. I'll finish with the formal reference section. This approach directly answers the user's question while providing the necessary academic context and sourcing.
</thinking>

## Analysis of Retrieved Articles

### Graphene-based Transistors for High-Frequency Electronics [1]
This research focuses on the development of graphene field-effect transistors (GFETs) capable of operating in the terahertz (THz) range. The main contribution and novelty of this work is a new substrate transfer method that significantly reduces impurities on the graphene sheet. This purification results in much higher electron mobility, which has been a major obstacle in creating practical high-frequency graphene electronics. The paper suggests this breakthrough could pave the way for next-generation communication systems. A potential research gap could be the scalability and cost-effectiveness of this new fabrication technique for mass production.

## Synthesized Overview

A significant recent application of graphene in electronics is the development of ultra-high-frequency transistors. Researchers have engineered graphene-based transistors that can operate at terahertz speeds, a critical step for next-generation wireless communication [1]. This was achieved by developing a novel fabrication process that enhances the material's electron mobility, overcoming a long-standing challenge in the field [1].

---
## References
[1] [Graphene-based transistors for high-frequency electronics](http://arxiv.org/abs/2201.01234)
---
**Now, perform this task using the following information, following the structure from the examples above:**

**USER'S ORIGINAL QUERY:**
${originalQuery}

**ACADEMIC PAPER ABSTRACTS:**
${toolOutput}

**YOUR COMPLETE, STRUCTURED RESPONSE:**
`;
    }
    else { // For RAG, KG, Academic, and other tools
        synthesizerUserMessage = `
**USER'S ORIGINAL QUERY:**
"${originalQuery}"

---
**INFORMATION GATHERED BY TOOL ('${toolName}'):**
${toolOutput}
---

Based **only** on the information gathered by the tool above, please provide a comprehensive, well-formatted final answer to my original query. Adhere to all formatting rules from your core instructions. Do not mention that a tool was used and do not include citation markers like [1], [2].
`;
    }
    return synthesizerUserMessage;
};

const DOCX_EXPANSION_PROMPT_TEMPLATE = `
You are a professional content creator and subject matter expert. Your task is to expand a given OUTLINE (which could be a list of key topics or FAQs) into a full, detailed, multi-page document in Markdown format. You must use the provided SOURCE DOCUMENT TEXT as your only source of truth. Do not use outside knowledge. The final output must be a single block of well-structured Markdown text.

**INSTRUCTIONS:**
1.  **Main Title:** Start the document with a main title using H1 syntax (e.g., '# Expanded Report on Key Topics').
2.  **Section per Outline Point:** For each point in the OUTLINE, create a detailed section with a clear H2 or H3 heading (e.g., '## Topic Name').
3.  **Content Expansion:** For each section, write detailed, professional paragraphs that elaborate on the outline point. Extract relevant facts, figures, and explanations from the SOURCE DOCUMENT TEXT.
4.  **Markdown Usage:** Use bullet points, bold text, and clear paragraphs to structure the content effectively.

---
**SOURCE DOCUMENT TEXT (Your knowledge base):**
{source_document_text}
---
**OUTLINE (Topics/FAQs to expand into a document):**
{outline_content}
---

**FINAL DOCUMENT MARKDOWN:**
`;

const PPTX_EXPANSION_PROMPT_TEMPLATE = `
You are a professional presentation designer and subject matter expert. Your task is to expand a given OUTLINE (which could be a list of key topics or FAQs) into a full, detailed, 6-8 slide presentation. You must use the provided SOURCE DOCUMENT TEXT as your only source of truth. Do not use outside knowledge. Your output MUST be a single, valid JSON array, where each object represents a slide.

**JSON Object Schema for each slide:**
{{
  "slide_title": "A concise and engaging title for the slide.",
  "slide_content": "Detailed, professional paragraph(s) and/or bullet points elaborating on the outline point. This text will be displayed on the slide. Use Markdown for formatting (e.g., **bold**, *italics*, - bullet points).",
  "image_prompt": "A highly descriptive, creative prompt for an AI text-to-image model (like DALL-E or Midjourney) to generate a relevant and visually appealing image for this specific slide. Describe the style, subject, and composition. Example: 'A photorealistic image of a futuristic server room with glowing blue data streams flowing between racks, symbolizing data processing. Cinematic lighting.'"
}}

**INSTRUCTIONS:**
1.  **Analyze Outline & Source:** For each point in the OUTLINE, create at least one slide object in the JSON array.
2.  **Expand Content:** Elaborate on each outline point using only information from the SOURCE DOCUMENT TEXT.
3.  **Create Image Prompts:** For each slide, generate a unique and descriptive \`image_prompt\` that visually represents the slide's content.
4.  **JSON Format:** Ensure the final output is a single, clean JSON array with no other text before or after it.

---
**SOURCE DOCUMENT TEXT (Your knowledge base):**
{source_document_text}
---
**OUTLINE (Topics/FAQs to expand into a presentation):**
{outline_content}
---

**FINAL PRESENTATION JSON ARRAY:**
`;

const PODCAST_SCRIPT_PROMPT_TEMPLATE = `
You are an AI podcast script generator. Your SOLE task is to generate a realistic, two-speaker educational dialogue based on the provided text.

**CRITICAL INSTRUCTION:** Your entire output must be ONLY the script itself. Start directly with "SPEAKER_A:". Do NOT include any preamble, introduction, or metadata like "Here is the script:".

---
## Podcast Style Guide

- **Format**: Two-speaker conversational podcast.
- **SPEAKER_A**: The "Curious Learner". Asks clarifying questions and represents the student's perspective.
- **SPEAKER_B**: The "Expert Teacher". Provides clear explanations and examples based on the document text.
- **Dialogue Flow**: The conversation must be a natural back-and-forth. SPEAKER_A asks a question, SPEAKER_B answers, and SPEAKER_A follows up.
- **Content Source**: All explanations and facts provided by SPEAKER_B MUST come from the \`DOCUMENT TEXT\` provided below.

---
## Script Structure

### 1. Opening
The script must begin with a brief, engaging conversation to set the stage.
\`SPEAKER_A: Hey, I was just reading this document about {study_focus}, and I'm a bit stuck on a few things. Can we talk through it?\`
\`SPEAKER_B: Absolutely! I'd be happy to. What's on your mind?\`

### 2. Main Body
The main part of the script should be a question-and-answer dialogue driven by SPEAKER_A, focusing on the key points of the \`STUDY FOCUS\`. Use the \`DOCUMENT TEXT\` to formulate SPEAKER_B's expert answers.

### 3. Closing
Conclude the podcast with a quick summary and an encouraging sign-off.
\`SPEAKER_A: This makes so much more sense now. Thanks for clarifying everything!\`
\`SPEAKER_B: You're welcome! The key is to break it down. Keep up the great work!\`

---
## Source Material

**STUDY FOCUS (The main topic for the podcast):**
{study_focus}

**DOCUMENT TEXT (Use this for all factual answers):**
{document_content}

---
**FINAL SCRIPT OUTPUT (Remember: Start IMMEDIATELY with "SPEAKER_A:")**
`;

module.exports = {
    // Analysis
    ANALYSIS_PROMPTS,
    // KG
    KG_GENERATION_SYSTEM_PROMPT,
    KG_BATCH_USER_PROMPT_TEMPLATE,
    // Chat
    CHAT_MAIN_SYSTEM_PROMPT,
    WEB_SEARCH_CHAT_SYSTEM_PROMPT,
    CHAT_USER_PROMPT_TEMPLATES,
    // ToT
    PLANNER_PROMPT_TEMPLATE,
    EVALUATOR_PROMPT_TEMPLATE,
    // Agentic Framework
    createAgenticSystemPrompt,
    createSynthesizerPrompt,
    // Content Generation
    DOCX_EXPANSION_PROMPT_TEMPLATE,
    PPTX_EXPANSION_PROMPT_TEMPLATE,
    PODCAST_SCRIPT_PROMPT_TEMPLATE,
};  
```

`server/middleware/authMiddleware.js`

```javascript
// server/middleware/authMiddleware.js
const jwt = require('jsonwebtoken');
const User = require('../models/User');
require('dotenv').config();

const authMiddleware = async (req, res, next) => {
    const authHeader = req.header('Authorization');

    if (!authHeader) {
        console.warn("Auth Middleware: No Authorization header found.");
        return res.status(401).json({ message: 'Not authorized, no token' });
    }

    const parts = authHeader.split(' ');

    if (parts.length !== 2 || parts[0] !== 'Bearer') {
        console.warn("Auth Middleware: Token format is 'Bearer <token>', received:", authHeader);
        return res.status(401).json({ message: 'Token format is invalid' });
    }

    const token = parts[1];

    try {
        const decoded = jwt.verify(token, process.env.JWT_SECRET);
        const user = await User.findById(decoded.userId).select('-password');

        if (!user) {
            console.warn(`Auth Middleware: User not found for ID: ${decoded.userId} from token.`);
            return res.status(401).json({ message: 'User not found, token invalid' });
        }

        req.user = user;
        next();
    } catch (error) {
        console.warn("Auth Middleware: Token verification failed:", error.message);
        if (error.name === 'TokenExpiredError') {
            return res.status(401).json({ message: 'Token expired' });
        }
        if (error.name === 'JsonWebTokenError') {
            return res.status(401).json({ message: 'Token is not valid' });
        }
        res.status(401).json({ message: 'Not authorized, token verification failed' });
    }
};

module.exports = { authMiddleware }; // ONLY export this
```

`server/middleware/fixedAdminAuthMiddleware.js`

```javascript
// server/middleware/fixedAdminAuthMiddleware.js
require('dotenv').config({ path: require('path').resolve(__dirname, '..', '.env') }); // Ensure .env from server directory is loaded

const ADMIN_USERNAME = process.env.FIXED_ADMIN_USERNAME || 'admin';
const ADMIN_PASSWORD = process.env.FIXED_ADMIN_PASSWORD || 'admin123';

const fixedAdminAuthMiddleware = (req, res, next) => {
    const authHeader = req.headers.authorization;

    if (!ADMIN_USERNAME || !ADMIN_PASSWORD) {
        console.error("FATAL: FIXED_ADMIN_USERNAME or FIXED_ADMIN_PASSWORD not set in environment for admin auth.");
        // Do not send WWW-Authenticate here as it's a server config issue
        return res.status(500).json({ message: "Admin authentication system not configured properly." });
    }

    if (!authHeader || !authHeader.toLowerCase().startsWith('basic ')) {
        // Prompt for Basic Authentication
        res.setHeader('WWW-Authenticate', 'Basic realm="Admin Document Area"');
        return res.status(401).json({ message: 'Admin authentication required (Basic Auth).' });
    }

    const encodedCreds = authHeader.substring(6); // Length of "Basic "
    let decodedCreds;
    try {
        decodedCreds = Buffer.from(encodedCreds, 'base64').toString('utf8');
    } catch (e) {
        console.warn("Admin Auth: Invalid Base64 encoding in Basic Auth header.");
        res.setHeader('WWW-Authenticate', 'Basic realm="Admin Document Area"'); // Re-prompt
        return res.status(400).json({ message: 'Invalid Basic Auth encoding format.' });
    }

    const [username, password] = decodedCreds.split(':', 2); // Split into max 2 parts

    if (username === ADMIN_USERNAME && password === ADMIN_PASSWORD) {
        // Attach a simple admin context to the request object
        // This isn't a full user object from DB, just an indicator
        req.adminUser = { 
            username: ADMIN_USERNAME, 
            id: "fixed_admin_id_marker" // A placeholder ID
        }; 
        return next(); // Authentication successful, proceed to the route handler
    }

    // Authentication failed
    console.warn(`Admin Auth Failed: Incorrect credentials received. Username: ${username}`);
    res.setHeader('WWW-Authenticate', 'Basic realm="Admin Document Area"'); // Re-prompt
    return res.status(401).json({ message: 'Invalid admin credentials.' });
};

module.exports = { fixedAdminAuthMiddleware };
```

`server/models/AdminDocument.js`

```javascript
// server/models/AdminDocument.js
const mongoose = require('mongoose');

const AdminDocumentSchema = new mongoose.Schema({
  filename: { // Server-generated unique filename (e.g., timestamp-originalname.ext)
    type: String,
    required: true,
    unique: true,
  },
  originalName: { // The original name of the file uploaded by the admin
    type: String,
    required: true,
  },
  text: { // Extracted text content from the document, ready for analysis input
    type: String,
    default: "",
  },
  analysis: {
    faq: { // Stores the full string output (including <thinking>) for FAQ generation
      type: String,
      default: "",
    },
    topics: { // Stores the full string output for Key Topics generation
      type: String,
      default: "",
    },
    mindmap: { // Stores the full string output for Mind Map generation
      type: String,
      default: "",
    },
  },
  uploadedAt: { // Timestamp of when the document record was created/file uploaded
    type: Date,
    default: Date.now,
  },
  // Optional: Add a timestamp for when analysis was last updated
  analysisUpdatedAt: {
    type: Date,
  }
});

// Index for frequently queried fields if necessary, e.g., originalName
AdminDocumentSchema.index({ originalName: 1 });

const AdminDocument = mongoose.model('AdminDocument', AdminDocumentSchema);

module.exports = AdminDocument;
```

`server/models/ChatHistory.js`

```javascript
// server/models/ChatHistory.js
const mongoose = require('mongoose');
const { v4: uuidv4 } = require('uuid');

const MessageSchema = new mongoose.Schema({
    role: { type: String, enum: ['user', 'model'], required: true },
    parts: [{ text: { type: String, required: true } }],
    timestamp: { type: Date, default: Date.now },
    thinking: { type: String, default: '' },
    references: { type: Array, default: [] },
    source_pipeline: { type: String, default: '' }
}, { _id: false });

const ChatHistorySchema = new mongoose.Schema({
    userId: {
        type: mongoose.Schema.Types.ObjectId,
        ref: 'User',
        required: true,
        index: true,
    },
    sessionId: {
        type: String,
        required: true,
        unique: true,
        index: true,
    },
    messages: [MessageSchema],
    summary: {
        type: String,
        default: ''
    },
    createdAt: {
        type: Date,
        default: Date.now,
    },
    updatedAt: {
        type: Date,
        default: Date.now,
    }
});

ChatHistorySchema.pre('save', function (next) {
    if (this.isModified()) {
      this.updatedAt = Date.now();
    }
    next();
});

ChatHistorySchema.pre('findOneAndUpdate', function(next) {
  this.set({ updatedAt: new Date() });
  next();
});

const ChatHistory = mongoose.model('ChatHistory', ChatHistorySchema);
module.exports = ChatHistory;
```

`server/models/User.js`

```javascript
// server/models/User.js
const mongoose = require('mongoose');
const bcrypt = require('bcryptjs');
const { encrypt } = require('../utils/crypto'); // Import the new encrypt utility

const ProfileSchema = new mongoose.Schema({
    name: { type: String, default: '', trim: true },
    college: { type: String, default: '', trim: true },
    universityNumber: { type: String, default: '', trim: true },
    degreeType: { type: String, default: '', trim: true },
    branch: { type: String, default: '', trim: true },
    year: { type: String, default: '', trim: true },
}, { _id: false });

const UserSchema = new mongoose.Schema({
  email: { // Changed from username to email
    type: String,
    required: [true, 'Please provide an email'],
    unique: true,
    trim: true,
    lowercase: true,
    match: [/^\w+([.-]?\w+)*@\w+([.-]?\w+)*(\.\w{2,3})+$/, 'Please provide a valid email address'],
  },
  password: {
    type: String,
    required: [true, 'Please provide a password'],
    minlength: 6,
    select: false,
  },
  profile: {
    type: ProfileSchema,
    default: () => ({})
  },
  encryptedApiKey: { 
    type: String,
    select: false, 
  },
  preferredLlmProvider: {
    type: String,
    enum: ['gemini', 'ollama'],
    default: 'gemini',
  },
  ollamaUrl: {
    type: String,
    trim: true,
    default: '',
  },
  ollamaModel: {
    type: String,
    default: process.env.OLLAMA_DEFAULT_MODEL || 'llama3',
  },
  uploadedDocuments: [
    {
      filename: { type: String },
      text: { type: String, default: "" },
      analysis: {
        faq: { type: String, default: "" },
        topics: { type: String, default: "" },
        mindmap: { type: String, default: "" },
      },
      ragStatus: { type: String, default: 'pending' },
      analysisStatus: { type: String, default: 'pending' },
      analysisTimestamp: { type: Date },
      kgStatus: { type: String, default: 'pending' },
      kgNodesCount: { type: Number, default: 0 },
      kgEdgesCount: { type: Number, default: 0 },
      kgTimestamp: { type: Date },
      uploadedAt: { type: Date, default: Date.now }
    },
  ],
  createdAt: {
    type: Date,
    default: Date.now,
  },
});

UserSchema.pre('save', async function (next) {
  if (this.isModified('password')) {
    const salt = await bcrypt.genSalt(10);
    this.password = await bcrypt.hash(this.password, salt);
  }
  if (this.isModified('encryptedApiKey') && this.encryptedApiKey) {
    try {
        this.encryptedApiKey = encrypt(this.encryptedApiKey);
    } catch (encError) {
        console.error("Error encrypting API key during user save:", encError);
        return next(new Error("Failed to encrypt API key."));
    }
  } else if (this.isModified('encryptedApiKey') && !this.encryptedApiKey) {
    this.encryptedApiKey = null;
  }
  next();
});

UserSchema.methods.comparePassword = async function (candidatePassword) {
  if (!this.password) return false;
  return await bcrypt.compare(candidatePassword, this.password);
};

UserSchema.statics.findByCredentials = async function(email, password) {
    const user = await this.findOne({ email }).select('+password');
    if (!user) {
        return null;
    }
    const isMatch = await user.comparePassword(password);
    if (!isMatch) {
        return null;
    }
    return user;
};

const User = mongoose.model('User', UserSchema);
module.exports = User;
```

`server/o.txt`

```

```

`server/protocols/contextProtocols.js`

```javascript
// server/protocols/contextProtocols.js

const createModelContext = ({ availableTools, currentMode = 'chat' }) => ({
  current_mode: currentMode,
  available_tools: Object.entries(availableTools).map(([name, details]) => ({
    name,
    description: details.description,
    parameters: details.requiredParams,
  })),
});

const createAgenticContext = ({ systemPrompt }) => ({
  agent_role: "AI Engineering Tutor",
  agent_objectives: ["Provide accurate, clear, and helpful answers.", "Intelligently use available tools to fulfill user requests."],
  long_term_goals: ["Help the user learn and solve complex engineering problems."],
  constraints: ["Base answers on provided context when available.", "Do not hallucinate facts.", "Adhere to safety guidelines."],
  base_instructions: systemPrompt,
});

const createThreadContext = ({ sessionId, userId, history }) => ({
  thread_id: sessionId,
  user_id: userId,
  prior_interactions_summary: null,
});

module.exports = {
    createModelContext,
    createAgenticContext,
    createThreadContext,
};
```

`server/rag_service/academic_search.py`

```python
# server/rag_service/academic_search.py
import requests
import xml.etree.ElementTree as ET
import logging
from typing import List, Dict, Any

logger = logging.getLogger(__name__)

def search_arxiv(query: str, max_results: int = 3) -> List[Dict[str, Any]]:
    """Searches the ArXiv API for papers."""
    base_url = 'http://export.arxiv.org/api/query?'
    search_query = f'search_query=all:{query}&start=0&max_results={max_results}&sortBy=relevance'
    
    logger.info(f"Querying ArXiv with: {query}")
    response = requests.get(base_url + search_query, timeout=10)
    response.raise_for_status()
    
    root = ET.fromstring(response.content)
    papers = []
    for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):
        paper = {
            'source': 'ArXiv',
            'title': entry.find('{http://www.w3.org/2005/Atom}title').text.strip(),
            'url': entry.find('{http://www.w3.org/2005/Atom}id').text.strip(),
            'summary': entry.find('{http://www.w3.org/2005/Atom}summary').text.strip(),
            'authors': [author.find('{http://www.w3.org/2005/Atom}name').text for author in entry.findall('{http://www.w3.org/2005/Atom}author')]
        }
        papers.append(paper)
    return papers

def search_semantic_scholar(query: str, max_results: int = 3) -> List[Dict[str, Any]]:
    """Searches the Semantic Scholar API."""
    base_url = 'https://api.semanticscholar.org/graph/v1/paper/search'
    params = {'query': query, 'limit': max_results, 'fields': 'title,url,abstract,authors'}
    
    logger.info(f"Querying Semantic Scholar with: {query}")
    response = requests.get(base_url, params=params, timeout=10)
    response.raise_for_status()
    
    data = response.json()
    papers = []
    if 'data' in data:
        for item in data['data']:
            paper = {
                'source': 'Semantic Scholar',
                'title': item.get('title'),
                'url': item.get('url'),
                'summary': item.get('abstract'),
                'authors': [author['name'] for author in item.get('authors', []) if 'name' in author]
            }
            papers.append(paper)
    return papers

def search_all_apis(query: str, max_results_per_api: int = 3) -> List[Dict[str, Any]]:
    """Searches all configured academic APIs and aggregates results."""
    all_results = []
    
    api_functions = {
        'ArXiv': search_arxiv,
        'Semantic Scholar': search_semantic_scholar
    }
    
    for api_name, search_func in api_functions.items():
        try:
            results = search_func(query, max_results=max_results_per_api)
            all_results.extend(results)
            logger.info(f"Found {len(results)} results from {api_name}.")
        except Exception as e:
            logger.warning(f"Could not retrieve results from {api_name}: {e}")
            
    # Simple de-duplication based on title to avoid showing the same paper from two sources
    unique_results = {paper['title'].lower(): paper for paper in all_results if paper.get('title')}.values()
    
    return list(unique_results)
```

`server/rag_service/ai_core.py`

```python
# ./ai_core.py

# Standard Library Imports
import logging
import os
import io
import re
import copy
import uuid
from typing import Any, Callable, Dict, List, Optional, Union
from datetime import datetime # For improved date parsing in metadata

# --- Global Initializations ---
logger = logging.getLogger(__name__)

# --- Configuration Import ---
try:
    import config # This should import server/config.py
except ImportError as e:
    logger.critical(f"CRITICAL: Failed to import 'config' (expected server/config.py): {e}. ")
    # Depending on how critical config is, you might want to sys.exit(1)
    # For now, we'll let it proceed and other parts will fail if config isn't loaded.


# Local aliases for config flags, models, constants, and classes from config.py
# Ensure all these are actually defined in your config.py
PYPDF_AVAILABLE = getattr(config, 'PYPDF_AVAILABLE', False)
PDFPLUMBER_AVAILABLE = getattr(config, 'PDFPLUMBER_AVAILABLE', False)
PANDAS_AVAILABLE = getattr(config, 'PANDAS_AVAILABLE', False)
DOCX_AVAILABLE = getattr(config, 'DOCX_AVAILABLE', False)
PPTX_AVAILABLE = getattr(config, 'PPTX_AVAILABLE', False)
PIL_AVAILABLE = getattr(config, 'PIL_AVAILABLE', False)
FITZ_AVAILABLE = getattr(config, 'FITZ_AVAILABLE', False)
PYTESSERACT_AVAILABLE = getattr(config, 'PYTESSERACT_AVAILABLE', False)
SPACY_MODEL_LOADED = getattr(config, 'SPACY_MODEL_LOADED', False)
PYPDF2_AVAILABLE = getattr(config, 'PYPDF2_AVAILABLE', False)
EMBEDDING_MODEL_LOADED = getattr(config, 'EMBEDDING_MODEL_LOADED', False)
MAX_TEXT_LENGTH_FOR_NER  = getattr(config, 'MAX_TEXT_LENGTH_FOR_NER', 500000)
LANGCHAIN_SPLITTER_AVAILABLE = getattr(config, 'LANGCHAIN_SPLITTER_AVAILABLE', False)

PYPDF_PDFREADERROR = getattr(config, 'PYPDF_PDFREADERROR', Exception)
TESSERACT_ERROR = getattr(config, 'TESSERACT_ERROR', Exception)

# Libraries and Models (ensure these are None if not available to prevent AttributeError)
pypdf = getattr(config, 'pypdf', None)
PyPDF2 = getattr(config, 'PyPDF2', None)
pdfplumber = getattr(config, 'pdfplumber', None)
pd = getattr(config, 'pd', None)
DocxDocument = getattr(config, 'DocxDocument', None)
Presentation = getattr(config, 'Presentation', None)
Image = getattr(config, 'Image', None)
fitz = getattr(config, 'fitz', None)
pytesseract = getattr(config, 'pytesseract', None)
nlp_spacy_core = getattr(config, 'nlp_spacy_core', None)
document_embedding_model = getattr(config, 'document_embedding_model', None)
RecursiveCharacterTextSplitter = getattr(config, 'RecursiveCharacterTextSplitter', None)

# Constants
AI_CORE_CHUNK_SIZE = getattr(config, 'AI_CORE_CHUNK_SIZE', 1024) # Default if not in config
AI_CORE_CHUNK_OVERLAP = getattr(config, 'AI_CORE_CHUNK_OVERLAP', 200) # Default if not in config
DOCUMENT_EMBEDDING_MODEL_NAME = getattr(config, 'DOCUMENT_EMBEDDING_MODEL_NAME', "unknown_model")


# ==============================================================================
# Phase 2: Unified Rich Element Extraction Layer
# ==============================================================================

# Standard Output Structure for Element Extractors
# {
#     'text_content': Optional[str],
#     'tables': List[Union[pd.DataFrame, List[List[str]]]],
#     'images': List[Image.Image],
#     'parser_metadata': Dict[str, Any],
#     'is_scanned_heuristic': bool
# }

def _make_empty_extraction_result() -> Dict[str, Any]:
    """Helper to create a default empty result structure."""
    return {
        'text_content': None,
        'tables': [],
        'images': [],
        'parser_metadata': {},
        'is_scanned_heuristic': False
    }

def _extract_pdf_elements(file_path: str) -> Dict[str, Any]:
    if not os.path.exists(file_path):
        logger.error(f"PDF file not found: {file_path}")
        return _make_empty_extraction_result()

    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    extracted_text_parts = []

    # 1. Text and Table Extraction with pdfplumber (if available)
    if PDFPLUMBER_AVAILABLE and pdfplumber:
        try:
            with pdfplumber.open(file_path) as pdf:
                num_pages_plumber = len(pdf.pages)
                for i, page in enumerate(pdf.pages):
                    page_text = page.extract_text(x_tolerance=1, y_tolerance=1.5, layout=False) # layout=False for more raw text
                    if page_text and page_text.strip():
                        extracted_text_parts.append(page_text.strip())

                    # Extract tables
                    page_tables_data = page.extract_tables()
                    if page_tables_data:
                        for table_data_list in page_tables_data:
                            if not table_data_list: continue
                            if PANDAS_AVAILABLE and pd:
                                try:
                                    # Attempt to use first row as header if meaningful
                                    if len(table_data_list) > 1 and all(c is not None and isinstance(c, str) for c in table_data_list[0]):
                                        df = pd.DataFrame(table_data_list[1:], columns=table_data_list[0])
                                    else:
                                        df = pd.DataFrame(table_data_list)
                                    result['tables'].append(df)
                                except Exception as df_err:
                                    logger.warning(f"pdfplumber: DataFrame conversion error for table on page {i+1} of {file_base_name}: {df_err}. Storing as list.")
                                    result['tables'].append(table_data_list)
                            else:
                                result['tables'].append(table_data_list)
                
                result['text_content'] = "\n\n".join(extracted_text_parts).strip() or None
                if result['tables']: logger.info(f"pdfplumber: Extracted {len(result['tables'])} tables from {file_base_name}.")

                # Scanned PDF Heuristic (based on pdfplumber text)
                if num_pages_plumber > 0:
                    total_chars = sum(len(pt.replace(" ", "")) for pt in extracted_text_parts)
                    avg_chars_per_page = total_chars / num_pages_plumber
                    # Heuristic: low average characters per page suggests scanned
                    if avg_chars_per_page < 20 and total_chars < (num_pages_plumber * 50): # Tunable thresholds
                        result['is_scanned_heuristic'] = True
                        logger.info(f"PDF {file_base_name} potentially scanned (low avg text [{avg_chars_per_page:.1f} chars/page] from pdfplumber).")

        except Exception as e_plumber:
            logger.warning(f"pdfplumber: Error processing PDF {file_base_name}: {e_plumber}", exc_info=True)
            # If pdfplumber fails, pypdf (now pypdf) can be a fallback for basic text
            if PYPDF_AVAILABLE and pypdf and not result['text_content']:
                logger.info(f"Attempting pypdf fallback for text extraction from {file_base_name}")
                try:
                    reader = pypdf.PdfReader(file_path)
                    pypdf_text_parts = []
                    for page in reader.pages:
                        page_text = page.extract_text()
                        if page_text and page_text.strip():
                            pypdf_text_parts.append(page_text.strip())
                    result['text_content'] = "\n\n".join(pypdf_text_parts).strip() or None
                except Exception as e_pypdf:
                    logger.warning(f"pypdf fallback also failed for {file_base_name}: {e_pypdf}")


    # 2. Image Extraction with Fitz (PyMuPDF)
    if FITZ_AVAILABLE and fitz and PIL_AVAILABLE and Image:
        try:
            doc_fitz = fitz.open(file_path)
            if not result['is_scanned_heuristic'] and not result['text_content'] and len(doc_fitz) > 0:
                # If no text from plumber/pypdf, but fitz finds pages, highly likely scanned.
                result['is_scanned_heuristic'] = True
                logger.info(f"PDF {file_base_name} likely scanned (no text extracted, but pages found by fitz).")

            for page_idx in range(len(doc_fitz)):
                for img_info_tuple in doc_fitz.get_page_images(page_idx):
                    xref = img_info_tuple[0]
                    try:
                        img_bytes_dict = doc_fitz.extract_image(xref)
                        if img_bytes_dict and "image" in img_bytes_dict:
                             result['images'].append(Image.open(io.BytesIO(img_bytes_dict["image"])))
                    except Exception as img_err:
                        logger.warning(f"fitz: Could not extract/open image xref {xref} from page {page_idx} of {file_base_name}: {img_err}")
            if result['images']: logger.info(f"fitz: Extracted {len(result['images'])} images from {file_base_name}.")
            doc_fitz.close()
        except Exception as e_fitz:
            logger.warning(f"fitz: Error processing PDF {file_base_name} for images: {e_fitz}", exc_info=True)

    # 3. Metadata with PyPDF2 (or pypdf if PyPDF2 not available/fails)
    metadata_extractor = None
    if PYPDF2_AVAILABLE and PyPDF2:
        metadata_extractor = PyPDF2.PdfReader
        extractor_name = "PyPDF2"
    elif PYPDF_AVAILABLE and pypdf: # Fallback to pypdf for metadata
        metadata_extractor = pypdf.PdfReader
        extractor_name = "pypdf"

    if metadata_extractor:
        try:
            with open(file_path, 'rb') as f:
                reader = metadata_extractor(f)
                info = reader.metadata
                if info:
                    if hasattr(info, 'title') and info.title: result['parser_metadata']['title'] = str(info.title).strip()
                    if hasattr(info, 'author') and info.author: result['parser_metadata']['author'] = str(info.author).strip()
                    
                    pdf_date_formats = [
                        "D:%Y%m%d%H%M%S%z",    
                        "D:%Y%m%d%H%M%S",
                        "D:%Y%m%d%H%M%SZ",
                        "%Y%m%d%H%M%S%z",
                        "%Y%m%d%H%M%S",
                        "%Y%m%d%H%M%SZ",
                    ]
                    def parse_pdf_date(date_val_str_or_dt):
                        if isinstance(date_val_str_or_dt, datetime): return date_val_str_or_dt
                        if not isinstance(date_val_str_or_dt, str): return None
                        clean_date_str = date_val_str_or_dt.strip().rstrip("'")
                        for fmt in pdf_date_formats:
                            try: return datetime.strptime(clean_date_str, fmt)
                            except ValueError: continue
                        return None
                    

                    raw_creation_date = info.get("/CreationDate") if isinstance(info, dict) else getattr(info, 'creation_date', None)
                    creation_date_obj = parse_pdf_date(raw_creation_date)

                    if creation_date_obj: result['parser_metadata']['creation_date'] = creation_date_obj.isoformat()
                    
                    raw_mod_date = info.get("/ModDate") if isinstance(info, dict) else getattr(info, 'modification_date', None)
                    modification_date_obj = parse_pdf_date(raw_mod_date)
                    
                    if modification_date_obj: result['parser_metadata']['modification_date'] = modification_date_obj.isoformat()

                result['parser_metadata']['page_count'] = len(reader.pages)
        except Exception as e_meta:
            logger.warning(f"Metadata: Error using {extractor_name} for {file_base_name}: {e_meta}", exc_info=True)
            if 'page_count' not in result['parser_metadata'] and FITZ_AVAILABLE and fitz: # Fallback page count
                try:
                    doc_fitz_pc = fitz.open(file_path)
                    result['parser_metadata']['page_count'] = len(doc_fitz_pc)
                    doc_fitz_pc.close()
                except: pass


    return result

def _extract_docx_elements(file_path: str) -> Dict[str, Any]:
    if not (DOCX_AVAILABLE and DocxDocument and PIL_AVAILABLE and Image):
        logger.error("python-docx or Pillow not available. DOCX parsing will be limited.")
        return _make_empty_extraction_result()
    
    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    text_content_parts = []

    try:
        doc = DocxDocument(file_path)
        # Text
        for para in doc.paragraphs:
            if para.text.strip():
                text_content_parts.append(para.text.strip())
        result['text_content'] = "\n".join(text_content_parts).strip() or None

        # Tables
        for i, table in enumerate(doc.tables):
            table_list = [[cell.text.strip() for cell in row.cells] for row in table.rows]
            if not table_list: continue
            if PANDAS_AVAILABLE and pd:
                try:
                    if len(table_list) > 1 and all(c for c in table_list[0]): # Use first row as header
                        result['tables'].append(pd.DataFrame(table_list[1:], columns=table_list[0]))
                    else:
                        result['tables'].append(pd.DataFrame(table_list))
                except Exception as df_err:
                    logger.warning(f"docx: DataFrame conversion error for table {i} in {file_base_name}: {df_err}. Storing as list.")
                    result['tables'].append(table_list)
            else:
                result['tables'].append(table_list)
        if result['tables']: logger.info(f"docx: Extracted {len(result['tables'])} tables from {file_base_name}.")

        # Images (Inline shapes)
        for rel_id, image_part in doc.part.image_parts:
             try:
                 img = Image.open(io.BytesIO(image_part.blob))
                 result['images'].append(img)
             except Exception as e_img:
                 logger.warning(f"docx: Error processing an image from {file_base_name}: {e_img}")
        # A more thorough way for inline_shapes if doc.part.image_parts is not sufficient:
        # for shape in doc.inline_shapes:
        #    if shape.type == MSO_SHAPE_TYPE.PICTURE: # Requires from docx.enum.shape import MSO_SHAPE_TYPE
        #        try:
        #            image_part = doc.part.related_parts[shape._inline.graphic.graphicData.pic.blipFill.blip.embed]
        #            img = Image.open(io.BytesIO(image_part.blob))
        #            result['images'].append(img)
        #        except Exception: pass # ignore if not an image or error
        if result['images']: logger.info(f"docx: Extracted {len(result['images'])} images from {file_base_name}.")


        # Metadata
        props = doc.core_properties
        if props.title: result['parser_metadata']['title'] = props.title
        if props.author: result['parser_metadata']['author'] = props.author
        if props.created: result['parser_metadata']['creation_date'] = props.created.isoformat()
        if props.modified: result['parser_metadata']['modification_date'] = props.modified.isoformat()
        result['parser_metadata']['page_count'] = len(doc.paragraphs) // 20 or 1 # Rough estimate

        # Scanned Heuristic
        if not result['text_content'] and result['images']:
            result['is_scanned_heuristic'] = True
            logger.info(f"DOCX {file_base_name} potentially image-based (no text, images present).")

    except FileNotFoundError:
        logger.error(f"docx: File not found: {file_path}")
    except Exception as e:
        logger.error(f"docx: Error parsing DOCX {file_base_name}: {e}", exc_info=True)
    
    return result

def _extract_pptx_elements(file_path: str) -> Dict[str, Any]:
    if not (PPTX_AVAILABLE and Presentation and PIL_AVAILABLE and Image):
        logger.error("python-pptx or Pillow not available. PPTX parsing will be limited.")
        return _make_empty_extraction_result()

    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    text_content_parts = []

    try:
        prs = Presentation(file_path)
        for slide_idx, slide in enumerate(prs.slides):
            slide_texts = []
            for shape in slide.shapes:
                if hasattr(shape, "text_frame") and shape.text_frame and shape.text_frame.text.strip():
                    slide_texts.append(shape.text_frame.text.strip())
                elif hasattr(shape, "text") and shape.text.strip(): # For shapes with direct text
                    slide_texts.append(shape.text.strip())
                
                # Image extraction
                if hasattr(shape, "image"): # If shape is an image
                    try:
                        image_bytes = shape.image.blob
                        img = Image.open(io.BytesIO(image_bytes))
                        result['images'].append(img)
                    except Exception as e_img_shape:
                        logger.warning(f"pptx: Error extracting image from shape on slide {slide_idx} of {file_base_name}: {e_img_shape}")
            
            if slide_texts:
                text_content_parts.append("\n".join(slide_texts))
        
        result['text_content'] = "\n\n".join(text_content_parts).strip() or None
        if result['images']: logger.info(f"pptx: Extracted {len(result['images'])} images from {file_base_name}.")

        # Metadata
        props = prs.core_properties
        if props.title: result['parser_metadata']['title'] = props.title
        if props.author: result['parser_metadata']['author'] = props.author
        if props.created: result['parser_metadata']['creation_date'] = props.created.isoformat()
        if props.last_modified_by : result['parser_metadata']['last_modified_by'] = props.last_modified_by
        if props.modified : result['parser_metadata']['modification_date'] = props.modified.isoformat()

        result['parser_metadata']['page_count'] = len(prs.slides)

        # Scanned Heuristic
        if not result['text_content'] and result['images']:
            result['is_scanned_heuristic'] = True
            logger.info(f"PPTX {file_base_name} potentially image-based (no text, images present).")

    except FileNotFoundError:
        logger.error(f"pptx: File not found: {file_path}")
    except Exception as e:
        logger.error(f"pptx: Error parsing PPTX {file_base_name}: {e}", exc_info=True)

    return result

def _extract_csv_elements(file_path: str) -> Dict[str, Any]:
    if not (PANDAS_AVAILABLE and pd):
        logger.error("pandas not available. CSV parsing will be limited.")
        return _extract_generic_text_elements(file_path, ".csv") # Fallback to text

    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    try:
        df = pd.read_csv(file_path)
        result['tables'].append(df)
        # Create a text representation of the CSV for text_content
        # Could be markdown, simple string, or first N rows.
        # Using to_string() for now. Consider to_markdown() for better structure if text will be LLM input.
        result['text_content'] = df.to_string(index=False, na_rep='NULL').strip() or None
        logger.info(f"csv: Extracted 1 table (shape: {df.shape}) from {file_base_name}.")
    except FileNotFoundError:
        logger.error(f"csv: File not found: {file_path}")
    except Exception as e:
        logger.error(f"csv: Error parsing CSV {file_base_name}: {e}", exc_info=True)
        # Fallback to generic text if pandas fails
        return _extract_generic_text_elements(file_path, ".csv")
    return result


def _extract_generic_text_elements(file_path: str, file_type_ext: str) -> Dict[str, Any]:
    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            text = f.read()
        result['text_content'] = text.strip() or None
        
        # For HTML/XML, optionally strip tags (basic)
        if file_type_ext in ['.html', '.xml'] and result['text_content']:
            stripped_text = re.sub(r'<[^>]+>', ' ', result['text_content'])
            result['text_content'] = re.sub(r'\s+', ' ', stripped_text).strip() or None

    except FileNotFoundError:
        logger.error(f"txt-like: File not found: {file_path}")
    except Exception as e:
        logger.error(f"txt-like: Error parsing {file_base_name}: {e}", exc_info=True)
    return result

def _extract_image_file_elements(file_path: str) -> Dict[str, Any]:
    if not (PIL_AVAILABLE and Image):
        logger.error("Pillow (PIL) not available. Image file parsing will fail.")
        return _make_empty_extraction_result()

    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    try:
        img = Image.open(file_path)
        result['images'].append(img)
        result['is_scanned_heuristic'] = True # By definition, an image file is "scanned" for OCR
        logger.info(f"Image file {file_base_name} opened.")
    except FileNotFoundError:
        logger.error(f"image-file: File not found: {file_path}")
    except Exception as e:
        logger.error(f"image-file: Error opening {file_base_name}: {e}", exc_info=True)
    return result


def _get_rich_extraction_results(file_path: str) -> Dict[str, Any]:
    """Dispatcher for rich element extraction based on file type."""
    ext = os.path.splitext(file_path)[1].lower()
    logger.info(f"Rich extraction: Dispatching for file type '{ext}' ({os.path.basename(file_path)})")

    if ext == '.pdf':
        return _extract_pdf_elements(file_path)
    elif ext == '.docx':
        return _extract_docx_elements(file_path)
    elif ext == '.pptx':
        return _extract_pptx_elements(file_path)
    elif ext == '.csv':
        return _extract_csv_elements(file_path)
    elif ext in ['.txt', '.py', '.js', '.md', '.log', '.html', '.xml', '.json']:
        return _extract_generic_text_elements(file_path, ext)
    elif ext in ['.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif']:
        return _extract_image_file_elements(file_path)
    else:
        logger.warning(f"Unsupported file extension for rich extraction: {ext} ({os.path.basename(file_path)}). Attempting generic text.")
        return _extract_generic_text_elements(file_path, ext) # Fallback for unknown types


# ==============================================================================
# Phase 3: Streamlined Main Processing Pipeline
# ==============================================================================

def _get_initial_parsed_document(file_path: str) -> Dict[str, Any]:
    """Calls the appropriate rich element extractor for the file."""
    return _get_rich_extraction_results(file_path)


# --- Stages 2-7 (OCR, Cleaning, Layout, Metadata, Chunking, Embedding) ---
# These functions are largely the same as your corrected versions, but will now consume
# the structured output from _get_initial_parsed_document.

def perform_ocr_on_images(image_objects: List[Any], file_base_name_for_log: str ="") -> str: # Added filename for logging
    if not image_objects: return ""
    if not (PYTESSERACT_AVAILABLE and pytesseract):
        logger.error(f"Pytesseract not available. OCR for {file_base_name_for_log} cannot be performed.")
        return ""

    logger.info(f"Performing OCR on {len(image_objects)} image(s) for {file_base_name_for_log}.")
    ocr_text_parts = []
    images_ocrd = 0
    for i, img_obj in enumerate(image_objects):
        try:
            if not (PIL_AVAILABLE and Image and isinstance(img_obj, Image.Image)):
                logger.warning(f"Skipping non-PIL Image object at index {i} for OCR of {file_base_name_for_log}.")
                continue
            # Improve image for OCR: convert to grayscale, potentially apply thresholding if needed
            processed_img_for_ocr = img_obj.convert('L') # Grayscale
            text = pytesseract.image_to_string(processed_img_for_ocr)
            if text and text.strip():
                ocr_text_parts.append(text.strip())
                images_ocrd += 1
        except Exception as e:
            if TESSERACT_ERROR and isinstance(e, TESSERACT_ERROR): # Check specific Tesseract error
                logger.critical(f"Tesseract executable not found or error for {file_base_name_for_log}. OCR will fail. Error: {e}")
                # Re-raise if it's a critical setup issue that will affect all subsequent OCR
                # For now, we'll let it try other images, but this indicates a setup problem.
            logger.error(f"Error during OCR for image {i+1}/{len(image_objects)} of {file_base_name_for_log}: {e}", exc_info=True)
    
    full_ocr_text = "\n\n--- OCR Text from Image ---\n\n".join(ocr_text_parts).strip()
    logger.info(f"OCR for {file_base_name_for_log}: Extracted {len(full_ocr_text)} chars from {images_ocrd} image(s).")
    return full_ocr_text


def clean_and_normalize_text_content(text: str, file_base_name_for_log: str ="") -> str:
    if not text or not text.strip(): return ""
    logger.info(f"Text cleaning for {file_base_name_for_log}: Initial length {len(text)}")
    
    # Basic regex cleaning (order matters)
    text = re.sub(r'<script[^>]*>.*?</script>|<style[^>]*>.*?</style>', ' ', text, flags=re.I | re.S) # Remove script/style
    text = re.sub(r'<[^>]+>', ' ', text) # Remove all other HTML tags
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE) # Remove URLs
    text = re.sub(r'\S*@\S*\s?', '', text, flags=re.MULTILINE) # Remove emails
    text = re.sub(r'\s*&\w+;\s*', ' ', text) # Remove HTML entities like 
    text = re.sub(r'[\n\r\t]+', ' ', text) # Normalize whitespace (newlines, tabs to single space)
    text = re.sub(r'\s+', ' ', text).strip() # Consolidate multiple spaces to one and strip ends
    
    # Character filtering (allow more common punctuation useful for context)
    # text = re.sub(r'[^\w\s.,!?"\'():;-]', '', text) # Keeps more standard punctuation
    # For more aggressive cleaning for embedding, you might use:
    text = re.sub(r'[^a-zA-Z0-9\s.,!?-]', '', text) # More restrictive, closer to your original

    text_lower = text.lower() # Convert to lowercase AFTER regex to preserve case for URLs/emails if needed

    if not (SPACY_MODEL_LOADED and nlp_spacy_core):
        logger.warning(f"SpaCy model not loaded for {file_base_name_for_log}. Skipping lemmatization. Returning regex-cleaned text.")
        return text_lower
    
    try:
        # Process in chunks if text is very long to avoid SpaCy memory issues, though less likely after cleaning
        max_spacy_len = 1000000 # SpaCy's default internal limit for nlp()
        if len(text_lower) > max_spacy_len:
            logger.warning(f"Text for SpaCy in {file_base_name_for_log} exceeds {max_spacy_len} chars. Processing in parts or truncating.")
            # Simple truncation for now, chunking for spacy is more complex
            text_lower = text_lower[:max_spacy_len]

        doc = nlp_spacy_core(text_lower, disable=['parser', 'ner']) # Disable unused pipes
        lemmatized_tokens = [
            token.lemma_ for token in doc 
            if not token.is_stop and \
               not token.is_punct and \
               not token.is_space and \
               len(token.lemma_) > 1 and \
               token.lemma_ != '-PRON-' # Exclude pronouns after lemmatization
        ]
        final_cleaned_text = " ".join(lemmatized_tokens)
        logger.info(f"SpaCy cleaning for {file_base_name_for_log}: Final length {len(final_cleaned_text)}")
        return final_cleaned_text
    except Exception as e:
        logger.error(f"SpaCy processing failed for {file_base_name_for_log}: {e}. Returning pre-SpaCy cleaned text.", exc_info=True)
        return text_lower


def reconstruct_document_layout(text_content: str, tables_data: List[Any], file_type: str, file_base_name_for_log: str ="") -> str:
    if not text_content and not tables_data: return ""
    logger.info(f"Layout reconstruction for {file_base_name_for_log} ({file_type}): Text len {len(text_content)}, Tables {len(tables_data)}")
    
    # Hyphenated word de-joining (if text_content is not None)
    processed_text = text_content if text_content else ""
    processed_text = re.sub(r'(\w+)-\s*\n\s*(\w+)', r'\1\2', processed_text) # Across newlines
    # processed_text = re.sub(r'(\w+)-(\w+)', r'\1\2', processed_text) # Within same line (less common needed after initial parse)

    if tables_data:
        table_md_parts = []
        for i, table_obj in enumerate(tables_data):
            table_header = f"\n\n[START OF TABLE {i+1} extracted from {file_base_name_for_log}]\n"
            table_footer = f"\n[END OF TABLE {i+1}]\n"
            md_table_content = ""
            try:
                if PANDAS_AVAILABLE and pd and isinstance(table_obj, pd.DataFrame):
                    md_table_content = table_obj.to_markdown(index=False)
                elif isinstance(table_obj, list) and table_obj and all(isinstance(row, list) for row in table_obj):
                    # Basic list of lists to Markdown
                    if table_obj[0]: # Assume first row is header
                        md_table_content = "| " + " | ".join(map(str, table_obj[0])) + " |\n"
                        md_table_content += "| " + " | ".join(["---"] * len(table_obj[0])) + " |\n"
                        for row_data in table_obj[1:]:
                            if len(row_data) == len(table_obj[0]):
                                md_table_content += "| " + " | ".join(map(str, row_data)) + " |\n"
                            else: logger.warning(f"Table {i+1} (list) row length mismatch in {file_base_name_for_log}.")
                    else: md_table_content = "[Empty Table Data]"
                else: md_table_content = str(table_obj) # Fallback
            except Exception as e_table_md:
                logger.warning(f"Table {i+1} to Markdown conversion error for {file_base_name_for_log}: {e_table_md}. Using raw string.")
                md_table_content = str(table_obj)
            
            if md_table_content.strip():
                table_md_parts.append(table_header + md_table_content.strip() + table_footer)
        
        if table_md_parts:
            processed_text += "\n\n" + "\n\n".join(table_md_parts)
    
    # Final whitespace cleanup
    final_layout_text = re.sub(r'\s{2,}', ' ', processed_text).strip() # Consolidate multiple spaces
    logger.info(f"Layout reconstruction for {file_base_name_for_log}: Final length {len(final_layout_text)}")
    return final_layout_text


def extract_document_metadata_info(
    file_path: str, 
    processed_text: str, 
    parsed_doc_elements: Dict[str, Any], # Output from _get_initial_parsed_document
    original_file_name: str, 
    user_id: str
) -> Dict[str, Any]:
    logger.info(f"Metadata extraction for: {original_file_name} (User: {user_id})")
    
    parser_meta = parsed_doc_elements.get('parser_metadata', {})
    file_type_from_parser = os.path.splitext(original_file_name)[1].lower() # Fallback if not in parser_meta

    doc_meta = {
        'file_name': original_file_name,
        'file_path_on_server': file_path,
        'original_file_type': parser_meta.get('file_type', file_type_from_parser),
        'processing_user': user_id,
        'title': parser_meta.get('title', original_file_name), # Prioritize parser title
        'author': parser_meta.get('author', "Unknown"),       # Prioritize parser author
        'creation_date': parser_meta.get('creation_date'),   # Expect ISO format from parser
        'modification_date': parser_meta.get('modification_date'), # Expect ISO format
        'page_count': parser_meta.get('page_count', 0),
        'char_count_processed_text': len(processed_text),
        'named_entities': {},
        'structural_elements': "Paragraphs" + (", Tables" if parsed_doc_elements.get('tables') else ""),
        'is_scanned_document': parsed_doc_elements.get('is_scanned_heuristic', False), # Initial guess
        'ocr_applied': False # Will be set to True if OCR text was actually used
    }

    # OS-level metadata (can augment or be overridden by parser_meta)
    try:
        doc_meta['file_size_bytes'] = os.path.getsize(file_path)
        if PANDAS_AVAILABLE and pd: # Using pandas for robust timestamp conversion
            # Only set OS dates if not already provided by a more specific parser
            if not doc_meta['creation_date']:
                 doc_meta['creation_date_os'] = pd.Timestamp(os.path.getctime(file_path), unit='s').isoformat()
            if not doc_meta['modification_date']:
                 doc_meta['modification_date_os'] = pd.Timestamp(os.path.getmtime(file_path), unit='s').isoformat()
    except Exception as e_os_meta:
        logger.warning(f"Metadata: OS metadata error for {original_file_name}: {e_os_meta}")

    # If page_count is still 0 after parser, estimate from text
    if doc_meta['page_count'] == 0 and processed_text:
        doc_meta['page_count'] = max(1, processed_text.count('\n\n') + 1) # Rough estimate

    # NER (Named Entity Recognition) - using SpaCy
    if processed_text and SPACY_MODEL_LOADED and nlp_spacy_core:
        logger.info(f"Extracting named entities for {original_file_name}...")
        try:
            text_for_ner = processed_text[:MAX_TEXT_LENGTH_FOR_NER] # Use config alias
            spacy_doc = nlp_spacy_core(text_for_ner) # NER pipe should be enabled by default
            
            entities_by_type = {}
            for ent in spacy_doc.ents:
                entities_by_type.setdefault(ent.label_, set()).add(ent.text)
            
            doc_meta['named_entities'] = {label: sorted(list(texts)) for label, texts in entities_by_type.items()}
            num_entities_found = sum(len(v) for v in doc_meta['named_entities'].values())
            logger.info(f"Extracted {num_entities_found} unique named entities for {original_file_name}.")
        except Exception as e_ner:
            logger.error(f"Metadata: NER error for {original_file_name}: {e_ner}", exc_info=True)
    else:
        logger.info(f"Skipping NER for {original_file_name} (no text or SpaCy model not loaded/configured for NER).")
    
    logger.info(f"Metadata extraction complete for {original_file_name}.")
    return doc_meta

# Chunking and Embedding functions remain largely the same as your corrected versions,
# just ensure they consume the correct data.
def chunk_document_into_segments(
    text_to_chunk: str,
    document_level_metadata: Dict[str, Any] # This is the output from extract_document_metadata_info
) -> List[Dict[str, Any]]:
    if not text_to_chunk or not text_to_chunk.strip():
        logger.warning(f"Chunking: No text for {document_level_metadata.get('file_name', 'unknown')}.")
        return []

    if not (LANGCHAIN_SPLITTER_AVAILABLE and RecursiveCharacterTextSplitter):
        logger.error("RecursiveCharacterTextSplitter not available. Cannot chunk text.")
        return []
        
    chunk_s = AI_CORE_CHUNK_SIZE
    chunk_o = AI_CORE_CHUNK_OVERLAP
    original_doc_name_for_log = document_level_metadata.get('file_name', 'unknown_doc')
    logger.info(f"Chunking {original_doc_name_for_log}: Size={chunk_s}, Overlap={chunk_o}")
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_s,
        chunk_overlap=chunk_o,
        length_function=len,
        separators=["\n\n", "\n", ". ", " ", ""], 
        keep_separator=True # Consider if True or False is better for your LLM
    )

    try:
        raw_text_segments: List[str] = text_splitter.split_text(text_to_chunk)
    except Exception as e_split: 
        logger.error(f"Chunking: Error splitting text for {original_doc_name_for_log}: {e_split}", exc_info=True)
        return []
        
    output_chunks: List[Dict[str, Any]] = []
    # Use a more robust base name if original name contains problematic characters for reference
    base_file_name_for_ref = re.sub(r'[^a-zA-Z0-9_-]', '_', os.path.splitext(original_doc_name_for_log)[0])


    for i, segment_content in enumerate(raw_text_segments):
        if not segment_content.strip(): 
            logger.debug(f"Skipping empty chunk at index {i} for {original_doc_name_for_log}.")
            continue

        # Create a deep copy of document-level metadata for each chunk
        chunk_specific_metadata = copy.deepcopy(document_level_metadata)
        
        qdrant_point_id = str(uuid.uuid4()) # Unique ID for this chunk in Qdrant

        # Add chunk-specific details to its metadata
        chunk_specific_metadata['chunk_id'] = qdrant_point_id 
        chunk_specific_metadata['chunk_reference_name'] = f"{base_file_name_for_ref}_chunk_{i:04d}"
        chunk_specific_metadata['chunk_index'] = i
        chunk_specific_metadata['chunk_char_count'] = len(segment_content)
        # Remove potentially very large or redundant fields from chunk metadata if necessary
        # e.g., chunk_specific_metadata.pop('named_entities', None) if too verbose per chunk
        
        output_chunks.append({
            'id': qdrant_point_id, # This ID is for Qdrant
            'text_content': segment_content,
            'metadata': chunk_specific_metadata # This payload goes into Qdrant
        })
    
    logger.info(f"Chunking: Split '{original_doc_name_for_log}' into {len(output_chunks)} non-empty chunks.")
    return output_chunks

def generate_segment_embeddings(document_chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    if not document_chunks: return []
    if not (EMBEDDING_MODEL_LOADED and document_embedding_model):
        logger.error("Embedding model not loaded. Cannot generate embeddings.")
        for chunk_dict in document_chunks: chunk_dict['embedding'] = None
        return document_chunks

    model_name_for_logging = DOCUMENT_EMBEDDING_MODEL_NAME
    logger.info(f"Embedding {len(document_chunks)} chunks using {model_name_for_logging}.")
    
    texts_to_embed: List[str] = []
    valid_chunk_indices: List[int] = [] # To map embeddings back to original chunk objects

    for i, chunk_dict in enumerate(document_chunks):
        text_content = chunk_dict.get('text_content')
        if text_content and text_content.strip():
            texts_to_embed.append(text_content)
            valid_chunk_indices.append(i)
        else:
            chunk_dict['embedding'] = None # Ensure 'embedding' key exists
            logger.debug(f"Embedding: Chunk {chunk_dict.get('id', i)} has no text, skipping.")

    if not texts_to_embed:
        logger.warning("Embedding: No text content found in chunks to generate embeddings.")
        return document_chunks

    try:
        embeddings_np_array = document_embedding_model.encode(texts_to_embed, show_progress_bar=True) # Set to True for long lists
        
        for i, original_chunk_idx in enumerate(valid_chunk_indices):
            if i < len(embeddings_np_array):
                document_chunks[original_chunk_idx]['embedding'] = embeddings_np_array[i].tolist()
            else: # Should not happen if encode works correctly
                logger.error(f"Embedding: Mismatch in embedding count for chunk at original index {original_chunk_idx}.")
                document_chunks[original_chunk_idx]['embedding'] = None
        
        logger.info(f"Embedding: Generated and assigned embeddings to {len(valid_chunk_indices)} chunks.")
    except Exception as e_embed:
        logger.error(f"Embedding: Error during generation with {model_name_for_logging}: {e_embed}", exc_info=True)
        for original_chunk_idx in valid_chunk_indices: # Ensure all attempted chunks get None on error
            document_chunks[original_chunk_idx]['embedding'] = None
            
    return document_chunks


# --- Main Orchestration Function ---
def process_document_for_qdrant(file_path: str, original_name: str, user_id: str) -> tuple[List[Dict[str, Any]], Optional[str], List[Dict[str, Any]]]:
    """
    Main orchestrator for processing a document.
    Returns:
        - final_chunks_for_qdrant: List of chunks with embeddings for Qdrant.
        - text_for_node_analysis: Consolidated text for Node.js general analysis (FAQ, Topics).
        - chunks_for_kg_worker: List of chunks with metadata (no embeddings) for KG worker.
    """
    logger.info(f"ai_core: Orchestrating document processing for '{original_name}', user '{user_id}'")
    if not os.path.exists(file_path):
        logger.error(f"File not found at ai_core entry: {file_path}")
        # Return empty tuple of expected types
        return [], None, []


    # Default return values for failure cases
    empty_qdrant_chunks = []
    no_analysis_text = None
    empty_kg_chunks = []

    try:
        # 1. Initial Parsing (Rich Element Extraction)
        parsed_doc_elements = _get_initial_parsed_document(file_path)
        initial_text_from_parser = parsed_doc_elements.get('text_content')
        images_from_parser = parsed_doc_elements.get('images', [])
        tables_from_parser = parsed_doc_elements.get('tables', [])
        is_scanned_heuristic = parsed_doc_elements.get('is_scanned_heuristic', False)
        file_type_from_parser = os.path.splitext(original_name)[1].lower() # Or get from parsed_doc_elements if available

        # 2. OCR if needed
        ocr_text_output = ""
        ocr_applied_flag = False
        # Decide if OCR is necessary:
        # - Explicitly image file types.
        # - Parser's heuristic says scanned.
        # - Parser extracted no text but found images (strong indicator for OCR).
        # - Parser extracted minimal text and images are present (e.g., a DOCX that's mostly a picture).
        should_ocr = is_scanned_heuristic or \
                     (file_type_from_parser in ['.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif']) or \
                     (not initial_text_from_parser and images_from_parser) or \
                     (initial_text_from_parser and len(initial_text_from_parser) < 200 * len(images_from_parser) and images_from_parser) # Heuristic for low text + images

        if should_ocr and images_from_parser:
            if PYTESSERACT_AVAILABLE and pytesseract:
                logger.info(f"OCR triggered for {original_name} based on heuristics/file type.")
                ocr_text_output = perform_ocr_on_images(images_from_parser, original_name)
                if ocr_text_output: ocr_applied_flag = True
            else:
                logger.warning(f"OCR needed for {original_name} but Pytesseract not available. Content may be incomplete.")
        
        # 3. Combine Text (Parser + OCR)
        combined_raw_text_parts = []
        if initial_text_from_parser: combined_raw_text_parts.append(initial_text_from_parser)
        if ocr_text_output: combined_raw_text_parts.append(ocr_text_output)
        combined_raw_text = "\n\n".join(combined_raw_text_parts).strip()

        if not combined_raw_text and not tables_from_parser:
            logger.warning(f"No text content or tables for {original_name} after initial parsing/OCR. Processing cannot continue.")
            return empty_qdrant_chunks, no_analysis_text, empty_kg_chunks

        # 4. Clean Text
        cleaned_text = clean_and_normalize_text_content(combined_raw_text, original_name)
        if not cleaned_text and not tables_from_parser: # If cleaning results in empty text
            logger.warning(f"No meaningful text for {original_name} after cleaning, and no tables. Processing cannot continue.")
            return empty_qdrant_chunks, no_analysis_text, empty_kg_chunks

        # 5. Reconstruct Layout (Integrate Tables as Markdown)
        text_for_further_processing = reconstruct_document_layout(
            cleaned_text, # Use the cleaned text
            tables_from_parser,
            file_type_from_parser,
            original_name
        )
        # This `text_for_further_processing` is a good candidate for Node.js analysis (FAQ, topics)
        # as it's cleaned and has table context.
        raw_text_for_node_analysis = text_for_further_processing 

        # 6. Extract Comprehensive Metadata
        doc_metadata = extract_document_metadata_info(
            file_path,
            text_for_further_processing, # Pass the final text that will be chunked
            parsed_doc_elements, # Pass the full initial parse results
            original_name,
            user_id
        )
        doc_metadata['ocr_applied'] = ocr_applied_flag # Update with actual OCR status

        # 7. Chunk Document
        # We chunk `text_for_further_processing` which includes table representations.
        chunks_with_metadata_for_qdrant_and_kg = chunk_document_into_segments(
            text_for_further_processing,
            doc_metadata # Pass rich metadata to chunks
        )
        if not chunks_with_metadata_for_qdrant_and_kg:
            logger.warning(f"No chunks produced for {original_name}. Cannot proceed with Qdrant/KG.")
            # Still return raw_text_for_node_analysis if it exists
            return empty_qdrant_chunks, raw_text_for_node_analysis, empty_kg_chunks

        # Prepare chunks for KG worker (these don't need embeddings yet)
        # Important: Deep copy if you modify this list before embedding,
        # or if embedding modifies in-place (unlikely with current generate_segment_embeddings)
        chunks_for_kg_worker = copy.deepcopy(chunks_with_metadata_for_qdrant_and_kg) 
        # Remove embedding from KG chunks if it somehow got there, or any very large fields not needed by KG LLM
        for chunk in chunks_for_kg_worker:
            chunk.pop('embedding', None) 
            # Consider removing other large metadata fields if KG LLM doesn't need them from each chunk's metadata

        # 8. Generate Embeddings for Qdrant chunks
        final_chunks_for_qdrant = generate_segment_embeddings(chunks_with_metadata_for_qdrant_and_kg)
        
        logger.info(f"ai_core: Successfully processed '{original_name}'. Generated {len(final_chunks_for_qdrant)} chunks for Qdrant.")
        return final_chunks_for_qdrant, raw_text_for_node_analysis, chunks_for_kg_worker

    except Exception as e:
        # Check for specific critical errors like Tesseract not found
        if TESSERACT_ERROR and isinstance(e, TESSERACT_ERROR):
            logger.critical(f"ai_core: Tesseract (OCR) not found processing {original_name}. OCR failed. Error: {e}", exc_info=False)
            # Depending on policy, you might still want to return any text extracted *before* OCR attempt.
            # For now, re-raise to indicate critical failure to the caller (app.py).
            raise
        
        logger.error(f"ai_core: Critical error processing {original_name}: {e}", exc_info=True)
        # Re-raise the exception to be handled by the caller in app.py
        raise
```

`server/rag_service/app.py`

```python
# server/rag_service/app.py
import os
import sys
import traceback
import logging
import atexit
import uuid
import io

from flask import Flask, request, jsonify, current_app, send_from_directory, after_this_request
from pydub import AudioSegment
from duckduckgo_search import DDGS
from qdrant_client import models as qdrant_models

# --- Add server directory to sys.path ---
SERVER_DIR = os.path.dirname(os.path.abspath(__file__))
if SERVER_DIR not in sys.path:
    sys.path.insert(0, SERVER_DIR)

import config
config.setup_logging()

# --- Import configurations and services ---
try:
    from vector_db_service import VectorDBService
    import ai_core
    import neo4j_handler 
    from neo4j import exceptions as neo4j_exceptions
    import document_generator
    import podcast_generator
    import academic_search
    import knowledge_graph_generator
    import google.generativeai as genai
except ImportError as e:
    print(f"CRITICAL IMPORT ERROR: {e}.")
    sys.exit(1)

logger = logging.getLogger(__name__)
app = Flask(__name__)

GENERATED_DOCS_DIR = os.path.join(SERVER_DIR, 'generated_docs')
os.makedirs(GENERATED_DOCS_DIR, exist_ok=True)
app.config['GENERATED_DOCS_DIR'] = GENERATED_DOCS_DIR

# --- Dynamic LLM Initialization & Wrapper ---
def get_llm_model(api_key: str):
    """Dynamically creates a GenerativeModel instance with the provided API key."""
    if not api_key:
        raise ValueError("An API key is required to initialize the LLM for this request.")
    
    genai.configure(api_key=api_key)
    safety_settings = [
        {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"},
    ]
    return genai.GenerativeModel(config.GEMINI_MODEL_NAME, safety_settings=safety_settings)

def llm_wrapper(prompt: str, api_key: str):
    """Wrapper that takes an api_key to initialize the model for each call."""
    if not api_key:
        raise ConnectionError("Gemini API Key was not provided for this operation.")
    
    llm_model = get_llm_model(api_key)
    
    for attempt in range(3):
        try:
            response = llm_model.generate_content(prompt)
            if response.parts:
                return "".join(part.text for part in response.parts if hasattr(part, 'text'))
            elif response.prompt_feedback and response.prompt_feedback.block_reason:
                 raise ValueError(f"Prompt blocked by API. Reason: {response.prompt_feedback.block_reason_message}")
            else:
                logger.warning("LLM returned empty response without explicit block reason.")
                return ""
        except Exception as e:
            logger.warning(f"LLM generation attempt {attempt + 1} failed: {e}")
            if attempt == 2: raise
    return ""

# --- Initialize other services ---
vector_service = None
try:
    vector_service = VectorDBService()
    vector_service.setup_collection()
    app.vector_service = vector_service
except Exception as e:
    logger.critical(f"Failed to initialize VectorDBService: {e}", exc_info=True)

try:
    neo4j_handler.init_driver()
except Exception as e:
    logger.critical(f"Neo4j driver failed to initialize: {e}.")

atexit.register(neo4j_handler.close_driver)

def create_error_response(message, status_code=500, details=None):
    log_message = f"API Error ({status_code}): {message}"
    if details: log_message += f" | Details: {details}"
    current_app.logger.error(log_message)
    response_payload = {"error": message}
    if details and status_code != 500: response_payload["details"] = details
    return jsonify(response_payload), status_code

# === API Endpoints ===

@app.route('/health', methods=['GET'])
def health_check():
    status_details = { "status": "error", "qdrant_service": "not_initialized", "neo4j_service": "not_initialized_via_handler", "neo4j_connection": "unknown"}
    http_status_code = 503
    if not vector_service:
        status_details["qdrant_service"] = "failed_to_initialize"
    else:
        status_details["qdrant_service"] = "initialized"
        try:
            vector_service.client.get_collection(collection_name=vector_service.collection_name)
            status_details["qdrant_collection_status"] = "exists_and_accessible"
        except Exception as e:
            status_details["qdrant_collection_status"] = f"error: {str(e)}"
    
    neo4j_ok, neo4j_conn_status = neo4j_handler.check_neo4j_connectivity()
    if neo4j_ok:
        status_details["neo4j_service"], status_details["neo4j_connection"] = "initialized_via_handler", "connected"
    else:
        status_details["neo4j_service"], status_details["neo4j_connection"] = "initialization_failed_or_handler_error", neo4j_conn_status
    
    if status_details["qdrant_service"] == "initialized" and status_details.get("qdrant_collection_status") == "exists_and_accessible" and neo4j_ok:
        status_details["status"], http_status_code = "ok", 200
    
    return jsonify(status_details), http_status_code

@app.route('/add_document', methods=['POST'])
def add_document_qdrant():
    data = request.get_json()
    if not data: return create_error_response("Request must be JSON", 400)
    user_id, file_path, original_name = data.get('user_id'), data.get('file_path'), data.get('original_name')
    if not all([user_id, file_path, original_name]): return create_error_response("Missing required fields", 400)
    if not os.path.exists(file_path): return create_error_response(f"File not found: {file_path}", 404)
    try:
        processed_chunks, raw_text, kg_chunks = ai_core.process_document_for_qdrant(file_path, original_name, user_id)
        num_added, status = 0, "processed_no_content"
        if processed_chunks:
            num_added = app.vector_service.add_processed_chunks(processed_chunks)
            if num_added > 0: status = "added_to_qdrant"
        return jsonify({ "message": "Document processed.", "status": status, "filename": original_name, "num_chunks_added_to_qdrant": num_added, "raw_text_for_analysis": raw_text or "", "chunks_with_metadata": kg_chunks }), 201
    except Exception as e: return create_error_response(f"Failed to process document: {str(e)}", 500)

@app.route('/query', methods=['POST'])
def search_qdrant_documents():
    data = request.get_json()
    if not data: return create_error_response("Request must be JSON", 400)
    query_text, user_id, k, doc_name = data.get('query'), data.get('user_id'), data.get('k', 5), data.get('documentContextName')
    if not query_text or not user_id: return create_error_response("Missing 'query' or 'user_id'", 400)
    try:
        must_conditions = [qdrant_models.FieldCondition(key="file_name", match=qdrant_models.MatchValue(value=doc_name))] if doc_name else []
        qdrant_filters = qdrant_models.Filter(must=must_conditions) if must_conditions else None
        retrieved, snippet, docs_map = vector_service.search_documents(query=query_text, k=k, filter_conditions=qdrant_filters)
        return jsonify({"retrieved_documents_list": [d.to_dict() for d in retrieved], "formatted_context_snippet": snippet, "retrieved_documents_map": docs_map}), 200
    except Exception as e: return create_error_response(f"Query failed: {str(e)}", 500)

@app.route('/academic_search', methods=['POST'])
def academic_search_route():
    data = request.get_json()
    if not data or 'query' not in data: return create_error_response("Missing 'query'", 400)
    try:
        results = academic_search.search_all_apis(data['query'], max_results_per_api=data.get('max_results', 3))
        return jsonify({"success": True, "results": results}), 200
    except Exception as e:
        return create_error_response(f"Academic search failed: {str(e)}", 500)

@app.route('/web_search', methods=['POST'])
def web_search_route():
    data = request.get_json()
    if not data or 'query' not in data: return create_error_response("Missing 'query'", 400)
    try:
        with DDGS() as ddgs:
            results = list(ddgs.text(data['query'], max_results=5))
        return jsonify([{"title": r.get("title"), "url": r.get("href"), "content": r.get("body")} for r in results]), 200
    except Exception as e: return create_error_response(f"Web search failed: {str(e)}", 500)

@app.route('/export_podcast', methods=['POST'])
def export_podcast_route():
    current_app.logger.info("--- /export_podcast Request (gTTS + Speed-Up) ---")
    data = request.get_json()
    if not data: return create_error_response("Request must be JSON", 400)
    
    source_document_text = data.get('sourceDocumentText')
    analysis_content = data.get('analysisContent')
    podcast_options = data.get('podcastOptions', {})
    api_key = data.get('api_key')
    
    if not all([source_document_text, analysis_content, api_key]):
        return create_error_response("Missing 'sourceDocumentText', 'analysisContent', or 'api_key'", 400)

    try:
        script = podcast_generator.generate_podcast_script(
            source_document_text, 
            analysis_content,
            podcast_options,
            lambda p: llm_wrapper(p, api_key)
        )
        
        temp_gtts_filename = f"podcast_gtts_{uuid.uuid4()}.mp3"
        temp_gtts_path = os.path.join(app.config['GENERATED_DOCS_DIR'], temp_gtts_filename)
        podcast_generator.synthesize_audio_with_gtts(script, temp_gtts_path)

        sound = AudioSegment.from_mp3(temp_gtts_path)
        sped_up_sound = sound.speedup(playback_speed=1.20)
        
        final_mp3_filename = f"podcast_final_{uuid.uuid4()}.mp3"
        final_mp3_path = os.path.join(app.config['GENERATED_DOCS_DIR'], final_mp3_filename)
        
        sped_up_sound.export(final_mp3_path, format="mp3")
        os.remove(temp_gtts_path)

        @after_this_request
        def cleanup(response):
            try: os.remove(final_mp3_path)
            except OSError as e: logger.error(f"Error deleting temp podcast MP3 file {final_mp3_path}: {e}")
            return response
            
        return send_from_directory(app.config['GENERATED_DOCS_DIR'], final_mp3_filename, as_attachment=True)
    except Exception as e:
        logger.error(f"Failed to generate podcast: {e}", exc_info=True)
        return create_error_response(f"Failed to generate podcast: {str(e)}", 500)

@app.route('/generate_kg_from_text', methods=['POST'])
def generate_kg_from_text_route():
    current_app.logger.info("--- /generate_kg_from_text Request ---")
    data = request.get_json()
    if not data: return create_error_response("Request must be JSON", 400)
    
    document_text = data.get('document_text')
    api_key = data.get('api_key')
    
    if not document_text or not api_key:
        return create_error_response("Missing 'document_text' or 'api_key' in request body", 400)
    
    try:
        graph_data = knowledge_graph_generator.generate_graph_from_text(
            document_text, 
            lambda p: llm_wrapper(p, api_key)
        )
        return jsonify({"success": True, "graph_data": graph_data}), 200
    except Exception as e:
        logger.error(f"Error during on-the-fly KG generation: {e}", exc_info=True)
        return create_error_response(f"KG Generation failed: {str(e)}", 500)

@app.route('/generate_document', methods=['POST'])
def generate_document_route():
    data = request.get_json()
    if not data: return create_error_response("Request must be JSON", 400)
    outline, doc_type, source_text, api_key = data.get('markdownContent'), data.get('docType'), data.get('sourceDocumentText'), data.get('api_key')
    if not all([outline, doc_type, source_text, api_key]): return create_error_response("Missing required fields", 400)
    try:
        expanded_content = document_generator.expand_content_with_llm(outline, source_text, doc_type, lambda p: llm_wrapper(p, api_key))
        slides = document_generator.parse_pptx_json(expanded_content) if doc_type == 'pptx' else document_generator.refined_parse_docx_markdown(expanded_content)
        filename, path = f"gen_{uuid.uuid4()}.{doc_type}", os.path.join(app.config['GENERATED_DOCS_DIR'], f"gen_{uuid.uuid4()}.{doc_type}")
        if doc_type == 'pptx': document_generator.create_ppt(slides, path)
        else: document_generator.create_doc(slides, path, "text_content")
        return jsonify({"success": True, "filename": filename}), 201
    except Exception as e: return create_error_response(f"Failed to generate document: {str(e)}", 500)

@app.route('/download_document/<filename>', methods=['GET'])
def download_document_route(filename):
    if '..' in filename: return create_error_response("Invalid filename.", 400)
    try:
        file_path = os.path.join(app.config['GENERATED_DOCS_DIR'], filename)
        if not os.path.exists(file_path): return create_error_response("File not found.", 404)
        @after_this_request
        def cleanup(response):
            try: os.remove(file_path)
            except OSError as e: logger.error(f"Error deleting temp file {file_path}: {e}")
            return response
        return send_from_directory(app.config['GENERATED_DOCS_DIR'], filename, as_attachment=True)
    except Exception as e:
        return create_error_response("Could not process download request.", 500)

# KG & DB Management Routes
@app.route('/delete_qdrant_document_data', methods=['DELETE'])
def delete_qdrant_data_route():
    data = request.get_json()
    if not data: return create_error_response("Request must be JSON", 400)
    user_id, document_name = data.get('user_id'), data.get('document_name') 
    if not user_id or not document_name: return create_error_response("Missing fields", 400)
    try:
        result = vector_service.delete_document_vectors(user_id, document_name)
        return jsonify(result), 200
    except Exception as e: return create_error_response(f"Deletion failed: {str(e)}", 500)

@app.route('/kg', methods=['POST'])
def add_or_update_kg_route():
    data = request.get_json()
    if not data: return create_error_response("Request must be JSON", 400)
    user_id, original_name, nodes, edges = data.get('userId'), data.get('originalName'), data.get('nodes'), data.get('edges')
    if not all([user_id, original_name, isinstance(nodes, list), isinstance(edges, list)]): return create_error_response("Missing fields", 400)
    try:
        result = neo4j_handler.ingest_knowledge_graph(user_id, original_name, nodes, edges)
        return jsonify({"message": "KG ingested", "status": "completed", **result}), 201
    except Exception as e: return create_error_response(f"KG ingestion failed: {str(e)}", 500)

@app.route('/kg/<user_id>/<path:document_name>', methods=['GET'])
def get_kg_route(user_id, document_name):
    try:
        kg_data = neo4j_handler.get_knowledge_graph(user_id, document_name)
        return jsonify(kg_data) if kg_data else create_error_response("KG not found", 404)
    except Exception as e: return create_error_response(f"KG retrieval failed: {str(e)}", 500)

@app.route('/kg/<user_id>/<path:document_name>', methods=['DELETE'])
def delete_kg_route(user_id, document_name):
    try:
        deleted = neo4j_handler.delete_knowledge_graph(user_id, document_name)
        return jsonify({"message": "KG deleted"}) if deleted else create_error_response("KG not found", 404)
    except Exception as e: return create_error_response(f"KG deletion failed: {str(e)}", 500)

if __name__ == '__main__':
    logger.info(f"--- Starting RAG API Service on port {config.API_PORT} ---")
    app.run(host='0.0.0.0', port=config.API_PORT, debug=False, threaded=True)

```

`server/rag_service/config.py`

```python
# server/rag_service/config.py
import os
import logging
from dotenv import load_dotenv

# --- Load .env from the parent 'server' directory ---
# This ensures that both Node.js and Python use the same .env file
# The path is calculated relative to this config.py file
dotenv_path = os.path.join(os.path.dirname(__file__), '..', '.env')
load_dotenv(dotenv_path=dotenv_path)


#  Logging Configuration 
logger = logging.getLogger(__name__)
LOGGING_LEVEL_NAME = os.getenv('LOGGING_LEVEL', 'INFO').upper()
LOGGING_LEVEL      = getattr(logging, LOGGING_LEVEL_NAME, logging.INFO)
LOGGING_FORMAT     = '%(asctime)s - %(levelname)s - [%(name)s:%(lineno)d] - %(message)s'

def setup_logging():
    """Configure logging across the app."""
    root_logger = logging.getLogger()
    if not root_logger.handlers:  # prevent duplicate handlers
        handler = logging.StreamHandler()
        formatter = logging.Formatter(LOGGING_FORMAT)
        handler.setFormatter(formatter)
        root_logger.addHandler(handler)
        root_logger.setLevel(LOGGING_LEVEL)

    logging.getLogger("urllib3").setLevel(logging.WARNING)
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logging.getLogger("faiss.loader").setLevel(logging.WARNING)
    logging.getLogger(__name__).info(f"Logging initialized at {LOGGING_LEVEL_NAME}")

# --- API Keys and Service URLs ---
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
GEMINI_MODEL_NAME = "gemini-1.5-flash-latest" # Or your preferred Gemini model

NEO4J_URI = os.getenv("NEO4J_URI", "bolt://localhost:7687")
NEO4J_USERNAME = os.getenv("NEO4J_USERNAME", "neo4j")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD", "password")
NEO4J_DATABASE = os.getenv("NEO4J_DATABASE", "neo4j")

QDRANT_HOST = os.getenv("QDRANT_HOST", "localhost")
QDRANT_PORT = int(os.getenv("QDRANT_PORT", 6333))
QDRANT_COLLECTION_NAME = os.getenv("QDRANT_COLLECTION_NAME", "my_qdrant_rag_collection")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY", None)
QDRANT_URL = os.getenv("QDRANT_URL", None)

# --- Embedding Model Configuration ---
DEFAULT_DOC_EMBED_MODEL = 'mixedbread-ai/mxbai-embed-large-v1'
DOCUMENT_EMBEDDING_MODEL_NAME = os.getenv('DOCUMENT_EMBEDDING_MODEL_NAME', DEFAULT_DOC_EMBED_MODEL)

_MODEL_TO_DIM_MAPPING = {
    'mixedbread-ai/mxbai-embed-large-v1': 1024,
    'BAAI/bge-large-en-v1.5': 1024,
    'all-MiniLM-L6-v2': 384,
    'sentence-transformers/all-mpnet-base-v2': 768,
}
_FALLBACK_DIM = 768
DOCUMENT_VECTOR_DIMENSION = int(os.getenv("DOCUMENT_VECTOR_DIMENSION", _MODEL_TO_DIM_MAPPING.get(DOCUMENT_EMBEDDING_MODEL_NAME, _FALLBACK_DIM)))
QDRANT_COLLECTION_VECTOR_DIM = DOCUMENT_VECTOR_DIMENSION

QUERY_EMBEDDING_MODEL_NAME = os.getenv("QUERY_EMBEDDING_MODEL_NAME", DOCUMENT_EMBEDDING_MODEL_NAME)
QUERY_VECTOR_DIMENSION = int(os.getenv("QUERY_VECTOR_DIMENSION", _MODEL_TO_DIM_MAPPING.get(QUERY_EMBEDDING_MODEL_NAME, _FALLBACK_DIM)))

if QUERY_VECTOR_DIMENSION != QDRANT_COLLECTION_VECTOR_DIM:
    logger.warning(f"[Config Warning] Query vector dim ({QUERY_VECTOR_DIMENSION}) != Qdrant dim ({QDRANT_COLLECTION_VECTOR_DIM})")

# --- AI Core & Search Configuration ---
AI_CORE_CHUNK_SIZE = int(os.getenv("AI_CORE_CHUNK_SIZE", 512))
AI_CORE_CHUNK_OVERLAP = int(os.getenv("AI_CORE_CHUNK_OVERLAP", 100))
MAX_TEXT_LENGTH_FOR_NER = int(os.getenv("MAX_TEXT_LENGTH_FOR_NER", 500000))
QDRANT_DEFAULT_SEARCH_K = int(os.getenv("QDRANT_DEFAULT_SEARCH_K", 5))
QDRANT_SEARCH_MIN_RELEVANCE_SCORE = float(os.getenv("QDRANT_SEARCH_MIN_RELEVANCE_SCORE", 0.1))

# --- SpaCy Configuration ---
SPACY_MODEL_NAME = os.getenv('SPACY_MODEL_NAME', 'en_core_web_sm')

# --- API Port Configuration ---
API_PORT = int(os.getenv('API_PORT', 5000))

# --- Tesseract OCR Path ---
TESSERACT_CMD = os.getenv('TESSERACT_CMD', r'C:\Program Files\Tesseract-OCR\tesseract.exe')


#  Library Availability Flags & Dynamic Imports 
try:
    import pypdf
    PYPDF_AVAILABLE = True
    PYPDF_PDFREADERROR = pypdf.errors.PdfReadError
except ImportError: PYPDF_AVAILABLE, PYPDF_PDFREADERROR = False, Exception

try:
    from docx import Document as DocxDocument
    DOCX_AVAILABLE = True
except ImportError: DOCX_AVAILABLE, DocxDocument = False, None

try:
    from pptx import Presentation
    PPTX_AVAILABLE = True
except ImportError: PPTX_AVAILABLE, Presentation = False, None

try:
    import pdfplumber
    PDFPLUMBER_AVAILABLE = True
except ImportError: PDFPLUMBER_AVAILABLE, pdfplumber = False, None

try:
    import pandas as pd
    PANDAS_AVAILABLE = True
except ImportError: PANDAS_AVAILABLE, pd = False, None

try:
    from PIL import Image
    PIL_AVAILABLE = True
except ImportError: PIL_AVAILABLE, Image = False, None

try:
    import fitz
    FITZ_AVAILABLE = True
except ImportError: FITZ_AVAILABLE, fitz = False, None

try:
    import pytesseract
    PYTESSERACT_AVAILABLE = True
    TESSERACT_ERROR = pytesseract.TesseractNotFoundError
    if TESSERACT_CMD: pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD
except ImportError: PYTESSERACT_AVAILABLE, pytesseract, TESSERACT_ERROR = False, None, Exception

try:
    import PyPDF2
    PYPDF2_AVAILABLE = True
except ImportError: PYPDF2_AVAILABLE, PyPDF2 = False, None

try:
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    LANGCHAIN_SPLITTER_AVAILABLE = True
except ImportError: LANGCHAIN_SPLITTER_AVAILABLE, RecursiveCharacterTextSplitter = False, None

#  Optional: Preload SpaCy & Embedding Model 
nlp_spacy_core, SPACY_MODEL_LOADED = None, False
try:
    import spacy
    nlp_spacy_core = spacy.load(SPACY_MODEL_NAME)
    SPACY_MODEL_LOADED = True
except Exception as e:
    logger.warning(f"Failed to load SpaCy model '{SPACY_MODEL_NAME}': {e}")

document_embedding_model, EMBEDDING_MODEL_LOADED = None, False
try:
    from sentence_transformers import SentenceTransformer
    document_embedding_model = SentenceTransformer(DOCUMENT_EMBEDDING_MODEL_NAME)
    EMBEDDING_MODEL_LOADED = True
except Exception as e:
    logger.warning(f"Failed to load Sentence Transformer model '{DOCUMENT_EMBEDDING_MODEL_NAME}': {e}")
```

`server/rag_service/document_generator.py`

```python
# server/rag_service/document_generator.py
import re
import json
from pptx import Presentation
from pptx.util import Inches, Pt
from pptx.dml.color import RGBColor
from pptx.enum.text import PP_ALIGN
from docx import Document
from docx.shared import Inches as DocxInches
import logging

logger = logging.getLogger(__name__)

# --- PROMPT FOR INTELLIGENT PPTX GENERATION (JSON-based) ---
PPTX_EXPANSION_PROMPT_TEMPLATE = """
You are a professional presentation designer and subject matter expert.
Your task is to expand a given OUTLINE (which could be a list of key topics or FAQs) into a full, detailed, 6-8 slide presentation.
You must use the provided SOURCE DOCUMENT TEXT as your only source of truth. Do not use outside knowledge.
Your output MUST be a single, valid JSON array, where each object represents a slide.

**JSON Object Schema for each slide:**
{{
  "slide_title": "A concise and engaging title for the slide.",
  "slide_content": "Detailed, professional paragraph(s) and/or bullet points elaborating on the outline point. This text will be displayed on the slide. Use Markdown for formatting (e.g., **bold**, *italics*, - bullet points).",
  "image_prompt": "A highly descriptive, creative prompt for an AI text-to-image model (like DALL-E or Midjourney) to generate a relevant and visually appealing image for this specific slide. Describe the style, subject, and composition. Example: 'A photorealistic image of a futuristic server room with glowing blue data streams flowing between racks, symbolizing data processing. Cinematic lighting.'"
}}

**INSTRUCTIONS:**
1.  **Analyze Outline & Source:** For each point in the OUTLINE, create at least one slide object in the JSON array.
2.  **Expand Content:** Elaborate on each outline point using only information from the SOURCE DOCUMENT TEXT.
3.  **Create Image Prompts:** For each slide, generate a unique and descriptive `image_prompt` that visually represents the slide's content.
4.  **JSON Format:** Ensure the final output is a single, clean JSON array with no other text before or after it.

---
**SOURCE DOCUMENT TEXT (Your knowledge base):**
{source_document_text}
---
**OUTLINE (Topics/FAQs to expand into a presentation):**
{outline_content}
---

**FINAL PRESENTATION JSON ARRAY:**
"""

# --- PROMPT FOR INTELLIGENT DOCX GENERATION (Markdown-based) ---
DOCX_EXPANSION_PROMPT_TEMPLATE = """
You are a professional content creator and subject matter expert.
Your task is to expand a given OUTLINE (which could be a list of key topics or FAQs) into a full, detailed, multi-page document in Markdown format.
You must use the provided SOURCE DOCUMENT TEXT as your only source of truth. Do not use outside knowledge.
The final output must be a single block of well-structured Markdown text.

**INSTRUCTIONS:**
1.  **Main Title:** Start the document with a main title using H1 syntax (e.g., `# Expanded Report on Key Topics`).
2.  **Section per Outline Point:** For each point in the OUTLINE, create a detailed section with a clear H2 or H3 heading (e.g., `## Topic Name`).
3.  **Content Expansion:** For each section, write detailed, professional paragraphs that elaborate on the outline point. Extract relevant facts, figures, and explanations from the SOURCE DOCUMENT TEXT.
4.  **Markdown Usage:** Use bullet points, bold text, and clear paragraphs to structure the content effectively.

---
**SOURCE DOCUMENT TEXT (Your knowledge base):**
{source_document_text}
---
**OUTLINE (Topics/FAQs to expand into a document):**
{outline_content}
---

**FINAL DOCUMENT MARKDOWN:**
"""

def expand_content_with_llm(outline_content, source_document_text, doc_type, llm_function):
    """Uses an LLM to expand an outline into full content for the specified doc type."""
    logger.info(f"Expanding outline for '{doc_type}' using LLM...")
    
    if doc_type == 'pptx':
        prompt = PPTX_EXPANSION_PROMPT_TEMPLATE.format(
            source_document_text=source_document_text,
            outline_content=outline_content
        )
    else: # for 'docx'
        prompt = DOCX_EXPANSION_PROMPT_TEMPLATE.format(
            source_document_text=source_document_text,
            outline_content=outline_content
        )

    expanded_content = llm_function(prompt)
    
    if not expanded_content or not expanded_content.strip():
        raise ValueError("LLM failed to generate expanded content.")
    
    logger.info(f"LLM generated expanded content for {doc_type}. Length: {len(expanded_content)}")
    return expanded_content

def parse_pptx_json(json_string):
    """Parses the LLM's JSON output for PPTX generation."""
    try:
        cleaned_str = re.sub(r'^```json\s*|\s*```$', '', json_string.strip())
        slides_data = json.loads(cleaned_str)
        if not isinstance(slides_data, list):
            raise ValueError("Parsed JSON is not a list of slides.")
        return slides_data
    except (json.JSONDecodeError, ValueError) as e:
        logger.error(f"Failed to parse JSON from LLM response: {e}")
        raise ValueError("LLM returned invalid JSON format for the presentation.") from e

def refined_parse_docx_markdown(markdown_content):
    """Parses the expanded markdown for DOCX generation into a single 'slide' object for consistency."""
    if not markdown_content or not markdown_content.strip():
        return []
    
    title_match = re.search(r"^\s*#\s+(.*)", markdown_content, re.MULTILINE)
    if title_match:
        title = title_match.group(1).strip()
        content = markdown_content[title_match.end():].strip()
    else:
        title = "Generated Document"
        content = markdown_content

    return [{"title": title, "text_content": content}]

def add_text_to_shape_with_markdown(text_frame, markdown_text, is_title=False, is_notes=False):
    text_frame.clear()
    text_frame.word_wrap = True
    title_font_size = Pt(36)
    content_font_size = Pt(16)
    notes_font_size = Pt(11)

    for line in markdown_text.split('\n'):
        p = text_frame.add_paragraph()
        p.alignment = PP_ALIGN.LEFT
        bullet_match = re.match(r'^(\s*)[\*\-]\s*(.*)', line)
        
        if bullet_match and not is_title:
            leading_spaces, content_line = bullet_match.groups()
            p.level = min(len(leading_spaces) // 2, 5)
        else:
            content_line = line.lstrip()

        segments = re.split(r'(\*\*.*?\*\*|__.*?__)', content_line)
        for segment in segments:
            if not segment: continue
            run = p.add_run()
            if (segment.startswith("**") and segment.endswith("**")) or (segment.startswith("__") and segment.endswith("__")):
                run.text = segment[2:-2]
                run.font.bold = True
            else:
                run.text = segment
            
            if is_title:
                run.font.color.rgb = RGBColor(255, 255, 255)
                run.font.size = title_font_size
            elif is_notes:
                run.font.color.rgb = RGBColor(210, 210, 230)
                run.font.size = notes_font_size
                run.font.italic = True
            else:
                run.font.color.rgb = RGBColor(255, 255, 255)
                run.font.size = content_font_size

def create_ppt(slides_data, output_path):
    prs = Presentation()
    prs.slide_width = Inches(16)
    prs.slide_height = Inches(9)

    for slide_data in slides_data:
        slide_layout = prs.slide_layouts[6] # Blank layout
        slide = prs.slides.add_slide(slide_layout)
        background = slide.background
        fill = background.fill
        fill.solid()
        fill.fore_color.rgb = RGBColor(15, 23, 42)

        title_shape = slide.shapes.add_textbox(Inches(0.5), Inches(0.2), prs.slide_width - Inches(1.0), Inches(1.0))
        add_text_to_shape_with_markdown(title_shape.text_frame, slide_data.get("slide_title", "Untitled Slide"), is_title=True)

        content_shape = slide.shapes.add_textbox(Inches(0.5), Inches(1.3), Inches(8.5), Inches(7.0))
        add_text_to_shape_with_markdown(content_shape.text_frame, slide_data.get("slide_content", "[No content provided]"))

        notes_shape = slide.shapes.add_textbox(Inches(9.5), Inches(1.3), Inches(6.0), Inches(7.0))
        image_prompt_header = " Image Generation Prompt:"
        image_prompt_body = slide_data.get("image_prompt", "N/A")
        add_text_to_shape_with_markdown(notes_shape.text_frame, f"**{image_prompt_header}**\n{image_prompt_body}", is_notes=True)

    prs.save(output_path)
    return True

def add_markdown_line_to_docx(doc, markdown_line):
    heading_match = re.match(r'^(#+)\s+(.*)', markdown_line)
    if heading_match:
        level = len(heading_match.group(1))
        doc.add_heading(heading_match.group(2).strip(), level=min(level, 4))
        return

    bullet_match = re.match(r'^(\s*)[\*\-]\s+(.*)', markdown_line)
    if bullet_match:
        leading_spaces, content_line = bullet_match.groups()
        p = doc.add_paragraph(style='List Bullet')
        p.paragraph_format.left_indent = DocxInches(0.25 * (len(leading_spaces) // 2))
    else:
        content_line = markdown_line
        p = doc.add_paragraph()
    
    segments = re.split(r'(\*\*.*?\*\*|__.*?__)', content_line)
    for segment in segments:
        if not segment: continue
        run = p.add_run()
        if (segment.startswith("**") and segment.endswith("**")) or (segment.startswith("__") and segment.endswith("__")):
            run.text = segment[2:-2]
            run.font.bold = True
        else:
            run.text = segment

def create_doc(slides_data, output_path, content_key="text_content"):
    doc = Document()
    if slides_data:
        doc_title = slides_data[0].get("title", "Generated Document")
        doc.add_heading(doc_title, level=0)
        
        content_to_add = slides_data[0].get(content_key, "")
        if content_to_add.strip():
            for line in content_to_add.split('\n'):
                add_markdown_line_to_docx(doc, line)
    else:
        doc.add_paragraph("[No content to generate]")
    doc.save(output_path)
    return True
```

`server/rag_service/file_parser.py`

```python
# server/rag_service/file_parser.py
import os
try:
    import pypdf
except ImportError:
    print("pypdf not found, PDF parsing will fail. Install with: pip install pypdf")
    pypdf = None # Set to None if not installed

try:
    from docx import Document as DocxDocument
except ImportError:
    print("python-docx not found, DOCX parsing will fail. Install with: pip install python-docx")
    DocxDocument = None

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.documents import Document as LangchainDocument
from rag_service import config # Import from package
import logging

# Configure logger for this module
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO) # Or DEBUG for more details
handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
if not logger.hasHandlers():
    logger.addHandler(handler)


def parse_pdf(file_path):
    """Extracts text content from a PDF file using pypdf."""
    if not pypdf: return None # Check if library loaded
    text = ""
    try:
        reader = pypdf.PdfReader(file_path)
        num_pages = len(reader.pages)
        # logger.debug(f"Reading {num_pages} pages from PDF: {os.path.basename(file_path)}")
        for i, page in enumerate(reader.pages):
            try:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n" # Add newline between pages
            except Exception as page_err:
                 logger.warning(f"Error extracting text from page {i+1} of {os.path.basename(file_path)}: {page_err}")
        # logger.debug(f"Extracted {len(text)} characters from PDF.")
        return text.strip() if text.strip() else None # Return None if empty after stripping
    except FileNotFoundError:
        logger.error(f"PDF file not found: {file_path}")
        return None
    except pypdf.errors.PdfReadError as pdf_err:
        logger.error(f"Error reading PDF {os.path.basename(file_path)} (possibly corrupted or encrypted): {pdf_err}")
        return None
    except Exception as e:
        logger.error(f"Unexpected error parsing PDF {os.path.basename(file_path)}: {e}", exc_info=True)
        return None

def parse_docx(file_path):
    """Extracts text content from a DOCX file."""
    if not DocxDocument: return None # Check if library loaded
    try:
        doc = DocxDocument(file_path)
        text = "\n".join([para.text for para in doc.paragraphs if para.text.strip()])
        # logger.debug(f"Extracted {len(text)} characters from DOCX.")
        return text.strip() if text.strip() else None
    except Exception as e:
        logger.error(f"Error parsing DOCX {os.path.basename(file_path)}: {e}", exc_info=True)
        return None

def parse_txt(file_path):
    """Reads text content from a TXT file (or similar plain text like .py, .js)."""
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            text = f.read()
        # logger.debug(f"Read {len(text)} characters from TXT file.")
        return text.strip() if text.strip() else None
    except Exception as e:
        logger.error(f"Error parsing TXT {os.path.basename(file_path)}: {e}", exc_info=True)
        return None

# Add PPTX parsing (requires python-pptx)
try:
    from pptx import Presentation
    PPTX_SUPPORTED = True
    def parse_pptx(file_path):
        """Extracts text content from a PPTX file."""
        text = ""
        try:
            prs = Presentation(file_path)
            for slide in prs.slides:
                for shape in slide.shapes:
                    if hasattr(shape, "text"):
                        shape_text = shape.text.strip()
                        if shape_text:
                            text += shape_text + "\n" # Add newline between shape texts
            # logger.debug(f"Extracted {len(text)} characters from PPTX.")
            return text.strip() if text.strip() else None
        except Exception as e:
            logger.error(f"Error parsing PPTX {os.path.basename(file_path)}: {e}", exc_info=True)
            return None
except ImportError:
    PPTX_SUPPORTED = False
    logger.warning("python-pptx not installed. PPTX parsing will be skipped.")
    def parse_pptx(file_path):
        logger.warning(f"Skipping PPTX file {os.path.basename(file_path)} as python-pptx is not installed.")
        return None


def parse_file(file_path):
    """Parses a file based on its extension, returning text content or None."""
    _, ext = os.path.splitext(file_path)
    ext = ext.lower()
    logger.debug(f"Attempting to parse file: {os.path.basename(file_path)} (Extension: {ext})")

    if ext == '.pdf':
        return parse_pdf(file_path)
    elif ext == '.docx':
        return parse_docx(file_path)
    elif ext == '.pptx':
        return parse_pptx(file_path) # Use the conditional function
    elif ext in ['.txt', '.py', '.js', '.md', '.log', '.csv', '.html', '.xml', '.json']: # Expand text-like types
        return parse_txt(file_path)
    # Add other parsers here if needed (e.g., for .doc, .xls)
    elif ext == '.doc':
        # Requires antiword or similar external tool, more complex
        logger.warning(f"Parsing for legacy .doc files is not implemented: {os.path.basename(file_path)}")
        return None
    else:
        logger.warning(f"Unsupported file extension for parsing: {ext} ({os.path.basename(file_path)})")
        return None

def chunk_text(text, file_name, user_id):
    """Chunks text and creates Langchain Documents with metadata."""
    if not text or not isinstance(text, str):
        logger.warning(f"Invalid text input for chunking (file: {file_name}). Skipping.")
        return []

    # Use splitter configured in config.py
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=config.CHUNK_SIZE,
        chunk_overlap=config.CHUNK_OVERLAP,
        length_function=len,
        is_separator_regex=False, # Use default separators
        # separators=["\n\n", "\n", " ", ""] # Default separators
    )

    try:
        chunks = text_splitter.split_text(text)
        if not chunks:
             logger.warning(f"Text splitting resulted in zero chunks for file: {file_name}")
             return []

        documents = []
        for i, chunk in enumerate(chunks):
             # Ensure chunk is not just whitespace before creating Document
             if chunk and chunk.strip():
                 documents.append(
                     LangchainDocument(
                         page_content=chunk,
                         metadata={
                             'userId': user_id, # Store user ID
                             'documentName': file_name, # Store original filename
                             'chunkIndex': i # Store chunk index for reference
                         }
                     )
                 )
        if documents:
            logger.info(f"Split '{file_name}' into {len(documents)} non-empty chunks.")
        else:
            logger.warning(f"No non-empty chunks created for file: {file_name} after splitting.")
        return documents
    except Exception as e:
        logger.error(f"Error during text splitting for file {file_name}: {e}", exc_info=True)
        return [] # Return empty list on error

```

`server/rag_service/knowledge_graph_generator.py`

```python
# server/rag_service/knowledge_graph_generator.py
import logging
import json
import re
from typing import List, Dict, Any

logger = logging.getLogger(__name__)

KG_GENERATION_PROMPT = """
You are an expert data architect. Your task is to analyze the provided text and extract a detailed knowledge graph. The graph should represent the core entities, concepts, and their relationships.

**INSTRUCTIONS:**
1.  **Identify Entities/Nodes**: Identify the key entities (people, places, concepts, processes, technologies). These will be your nodes. For each node, provide a unique ID (a short, descriptive string) and a 'type' (e.g., 'Concept', 'Technology', 'Process').
2.  **Identify Relationships/Edges**: Determine how these nodes are connected. The relationship should be a descriptive verb phrase (e.g., 'IS_A', 'USES', 'RESULTS_IN', 'PART_OF').
3.  **Format as JSON**: Your entire output MUST be a single, valid JSON object containing two keys: "nodes" and "edges".
    -   **Nodes**: An array of objects, where each object is `{"id": "NodeID", "label": "Full Node Name", "type": "NodeType"}`. The `label` is the full name, the `id` is a concise version for linking.
    -   **Edges**: An array of objects, where each object is `{"from": "SourceNodeID", "to": "TargetNodeID", "relationship": "RELATIONSHIP_TYPE"}`.
4.  **Be Thorough**: Extract as many meaningful nodes and edges as possible to create a rich, interconnected graph.

---
**DOCUMENT TEXT TO ANALYZE:**
__DOCUMENT_TEXT_PLACEHOLDER__
---

**FINAL KNOWLEDGE GRAPH JSON (start immediately with `{`):**
"""

def generate_graph_from_text(document_text: str, llm_function) -> Dict[str, Any]:
    """Uses an LLM to generate a knowledge graph from a block of text."""
    logger.info(f"Generating knowledge graph from text of length {len(document_text)}...")
    
    prompt = KG_GENERATION_PROMPT.replace(
        "__DOCUMENT_TEXT_PLACEHOLDER__", 
        document_text[:60000]
    )
    
    response_text = llm_function(prompt)
    
    if not response_text or not response_text.strip():
        raise ValueError("LLM failed to generate knowledge graph content.")
        
    json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
    if not json_match:
        raise ValueError("LLM response did not contain a valid JSON object for the knowledge graph.")
    
    json_string = json_match.group(0)
    
    try:
        graph_data = json.loads(json_string)
        if "nodes" not in graph_data or "edges" not in graph_data:
            raise ValueError("Parsed JSON is missing 'nodes' or 'edges' keys.")
        
        logger.info(f"Successfully generated knowledge graph with {len(graph_data['nodes'])} nodes and {len(graph_data['edges'])} edges.")
        return graph_data
    except json.JSONDecodeError as e:
        logger.error(f"Failed to parse JSON from LLM response for KG: {e}")
        raise ValueError("LLM returned invalid JSON format for the knowledge graph.") from e
```

`server/rag_service/neo4j_handler.py`

```python
# server/rag_service/neo4j_handler.py

import logging
from neo4j import GraphDatabase, exceptions as neo4j_exceptions
import config

logger = logging.getLogger(__name__)

# --- Neo4j Driver Management (No changes here) ---
_neo4j_driver = None
def init_driver():
    global _neo4j_driver
    if _neo4j_driver is not None:
        try: _neo4j_driver.verify_connectivity(); return
        except Exception: 
            if _neo4j_driver: _neo4j_driver.close()
            _neo4j_driver = None
    try:
        _neo4j_driver = GraphDatabase.driver(config.NEO4J_URI, auth=(config.NEO4J_USERNAME, config.NEO4J_PASSWORD))
        _neo4j_driver.verify_connectivity()
        logger.info(f"Neo4j driver initialized. Connected to: {config.NEO4J_URI}")
    except Exception as e:
        logger.critical(f"Failed to initialize Neo4j driver: {e}", exc_info=True)
        _neo4j_driver = None
def get_driver_instance():
    if _neo4j_driver is None: init_driver()
    if _neo4j_driver is None: raise ConnectionError("Neo4j driver is not available.")
    return _neo4j_driver
def close_driver():
    global _neo4j_driver
    if _neo4j_driver: _neo4j_driver.close(); _neo4j_driver = None
def check_neo4j_connectivity():
    try: get_driver_instance().verify_connectivity(); return True, "connected"
    except Exception as e: return False, f"disconnected: {e}"
def _execute_read_tx(tx_function, *args, **kwargs):
    with get_driver_instance().session(database=config.NEO4J_DATABASE) as session:
        return session.execute_read(tx_function, *args, **kwargs)
def _execute_write_tx(tx_function, *args, **kwargs):
    with get_driver_instance().session(database=config.NEO4J_DATABASE) as session:
        return session.execute_write(tx_function, *args, **kwargs)


# --- Private Transactional Cypher Functions ---
# (ingest/delete/add functions are correct and do not need changes)
def _delete_kg_transactional(tx, user_id, document_name):
    query = "MATCH (n:KnowledgeNode {userId: $userId, documentName: $documentName}) DETACH DELETE n"
    tx.run(query, userId=user_id, documentName=document_name)
    return True
def _add_nodes_transactional(tx, nodes_param, user_id, document_name):
    processed_nodes = [
        {"id": n["id"].strip(), "type": n.get("type", "concept"), "description": n.get("description", ""), "llm_parent_id": n.get("parent")}
        for n in nodes_param if isinstance(n.get("id"), str) and n.get("id").strip()
    ]
    if not processed_nodes: return 0
    query = """
    UNWIND $nodes_data as props MERGE (n:KnowledgeNode {nodeId: props.id, userId: $userId, documentName: $documentName})
    SET n += props, n.userId = $userId, n.documentName = $documentName RETURN count(n)
    """
    result = tx.run(query, nodes_data=processed_nodes, userId=user_id, documentName=document_name)
    return result.single()[0] if result.peek() else 0
def _add_edges_transactional(tx, edges_param, user_id, document_name):
    valid_edges = [
        {"from": e["from"].strip(), "to": e["to"].strip(), "relationship": e["relationship"].strip().upper().replace(" ", "_")}
        for e in edges_param if isinstance(e.get("from"), str) and e["from"].strip() and isinstance(e.get("to"), str) and e["to"].strip() and isinstance(e.get("relationship"), str) and e["relationship"].strip()
    ]
    if not valid_edges: return 0
    query = """
    UNWIND $edges_data as edge
    MATCH (startNode:KnowledgeNode {nodeId: edge.from, userId: $userId, documentName: $documentName})
    MATCH (endNode:KnowledgeNode {nodeId: edge.to, userId: $userId, documentName: $documentName})
    MERGE (startNode)-[r:RELATED_TO {type: edge.relationship}]->(endNode) RETURN count(r)
    """
    result = tx.run(query, edges_data=valid_edges, userId=user_id, documentName=document_name)
    return result.single()[0] if result.peek() else 0

# --- CORRECTED SEARCH AND GET QUERIES ---

def _search_kg_transactional(tx, user_id, document_name, query_text):
    logger.info(f"Neo4j TX: Searching KG for user '{user_id}', doc '{document_name}' with query: '{query_text[:50]}...'")
    
    query = """
    CALL db.index.fulltext.queryNodes("node_search_index", $query_text) YIELD node, score
    WHERE node.userId = $userId AND toLower(node.documentName) = toLower($documentName)
    WITH node, score ORDER BY score DESC LIMIT 5
    MATCH (node)-[r:RELATED_TO]-(neighbor)
    WHERE neighbor.userId = $userId AND toLower(neighbor.documentName) = toLower($documentName)
    RETURN node.nodeId AS nodeId, node.description AS description, 
           COLLECT(DISTINCT { relationship: r.type, neighborId: neighbor.nodeId }) AS relations
    """
    
    results = tx.run(query, userId=user_id, documentName=document_name, query_text=query_text)
    
    # --- THIS IS THE FIX ---
    # The f-string was changed to use double quotes on the outside,
    # so the inner single quotes don't need to be escaped.
    facts = []
    for record in results:
        fact = f"- Concept '{record['nodeId']}': {record['description']}"
        relations = [f"is '{rel['relationship']}' '{rel['neighborId']}'" for rel in record['relations'] if rel.get('relationship') and rel.get('neighborId')]
        if relations:
            fact += f" | It {', '.join(relations)}."
        facts.append(fact)
    # --- END OF FIX ---
        
    if not facts:
        return "No specific facts were found in the knowledge graph for this query."
        
    return "Facts from Knowledge Graph:\n" + "\n".join(facts)


def _get_kg_transactional(tx, user_id, document_name):
    logger.info(f"Neo4j TX: Retrieving FULL KG for visualization. User '{user_id}', Doc '{document_name}'")
    
    nodes_query = """
    MATCH (n:KnowledgeNode {userId: $userId}) WHERE toLower(n.documentName) = toLower($documentName)
    RETURN n.nodeId AS id, n.type AS type, n.description AS description, n.llm_parent_id AS parent
    """
    nodes_result = tx.run(nodes_query, userId=user_id, documentName=document_name)
    nodes_data = [dict(record) for record in nodes_result]

    edges_query = """
    MATCH (startNode:KnowledgeNode {userId: $userId})-[r:RELATED_TO]->(endNode:KnowledgeNode {userId: $userId})
    WHERE toLower(startNode.documentName) = toLower($documentName) AND toLower(endNode.documentName) = toLower($documentName)
    RETURN startNode.nodeId AS from, endNode.nodeId AS to, r.type AS relationship
    """
    edges_result = tx.run(edges_query, userId=user_id, documentName=document_name)
    edges_data = [dict(record) for record in edges_result]

    logger.info(f"Neo4j TX: Retrieved {len(nodes_data)} nodes and {len(edges_data)} edges for '{document_name}'.")
    return {"nodes": nodes_data, "edges": edges_data}


# --- Public Service Functions ---
def ingest_knowledge_graph(user_id: str, document_name: str, nodes: list, edges: list) -> dict:
    try:
        _execute_write_tx(_delete_kg_transactional, user_id, document_name)
        nodes_affected = _execute_write_tx(_add_nodes_transactional, nodes, user_id, document_name) if nodes else 0
        edges_affected = _execute_write_tx(_add_edges_transactional, edges, user_id, document_name) if edges else 0
        return {"success": True, "message": "KG ingested.", "nodes_affected": nodes_affected, "edges_affected": edges_affected}
    except Exception as e:
        logger.error(f"Error during KG ingestion for doc '{document_name}': {e}", exc_info=True)
        raise

def get_knowledge_graph(user_id: str, document_name: str) -> dict:
    try:
        kg_data = _execute_read_tx(_get_kg_transactional, user_id, document_name)
        if not kg_data or (not kg_data.get("nodes") and not kg_data.get("edges")):
            logger.info(f"No KG data found for user '{user_id}', document '{document_name}'.")
            return None
        return kg_data
    except Exception as e:
        logger.error(f"Error retrieving KG for doc '{document_name}': {e}", exc_info=True)
        raise

def delete_knowledge_graph(user_id: str, document_name: str) -> bool:
    try:
        return _execute_write_tx(_delete_kg_transactional, user_id, document_name)
    except Exception as e:
        logger.error(f"Error deleting KG for doc '{document_name}': {e}", exc_info=True)
        raise

def search_knowledge_graph(user_id: str, document_name: str, query_text: str) -> str:
    try:
        return _execute_read_tx(_search_kg_transactional, user_id, document_name, query_text)
    except Exception as e:
        logger.error(f"Error searching KG for doc '{document_name}', user '{user_id}': {e}", exc_info=True)
        return f"An error occurred while searching the knowledge graph: {e}"
```

`server/rag_service/podcast_generator.py`

```python

# server/rag_service/podcast_generator.py
import logging
import re
from gtts import gTTS

logger = logging.getLogger(__name__)

PODCAST_SCRIPT_PROMPT_TEMPLATE = """
You are an AI podcast script generator. Your SOLE task is to generate a realistic, two-speaker educational dialogue based on the provided text. The script should be substantial, aiming for a length of at least 600-800 words to ensure a meaningful discussion.

**CRITICAL INSTRUCTION:** Your entire output must be ONLY the script itself. Start directly with "SPEAKER_A:". Do NOT include any preamble, introduction, or metadata like "Here is the script:".

---
## Podcast Style Guide
- **Format**: Two-speaker conversational podcast.
- **SPEAKER_A**: The "Curious Learner". Asks clarifying questions and drives the conversation.
- **SPEAKER_B**: The "Expert Teacher". Provides clear, detailed explanations based on the document.
- **Dialogue Flow**: Natural back-and-forth. Create at least 5-7 exchanges.

---
## Task-Specific Instructions
- **Podcast Purpose**: {purpose_instruction}
- **Podcast Length**: {length_instruction}

---
## Source Material
**STUDY FOCUS (The main topic for the podcast):**
{study_focus}
**DOCUMENT TEXT (Use this for all factual answers):**
{document_content}
---
**FINAL SCRIPT OUTPUT (Remember: Start IMMEDIATELY with "SPEAKER_A:"):**
"""

def generate_podcast_script(source_document_text, outline_content, podcast_options, llm_function):
    """Generates a two-speaker podcast script using the LLM with dynamic options."""
    logger.info(f"Generating podcast script with options: {podcast_options}")

    purpose_map = {
        'introduction': "Focus on high-level concepts and definitions. Assume the listener is new to the topic. Keep explanations simple and clear.",
        'exam_prep': "Focus on key facts, data, and potential test questions. The dialogue should be structured like a Q&A review session, covering the most important material for an exam.",
        'deep_dive': "Explore the topic in great detail. Discuss nuances, complexities, and specific examples from the text. Assume the listener has some prior knowledge.",
        'review': "Provide a balanced overview of the main topics. Cover the most important points without getting lost in minor details. This is for general understanding."
    }
    
    length_map = {
        'quick': "The script should be concise, resulting in approximately 5-7 minutes of spoken audio. Aim for around 800-1000 words.",
        'standard': "The script should be of a standard length, resulting in approximately 10-15 minutes of spoken audio. Aim for around 1500-2000 words.",
        'comprehensive': "The script should be very detailed and long, resulting in approximately 15-25 minutes of spoken audio. Aim for over 2500 words."
    }

    purpose_instruction = purpose_map.get(podcast_options.get('studyPurpose'), purpose_map['review'])
    length_instruction = length_map.get(podcast_options.get('sessionLength'), length_map['standard'])

    prompt = PODCAST_SCRIPT_PROMPT_TEMPLATE.format(
        purpose_instruction=purpose_instruction,
        length_instruction=length_instruction,
        document_content=source_document_text[:60000],
        study_focus=outline_content,
    )
    
    script = llm_function(prompt)
    if not script or not script.strip():
        raise ValueError("LLM failed to generate a podcast script.")
    logger.info(f"LLM generated podcast script. Length: {len(script)}")
    return script

def synthesize_audio_with_gtts(text: str, output_path: str):
    """
    Synthesizes audio from text using the gTTS library and saves it as an MP3.
    """
    logger.info(f"Synthesizing audio with gTTS for text of length {len(text)}...")
    
    clean_text = re.sub(r'SPEAKER_[AB]:', '', text).replace('*', '').replace('#', '').strip()
    
    try:
        tts = gTTS(text=clean_text, lang='en', slow=False)
        tts.save(output_path)
        logger.info(f"gTTS audio saved successfully to {output_path}")
    except Exception as e:
        logger.error(f"gTTS failed during synthesis: {e}", exc_info=True)
        raise IOError("Text-to-Speech synthesis with gTTS failed.") from e

```

`server/rag_service/requirements.txt`

```
<<<<<<< HEAD
# server/rag_service/requirements.txt
flask
requests
faiss-cpu # or faiss-gpu
langchain
langchain-huggingface
pypdf
PyPDF2
python-docx
python-dotenv
ollama # Keep if using Ollama embeddings
python-pptx
uuid
langchain-community
pdfplumber
fitz # PyMuPDF for PDF parsing
pytesseract
nltk
spacy-layout
pandas
numpy
typing
pytesseract # OCR
pillow
qdrant-client
neo4j
sentence_transformers
spacy
opencv-python
duckduckgo-search
python-pptx
python-docx
reportlab
google-generativeai
gTTS

=======

# server/rag_service/requirements.txt

# --- Core and Web ---
flask
python-dotenv
requests
pydub

# --- Document Parsing ---
pdfplumber
PyMuPDF
pypdf
python-docx
python-pptx

# --- AI & NLP ---
google-generativeai
langchain
langchain-community
langchain-huggingface
ollama
sentencepiece
sentence_transformers
spacy
transformers

# --- Vector & Graph Databases ---
neo4j
qdrant-client

# --- Search & Utility ---
arxiv
duckduckgo-search
opencv-python
pytesseract
soundfile

# --- Final, Simple, and Free TTS ---
gTTS
>>>>>>> origin/skms

```

`server/rag_service/speech_enhancer.py`

```python
# server/rag_service/speech_enhancer.py
import speech_recognition as sr
import logging
import io

logger = logging.getLogger(__name__)

recognizer = sr.Recognizer()

def transcribe_audio_from_wav_bytes(audio_bytes: bytes) -> str:
    """
    Transcribes audio from an in-memory WAV byte buffer using Google's free API.
    Note: The input MUST be WAV format bytes.
    """
    logger.info("Transcribing audio using SpeechRecognition (Google Web Speech API free tier)...")
    try:
        # The library's AudioFile class can read from a file-like object (the byte buffer)
        with sr.AudioFile(io.BytesIO(audio_bytes)) as source:
            audio_data = recognizer.record(source)
            text = recognizer.recognize_google(audio_data)
            logger.info(f"Transcription successful. Length: {len(text)}")
            return text
    except sr.UnknownValueError:
        logger.warning("Google Speech Recognition could not understand audio.")
        raise ValueError("Could not understand the audio. It may be silent or unclear.")
    except sr.RequestError as e:
        logger.error(f"Could not request results from Google Speech Recognition service; {e}")
        raise ConnectionError(f"Speech recognition service request failed: {e}")
    except Exception as e:
        logger.error(f"An unexpected error occurred during transcription: {e}", exc_info=True)
        raise

ENHANCEMENT_PROMPT_TEMPLATE = """
You are an expert academic editor and content strategist.
You have been given a raw, unedited transcription of a spoken audio clip. You also have the full source document the speaker was referencing.

Your task is to **enhance the raw transcription** into a polished, professional, and insightful script. You MUST adhere to these rules:
1.  **Correct Errors:** Fix any grammatical errors, stutters, or awkward phrasing from the raw transcription.
2.  **Add Academic Depth:** Seamlessly integrate key facts, data, or concepts from the provided **SOURCE DOCUMENT TEXT** to add depth and accuracy to the speaker's points.
3.  **Maintain Speaker's Voice:** The output should still sound like a natural, spoken script, not a dense academic paper. Keep the original intent and tone.
4.  **Output Only the Polished Script:** Your entire response must be ONLY the final, enhanced script text. Do not include any preambles like "Here is the enhanced script:".

---
**SOURCE DOCUMENT TEXT (Your knowledge base):**
{source_document_text}
---
**RAW AUDIO TRANSCRIPTION (To be enhanced):**
{raw_transcription}
---

**FINAL, ENHANCED SCRIPT (Start immediately with the first sentence):**
"""

def enhance_script_with_llm(raw_transcription: str, source_document_text: str, llm_function) -> str:
    """Uses an LLM to enhance a raw transcription with context from a source document."""
    logger.info("Enhancing transcribed script using LLM...")
    
    prompt = ENHANCEMENT_PROMPT_TEMPLATE.format(
        source_document_text=source_document_text[:40000], # Limit context to avoid excessive token usage
        raw_transcription=raw_transcription
    )
    
    enhanced_script = llm_function(prompt)
    if not enhanced_script or not enhanced_script.strip():
        raise ValueError("LLM failed to generate the enhanced script.")
        
    logger.info(f"LLM generated enhanced script. Length: {len(enhanced_script)}")
    return enhanced_script
```

`server/rag_service/vector_db_service.py`

```python
import uuid
import logging
from typing import List, Dict, Tuple, Optional, Any

from qdrant_client import QdrantClient, models
from sentence_transformers import SentenceTransformer

# Assuming vector_db_service.py and config.py are in the same package directory (e.g., rag_service/)
# and you run your application as a module (e.g., python -m rag_service.main_app)
# or have otherwise correctly set up the Python path.
import config # Changed to relative import

# Configure basic logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class Document: # For search result formatting
    def __init__(self, page_content: str, metadata: dict):
        self.page_content = page_content
        self.metadata = metadata

    def to_dict(self):
        return {"page_content": self.page_content, "metadata": self.metadata}

class VectorDBService:
    def __init__(self):
        logger.info("Initializing VectorDBService...")
        logger.info(f"  Qdrant Host: {config.QDRANT_HOST}, Port: {config.QDRANT_PORT}, URL: {config.QDRANT_URL}")
        logger.info(f"  Collection: {config.QDRANT_COLLECTION_NAME}")
        logger.info(f"  Query Embedding Model: {config.QUERY_EMBEDDING_MODEL_NAME}")
        
        # The vector dimension for the Qdrant collection is defined by the DOCUMENT embedding model
        # This is set in config.QDRANT_COLLECTION_VECTOR_DIM
        self.vector_dim = config.QDRANT_COLLECTION_VECTOR_DIM
        logger.info(f"  Service expects Vector Dim for Qdrant collection: {self.vector_dim} (from document model config)")

        if config.QDRANT_URL:
            self.client = QdrantClient(
                url=config.QDRANT_URL,
                api_key=config.QDRANT_API_KEY,
                timeout=30
            )
        else:
            self.client = QdrantClient(
                host=config.QDRANT_HOST,
                port=config.QDRANT_PORT,
                api_key=config.QDRANT_API_KEY,
                timeout=30
            )

        try:
            # This model is for encoding search queries.
            # Its output dimension MUST match self.vector_dim (QDRANT_COLLECTION_VECTOR_DIM).
            logger.info(f"  Loading query embedding model: '{config.QUERY_EMBEDDING_MODEL_NAME}'")
            self.model = SentenceTransformer(config.QUERY_EMBEDDING_MODEL_NAME)
            model_embedding_dim = self.model.get_sentence_embedding_dimension()
            logger.info(f"  Query model loaded. Output dimension: {model_embedding_dim}")

            if model_embedding_dim != self.vector_dim:
                error_msg = (
                    f"CRITICAL DIMENSION MISMATCH: Query model '{config.QUERY_EMBEDDING_MODEL_NAME}' "
                    f"outputs embeddings of dimension {model_embedding_dim}, but the Qdrant collection "
                    f"is configured for dimension {self.vector_dim} (derived from document model: "
                    f"'{config.DOCUMENT_EMBEDDING_MODEL_NAME}'). Search functionality will fail. "
                    "Ensure query and document models produce compatible embedding dimensions, "
                    "or environment variables for dimensions are correctly set."
                )
                logger.error(error_msg)
                raise ValueError(error_msg) # Critical error, stop initialization
            else:
                logger.info(f"  Query model output dimension ({model_embedding_dim}) matches "
                            f"Qdrant collection dimension ({self.vector_dim}).")

        except Exception as e:
            logger.error(f"Error initializing SentenceTransformer model '{config.QUERY_EMBEDDING_MODEL_NAME}' for query encoding: {e}", exc_info=True)
            raise # Re-raise to prevent service startup with a non-functional query encoder

        self.collection_name = config.QDRANT_COLLECTION_NAME
        # No ThreadPoolExecutor needed here if document encoding is external

    def _recreate_qdrant_collection(self):
        logger.info(f"Attempting to (re)create collection '{self.collection_name}' with vector size {self.vector_dim}.")
        try:
            self.client.recreate_collection(
                collection_name=self.collection_name,
                vectors_config=models.VectorParams(
                    size=self.vector_dim,
                    distance=models.Distance.COSINE,
                ),
            )
            logger.info(f"Collection '{self.collection_name}' (re)created successfully.")
        except Exception as e_recreate:
            logger.error(f"Failed to (re)create collection '{self.collection_name}': {e_recreate}", exc_info=True)
            raise

    def setup_collection(self):
        try:
            collection_info = self.client.get_collection(collection_name=self.collection_name)
            logger.info(f"Collection '{self.collection_name}' already exists.")
            
            # Handle different Qdrant client versions for accessing vector config
            current_vectors_config = None
            if hasattr(collection_info.config.params, 'vectors'): # For simple vector config
                if isinstance(collection_info.config.params.vectors, models.VectorParams):
                     current_vectors_config = collection_info.config.params.vectors
                elif isinstance(collection_info.config.params.vectors, dict): # For named vectors
                    # Assuming default unnamed vector or first one if named
                    default_vector_name = '' # Common for single vector setup
                    if default_vector_name in collection_info.config.params.vectors:
                        current_vectors_config = collection_info.config.params.vectors[default_vector_name]
                    elif collection_info.config.params.vectors: # Get first one if default not found
                        current_vectors_config = next(iter(collection_info.config.params.vectors.values()))

            if not current_vectors_config:
                 logger.error(f"Could not determine vector configuration for existing collection '{self.collection_name}'. Recreating.")
                 self._recreate_qdrant_collection()
            elif current_vectors_config.size != self.vector_dim:
                logger.warning(f"Collection '{self.collection_name}' vector size {current_vectors_config.size} "
                               f"differs from service's expected {self.vector_dim}. Recreating.")
                self._recreate_qdrant_collection()
            elif current_vectors_config.distance != models.Distance.COSINE: # Ensure distance is also checked
                logger.warning(f"Collection '{self.collection_name}' distance {current_vectors_config.distance} "
                               f"differs from expected {models.Distance.COSINE}. Recreating.")
                self._recreate_qdrant_collection()
            else:
                logger.info(f"Collection '{self.collection_name}' configuration is compatible (Size: {current_vectors_config.size}, Distance: {current_vectors_config.distance}).")

        except Exception as e: # Broad exception for Qdrant client errors
            # More specific check for "Not found" type errors
            if "not found" in str(e).lower() or \
               (hasattr(e, 'status_code') and e.status_code == 404) or \
               " " in str(e).lower(): # "Lucky" in Bengali, seems to be part of an error message you encountered
                 logger.info(f"Collection '{self.collection_name}' not found. Attempting to create...")
            else:
                 logger.warning(f"Error checking collection '{self.collection_name}': {type(e).__name__} - {e}. Attempting to (re)create anyway...")
            self._recreate_qdrant_collection()

    def add_processed_chunks(self, processed_chunks: List[Dict[str, Any]]) -> int:
        if not processed_chunks:
            logger.warning("add_processed_chunks received an empty list. No points to upsert.")
            return 0

        points_to_upsert = []
        doc_name_for_logging = "Unknown Document"

        for chunk_data in processed_chunks:
            point_id = chunk_data.get('id', str(uuid.uuid4()))
            vector = chunk_data.get('embedding')
            
            payload = chunk_data.get('metadata', {}).copy()
            payload['chunk_text_content'] = chunk_data.get('text_content', '')

            if not doc_name_for_logging or doc_name_for_logging == "Unknown Document":
                doc_name_for_logging = payload.get('original_name', payload.get('document_name', "Unknown Document"))

            if not vector:
                logger.warning(f"Chunk with ID '{point_id}' from '{doc_name_for_logging}' is missing 'embedding'. Skipping.")
                continue
            if not isinstance(vector, list) or not all(isinstance(x, (float, int)) for x in vector): # Allow int too, SentenceTransformer can return float32 which might be int-like in lists
                logger.warning(f"Chunk with ID '{point_id}' from '{doc_name_for_logging}' has an invalid 'embedding' format. Skipping.")
                continue
            if len(vector) != self.vector_dim:
                logger.error(f"Chunk with ID '{point_id}' from '{doc_name_for_logging}' has embedding dimension {len(vector)}, "
                             f"but collection expects {self.vector_dim}. Skipping. "
                             f"Ensure ai_core's document embedding model ('{config.DOCUMENT_EMBEDDING_MODEL_NAME}') "
                             f"output dimension matches configuration.")
                continue

            points_to_upsert.append(models.PointStruct(
                id=point_id,
                vector=[float(v) for v in vector], # Ensure all are floats for Qdrant
                payload=payload
            ))

        if not points_to_upsert:
            logger.warning(f"No valid points constructed from processed_chunks for document: {doc_name_for_logging}.")
            return 0

        try:
            self.client.upsert(collection_name=self.collection_name, points=points_to_upsert, wait=True) # wait=True can be useful for debugging
            logger.info(f"Successfully upserted {len(points_to_upsert)} chunks for document: {doc_name_for_logging} into Qdrant.")
            return len(points_to_upsert)
        except Exception as e:
            logger.error(f"Error upserting processed chunks to Qdrant for document: {doc_name_for_logging}: {e}", exc_info=True)
            raise

    def search_documents(self, query: str, k: int = -1, filter_conditions: Optional[models.Filter] = None) -> Tuple[List[Document], str, Dict]:
        # Use default k from config if not provided or invalid
        if k <= 0:
            k_to_use = config.QDRANT_DEFAULT_SEARCH_K
        else:
            k_to_use = k

        context_docs = []
        formatted_context_text = "No relevant context was found in the available documents."
        context_docs_map = {}

        logger.info(f"Searching with query (first 50 chars): '{query[:50]}...', k: {k_to_use}")
        if filter_conditions:
            try: filter_dict = filter_conditions.dict()
            except AttributeError: # For older Pydantic versions
                try: filter_dict = filter_conditions.model_dump()
                except AttributeError: filter_dict = str(filter_conditions) # Fallback
            logger.info(f"Applying filter: {filter_dict}")
        else:
            logger.info("No filter applied for search.")

        try:
            query_embedding = self.model.encode(query).tolist()
            logger.debug(f"Generated query_embedding (length: {len(query_embedding)}, first 5 dims: {query_embedding[:5]})")

            search_results = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_embedding,
                query_filter=filter_conditions,
                limit=k_to_use,
                with_payload=True,
                score_threshold=config.QDRANT_SEARCH_MIN_RELEVANCE_SCORE # Apply score threshold directly in search
            )
            logger.info(f"Qdrant client.search returned {len(search_results)} results (after score threshold).")

            if not search_results:
                return context_docs, formatted_context_text, context_docs_map

            for idx, point in enumerate(search_results):
                # Score threshold is already applied by Qdrant if score_threshold parameter is used.
                # If not using score_threshold in client.search, uncomment this:
                # if point.score < config.QDRANT_SEARCH_MIN_RELEVANCE_SCORE:
                #     logger.debug(f"Skipping point ID {point.id} with score {point.score:.4f} (below threshold {config.QDRANT_SEARCH_MIN_RELEVANCE_SCORE})")
                #     continue

                payload = point.payload
                content = payload.get("chunk_text_content", payload.get("text_content", payload.get("chunk_text", "")))

                retrieved_metadata = payload.copy()
                retrieved_metadata["qdrant_id"] = point.id
                retrieved_metadata["score"] = point.score

                doc = Document(page_content=content, metadata=retrieved_metadata)
                context_docs.append(doc)

            # Format context and citations
            formatted_context_parts = []
            for i, doc_obj in enumerate(context_docs):
                citation_index = i + 1
                doc_meta = doc_obj.metadata
                # Use more robust fetching of metadata keys
                display_subject = doc_meta.get("title", doc_meta.get("subject", "Unknown Subject")) # Prefer title for subject
                doc_name = doc_meta.get("original_name", doc_meta.get("file_name", "N/A"))
                page_num_info = f" (Page: {doc_meta.get('page_number', 'N/A')})" if doc_meta.get('page_number') else "" # Add page number if available
                
                content_preview = doc_obj.page_content[:200] + "..." if len(doc_obj.page_content) > 200 else doc_obj.page_content

                formatted = (f"[{citation_index}] Score: {doc_meta.get('score', 0.0):.4f} | "
                             f"Source: {doc_name}{page_num_info} | Subject: {display_subject}\n"
                             f"Content: {content_preview}") # Show content preview
                formatted_context_parts.append(formatted)

                context_docs_map[str(citation_index)] = {
                    "subject": display_subject,
                    "document_name": doc_name,
                    "page_number": doc_meta.get("page_number"),
                    "content_preview": content_preview, # Store preview
                    "full_content": doc_obj.page_content, # Store full content for potential later use
                    "score": doc_meta.get("score", 0.0),
                    "qdrant_id": doc_meta.get("qdrant_id"),
                    "original_metadata": doc_meta # Store all original metadata from payload
                }
            if formatted_context_parts:
                formatted_context_text = "\n\n---\n\n".join(formatted_context_parts)
            else:
                formatted_context_text = "No sufficiently relevant context was found after filtering."

        except Exception as e:
            logger.error(f"Qdrant search/RAG error: {e}", exc_info=True)
            formatted_context_text = "Error retrieving context due to an internal server error."

        return context_docs, formatted_context_text, context_docs_map
    
    # Add this method to the VectorDBService class in vector_db_service.py

    def delete_document_vectors(self, user_id: str, document_name: str) -> Dict[str, Any]:
        logger.info(f"Attempting to delete vectors for document: '{document_name}', user: '{user_id}' from Qdrant collection '{self.collection_name}'.")
        
        # These metadata keys must match what's stored during ingestion from ai_core.py
        # 'processing_user' was the user_id passed to ai_core
        # 'file_name' was the original_name passed to ai_core
        qdrant_filter = models.Filter(
            must=[
                models.FieldCondition(
                    key="processing_user", # The metadata field storing the user ID
                    match=models.MatchValue(value=user_id)
                ),
                models.FieldCondition(
                    key="file_name", # The metadata field storing the original document name
                    match=models.MatchValue(value=document_name)
                )
            ]
        )
        
        try:
            # Optional: Count points before deleting for logging/confirmation
            # count_response = self.client.count(collection_name=self.collection_name, count_filter=qdrant_filter)
            # num_to_delete = count_response.count
            # logger.info(f"Qdrant: Found {num_to_delete} points matching criteria for document '{document_name}', user '{user_id}'.")

            # if num_to_delete == 0:
            #     logger.info(f"Qdrant: No points found to delete for document '{document_name}', user '{user_id}'.")
            #     return {"success": True, "message": "No matching vectors found in Qdrant to delete.", "deleted_count": 0}

            delete_result = self.client.delete(
                collection_name=self.collection_name,
                points_selector=models.FilterSelector(filter=qdrant_filter),
                wait=True # Make it synchronous
            )
            
            # Check the status of the delete operation
            # delete_result should be an UpdateResult object
            if delete_result.status == models.UpdateStatus.COMPLETED or delete_result.status == models.UpdateStatus.ACKNOWLEDGED:
                # The actual number of deleted points isn't directly returned by filter-based delete.
                # We can infer it was successful if no error.
                # For a precise count, you'd need to list IDs by filter, then delete by IDs.
                logger.info(f"Qdrant delete operation for document '{document_name}', user '{user_id}' acknowledged/completed. Status: {delete_result.status}")
                return {"success": True, "message": f"Qdrant vector deletion for document '{document_name}' completed. Status: {delete_result.status}."}
            else:
                logger.warning(f"Qdrant delete operation for document '{document_name}', user '{user_id}' returned status: {delete_result.status}")
                return {"success": False, "message": f"Qdrant delete operation status: {delete_result.status}"}

        except Exception as e:
            logger.error(f"Error deleting document vectors from Qdrant for document '{document_name}', user '{user_id}': {e}", exc_info=True)
            # Check for specific Qdrant client errors if possible, e.g., if the collection doesn't exist.
            return {"success": False, "message": f"Failed to delete Qdrant vectors: {str(e)}"}

    def close(self):
        logger.info("VectorDBService close called.")
        # No specific resources like ThreadPoolExecutor to release in this version.
        # QdrantClient does not have an explicit close() method in recent versions.
```

`server/rag_service/__init__.py`

```python

```

`server/routes/adminDocuments.js`

```javascript


// server/routes/adminDocuments.js
const express = require('express');
const multer = require('multer');
const path = require('path');
const fs = require('fs');
const fsPromises = fs.promises;
const AdminDocument = require('../models/AdminDocument');
const { fixedAdminAuthMiddleware } = require('../middleware/fixedAdminAuthMiddleware');
const axios = require('axios');

const router = express.Router();

// --- Constants & Multer Config ---
const ADMIN_UPLOAD_DIR_BASE = path.join(__dirname, '..', 'assets', '_admin_uploads_');
const MAX_FILE_SIZE = 20 * 1024 * 1024;
const allowedAdminMimeTypes = {
    'application/pdf': 'docs',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document': 'docs',
    'text/plain': 'docs',
    'text/markdown': 'docs',
};
const allowedAdminExtensions = ['.pdf', '.docx', '.txt', '.md'];

const adminStorage = multer.diskStorage({
    destination: (req, file, cb) => {
        const fileMimeType = file.mimetype.toLowerCase();
        const fileTypeSubfolder = allowedAdminMimeTypes[fileMimeType] || 'others';
        const destinationPath = path.join(ADMIN_UPLOAD_DIR_BASE, fileTypeSubfolder);
        fs.mkdir(destinationPath, { recursive: true }, (err) => {
            if (err) return cb(err);
            cb(null, destinationPath);
        });
    },
    filename: (req, file, cb) => {
        const timestamp = Date.now();
        const fileExt = path.extname(file.originalname).toLowerCase();
        const sanitizedBaseName = path.basename(file.originalname, fileExt)
            .replace(/[^a-zA-Z0-9._-]/g, '_').substring(0, 100);
        cb(null, `${timestamp}-${sanitizedBaseName}${fileExt}`);
    }
});
const adminFileFilter = (req, file, cb) => {
    const fileExt = path.extname(file.originalname).toLowerCase();
    const mimeType = file.mimetype.toLowerCase();
    if (allowedAdminMimeTypes[mimeType] && allowedAdminExtensions.includes(fileExt)) {
        cb(null, true);
    } else {
        const error = new multer.MulterError('LIMIT_UNEXPECTED_FILE_TYPE_ADMIN');
        error.message = `Invalid file type. Allowed: ${allowedAdminExtensions.join(', ')}`;
        cb(error, false);
    }
};
const adminUpload = multer({ storage: adminStorage, fileFilter: adminFileFilter, limits: { fileSize: MAX_FILE_SIZE }});
async function triggerPythonTextExtractionForAdmin(filePath, originalName) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
    if (!pythonServiceUrl) return { success: false, message: "Python service URL not configured.", text: null };
    const addDocumentUrl = `${pythonServiceUrl}/add_document`;
    try {
        const response = await axios.post(addDocumentUrl, {
            user_id: "fixed_admin_text_extraction_user",
            file_path: filePath, original_name: originalName
        }, { timeout: 300000 });
        const text = response.data?.raw_text_for_analysis || null;
        if (text) return { success: true, message: "Text extracted.", text: text };
        return { success: false, message: response.data?.message || "Python extracted no text.", text: null };
    } catch (error) {
        const errorMsg = error.response?.data?.error || error.message || "Unknown error calling Python RAG.";
        return { success: false, message: `Python RAG call failed: ${errorMsg}`, text: null };
    }
}


// @route   POST /api/admin/documents/upload
router.post('/upload', fixedAdminAuthMiddleware, adminUpload.single('file'), async (req, res) => {
    if (!req.file) {
        return res.status(400).json({ message: 'No file uploaded or file type rejected.' });
    }
    const { filename: serverFilename, originalname: originalName, path: tempServerPath } = req.file;
    let adminDocRecord;
    try {
        const existingDoc = await AdminDocument.findOne({ originalName: originalName });
        if (existingDoc) {
            await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Error deleting duplicate temp file ${tempServerPath}:`, e));
            return res.status(409).json({ message: `Document with original name '${originalName}' already exists for admin.` });
        }
        const textExtractionResult = await triggerPythonTextExtractionForAdmin(tempServerPath, originalName);
        if (!textExtractionResult.success || !textExtractionResult.text || textExtractionResult.text.trim() === "") {
            await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Error deleting temp file ${tempServerPath} after failed text extraction:`, e));
            return res.status(422).json({
                message: textExtractionResult.message || "Failed to extract usable text from the document.",
                filename: serverFilename, originalname: originalName
            });
        }
        adminDocRecord = new AdminDocument({
            filename: serverFilename, originalName: originalName, text: textExtractionResult.text,
            analysis: { faq: "", topics: "", mindmap: "" }, analysisUpdatedAt: null,
        });
        await adminDocRecord.save();
        await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Non-critical error deleting temp file ${tempServerPath} after DB save:`, e));
        
        res.status(202).json({
            message: `Admin document '${originalName}' uploaded. Text extracted. Analysis initiated.`,
            filename: serverFilename, originalname: originalName,
        });

        const { Worker } = require('worker_threads');
        const adminAnalysisWorkerPath = path.resolve(__dirname, '..', 'workers', 'adminAnalysisWorker.js');
        if (fs.existsSync(adminAnalysisWorkerPath)) {
            // --- THIS IS THE CRITICAL FIX ---
            // The admin worker always uses the server's global API key.
            const worker = new Worker(adminAnalysisWorkerPath, {
                workerData: {
                    adminDocumentId: adminDocRecord._id.toString(),
                    originalName: originalName,
                    textForAnalysis: textExtractionResult.text,
                    // NOTE: Admin analysis ALWAYS uses the server's Gemini key
                    llmProvider: 'gemini', 
                    apiKey: process.env.GEMINI_API_KEY // Pass the global key from .env
                }
            });
            worker.on('message', (msg) => console.log(`Admin Analysis Worker [Doc: ${msg.originalName || originalName}]: ${msg.message || JSON.stringify(msg)}`));
            worker.on('error', (err) => console.error(`Admin Analysis Worker Error [Doc: ${originalName}]:`, err));
            worker.on('exit', (code) => console.log(`Admin Analysis Worker [Doc: ${originalName}] exited (code ${code}).`));
            // --- END OF FIX ---
        } else {
            console.error(`Admin Upload: adminAnalysisWorker.js not found at ${adminAnalysisWorkerPath}.`);
        }
    } catch (error) {
        console.error(`Admin Upload: Overall error for '${originalName || (req.file && req.file.originalname)}':`, error);
        if (tempServerPath) await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Error cleaning up temp file ${tempServerPath} after overall error:`, e));
        if (!res.headersSent) {
            if (error.code === 11000) res.status(409).json({ message: 'Document processing conflict.' });
            else res.status(500).json({ message: 'Server error during admin document upload.' });
        }
    }
});

// @route   GET /api/admin/documents
router.get('/', fixedAdminAuthMiddleware, async (req, res) => {
    try {
        const adminDocs = await AdminDocument.find().sort({ uploadedAt: -1 })
            .select('originalName filename uploadedAt analysisUpdatedAt analysis.faq analysis.topics analysis.mindmap');
        const documentsList = adminDocs.map(doc => ({
            originalName: doc.originalName, serverFilename: doc.filename, uploadedAt: doc.uploadedAt,
            analysisUpdatedAt: doc.analysisUpdatedAt,
            hasFaq: !!(doc.analysis && doc.analysis.faq && doc.analysis.faq.trim() !== ""),
            hasTopics: !!(doc.analysis && doc.analysis.topics && doc.analysis.topics.trim() !== ""),
            hasMindmap: !!(doc.analysis && doc.analysis.mindmap && doc.analysis.mindmap.trim() !== ""),
        }));
        res.json({ documents: documentsList });
    } catch (error) {
        res.status(500).json({ message: 'Server error fetching admin documents.' });
    }
});

// @route   DELETE /api/admin/documents/:serverFilename
router.delete('/:serverFilename', fixedAdminAuthMiddleware, async (req, res) => {
    const { serverFilename } = req.params;
    if (!serverFilename) return res.status(400).json({ message: 'Server filename parameter is required.' });
    try {
        const docToDelete = await AdminDocument.findOneAndDelete({ filename: serverFilename });
        if (!docToDelete) return res.status(404).json({ message: `Admin document '${serverFilename}' not found.` });
        res.status(200).json({ message: `Admin document '${docToDelete.originalName}' record deleted.` });
    } catch (error) {
        res.status(500).json({ message: 'Server error during admin document deletion.' });
    }
});

// @route   GET /api/admin/documents/:serverFilename/analysis
router.get('/:serverFilename/analysis', fixedAdminAuthMiddleware, async (req, res) => {
    const { serverFilename } = req.params;
    if (!serverFilename) return res.status(400).json({ message: 'Server filename parameter is required.' });
    try {
        const adminDoc = await AdminDocument.findOne({ filename: serverFilename }).select('originalName analysis analysisUpdatedAt');
        if (!adminDoc) return res.status(404).json({ message: `Admin document '${serverFilename}' not found.` });
        if (!adminDoc.analysis || (!adminDoc.analysis.faq && !adminDoc.analysis.topics && !adminDoc.analysis.mindmap)) {
            return res.status(200).json({
                originalName: adminDoc.originalName, message: 'Analysis not generated or empty.',
                analysis: { faq: "", topics: "", mindmap: "" }, analysisUpdatedAt: adminDoc.analysisUpdatedAt
            });
        }
        res.status(200).json({
            originalName: adminDoc.originalName, analysis: adminDoc.analysis,
            analysisUpdatedAt: adminDoc.analysisUpdatedAt
        });
    } catch (error) {
        res.status(500).json({ message: 'Server error retrieving admin document analysis.' });
    }
});

// @route   GET /api/admin/documents/by-original-name/:originalName/analysis
router.get('/by-original-name/:originalName/analysis', fixedAdminAuthMiddleware, async (req, res) => {
    const { originalName } = req.params;
    if (!originalName) {
        return res.status(400).json({ message: 'Original name parameter is required.' });
    }
    try {
        const decodedOriginalName = decodeURIComponent(originalName);
        const adminDoc = await AdminDocument.findOne({ originalName: decodedOriginalName })
            .select('originalName filename analysis analysisUpdatedAt');

        if (!adminDoc) {
            return res.status(404).json({ message: `Admin document with original name '${decodedOriginalName}' not found.` });
        }
        
        res.status(200).json({
            originalName: adminDoc.originalName,
            serverFilename: adminDoc.filename,
            analysis: adminDoc.analysis,
            analysisUpdatedAt: adminDoc.analysisUpdatedAt
        });
    } catch (error) {
        console.error(`Error fetching analysis for admin document by original name '${originalName}':`, error);
        res.status(500).json({ message: 'Server error while retrieving admin document analysis by original name.' });
    }
});

module.exports = router;
```

`server/routes/analysis.js`

```javascript
// server/routes/analysis.js
const express = require('express');
const router = express.Router();
const { authMiddleware } = require('../middleware/authMiddleware');
const User = require('../models/User');

// @route   GET /api/analysis/:documentFilename
// @desc    Get analysis data (faq, topics, mindmap) for a specific document
// @access  Private (requires auth)
router.get('/:documentFilename', authMiddleware, async (req, res) => {
    const userId = req.user._id; // From authMiddleware
    const { documentFilename } = req.params;
    
    if (!documentFilename) {
        return res.status(400).json({ message: 'Document filename parameter is required.' });
    }

    try {
        const user = await User.findById(userId).select('uploadedDocuments');
        if (!user) {
            return res.status(404).json({ message: 'User not found.' });
        }

        const document = user.uploadedDocuments.find(doc => doc.filename === documentFilename);

        if (!document) {
            return res.status(404).json({ message: `Document '${documentFilename}' not found for this user.` });
        }

        if (!document.analysis) {
            // This case might happen if the analysis object itself is missing, though schema has defaults.
            console.warn(`Analysis object missing for document '${documentFilename}', user '${userId}'. Sending empty analysis.`);
            return res.status(200).json({
                faq: "",
                topics: "",
                mindmap: ""
            });
        }
        
        // Send the analysis sub-document
        res.status(200).json(document.analysis);

    } catch (error) {
        console.error(`Error fetching analysis for document '${documentFilename}', user '${userId}':`, error);
        res.status(500).json({ message: 'Server error while retrieving document analysis.' });
    }
});

module.exports = router;
```

`server/routes/auth.js`

```javascript
// server/routes/auth.js
const express = require('express');
const jwt = require('jsonwebtoken');
const { v4: uuidv4 } = require('uuid');
const User = require('../models/User');
const { authMiddleware } = require('../middleware/authMiddleware');
require('dotenv').config();

const router = express.Router();
const JWT_EXPIRATION = process.env.JWT_EXPIRATION || '7d';

// --- @route   POST /api/auth/signup ---
router.post('/signup', async (req, res) => {
  // 1. Destructure all possible fields from the request body
  const { email, password, apiKey, ollamaUrl, preferredLlmProvider } = req.body;

  if (!email || !password) {
    return res.status(400).json({ message: 'Email and password are required.' });
  }
  if (!/^\w+([.-]?\w+)*@\w+([.-]?\w+)*(\.\w{2,3})+$/.test(email)) {
    return res.status(400).json({ message: 'Please provide a valid email address.' });
  }
  if (password.length < 6) {
     return res.status(400).json({ message: 'Password must be at least 6 characters long.' });
  }

  // 2. Validate provider-specific fields
  if (preferredLlmProvider === 'gemini' && (!apiKey || apiKey.trim() === '')) {
    return res.status(400).json({ message: 'A Gemini API Key is required when Gemini is selected.' });
  }
  if (preferredLlmProvider === 'ollama' && (!ollamaUrl || ollamaUrl.trim() === '')) {
    return res.status(400).json({ message: 'An Ollama URL is required when Ollama is selected.' });
  }

  try {
    const existingUser = await User.findOne({ email });
    if (existingUser) {
      return res.status(400).json({ message: 'An account with this email already exists.' });
    }

    // 3. Create a new user with conditional logic for credentials
    const newUser = new User({
      email,
      password, // Password will be hashed by the pre-save hook
      preferredLlmProvider: preferredLlmProvider || 'gemini',
      // Only save the credential that matches the chosen provider
      encryptedApiKey: (preferredLlmProvider === 'gemini') ? apiKey : null,
      ollamaUrl: (preferredLlmProvider === 'ollama') ? ollamaUrl.trim() : '',
    });
    
    await newUser.save();

    const payload = { userId: newUser._id, email: newUser.email };
    const token = jwt.sign(payload, process.env.JWT_SECRET, { expiresIn: JWT_EXPIRATION });

    res.status(201).json({
      token,
      _id: newUser._id,
      email: newUser.email,
      sessionId: uuidv4(),
      message: 'User registered successfully',
    });
  } catch (error) {
    console.error('Signup Error:', error);
    if (error.code === 11000 || error.message.includes('duplicate key error collection')) {
        return res.status(400).json({ message: 'An account with this email already exists.' });
    }
    if (error.name === 'ValidationError') {
        const messages = Object.values(error.errors).map(val => val.message);
        return res.status(400).json({ message: messages.join(', ') });
    }
    res.status(500).json({ message: 'Server error during signup.' });
  }
});

// --- @route   POST /api/auth/signin ---
router.post('/signin', async (req, res) => {
  const { email, password } = req.body;

  if (!email || !password) {
    return res.status(400).json({ message: 'Please provide email and password.' });
  }

  try {
    const ADMIN_EMAIL = process.env.FIXED_ADMIN_USERNAME || 'admin@admin.com';
    const ADMIN_PASSWORD = process.env.FIXED_ADMIN_PASSWORD || 'admin123';

    if (email === ADMIN_EMAIL && password === ADMIN_PASSWORD) {
        console.log("Admin login successful via special auth check.");
        return res.status(200).json({
            isAdminLogin: true,
            message: 'Admin login successful',
        });
    }

    const user = await User.findByCredentials(email, password);
    if (!user) {
      return res.status(401).json({ message: 'Invalid email address or password.' });
    }

    const payload = { userId: user._id, email: user.email };
    const token = jwt.sign(payload, process.env.JWT_SECRET, { expiresIn: JWT_EXPIRATION });

    res.status(200).json({
      token,
      _id: user._id,
      email: user.email,
      sessionId: uuidv4(),
      message: 'Login successful',
    });
  } catch (error) {
    console.error('Signin Error:', error);
    res.status(500).json({ message: 'Server error during signin.' });
  }
});

// --- @route   GET /api/auth/me ---
router.get('/me', authMiddleware, async (req, res) => {
  if (!req.user) {
    return res.status(401).json({ message: 'Not authorized.' });
  }
  res.status(200).json({
    _id: req.user._id,
    email: req.user.email,
  });
});

module.exports = router;
```

`server/routes/chat.js`

```javascript
// server/routes/chat.js
const express = require('express');
const { v4: uuidv4 } = require('uuid');
const ChatHistory = require('../models/ChatHistory');
const User = require('../models/User');
const { processQueryWithToT_Streaming } = require('../services/totOrchestrator');
const { createOrUpdateSummary } = require('../services/summarizationService');
const { processAgenticRequest } = require('../services/agentService');
const { decrypt } = require('../utils/crypto');

const router = express.Router();


function streamEvent(res, eventData) {
    if (res.writableEnded) {
        console.warn('[Chat Route Stream] Attempted to write to an already closed stream.');
        return;
    }
    res.write(`data: ${JSON.stringify(eventData)}\n\n`);
}



function doesQuerySuggestRecall(query) {
    const lowerCaseQuery = query.toLowerCase();
    const recallKeywords = [
        'my name', 'my profession', 'i am', 'i told you',
        'remember', 'recall', 'remind me', 'go back to',
        'previously', 'before', 'we discussed', 'we were talking about',
        'earlier', 'yesterday', 'last session',
        'what did i say', 'what was', 'what were', 'who am i',
        'do you know', 'can you tell me again',
        'continue with', 'let\'s continue', 'pick up where we left off',
    ];
    return recallKeywords.some(keyword => lowerCaseQuery.includes(keyword));
}


router.post('/message', async (req, res) => {
    const {
        query, sessionId, useWebSearch, useAcademicSearch,
        systemPrompt: clientProvidedSystemInstruction, criticalThinkingEnabled,
        documentContextName, filter
    } = req.body;
    
    const userId = req.user._id;

    if (!query || typeof query !== 'string' || query.trim() === '') {
        return res.status(400).json({ message: 'Query message text required.' });
    }
    if (!sessionId || typeof sessionId !== 'string') {
        return res.status(400).json({ message: 'Session ID required.' });
    }

    const userMessageForDb = { role: 'user', parts: [{ text: query }], timestamp: new Date() };
    console.log(`>>> POST /api/chat/message: User=${userId}, Session=${sessionId}, CriticalThinking=${criticalThinkingEnabled}, Query: "${query.substring(0, 50)}..."`);

    try {
        const [chatSession, user] = await Promise.all([
            ChatHistory.findOne({ sessionId: sessionId, userId: userId }),
            User.findById(userId).select('+encryptedApiKey preferredLlmProvider ollamaModel ollamaUrl').lean()
        ]);

        const llmProvider = user?.preferredLlmProvider || 'gemini';
        const ollamaModel = user?.ollamaModel || process.env.OLLAMA_DEFAULT_MODEL;

        const historyFromDb = chatSession ? chatSession.messages : [];
        const summaryFromDb = chatSession ? chatSession.summary || "" : "";
        
        const historyForLlm = [];

        if (summaryFromDb && doesQuerySuggestRecall(query.trim())) {
            historyForLlm.push({ 
                role: 'user', 
                parts: [{ text: `CONTEXT (Summary of Past Conversations): """${summaryFromDb}"""` }] 
            });
            historyForLlm.push({ 
                role: 'model', 
                parts: [{ text: "Understood. I will use this context if the user's query is about our past conversations." }] 
            });
        }

        const formattedDbMessages = historyFromDb.map(msg => ({
            role: msg.role, parts: msg.parts.map(part => ({ text: part.text || '' }))
        }));
        historyForLlm.push(...formattedDbMessages);
        
        const requestContext = {
            documentContextName, criticalThinkingEnabled, filter,
            llmProvider, ollamaModel,
            isWebSearchEnabled: !!useWebSearch, isAcademicSearchEnabled: !!useAcademicSearch,
            userId: userId.toString(), ollamaUrl: user.ollamaUrl,
            systemPrompt: clientProvidedSystemInstruction
        };

        if (llmProvider === 'gemini') {
            requestContext.apiKey = user.encryptedApiKey ? decrypt(user.encryptedApiKey) : null;
        }

        if (criticalThinkingEnabled) {
            console.log(`[Chat Route] Diverting to ToT Orchestrator.`);
            
            res.setHeader('Content-Type', 'text/event-stream');
            res.setHeader('Cache-Control', 'no-cache');
            res.setHeader('Connection', 'keep-alive');
            res.flushHeaders();

            // Pass the local streamEvent function as a callback
            const streamCallback = (eventData) => streamEvent(res, eventData);

            const totResult = await processQueryWithToT_Streaming(
                query.trim(), historyForLlm, requestContext, streamCallback
            );

            const aiMessageForDbAndClient = {
                sender: 'bot', role: 'model',
                parts: [{ text: totResult.finalAnswer }],
                text: totResult.finalAnswer,
                timestamp: new Date(),
                thinking: totResult.thoughts.join('\n'),
                references: totResult.references || [],
                source_pipeline: totResult.sourcePipeline,
            };

            await ChatHistory.findOneAndUpdate(
                { sessionId: sessionId, userId: userId },
                { $push: { messages: { $each: [userMessageForDb, aiMessageForDbAndClient] } } },
                { upsert: true, new: true }
            );
            console.log(`<<< POST /api/chat/message (ToT) successful for Session ${sessionId}.`);
            res.end();

        } else {
            console.log(`[Chat Route] Diverting to standard Agentic Service.`);

            const agentResponse = await processAgenticRequest(
                query.trim(), historyForLlm, clientProvidedSystemInstruction, requestContext
            );

            const aiMessageForDbAndClient = {
                sender: 'bot', role: 'model',
                parts: [{ text: agentResponse.finalAnswer }],
                text: agentResponse.finalAnswer,
                timestamp: new Date(),
                thinking: agentResponse.thinking || null,
                references: agentResponse.references || [],
                source_pipeline: agentResponse.sourcePipeline,
            };

            await ChatHistory.findOneAndUpdate(
                { sessionId: sessionId, userId: userId },
                { $push: { messages: { $each: [userMessageForDb, aiMessageForDbAndClient] } } },
                { upsert: true, new: true }
            );

            console.log(`<<< POST /api/chat/message (Agentic) successful for Session ${sessionId}.`);
            res.status(200).json({ reply: aiMessageForDbAndClient });
        }

    } catch (error) {
        console.error(`!!! Error processing chat message for Session ${sessionId}:`, error);
        const clientMessage = error.message || "Failed to get response from AI service.";
        
        if (res.headersSent && !res.writableEnded) {
            streamEvent(res, { type: 'error', content: clientMessage });
            res.end();
        } else if (!res.headersSent) {
            res.status(error.status || 500).json({ message: clientMessage });
        }
    }
});


router.post('/history', async (req, res) => {
    const { previousSessionId } = req.body;
    const userId = req.user._id;
    const newSessionId = uuidv4();
    let summaryOfOldSession = "";
    if (previousSessionId) {
        try {
            const [oldSession, user] = await Promise.all([
                ChatHistory.findOne({ sessionId: previousSessionId, userId: userId }),
                User.findById(userId).select('preferredLlmProvider ollamaModel ollamaUrl +encryptedApiKey').lean()
            ]);

            if (oldSession && oldSession.messages?.length > 0) {
                const llmProvider = user.preferredLlmProvider || 'gemini';
                const ollamaModel = user.ollamaModel || process.env.OLLAMA_DEFAULT_MODEL;
                const userOllamaUrl = user.ollamaUrl || null;
                let userApiKey = null;
                if (llmProvider === 'gemini') {
                    userApiKey = user.encryptedApiKey ? decrypt(user.encryptedApiKey) : null;
                }
                summaryOfOldSession = await createOrUpdateSummary(
                    oldSession.messages, oldSession.summary, llmProvider, 
                    ollamaModel, userApiKey, userOllamaUrl
                );
            }
        } catch (summaryError) {
            console.error(`Could not summarize previous session ${previousSessionId}:`, summaryError);
        }
    }
    
    try {
        await ChatHistory.create({ userId, sessionId: newSessionId, messages: [], summary: summaryOfOldSession });
        res.status(200).json({ message: 'New session started.', newSessionId });
    } catch (dbError) {
        res.status(500).json({ message: 'Failed to create new session.' });
    }
});

router.get('/sessions', async (req, res) => {
    try {
        const sessions = await ChatHistory.find({ userId: req.user._id }).sort({ updatedAt: -1 }).select('sessionId createdAt updatedAt messages').lean();
        const sessionSummaries = sessions.map(session => {
            const firstUserMessage = session.messages?.find(m => m.role === 'user');
            let preview = firstUserMessage?.parts?.[0]?.text?.substring(0, 75) || 'Chat Session';
            if (preview.length === 75) preview += '...';
            return { sessionId: session.sessionId, createdAt: session.createdAt, updatedAt: session.updatedAt, messageCount: session.messages?.length || 0, preview: preview };
        });
        res.status(200).json(sessionSummaries);
    } catch (error) {
        res.status(500).json({ message: 'Failed to retrieve chat sessions.' });
    }
});

router.get('/session/:sessionId', async (req, res) => {
    try {
        const session = await ChatHistory.findOne({ sessionId: req.params.sessionId, userId: req.user._id }).lean();
        if (!session) return res.status(404).json({ message: 'Chat session not found.' });
        const messagesForFrontend = (session.messages || []).map(msg => ({ id: msg._id || uuidv4(), sender: msg.role === 'model' ? 'bot' : 'user', text: msg.parts?.[0]?.text || '', thinking: msg.thinking, references: msg.references, timestamp: msg.timestamp, source_pipeline: msg.source_pipeline }));
        res.status(200).json({ ...session, messages: messagesForFrontend });
    } catch (error) {
        res.status(500).json({ message: 'Failed to retrieve chat session.' });
    }
});

router.delete('/session/:sessionId', async (req, res) => {
    const { sessionId } = req.params;
    const userId = req.user._id;
    try {
        const result = await ChatHistory.deleteOne({ sessionId: sessionId, userId: userId });
        if (result.deletedCount === 0) {
            return res.status(404).json({ message: 'Chat session not found.' });
        }
        res.status(200).json({ message: 'Chat session deleted successfully.' });
    } catch (error) {
        res.status(500).json({ message: 'Server error while deleting chat session.' });
    }
});

module.exports = router;
```

`server/routes/export.js`

```javascript
// server/routes/export.js
const express = require('express');
const axios = require('axios');
const router = express.Router();
const User = require('../models/User');
const AdminDocument = require('../models/AdminDocument');
const { decrypt } = require('../utils/crypto');

router.post('/podcast', async (req, res) => {
    const { analysisContent, sourceDocumentName, podcastOptions } = req.body;
    const userId = req.user._id;

    if (!analysisContent || !sourceDocumentName || !podcastOptions) {
        return res.status(400).json({ message: 'analysisContent, sourceDocumentName, and podcastOptions are required.' });
    }

    try {
        let sourceDocumentText = null;
        let apiKeyForRequest = null;
        
        // Fetch the user to get their documents and encrypted API key
        const user = await User.findById(userId).select('uploadedDocuments.filename uploadedDocuments.text +encryptedApiKey');

        // Check user's documents first
        const userDoc = user?.uploadedDocuments.find(doc => doc.filename === sourceDocumentName);
        if (userDoc?.text) {
            sourceDocumentText = userDoc.text;
            if (user.encryptedApiKey) {
                apiKeyForRequest = decrypt(user.encryptedApiKey);
            }
        } else {
            // Fallback to checking admin documents
            const adminDoc = await AdminDocument.findOne({ originalName: sourceDocumentName }).select('text');
            if (adminDoc?.text) {
                sourceDocumentText = adminDoc.text;
                apiKeyForRequest = process.env.GEMINI_API_KEY; // Admin docs use server's key
            }
        }
        
        if (!sourceDocumentText) {
            return res.status(404).json({ message: `Source document '${sourceDocumentName}' not found.` });
        }
        if (!apiKeyForRequest) {
            return res.status(400).json({ message: "API Key for podcast generation is missing." });
        }

        const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
        if (!pythonServiceUrl) {
            return res.status(500).json({ message: "Audio generation service is not configured." });
        }

        const generationUrl = `${pythonServiceUrl}/export_podcast`;
        
        console.log(`[Node Export] Forwarding HQ podcast request to Python with API Key.`);

        const pythonPayload = {
            sourceDocumentText: sourceDocumentText,
            analysisContent: analysisContent,
            podcastOptions: podcastOptions,
            api_key: apiKeyForRequest // <<< Pass the correct key
        };
        
        const fileResponse = await axios.post(generationUrl, pythonPayload, {
            responseType: 'stream',
            timeout: 600000 // 10 minute timeout
        });

        const safeFilename = sourceDocumentName.split('.')[0].replace(/[^a-zA-Z0-9]/g, '_');
        const finalFilename = `HQ_Podcast_${safeFilename}.mp3`;
        
        res.setHeader('Content-Disposition', `attachment; filename="${finalFilename}"`);
        res.setHeader('Content-Type', 'audio/mpeg');
        fileResponse.data.pipe(res);

    } catch (error) {
        const errorMsg = error.response?.data?.error || error.message || "Failed to generate podcast.";
        console.error(`[Node Export] Error proxying podcast generation: ${errorMsg}`);
        if (!res.headersSent) {
            res.status(error.response?.status || 500).json({ message: errorMsg });
        }
    }
});

module.exports = router;
```

`server/routes/files.js`

```javascript
// server/routes/files.js
const express = require('express');
const fs = require('fs').promises;
const path = require('path');
const { authMiddleware } = require('../middleware/authMiddleware');
const User = require('../models/User');
const axios = require('axios');
const router = express.Router();

const ASSETS_DIR = path.join(__dirname, '..', 'assets');
const BACKUP_DIR = path.join(__dirname, '..', 'backup_assets');

// --- Helper functions (sanitizeUsernameForDir, parseServerFilename, ensureDirExists are existing) ---
const sanitizeUsernameForDir = (username) => {
    if (!username) return '';
    return username.replace(/[^a-zA-Z0-9_-]/g, '_');
};

const parseServerFilename = (filename) => {
    // Matches "timestamp-originalName.ext"
    // Allows originalName to contain dots now.
    const match = filename.match(/^(\d+)-(.+?)(\.\w+)$/);
    if (match && match.length === 4) {
        return { timestamp: match[1], originalName: `${match[2]}${match[3]}`, extension: match[3] };
    }
    // Fallback for names that might not perfectly fit the new pattern, or originalName without extension before timestamp
    const ext = path.extname(filename);
    const baseWithoutExt = filename.substring(0, filename.length - ext.length);
    const tsMatch = baseWithoutExt.match(/^(\d+)-(.*)$/);
    if (tsMatch) {
        return { timestamp: tsMatch[1], originalName: `${tsMatch[2]}${ext}`, extension: ext };
    }
    // Final fallback if no timestamp prefix is reliably parsed
    return { timestamp: null, originalName: filename, extension: path.extname(filename) };
};

const ensureDirExists = async (dirPath) => {
    try { await fs.mkdir(dirPath, { recursive: true }); }
    catch (error) { if (error.code !== 'EEXIST') { console.error(`Error creating dir ${dirPath}:`, error); throw error; } }
};

async function callPythonDeletionEndpoint(method, endpointPath, userId, originalName, logContext) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL || process.env.DEFAULT_PYTHON_RAG_URL || 'http://localhost:5000'; // Fallback if not set
    if (!pythonServiceUrl) {
        console.error(`Python Service Deletion Error for ${logContext}: PYTHON_RAG_SERVICE_URL not set.`);
        return { success: false, message: "Python service URL not configured." };
    }

    const deleteUrl = `${pythonServiceUrl.replace(/\/$/, '')}${endpointPath}`;

    try {
        console.log(`Calling Python Service (${method.toUpperCase()}) for deletion: ${deleteUrl} (Doc: ${originalName}, User: ${userId})`);
        let response;
        if (method.toUpperCase() === 'DELETE') {
            // For DELETE, data is often in query params or path, but axios allows a 'data' field for body
            response = await axios.delete(deleteUrl, {
                data: { // For Python endpoints that expect a body (like a new Qdrant delete one)
                    user_id: userId,
                    document_name: originalName
                },
                timeout: 30000 // 30s timeout
            });
        } else {
            throw new Error(`Unsupported method for Python deletion: ${method}`);
        }

        if (response.status === 200 || response.status === 204) { // 204 No Content is also success
            return { success: true, message: response.data?.message || `Successfully deleted from ${endpointPath}` };
        } else {
            return { success: false, message: response.data?.message || `Python service returned ${response.status} for ${endpointPath}` };
        }
    } catch (error) {
        const errorMsg = error.response?.data?.error || error.response?.data?.message || error.message || `Unknown error deleting from ${endpointPath}`;
        console.error(`Error calling Python Service for deletion (${deleteUrl}) for ${originalName} (User: ${userId}): ${errorMsg}`, error.response ? { status: error.response.status, data: error.response.data } : error);
        return { success: false, message: `Python service call failed for ${endpointPath}: ${errorMsg}` };
    }
}
// --- End Helper Functions ---


// --- @route   GET /api/files ---
// Use authMiddleware middleware 
// TO GET FILE NAMES
router.get('/', authMiddleware, async (req, res) => {
    
    const userFiles = []
    try {
        const userId = req.user._id.toString();

        // Find user by ID, select only uploadedDocuments to optimize
        const user = await User.findById(userId).select('uploadedDocuments');

        if (!user) return res.status(404).json({ msg: 'User not found' });

        // Extract filenames
        const filenames = user.uploadedDocuments
        .map(doc => doc.filename)
        .filter(Boolean)  // filter out undefined or null filenames just in case
        .reverse();       // reverse the order

        return res.json({ filenames });

    } catch (error) {
        console.log(error.message);
        return res.status(500).json({ msg: 'Server error' });
    }
});


// --- @route   DELETE /api/files/:serverFilename ---
// Use authMiddleware middleware
router.delete('/:serverFilename', authMiddleware, async (req, res) => {
  
    const { serverFilename } = req.params;
    const userId = req.user._id.toString(); // Get userId from authenticated user
    const usernameForLog = req.user.username;

    if (!serverFilename) {
        return res.status(400).json({ message: 'Server filename parameter is required.' });
    }

    const parsedFileDetails = parseServerFilename(serverFilename);
    const originalName = parsedFileDetails.originalName;
    if (!originalName) {
        console.error(`DELETE /api/files: Could not parse originalName from serverFilename: ${serverFilename}`);
        return res.status(400).json({ message: 'Invalid server filename format for deletion.' });
    }
    const logContext = `File: '${originalName}' (server: ${serverFilename}), User: ${usernameForLog} (${userId})`;
    console.log(`Attempting to delete all data for ${logContext}`);

    const results = {
        mongodb: { success: false, message: "Not attempted" },
        qdrant: { success: false, message: "Not attempted" },
        neo4j: { success: false, message: "Not attempted" },
        filesystem: { success: false, message: "Not attempted" },
    };
    let overallSuccess = true; // Assume success, set to false if any critical step fails
    let httpStatus = 200;
    let fileFoundInMongo = false;
    let physicalFileFound = false;

    try {
        // 1. Delete from MongoDB
        try {
            const user = await User.findById(userId);
            if (!user) {
                results.mongodb.message = "User not found.";
                // If user not found, we can't confirm if the file was theirs.
                // Treat as if the file wasn't found for this user.
            } else {
                const docIndex = user.uploadedDocuments.findIndex(doc => doc.filename === originalName);
                if (docIndex > -1) {
                    fileFoundInMongo = true;
                    user.uploadedDocuments.splice(docIndex, 1);
                    await user.save();
                    results.mongodb.success = true;
                    results.mongodb.message = "Successfully removed from user's document list.";
                    console.log(`MongoDB: Document entry '${originalName}' removed for user ${userId}.`);
                } else {
                    results.mongodb.message = "Document not found in user's list.";
                    console.log(`MongoDB: Document entry '${originalName}' not found for user ${userId}.`);
                }
            }
        } catch (mongoError) {
            console.error(`MongoDB Deletion Error for ${logContext}:`, mongoError);
            results.mongodb.message = `MongoDB deletion failed: ${mongoError.message}`;
            overallSuccess = false; // DB error is critical
        }

        // 2. Delete from Qdrant (via Python service)
        // This endpoint will need to be created in Python: e.g., /delete_qdrant_document_data
        // It should expect { user_id: userId, document_name: originalName } in the body
        const qdrantDeleteResult = await callPythonDeletionEndpoint(
            'DELETE',
            `/delete_qdrant_document_data`,
            userId,
            originalName,
            logContext
        );
        results.qdrant = qdrantDeleteResult;
        if (!qdrantDeleteResult.success) {
            console.warn(`Qdrant deletion failed or reported no data for ${logContext}. Message: ${qdrantDeleteResult.message}`);
            // overallSuccess = false; // Non-critical for now, but log
        }

        // 3. Delete from Neo4j (via Python service)
        // This uses the existing Python endpoint: /kg/<user_id>/<document_name>
        const neo4jEndpointPath = `/kg/${userId}/${encodeURIComponent(originalName)}`;
        const neo4jDeleteResult = await callPythonDeletionEndpoint(
            'DELETE',
            neo4jEndpointPath, // userId and originalName are in the path
            userId, // still pass for logging consistency in helper
            originalName, // still pass for logging consistency in helper
            logContext
        );
        results.neo4j = neo4jDeleteResult;
        if (!neo4jDeleteResult.success) {
            console.warn(`Neo4j deletion failed or reported no data for ${logContext}. Message: ${neo4jDeleteResult.message}`);
            // overallSuccess = false; // Non-critical for now, but log
        }

        // 4. Move physical file to backup (filesystem operation)
        let currentPath = null;
        let fileType = '';
        const fileTypesToSearch = ['docs', 'images', 'code', 'others'];
        const sanitizedUsernameForPath = sanitizeUsernameForDir(usernameForLog);

        for (const type of fileTypesToSearch) {
            const potentialPath = path.join(ASSETS_DIR, sanitizedUsernameForPath, type, serverFilename);
            try {
                await fs.access(potentialPath); // Check if file exists
                currentPath = potentialPath;
                fileType = type;
                physicalFileFound = true;
                break;
            } catch (e) {
                if (e.code !== 'ENOENT') {
                    console.warn(`Filesystem: Error accessing ${potentialPath} during delete scan: ${e.message}`);
                }
            }
        }

        if (currentPath) { // If physical file was found
            const backupUserDir = path.join(BACKUP_DIR, sanitizedUsernameForPath, fileType);
            await ensureDirExists(backupUserDir);
            const backupPath = path.join(backupUserDir, serverFilename);
            try {
                await fs.rename(currentPath, backupPath);
                results.filesystem = { success: true, message: "File moved to backup successfully." };
                console.log(`Filesystem: Moved '${currentPath}' to '${backupPath}'.`);
            } catch (fsError) {
                console.error(`Filesystem: Error moving file ${currentPath} to backup for ${logContext}:`, fsError);
                results.filesystem.message = `Filesystem move to backup failed: ${fsError.message}`;
                // overallSuccess = false; // Decide if this is critical enough to mark overall failure
            }
        } else {
            results.filesystem.message = "Physical file not found in assets, or already moved.";
            console.log(`Filesystem: Physical file '${serverFilename}' not found for user ${usernameForLog}.`);
        }

        // Determine final status and message
        const successfulDeletes = [results.mongodb.success, results.qdrant.success, results.neo4j.success, results.filesystem.success].filter(Boolean).length;

        if (!fileFoundInMongo && !physicalFileFound) {
            httpStatus = 404;
            finalMessage = `File '${originalName}' not found for user.`;
        } else if (results.mongodb.success) { // Primary record deleted
            if (successfulDeletes === 4) {
                finalMessage = `Successfully deleted all data associated with '${originalName}'.`;
                httpStatus = 200;
            } else {
                finalMessage = `File '${originalName}' removed from your list. Some backend data cleanup attempts had issues. Check server logs for details.`;
                httpStatus = 207; // Multi-Status
            }
        } else { // MongoDB deletion failed, but file might have existed
            finalMessage = `Failed to remove '${originalName}' from your list. Some backend data cleanup may have also failed. Check server logs.`;
            httpStatus = 500;
        }

        console.log(`Deletion outcome for ${logContext}: HTTP Status=${httpStatus}, Overall Success Flag (was pre-status logic)=${overallSuccess}`);
        return res.status(httpStatus).json({
            message: finalMessage,
            details: results
        });

    } catch (error) {
        console.error(`!!! UNEXPECTED Error in DELETE /api/files/${serverFilename} for user ${usernameForLog}:`, error);
        return res.status(500).json({
            message: 'An unexpected server error occurred during file deletion.',
            details: results // Send partial results if any
        });
    }
});


module.exports = router;

```

`server/routes/generation.js`

```javascript
// // server/routes/generation.js
// const express = require('express');
// const axios = require('axios');
// const router = express.Router();

// // This route is protected by authMiddleware applied in server.js

// // @route   POST /api/generate/document
// // @desc    Generate a document (PPTX or DOCX) by proxying to the Python service.
// // @access  Private
// router.post('/document', async (req, res) => {
//     const { markdownContent, docType } = req.body;

//     if (!markdownContent || !docType) {
//         return res.status(400).json({ message: 'markdownContent and docType are required.' });
//     }

//     const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
//     if (!pythonServiceUrl) {
//         console.error("[Generation Route] PYTHON_RAG_SERVICE_URL is not set.");
//         return res.status(500).json({ message: "Document generation service is not configured." });
//     }

//     const generationUrl = `${pythonServiceUrl}/generate_document`;
//     console.log(`[Generation Route] Forwarding request to Python service: ${generationUrl}`);

//     try {
//         const pythonResponse = await axios.post(generationUrl, {
//             markdownContent,
//             docType
//         }, { timeout: 60000 }); // 1 minute timeout for generation

//         if (pythonResponse.data && pythonResponse.data.success) {
//             const filename = pythonResponse.data.filename;
//             // Construct the full download URL for the client
//             const downloadUrl = `${pythonServiceUrl}/download_document/${filename}`;
            
//             res.status(200).json({
//                 success: true,
//                 downloadUrl: downloadUrl,
//                 filename: filename
//             });
//         } else {
//             throw new Error(pythonResponse.data.error || "Unknown error from generation service.");
//         }
//     } catch (error) {
//         const errorMsg = error.response?.data?.error || error.message || "Failed to generate document.";
//         console.error(`[Generation Route] Error calling Python service: ${errorMsg}`);
//         res.status(500).json({ message: errorMsg });
//     }
// });

// module.exports = router;














// // server/routes/generation.js
// const express = require('express');
// const axios = require('axios');
// const router = express.Router();
// const User = require('../models/User'); // <-- Import User model

// // This route is protected by authMiddleware applied in server.js

// // @route   POST /api/generate/document
// // @desc    Generate a document (PPTX or DOCX) by proxying to the Python service.
// // @access  Private
// router.post('/document', async (req, res) => {
//     // --- MODIFIED: Destructure new fields ---
//     const { markdownContent, docType, sourceDocumentName } = req.body;
//     const userId = req.user._id;

//     if (!markdownContent || !docType || !sourceDocumentName) {
//         return res.status(400).json({ message: 'markdownContent, docType, and sourceDocumentName are required.' });
//     }

//     try {
//         // --- NEW: Fetch the full text of the source document ---
//         const user = await User.findById(userId).select('uploadedDocuments');
//         if (!user) {
//             return res.status(404).json({ message: 'User not found.' });
//         }
//         const sourceDocument = user.uploadedDocuments.find(doc => doc.filename === sourceDocumentName);
//         if (!sourceDocument || !sourceDocument.text) {
//             return res.status(404).json({ message: `Source document '${sourceDocumentName}' or its text content not found.` });
//         }
//         const sourceDocumentText = sourceDocument.text;
//         // --- END NEW ---

//         const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
//         if (!pythonServiceUrl) {
//             console.error("[Generation Route] PYTHON_RAG_SERVICE_URL is not set.");
//             return res.status(500).json({ message: "Document generation service is not configured." });
//         }

//         const generationUrl = `${pythonServiceUrl}/generate_document`;
//         console.log(`[Generation Route] Forwarding request to Python service: ${generationUrl}`);

//         const pythonResponse = await axios.post(generationUrl, {
//             markdownContent, // This is the outline (e.g., FAQ, Key Topics)
//             docType,
//             sourceDocumentText // Pass the full text for context
//         }, { timeout: 300000 }); // Increased timeout to 5 minutes for LLM generation

//         if (pythonResponse.data && pythonResponse.data.success) {
//             const filename = pythonResponse.data.filename;
//             const downloadUrl = `${pythonServiceUrl}/download_document/${filename}`;
            
//             res.status(200).json({
//                 success: true,
//                 downloadUrl: downloadUrl,
//                 filename: filename
//             });
//         } else {
//             throw new Error(pythonResponse.data.error || "Unknown error from generation service.");
//         }
//     } catch (error) {
//         const errorMsg = error.response?.data?.error || error.message || "Failed to generate document.";
//         console.error(`[Generation Route] Error: ${errorMsg}`);
//         res.status(500).json({ message: errorMsg });
//     }
// });

// module.exports = router;










// // server/routes/generation.js
// const express = require('express');
// const axios = require('axios');
// const router = express.Router();
// const User = require('../models/User');
// const AdminDocument = require('../models/AdminDocument'); // <-- Import AdminDocument model

// // This route is protected by authMiddleware applied in server.js

// // @route   POST /api/generate/document
// // @desc    Generate a document (PPTX or DOCX) by proxying to the Python service.
// // @access  Private
// router.post('/document', async (req, res) => {
//     const { markdownContent, docType, sourceDocumentName } = req.body;
//     const userId = req.user._id;

//     if (!markdownContent || !docType || !sourceDocumentName) {
//         return res.status(400).json({ message: 'markdownContent, docType, and sourceDocumentName are required.' });
//     }

//     try {
//         let sourceDocumentText = null;

//         // --- NEW UNIFIED DOCUMENT RETRIEVAL LOGIC ---
//         // 1. First, try to find the document in the user's personal documents.
//         const user = await User.findById(userId).select('uploadedDocuments');
//         if (user) {
//             const userDocument = user.uploadedDocuments.find(doc => doc.filename === sourceDocumentName);
//             if (userDocument && userDocument.text) {
//                 sourceDocumentText = userDocument.text;
//                 console.log(`[Generation Route] Found source text in user's documents for: ${sourceDocumentName}`);
//             }
//         }

//         // 2. If not found in user's docs, try to find it in the Admin documents.
//         if (!sourceDocumentText) {
//             console.log(`[Generation Route] Not found in user docs. Checking admin 'Subjects' for: ${sourceDocumentName}`);
//             const adminDocument = await AdminDocument.findOne({ originalName: sourceDocumentName }).select('text');
//             if (adminDocument && adminDocument.text) {
//                 sourceDocumentText = adminDocument.text;
//                 console.log(`[Generation Route] Found source text in admin documents for: ${sourceDocumentName}`);
//             }
//         }
//         // --- END UNIFIED LOGIC ---
        
//         // 3. If still not found after checking both, return an error.
//         if (!sourceDocumentText) {
//             return res.status(404).json({ message: `Source document '${sourceDocumentName}' not found.` });
//         }

//         const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
//         if (!pythonServiceUrl) {
//             console.error("[Generation Route] PYTHON_RAG_SERVICE_URL is not set.");
//             return res.status(500).json({ message: "Document generation service is not configured." });
//         }

//         const generationUrl = `${pythonServiceUrl}/generate_document`;
//         console.log(`[Generation Route] Forwarding request to Python service: ${generationUrl}`);

//         const pythonResponse = await axios.post(generationUrl, {
//             markdownContent,
//             docType,
//             sourceDocumentText // Pass the full text from whichever source it was found
//         }, { timeout: 300000 });

//         if (pythonResponse.data && pythonResponse.data.success) {
//             const filename = pythonResponse.data.filename;
//             const downloadUrl = `${pythonServiceUrl}/download_document/${filename}`;
            
//             res.status(200).json({
//                 success: true,
//                 downloadUrl: downloadUrl,
//                 filename: filename
//             });
//         } else {
//             throw new Error(pythonResponse.data.error || "Unknown error from generation service.");
//         }
//     } catch (error) {
//         const errorMsg = error.response?.data?.error || error.message || "Failed to generate document.";
//         console.error(`[Generation Route] Error: ${errorMsg}`);
//         res.status(500).json({ message: errorMsg });
//     }
// });

// module.exports = router;









// server/routes/generation.js
const express = require('express');
const axios = require('axios');
const router = express.Router();
const User = require('../models/User');
const AdminDocument = require('../models/AdminDocument');

router.post('/document', async (req, res) => {
    const { markdownContent, docType, sourceDocumentName } = req.body;
    const userId = req.user._id;

    if (!markdownContent || !docType || !sourceDocumentName) {
        return res.status(400).json({ message: 'markdownContent, docType, and sourceDocumentName are required.' });
    }

    try {
        let sourceDocumentText = null;

        const user = await User.findById(userId).select('uploadedDocuments');
        if (user) {
            const userDocument = user.uploadedDocuments.find(doc => doc.filename === sourceDocumentName);
            if (userDocument && userDocument.text) {
                sourceDocumentText = userDocument.text;
            }
        }

        if (!sourceDocumentText) {
            const adminDocument = await AdminDocument.findOne({ originalName: sourceDocumentName }).select('text');
            if (adminDocument && adminDocument.text) {
                sourceDocumentText = adminDocument.text;
            }
        }
        
        if (!sourceDocumentText) {
            return res.status(404).json({ message: `Source document '${sourceDocumentName}' not found.` });
        }

        const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
        if (!pythonServiceUrl) {
            return res.status(500).json({ message: "Document generation service is not configured." });
        }

        const generationUrl = `${pythonServiceUrl}/generate_document`;
        
        // 1. Ask Python to generate the document and get the filename
        const genResponse = await axios.post(generationUrl, {
            markdownContent, docType, sourceDocumentText
        }, { timeout: 300000 });

        if (!genResponse.data || !genResponse.data.success) {
            throw new Error(genResponse.data.error || "Python service failed to generate the document.");
        }

        const filename = genResponse.data.filename;
        const downloadUrl = `${pythonServiceUrl}/download_document/${filename}`;

        // 2. Fetch the generated document from Python as a stream (blob)
        console.log(`[Generation Route] Fetching generated file from Python: ${downloadUrl}`);
        const fileResponse = await axios.get(downloadUrl, {
            responseType: 'stream'
        });

        // 3. Stream the file directly back to the client
        res.setHeader('Content-Disposition', `attachment; filename=${filename}`);
        res.setHeader('Content-Type', fileResponse.headers['content-type']);
        fileResponse.data.pipe(res);

    } catch (error) {
        const errorMsg = error.response?.data?.error || error.message || "Failed to generate document.";
        console.error(`[Generation Route] Error: ${errorMsg}`);
        res.status(500).json({ message: errorMsg });
    }
});

module.exports = router;
```

`server/routes/kg.js`

```javascript
// server/routes/kg.js
const express = require('express');
const router = express.Router();
const axios = require('axios');
const User = require('../models/User');
const AdminDocument = require('../models/AdminDocument');
const { decrypt } = require('../utils/crypto');

router.get('/visualize/:documentName', async (req, res) => {
    const { documentName } = req.params;
    const currentUserId = req.user._id;

    if (!documentName) {
        return res.status(400).json({ message: 'Document name is required.' });
    }

    try {
        let sourceDocumentText = null;
        let apiKeyForRequest = null;
        
        // We need to fetch the user to get their encrypted API key
        const user = await User.findById(currentUserId).select('uploadedDocuments.filename uploadedDocuments.text +encryptedApiKey');

        // Check if the requested document belongs to the user
        const userDoc = user?.uploadedDocuments.find(doc => doc.filename === documentName);
        
        if (userDoc?.text) {
            sourceDocumentText = userDoc.text;
            // Decrypt the key if the document is a user document
            if (user.encryptedApiKey) {
                apiKeyForRequest = decrypt(user.encryptedApiKey);
            }
        } else {
            // If not a user document, check if it's an admin document (Subject)
            const adminDoc = await AdminDocument.findOne({ originalName: documentName }).select('text');
            if (adminDoc?.text) {
                sourceDocumentText = adminDoc.text;
                // For admin docs, use the server's global API key
                apiKeyForRequest = process.env.GEMINI_API_KEY;
            }
        }
        
        if (!sourceDocumentText) {
            return res.status(404).json({ message: `Source document '${documentName}' not found.` });
        }

        if (!apiKeyForRequest) {
             return res.status(400).json({ message: "API Key for document processing is missing." });
        }

        const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
        if (!pythonServiceUrl) {
            return res.status(500).json({ message: "Knowledge Graph service is not configured." });
        }
        
        const getKgUrl = `${pythonServiceUrl}/generate_kg_from_text`;
        
        console.log(`[KG Visualize] Proxying request to Python with API Key for KG generation.`);
        
        const pythonResponse = await axios.post(getKgUrl, {
            document_text: sourceDocumentText,
            api_key: apiKeyForRequest // <<< Pass the correct key
        }, { timeout: 300000 });

        if (pythonResponse.data && pythonResponse.data.success) {
            res.status(200).json(pythonResponse.data.graph_data);
        } else {
            throw new Error(pythonResponse.data.error || "Python service failed to generate the knowledge graph.");
        }
    } catch (error) {
        const errorMsg = error.response?.data?.error || error.message || "Failed to retrieve knowledge graph.";
        console.error(`[KG Visualize] Error for '${documentName}': ${errorMsg}`);
        res.status(error.response?.status || 500).json({ error: errorMsg });
    }
});

module.exports = router;
```

`server/routes/llmConfig.js`

```javascript
// server/routes/llmConfig.js
const express = require('express');
const router = express.Router();
const User = require('../models/User');
const { encrypt } = require('../utils/crypto');

// @route   PUT /api/llm/config
// @desc    Update user's LLM preferences (provider, key, or URL)
// @access  Private
router.put('/config', async (req, res) => {
    // 1. Destructure all possible fields.
    const { llmProvider, apiKey, ollamaUrl, ollamaModel } = req.body;
    const userId = req.user._id;

    try {
        // 2. Start with a blank object. We will only update what is sent.
        const updates = {};

        if (llmProvider) {
            if (!['gemini', 'ollama'].includes(llmProvider)) {
                return res.status(400).json({ message: "Invalid LLM provider specified." });
            }
            updates.preferredLlmProvider = llmProvider;
        }

        // If a new API key is provided, encrypt and add it to updates.
        if (apiKey) {
            updates.encryptedApiKey = encrypt(apiKey);
        }

        // If a new Ollama URL is provided, add it to updates.
        if (typeof ollamaUrl === 'string') {
            updates.ollamaUrl = ollamaUrl.trim();
        }

        // If a new Ollama model is provided, add it to updates.
        if (ollamaModel) {
            updates.ollamaModel = ollamaModel;
        }

        // 3. If the updates object is empty, nothing was sent to change.
        if (Object.keys(updates).length === 0) {
            return res.status(400).json({ message: "No valid update information provided." });
        }
        
        // 4. Use $set to only modify the fields present in the 'updates' object.
        // This will NEVER delete a field that isn't included in the request.
        await User.updateOne({ _id: userId }, { $set: updates });

        res.status(200).json({ message: "LLM preferences updated successfully." });
    } catch (error) {
        console.error(`Error updating LLM config for user ${userId}:`, error);
        res.status(500).json({ message: `Server error while updating LLM preferences: ${error.message}` });
    }
});


// This GET route is correct and doesn't need changes, but it should also return ollamaUrl
router.get('/config', async (req, res) => {
    const userId = req.user._id;
    try {
        const user = await User.findById(userId).select('preferredLlmProvider ollamaModel ollamaUrl');
        if (!user) {
            return res.status(404).json({ message: "User not found." });
        }
        res.status(200).json({
            preferredLlmProvider: user.preferredLlmProvider,
            ollamaModel: user.ollamaModel,
            ollamaUrl: user.ollamaUrl // Also return the URL
        });
    } catch (error) {
        console.error(`Error fetching LLM config for user ${userId}:`, error);
        res.status(500).json({ message: "Server error fetching LLM preferences." });
    }
});

module.exports = router;
```

`server/routes/mindmap.js`

```javascript
// server/routes/mindmap.js
const express = require('express');
const router = express.Router();
const { authMiddleware } = require('../middleware/authMiddleware');
const User = require('../models/User'); // For a more advanced implementation

// @route   GET /api/mindmap
// @desc    Get Mermaid code for a mind map
// @access  Private (requires auth)
router.get('/', authMiddleware, async (req, res) => {
    const userId = req.user._id; // User is authenticated
    console.log(`>>> GET /api/mindmap: User=${userId}`);

    try {
        const user = await User.findById(userId).select('uploadedDocuments.filename uploadedDocuments.analysis.mindmap'); // Select only necessary fields
        
        let mindmapCode = null;
        let sourceDocumentName = "Unknown Document";

        if (user && user.uploadedDocuments && user.uploadedDocuments.length > 0) {
            // Find the most recent document that has a mindmap analysis.
            // This assumes higher index means more recent, or you'd sort by an explicit timestamp if available.
            for (let i = user.uploadedDocuments.length - 1; i >= 0; i--) {
                const doc = user.uploadedDocuments[i];
                if (doc.analysis && typeof doc.analysis.mindmap === 'string' && doc.analysis.mindmap.trim() !== "") {
                    mindmapCode = doc.analysis.mindmap.trim();
                    sourceDocumentName = doc.filename || "Untitled Document";
                    console.log(`   Found mindmap for document '${sourceDocumentName}' for user ${userId}.`);
                    break;
                }
            }
        }

        if (mindmapCode) {
            // Basic check if the code starts with a known Mermaid diagram type.
            // This is a simple heuristic. Robust validation is complex.
            const trimmedCode = mindmapCode; // Already trimmed
            const validMermaidPrefixes = ['mindmap', 'graph', 'flowchart', 'sequenceDiagram', 'gantt', 'classDiagram', 'stateDiagram', 'pie', 'erDiagram', 'journey', 'requirementDiagram', 'gitGraph'];
            
            const isPotentiallyValidMermaid = validMermaidPrefixes.some(prefix => 
                trimmedCode.toLowerCase().startsWith(prefix)
            );

            if (!isPotentiallyValidMermaid) {
                // If the stored code doesn't look like Mermaid, prepend 'mindmap'
                // This is an assumption that the stored data *should* be a mindmap if it's in this field.
                console.warn(`   Mindmap code for '${sourceDocumentName}' does not start with a recognized Mermaid type. Prefixing with 'mindmap'.`);
                mindmapCode = `mindmap\n${trimmedCode}`; 
            } else if (!trimmedCode.toLowerCase().startsWith('mindmap')) {
                 // If it's valid Mermaid but not explicitly 'mindmap' (e.g. 'graph TD'),
                 // and the user specifically clicked "Mind Map", it's still okay to send.
                 // The Mermaid library on the frontend can render various diagram types.
                console.log(`   Sending stored analysis as Mermaid diagram. Type: ${trimmedCode.split('\n')[0].trim()}`);
            }
            return res.status(200).json({ mermaidCode: mindmapCode, source: sourceDocumentName });
        } else {
            console.log(`   No mindmap analysis found for user ${userId}. Returning default mindmap.`);
            const defaultMermaidCode = `
mindmap
  root((No Mind Map Available))
    (Please upload a document and ensure its analysis includes a mind map.)
    (Or, no documents processed yet.)
`;
            return res.status(200).json({ mermaidCode: defaultMermaidCode, source: "Default" });
        }

    } catch (error) {
        console.error(`!!! Error in GET /api/mindmap for User ${userId}:`, error);
        res.status(500).json({ message: "Failed to retrieve mind map code due to a server error." });
    }
});

module.exports = router;
```

`server/routes/network.js`

```javascript
const express = require('express');
const router = express.Router();
const os = require('os');

function getAllIPs() {
    const interfaces = os.networkInterfaces();
    const ips = new Set(['localhost']); // Include localhost by default

    for (const [name, netInterface] of Object.entries(interfaces)) {
        // Skip loopback and potentially virtual interfaces if desired
        if (name.includes('lo') || name.toLowerCase().includes('virtual') || name.toLowerCase().includes('vmnet')) continue;

        for (const addr of netInterface) {
            // Focus on IPv4, non-internal addresses
            if (addr.family === 'IPv4' && !addr.internal) {
                ips.add(addr.address);
            }
        }
    }
    return Array.from(ips);
}

router.get('/ip', (req, res) => {
    res.json({
        ips: getAllIPs(),
        // req.ip might be less reliable behind proxies, but can be included
        // currentRequestIp: req.ip
    });
});

module.exports = router;

```

`server/routes/subjects.js`

```javascript
// server/routes/subjects.js
const express = require('express');
const router = express.Router();
const AdminDocument = require('../models/AdminDocument'); // Model for admin-uploaded documents

// @route   GET /api/subjects
// @desc    Get a list of available subject names (derived from admin-uploaded document originalNames)
// @access  Private (Regular User Authenticated via JWT)
router.get('/', async (req, res) => {
    // req.user is available here from authMiddleware
    console.log(`User ${req.user.username} is requesting the list of subjects.`);
    try {
        // Fetch distinct originalName values from the AdminDocument collection
        // and sort them alphabetically.
        const subjectObjects = await AdminDocument.find().sort({ originalName: 1 }).select('originalName').lean();
        const subjectNames = subjectObjects.map(doc => doc.originalName);
        
        // Alternative using distinct, but sorting might be different or need post-processing
        // const subjectNames = await AdminDocument.distinct('originalName').exec();
        // subjectNames.sort((a, b) => a.localeCompare(b));


        res.json({ subjects: subjectNames }); // Send as { subjects: ["Subject 1", "Subject 2", ...] }
    } catch (error) {
        console.error("Error fetching subjects for user display:", error);
        res.status(500).json({ message: "Server error while fetching available subjects." });
    }
});

module.exports = router;
```

`server/routes/syllabus.js`

```javascript
// server/routes/syllabus.js
const express = require('express');
const fs = require('fs').promises;
const path = require('path');
const { authMiddleware } = require('../middleware/authMiddleware'); // Protect the route

const router = express.Router();
const SYLLABI_DIR = path.join(__dirname, '..', 'syllabi');

// --- @route   GET /api/syllabus/:subjectId ---
// --- @desc    Get syllabus content for a specific subject ---
// --- @access  Private (requires auth) ---
router.get('/:subjectId', authMiddleware, async (req, res) => {
    const { subjectId } = req.params;

    // Basic sanitization: Allow only alphanumeric and underscores
    // Prevents directory traversal (e.g., ../../etc/passwd)
    const sanitizedSubjectId = subjectId.replace(/[^a-zA-Z0-9_]/g, '');

    if (!sanitizedSubjectId || sanitizedSubjectId !== subjectId) {
        console.warn(`Syllabus request rejected due to invalid characters: ${subjectId}`);
        return res.status(400).json({ message: 'Invalid subject identifier format.' });
    }

    const filePath = path.join(SYLLABI_DIR, `${sanitizedSubjectId}.md`);

    try {
        // Check if file exists first (more specific error)
        await fs.access(filePath);

        // Read the file content
        const content = await fs.readFile(filePath, 'utf-8');

        res.status(200).json({ syllabus: content });

    } catch (error) {
        if (error.code === 'ENOENT') {
            console.warn(`Syllabus file not found: ${filePath}`);
            return res.status(404).json({ message: `Syllabus for '${subjectId}' not found.` });
        } else {
            console.error(`Error reading syllabus file ${filePath}:`, error);
            return res.status(500).json({ message: 'Server error retrieving syllabus.' });
        }
    }
});

module.exports = router;

```

`server/routes/upload.js`

```javascript


// server/routes/upload.js
const express = require('express');
const multer = require('multer');
const path = require('path');
const fs = require('fs');
const axios = require('axios');
const { authMiddleware } = require('../middleware/authMiddleware');
const User = require('../models/User');
const { Worker } = require('worker_threads');
const { decrypt } = require('../utils/crypto');

const router = express.Router();

// --- Constants & Multer Config ---
const UPLOAD_DIR = path.join(__dirname, '..', 'assets');
const MAX_FILE_SIZE = 20 * 1024 * 1024;
const allowedMimeTypes = {
    'application/pdf': 'docs',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document': 'docs',
    'application/msword': 'docs',
    'application/vnd.openxmlformats-officedocument.presentationml.presentation': 'docs',
    'application/vnd.ms-powerpoint': 'docs',
    'text/plain': 'docs', 'text/x-python': 'code', 'application/javascript': 'code',
    'text/javascript': 'code', 'text/markdown': 'code', 'text/html': 'code',
    'application/xml': 'code', 'text/xml': 'code', 'application/json': 'code',
    'text/csv': 'code', 'image/jpeg': 'images', 'image/png': 'images',
    'image/bmp': 'images', 'image/gif': 'images',
};
const allowedExtensions = [
    '.pdf', '.docx', '.doc', '.pptx', '.ppt', '.txt', '.py', '.js', '.md', 
    '.html', '.xml', '.json', '.csv', '.log', '.jpg', '.jpeg', '.png', '.bmp', '.gif'
];

const storage = multer.diskStorage({
    destination: (req, file, cb) => {
        if (!req.user || !req.user.email) {
            return cb(new Error("Authentication error: User context not found for upload destination."));
        }
        const sanitizedUsername = req.user.email.split('@')[0].replace(/[^a-zA-Z0-9_-]/g, '_');
        const fileMimeType = file.mimetype.toLowerCase();
        const fileTypeSubfolder = allowedMimeTypes[fileMimeType] || 'others';
        const destinationPath = path.join(UPLOAD_DIR, sanitizedUsername, fileTypeSubfolder);
        fs.mkdir(destinationPath, { recursive: true }, (err) => {
             if (err) cb(err); else cb(null, destinationPath);
         });
    },
    filename: (req, file, cb) => {
        const timestamp = Date.now();
        const fileExt = path.extname(file.originalname).toLowerCase();
        const sanitizedBaseName = path.basename(file.originalname, fileExt)
                                      .replace(/[^a-zA-Z0-9._-]/g, '_').substring(0, 100);
        const uniqueFilename = `${timestamp}-${sanitizedBaseName}${fileExt}`;
        cb(null, uniqueFilename);
    }
});

const fileFilter = (req, file, cb) => {
    if (!req.user) {
         const err = new multer.MulterError('UNAUTHENTICATED');
         err.message = 'User not authenticated.';
         return cb(err, false);
    }
    const fileExt = path.extname(file.originalname).toLowerCase();
    const mimeType = file.mimetype.toLowerCase();
    if (allowedMimeTypes[mimeType] && allowedExtensions.includes(fileExt)) {
        cb(null, true);
    } else {
        const err = new multer.MulterError('LIMIT_UNEXPECTED_FILE');
        err.message = `Invalid file type. Allowed: ${allowedExtensions.join(', ')}.`;
        cb(err, false);
    }
};

const upload = multer({ storage, fileFilter, limits: { fileSize: MAX_FILE_SIZE }});

async function triggerPythonRagProcessing(userId, filePath, originalName) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
    if (!pythonServiceUrl) {
        return { success: false, message: "RAG service URL not configured." };
    }
    const addDocumentUrl = `${pythonServiceUrl}/add_document`;
    try {
        const response = await axios.post(addDocumentUrl, { user_id: userId, file_path: filePath, original_name: originalName });
        const pythonData = response.data;
        const text = pythonData?.raw_text_for_analysis || null;
        return {
            success: !!(text && text.trim()),
            status: pythonData?.status,
            message: pythonData?.message || "No message from Python.",
            text: text,
            chunksForKg: pythonData?.chunks_with_metadata || []
        };
    } catch (error) {
        return { success: false, message: `Python RAG call failed: ${error.response?.data?.error || error.message}`};
    }
}

router.post('/', (req, res) => {
    const uploader = upload.single('file');

    uploader(req, res, async function (err) {
        if (!req.user) {
            return res.status(401).json({ message: "Authentication error: User context not found." });
        }
        if (err) {
            console.error(`Upload Route: Multer error for user '${req.user.email}': ${err.message}`);
            return res.status(err instanceof multer.MulterError ? 400 : 500).json({ message: err.message });
        }
        if (!req.file) {
            return res.status(400).json({ message: "No file received or file type rejected." });
        }

        const userId = req.user._id.toString();
        const { originalname: originalName, path: tempServerPath } = req.file;
        if (!tempServerPath) {
            return res.status(500).json({ message: "File upload failed, temporary path not created." });
        }
        const absoluteFilePath = path.resolve(tempServerPath);

        try {
            const user = await User.findById(userId).select('uploadedDocuments.filename preferredLlmProvider ollamaModel ollamaUrl +encryptedApiKey');
            if (!user) {
                await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Cleanup Error: ${e.message}`));
                return res.status(404).json({ message: "User not found." });
            }

            if (user.uploadedDocuments.some(doc => doc.filename === originalName)) {
                await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Cleanup Error: ${e.message}`));
                return res.status(409).json({ message: `File '${originalName}' already exists.` });
            }

            const ragResult = await triggerPythonRagProcessing(userId, absoluteFilePath, originalName);

            if (!ragResult.success) {
                await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Cleanup Error: ${e.message}`));
                return res.status(422).json({ message: ragResult.message || "Failed to extract text." });
            }
            
            const newDocEntry = {
                filename: originalName, text: ragResult.text,
                analysis: {}, uploadedAt: new Date(), ragStatus: ragResult.status,
                analysisStatus: "pending", kgStatus: "pending"
            };
            await User.updateOne({ _id: userId }, { $push: { uploadedDocuments: newDocEntry } });
            
            res.status(202).json({
                message: `File '${originalName}' accepted. Background processing initiated.`,
                originalname: originalName,
            });

            const userApiKey = user.encryptedApiKey ? decrypt(user.encryptedApiKey) : null;
            const llmProviderForWorkers = user.preferredLlmProvider || 'gemini';

            if (llmProviderForWorkers === 'gemini' && !userApiKey) {
                console.warn(`[Upload Route] User ${userId} selected Gemini but has no API key. Workers may fail.`);
            }
            
            const workerData = { 
                userId, 
                originalName, 
                textForAnalysis: ragResult.text, 
                llmProvider: llmProviderForWorkers, 
                ollamaModel: user.ollamaModel,
                apiKey: userApiKey,
                ollamaUrl: user.ollamaUrl
            };
            const kgWorkerData = { ...workerData, chunksForKg: ragResult.chunksForKg };

            const analysisWorker = new Worker(path.resolve(__dirname, '../workers/analysisWorker.js'), { workerData });
            analysisWorker.on('error', (err) => console.error(`Analysis Worker Error [${originalName}]:`, err));

            if (ragResult.chunksForKg && ragResult.chunksForKg.length > 0) {
                const kgWorker = new Worker(path.resolve(__dirname, '../workers/kgWorker.js'), { workerData: kgWorkerData });
                kgWorker.on('error', (err) => console.error(`KG Worker Error [${originalName}]:`, err));
            } else {
                 await User.updateOne({ _id: userId, "uploadedDocuments.filename": originalName }, { $set: { "uploadedDocuments.$.kgStatus": "skipped_no_chunks" } });
            }

            await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Non-critical cleanup error: ${e.message}`));

        } catch (error) {
            console.error(`Overall Upload Error for ${originalName}:`, error);
            if (fs.existsSync(tempServerPath)) {
                await fs.promises.unlink(tempServerPath).catch(e => console.error(`Final Cleanup Error: ${e.message}`));
            }
            if (!res.headersSent) {
                res.status(500).json({ message: "Server error during file processing." });
            }
        }
    });
});

module.exports = router;
```

`server/routes/user.js`

```javascript
// server/routes/user.js
const express = require('express');
const router = express.Router();
const User = require('../models/User');

// Note: The main 'authMiddleware' will be applied in server.js before this router is used,
// so we don't need to add it to each route here. req.user will be available.

// @route   GET /api/user/profile
// @desc    Get the current user's profile data
// @access  Private
router.get('/profile', async (req, res) => {
    try {
        const user = await User.findById(req.user._id).select('profile');
        if (!user) {
            return res.status(404).json({ message: 'User not found.' });
        }
        // Return the profile object, or an empty object if it doesn't exist
        res.json(user.profile || {});
    } catch (error) {
        console.error('Error fetching user profile:', error);
        res.status(500).json({ message: 'Server error while fetching profile.' });
    }
});

// @route   PUT /api/user/profile
// @desc    Update the current user's profile data
// @access  Private
router.put('/profile', async (req, res) => {
    const { name, college, universityNumber, degreeType, branch, year } = req.body;

    // Basic backend validation
    if (!name || !college || !universityNumber || !degreeType || !branch || !year) {
        return res.status(400).json({ message: 'All profile fields are required.' });
    }

    try {
        const user = await User.findById(req.user._id);
        if (!user) {
            return res.status(404).json({ message: 'User not found.' });
        }

        // Update the profile sub-document
        user.profile = {
            name,
            college,
            universityNumber,
            degreeType,
            branch,
            year
        };

        await user.save();

        res.json({
            message: 'Profile updated successfully!',
            profile: user.profile
        });

    } catch (error) {
        console.error('Error updating user profile:', error);
        res.status(500).json({ message: 'Server error while updating profile.' });
    }
});

module.exports = router;
```

`server/server.js`

```javascript


// server/server.js
const dotenv = require('dotenv');
dotenv.config();

const express = require('express');
const cors = require('cors');
const path = require('path');
const fs = require('fs');
const axios = require('axios');
const mongoose = require('mongoose');

// --- Custom Modules & Middleware ---
const connectDB = require('./config/db');
const { getLocalIPs } = require('./utils/networkUtils');
const { performAssetCleanup } = require('./utils/assetCleanup');
const { authMiddleware } = require('./middleware/authMiddleware');

// --- Route Imports ---
const networkRoutes = require('./routes/network');
const authRoutes = require('./routes/auth');
const userRoutes = require('./routes/user');
const chatRoutes = require('./routes/chat');
const uploadRoutes = require('./routes/upload');
const filesRoutes = require('./routes/files');
const analysisRoutes = require('./routes/analysis');
const adminDocsRoutes = require('./routes/adminDocuments');
const subjectsRoutes = require('./routes/subjects');
const generationRoutes = require('./routes/generation');
const exportRoutes = require('./routes/export');
const kgRoutes = require('./routes/kg');
const llmConfigRoutes = require('./routes/llmConfig');

// --- Configuration & Express App Setup ---
const port = process.env.PORT || 5001;
const mongoUri = process.env.MONGO_URI;
const pythonRagUrl = process.env.PYTHON_RAG_SERVICE_URL;

if (!process.env.JWT_SECRET || !process.env.ENCRYPTION_SECRET) {
    console.error("!!! FATAL: JWT_SECRET or ENCRYPTION_SECRET is not set in .env file.");
    process.exit(1);
}
if (!mongoUri) {
    console.error("!!! FATAL: MONGO_URI is not set in .env file.");
    process.exit(1);
}

const app = express();
app.use(cors());
app.use(express.json({ limit: '10mb' }));
app.use(express.urlencoded({ extended: true, limit: '10mb' }));

// --- API Route Mounting ---
app.get('/', (req, res) => res.send('AI Tutor Backend API is running...'));
app.use('/api/network', networkRoutes);
app.use('/api/auth', authRoutes);
app.use('/api/admin/documents', adminDocsRoutes);

// All subsequent routes are protected by the authMiddleware
app.use(authMiddleware); 
app.use('/api/user', userRoutes);
app.use('/api/chat', chatRoutes);
app.use('/api/upload', uploadRoutes);
app.use('/api/files', filesRoutes);
app.use('/api/analysis', analysisRoutes);
app.use('/api/subjects', subjectsRoutes);
app.use('/api/generate', generationRoutes);
app.use('/api/export', exportRoutes);
app.use('/api/kg', kgRoutes);
app.use('/api/llm', llmConfigRoutes);

// --- Centralized Error Handling ---
app.use((err, req, res, next) => {
    console.error("Unhandled Error:", err.stack || err);
    const statusCode = err.status || 500;
    const message = err.message || 'An internal server error occurred.';
    if (!res.headersSent) {
        res.status(statusCode).json({ message });
    }
});

// --- Server Startup Logic ---
async function startServer() {
    console.log("\n--- Starting Server Initialization ---");
    try {
        await ensureServerDirectories();
        await connectDB(mongoUri); 
        await performAssetCleanup(); 
        await checkRagService(pythonRagUrl);

        const server = app.listen(port, '0.0.0.0', () => {
            console.log('\n=== Node.js Server Ready ===');
            console.log(` Server listening on port ${port}`);
            getLocalIPs().forEach(ip => {
                 console.log(`   - http://${ip}:${port}`);
            });
            console.log('============================\n');
        });
        
        const gracefulShutdown = (signal) => {
            console.log(`\n${signal} received. Shutting down...`);
            server.close(() => {
                mongoose.connection.close(false, () => {
                    console.log('MongoDB connection closed.');
                    process.exit(0);
                });
            });
        };
        process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
        process.on('SIGINT', () => gracefulShutdown('SIGINT'));

    } catch (error) {
        console.error("!!! Failed to start Node.js server:", error.message);
        process.exit(1);
    }
}

// Helper functions
async function ensureServerDirectories() {
    const dirs = [path.join(__dirname, 'assets'), path.join(__dirname, 'backup_assets'), path.join(__dirname, 'generated_docs')];
    for (const dir of dirs) {
        if (!fs.existsSync(dir)) await fs.promises.mkdir(dir, { recursive: true });
    }
}
async function checkRagService(url) {
    if(!url) { console.warn('! Python RAG service URL not configured.'); return; }
    try {
        const response = await axios.get(`${url}/health`, { timeout: 7000 });
        if (response.data.status === 'ok') {
            console.log(' Python RAG service is available.');
        } else {
            console.warn(`! Python RAG service responded but is not healthy. Status: ${response.data.status}`);
        }
    } catch (error) {
        console.warn('! Python RAG service is not reachable.');
    }
}

startServer();

```

`server/services/adminDocuments.js`

```javascript
// server/routes/adminDocuments.js
const express = require('express');
const multer = require('multer');
const path = require('path');
const fs = require('fs'); // Using Node.js fs for directory creation and file ops
const fsPromises = fs.promises; // For async file operations
const AdminDocument = require('../models/AdminDocument');
const { fixedAdminAuthMiddleware } = require('../middleware/fixedAdminAuthMiddleware');
const axios = require('axios'); // For calling Python RAG service

const router = express.Router();

// --- Constants for Admin Uploads ---
const ADMIN_UPLOAD_DIR_BASE = path.join(__dirname, '..', 'assets', '_admin_uploads_');
const MAX_FILE_SIZE = 20 * 1024 * 1024; // 20 MB

// Allowed types for admin uploads
const allowedAdminMimeTypes = {
    'application/pdf': 'docs',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document': 'docs', // docx
    'text/plain': 'docs', // txt
    'text/markdown': 'docs', // md
    // Add more as needed for admin
};
const allowedAdminExtensions = ['.pdf', '.docx', '.txt', '.md'];

// --- Multer Config for Admin Uploads ---
const adminStorage = multer.diskStorage({
    destination: (req, file, cb) => {
        const fileMimeType = file.mimetype.toLowerCase();
        const fileTypeSubfolder = allowedAdminMimeTypes[fileMimeType] || 'others'; // Default to 'others'
        const destinationPath = path.join(ADMIN_UPLOAD_DIR_BASE, fileTypeSubfolder);

        fs.mkdir(destinationPath, { recursive: true }, (err) => {
            if (err) {
                console.error(`Admin Upload Multer: Error creating destination path ${destinationPath}:`, err);
                return cb(err);
            }
            cb(null, destinationPath);
        });
    },
    filename: (req, file, cb) => {
        const timestamp = Date.now();
        const fileExt = path.extname(file.originalname).toLowerCase();
        const sanitizedBaseName = path.basename(file.originalname, fileExt)
            .replace(/[^a-zA-Z0-9._-]/g, '_')
            .substring(0, 100); // Limit base name length
        const uniqueFilename = `${timestamp}-${sanitizedBaseName}${fileExt}`;
        cb(null, uniqueFilename);
    }
});

const adminFileFilter = (req, file, cb) => {
    const fileExt = path.extname(file.originalname).toLowerCase();
    const mimeType = file.mimetype.toLowerCase();

    const isMimeTypeAllowed = !!allowedAdminMimeTypes[mimeType];
    const isExtensionAllowed = allowedAdminExtensions.includes(fileExt);

    if (isMimeTypeAllowed && isExtensionAllowed) {
        cb(null, true);
    } else {
        console.warn(`Admin Upload Rejected (Filter): File='${file.originalname}', MIME='${mimeType}', Ext='${fileExt}'.`);
        const error = new multer.MulterError('LIMIT_UNEXPECTED_FILE_TYPE_ADMIN');
        error.message = `Invalid file type or extension for admin upload. Allowed: ${allowedAdminExtensions.join(', ')}`;
        cb(error, false);
    }
};

const adminUpload = multer({
    storage: adminStorage,
    fileFilter: adminFileFilter,
    limits: { fileSize: MAX_FILE_SIZE }
});

// --- Helper to call Python RAG service for Admin Docs (Text Extraction Only) ---
async function triggerPythonTextExtractionForAdmin(filePath, originalName) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
    if (!pythonServiceUrl) {
        console.error("ADMIN RAG: PYTHON_RAG_SERVICE_URL not set. Cannot extract text.");
        return { success: false, message: "Python service URL not configured for text extraction.", text: null };
    }
    const addDocumentUrl = `${pythonServiceUrl}/add_document`;
    console.log(`ADMIN RAG: Calling Python Service: ${addDocumentUrl} for text extraction of '${originalName}'`);

    try {
        // For admin docs, we pass a generic user_id or a specific marker.
        // The Python service might try to add to Qdrant/Neo4j with this ID.
        // If admin docs are NOT to be in the main Qdrant/Neo4j, the Python service
        // would ideally have a flag to skip DB insertions for certain user_ids/contexts.
        // For now, Node.js only cares about the returned text.
        const response = await axios.post(addDocumentUrl, {
            user_id: "fixed_admin_text_extraction_user", // A distinct ID for Python's logging/potential filtering
            file_path: filePath,
            original_name: originalName
        }, { timeout: 300000 }); // 5 min timeout

        const pythonData = response.data;
        const text = pythonData?.raw_text_for_analysis || null;

        if (text) {
            console.log(`ADMIN RAG: Text extracted successfully for '${originalName}'. Length: ${text.length}`);
            return { success: true, message: "Text extracted.", text: text };
        } else {
            console.warn(`ADMIN RAG: Python service returned no text for '${originalName}'. Status: ${pythonData?.status}, Message: ${pythonData?.message}`);
            return { success: false, message: pythonData?.message || "Python service extracted no text.", text: null };
        }
    } catch (error) {
        const errorMsg = error.response?.data?.error || error.response?.data?.message || error.message || "Unknown error calling Python RAG for text extraction.";
        console.error(`ADMIN RAG: Error calling Python service for '${originalName}': ${errorMsg}`);
        return { success: false, message: `Python RAG call failed: ${errorMsg}`, text: null };
    }
}


// --- Admin Document Routes ---

// @route   POST /api/admin/documents/upload
// @desc    Upload a document for the admin, extract text, and initiate analysis.
// @access  Admin Only (via fixedAdminAuthMiddleware)
router.post('/upload', fixedAdminAuthMiddleware, adminUpload.single('file'), async (req, res) => {
    if (!req.file) {
        return res.status(400).json({ message: 'No file uploaded or file type rejected.' });
    }

    const { filename: serverFilename, originalname: originalName, path: tempServerPath } = req.file;
    let adminDocRecord;

    try {
        // 1. Check for existing document with the same originalName
        const existingDoc = await AdminDocument.findOne({ originalName: originalName });
        if (existingDoc) {
            await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Error deleting duplicate temp file ${tempServerPath}:`, e));
            return res.status(409).json({ message: `Document with original name '${originalName}' already exists for admin.` });
        }

        // 2. Extract text using Python RAG service
        console.log(`Admin Upload: Attempting text extraction for '${originalName}' from ${tempServerPath}`);
        const textExtractionResult = await triggerPythonTextExtractionForAdmin(tempServerPath, originalName);

        if (!textExtractionResult.success || !textExtractionResult.text || textExtractionResult.text.trim() === "") {
            await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Error deleting temp file ${tempServerPath} after failed text extraction:`, e));
            return res.status(422).json({ // Unprocessable Entity
                message: textExtractionResult.message || "Failed to extract usable text from the document.",
                filename: serverFilename,
                originalname: originalName
            });
        }
        console.log(`Admin Upload: Text extracted for '${originalName}'. Proceeding to save and analyze.`);

        // 3. Save initial AdminDocument record
        adminDocRecord = new AdminDocument({
            filename: serverFilename,
            originalName: originalName,
            text: textExtractionResult.text,
            // serverPath and fileTypeSubfolder are not in the simplified model.
            // If we decide to keep the file, we'd need to move it from tempServerPath
            // to a final location and store that path. For now, assume tempServerPath is cleaned up.
            analysis: { faq: "", topics: "", mindmap: "" }, // Initialize analysis
            analysisUpdatedAt: null,
        });
        await adminDocRecord.save();
        console.log(`Admin Upload: Initial DB record saved for '${originalName}' (Server: ${serverFilename}).`);

        // 4. Delete the temporary file uploaded by multer as text is now in DB
        // If you decide to keep the physical file, this step would be a move operation instead.
        await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Non-critical error deleting temp file ${tempServerPath} after DB save:`, e));


        // 5. Respond to client (202 Accepted) & Trigger Background Analysis
        res.status(202).json({
            message: `Admin document '${originalName}' uploaded. Text extracted. Analysis initiated.`,
            filename: serverFilename,
            originalname: originalName,
        });
        console.log(`Admin Upload: Sent 202 Accepted for '${originalName}'. Offloading analysis.`);

        // --- Trigger Background Analysis Worker ---
        // This requires an 'adminAnalysisWorker.js'
        const { Worker } = require('worker_threads');
        const adminAnalysisWorkerPath = path.resolve(__dirname, '..', 'workers', 'adminAnalysisWorker.js');
        
        try {
            if (fs.existsSync(adminAnalysisWorkerPath)) { // Check if worker file exists
                const worker = new Worker(adminAnalysisWorkerPath, {
                    workerData: {
                        adminDocumentId: adminDocRecord._id.toString(), // Pass ID to update the specific doc
                        originalName: originalName,
                        textForAnalysis: textExtractionResult.text
                    }
                });
                worker.on('message', (msg) => console.log(`Admin Analysis Worker [Doc: ${msg.originalName || originalName}]: ${msg.message || JSON.stringify(msg)}`));
                worker.on('error', (err) => console.error(`Admin Analysis Worker Error [Doc: ${originalName}]:`, err));
                worker.on('exit', (code) => console.log(`Admin Analysis Worker [Doc: ${originalName}] exited (code ${code}).`));
            } else {
                console.error(`Admin Upload: adminAnalysisWorker.js not found at ${adminAnalysisWorkerPath}. Analysis cannot be started.`);
                // Optionally update the AdminDocument status to 'analysis_launch_failed'
            }
        } catch (workerError) {
            console.error(`Admin Upload: Error launching Admin Analysis Worker for '${originalName}':`, workerError);
        }

    } catch (error) {
        console.error(`Admin Upload: Overall error for '${originalName || (req.file && req.file.originalname)}':`, error);
        if (tempServerPath) { // If path is known, try to clean up temp file
            await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Error cleaning up temp file ${tempServerPath} after overall error:`, e));
        }
        if (!res.headersSent) {
            if (error.code === 11000) { // MongoDB duplicate key
                 res.status(409).json({ message: 'Document processing conflict (e.g., duplicate server filename). Please try again.' });
            } else {
                 res.status(500).json({ message: 'Server error during admin document upload processing.' });
            }
        }
    }
});

// @route   GET /api/admin/documents
// @desc    Get list of documents uploaded by the admin
// @access  Admin Only (via fixedAdminAuthMiddleware)
router.get('/', fixedAdminAuthMiddleware, async (req, res) => {
    try {
        // Fetching fields relevant for listing and identifying documents.
        // Exclude 'text' and full 'analysis' objects by default to keep payload small.
        const adminDocs = await AdminDocument.find()
            .sort({ uploadedAt: -1 })
            .select('originalName filename uploadedAt analysisUpdatedAt analysis.faq analysis.topics analysis.mindmap'); // Select specific fields

        const documentsList = adminDocs.map(doc => ({
            originalName: doc.originalName,
            serverFilename: doc.filename, // Useful if frontend needs to make further requests (e.g., delete)
            uploadedAt: doc.uploadedAt,
            analysisUpdatedAt: doc.analysisUpdatedAt,
            hasFaq: !!(doc.analysis && doc.analysis.faq && doc.analysis.faq.trim() !== ""),
            hasTopics: !!(doc.analysis && doc.analysis.topics && doc.analysis.topics.trim() !== ""),
            hasMindmap: !!(doc.analysis && doc.analysis.mindmap && doc.analysis.mindmap.trim() !== ""),
        }));

        // For frontend compatibility with existing DocumentList component,
        // it might expect an array of strings (originalName).
        // If so, change `res.json({ documents: documentsList });` to
        // `res.json({ filenames: documentsList.map(d => d.originalName) });`
        // However, sending more info like `documentsList` is generally more useful.
        res.json({ documents: documentsList });

    } catch (error) {
        console.error('Admin List Documents Error:', error);
        res.status(500).json({ message: 'Server error fetching admin documents.' });
    }
});

// @route   DELETE /api/admin/documents/:serverFilename
// @desc    Delete a document uploaded by the admin (DB record only for simplified model)
// @access  Admin Only (via fixedAdminAuthMiddleware)
router.delete('/:serverFilename', fixedAdminAuthMiddleware, async (req, res) => {
    const { serverFilename } = req.params;

    if (!serverFilename) {
        return res.status(400).json({ message: 'Server filename parameter is required for deletion.' });
    }

    try {
        const docToDelete = await AdminDocument.findOneAndDelete({ filename: serverFilename });

        if (!docToDelete) {
            return res.status(404).json({ message: `Admin document with server name '${serverFilename}' not found.` });
        }

        console.log(`Admin Delete: Document record '${docToDelete.originalName}' (Server: ${serverFilename}) deleted from MongoDB.`);
        
        // Since we are not storing serverPath in the simplified model and deleting temp files after text extraction,
        // there's no physical file to delete from 'assets/_admin_uploads_' based on DB record alone at this stage.
        // If, in the future, you decide to *keep* admin-uploaded files, you'd add file deletion logic here
        // and would need to store `serverPath` in AdminDocument model.

        // TODO (Future): If admin documents were processed by Qdrant/Neo4j,
        // trigger deletion from those services here.

        res.status(200).json({ message: `Admin document '${docToDelete.originalName}' record deleted successfully.` });

    } catch (error) {
        console.error(`Admin Delete Error for serverFilename '${serverFilename}':`, error);
        res.status(500).json({ message: 'Server error during admin document deletion.' });
    }
});


// @route   GET /api/admin/documents/:serverFilename/analysis
// @desc    Get analysis data for a specific admin document
// @access  Admin Only
router.get('/:serverFilename/analysis', fixedAdminAuthMiddleware, async (req, res) => {
    const { serverFilename } = req.params;
    if (!serverFilename) {
        return res.status(400).json({ message: 'Server filename parameter is required.' });
    }

    try {
        const adminDoc = await AdminDocument.findOne({ filename: serverFilename }).select('originalName analysis analysisUpdatedAt');
        if (!adminDoc) {
            return res.status(404).json({ message: `Admin document '${serverFilename}' not found.` });
        }
        if (!adminDoc.analysis || 
            (!adminDoc.analysis.faq && !adminDoc.analysis.topics && !adminDoc.analysis.mindmap)) {
            return res.status(200).json({ 
                originalName: adminDoc.originalName,
                message: 'Analysis has not been generated or is empty for this document.',
                analysis: { faq: "", topics: "", mindmap: "" }, // Return empty structure
                analysisUpdatedAt: adminDoc.analysisUpdatedAt
            });
        }
        res.status(200).json({
            originalName: adminDoc.originalName,
            analysis: adminDoc.analysis, // Contains faq, topics, mindmap strings
            analysisUpdatedAt: adminDoc.analysisUpdatedAt
        });
    } catch (error) {
        console.error(`Error fetching analysis for admin document '${serverFilename}':`, error);
        res.status(500).json({ message: 'Server error while retrieving admin document analysis.' });
    }
});


module.exports = router;
```

`server/services/agentService.js`

```javascript
// server/services/agentService.js
const { CHAT_MAIN_SYSTEM_PROMPT, createSynthesizerPrompt, createAgenticSystemPrompt } = require('../config/promptTemplates.js');
const { availableTools } = require('./toolRegistry.js');
const { createModelContext, createAgenticContext } = require('../protocols/contextProtocols.js');
const geminiService = require('./geminiService.js');
const ollamaService = require('./ollamaService.js');

function parseToolCall(responseText) {
    try {
        const jsonMatch = responseText.match(/```(json)?\s*([\s\S]+?)\s*```/);
        const jsonString = jsonMatch ? jsonMatch[2] : responseText;
        const jsonResponse = JSON.parse(jsonString);
        if (jsonResponse && typeof jsonResponse.tool_call !== 'undefined') {
            return jsonResponse.tool_call;
        }
        return null;
    } catch (e) {
        console.warn(`[AgentService] Failed to parse JSON tool_call from LLM. Response: ${responseText.substring(0, 200)}...`);
        return null;
    }
}

async function processAgenticRequest(userQuery, chatHistory, clientSystemPrompt, requestContext) {
    const { llmProvider, ollamaModel, userId, ollamaUrl, documentContextName, apiKey } = requestContext;
    
    const llmService = llmProvider === 'ollama' ? ollamaService : geminiService;
    const llmOptions = {
        ...(llmProvider === 'ollama' && { model: ollamaModel }),
        apiKey: apiKey,
        ollamaUrl: ollamaUrl
    };

    const modelContext = createModelContext({ availableTools });
    const agenticContext = createAgenticContext({ systemPrompt: clientSystemPrompt });
    const routerSystemPrompt = createAgenticSystemPrompt(modelContext, agenticContext, { userQuery, ...requestContext });

    console.log(`[AgentService] Performing Router call using ${llmProvider}...`);
    const routerResponseText = await llmService.generateContentWithHistory([], "Analyze the query and decide on an action.", routerSystemPrompt, llmOptions);
    const toolCall = parseToolCall(routerResponseText);

    // --- DIRECT ANSWER PATH (Corrected Logic) ---
    if (!toolCall || !toolCall.tool_name) {
        console.log('[AgentService] Decision: Direct Answer. Using main prompt engine.');
        // This now correctly combines your base instructions with the user's selected persona.
        const finalSystemPrompt = CHAT_MAIN_SYSTEM_PROMPT();
        const fullUserQuery = `${clientSystemPrompt}\n\nUSER QUERY:\n${userQuery}`;
        
        const directAnswer = await llmService.generateContentWithHistory(
            chatHistory,
            fullUserQuery,
            finalSystemPrompt,
            llmOptions
        );

        // Extract thinking if present
        const thinkingMatch = directAnswer.match(/<thinking>([\s\S]*?)<\/thinking>/i);
        const thinking = thinkingMatch ? thinkingMatch[1].trim() : null;
        const mainContent = thinking ? directAnswer.replace(/<thinking>[\s\S]*?<\/thinking>\s*/i, '').trim() : directAnswer;

        return {
            finalAnswer: mainContent,
            thinking: thinking,
            references: [],
            sourcePipeline: `${llmProvider}-agent-direct`,
        };
    }

    // --- TOOL-BASED ANSWER PATH (With KG Enhancement) ---
    console.log(`[AgentService] Decision: Tool Call -> ${toolCall.tool_name}`);
    const mainTool = availableTools[toolCall.tool_name];
    if (!mainTool) {
        return { finalAnswer: "I tried to use a tool that doesn't exist. Please try again.", references: [], sourcePipeline: 'agent-error-unknown-tool' };
    }

    try {
        const toolExecutionPromises = [mainTool.execute(toolCall.parameters, requestContext)];
        const executedToolNames = [toolCall.tool_name];
        let pipeline = `${llmProvider}-agent-${toolCall.tool_name}`;

        // If the main tool is RAG and a document is selected, automatically add KG search.
        if (toolCall.tool_name === 'rag_search' && documentContextName) {
            console.log('[AgentService] RAG search triggered. Automatically adding KG search to execution plan.');
            const kgTool = availableTools['kg_search'];
            toolExecutionPromises.push(kgTool.execute(toolCall.parameters, { ...requestContext, userId }));
            executedToolNames.push('kg_search');
            pipeline += '+kg';
        }

        const toolResults = await Promise.all(toolExecutionPromises);
        
        const combinedToolOutput = toolResults.map((result, index) => 
            `--- CONTEXT FROM: ${executedToolNames[index].toUpperCase()} ---\n${result.toolOutput}`
        ).join('\n\n');
        const combinedReferences = toolResults.flatMap(result => result.references || []);

        console.log(`[AgentService] Performing Synthesizer call using ${llmProvider}...`);
        
        const finalSystemPrompt = CHAT_MAIN_SYSTEM_PROMPT();
        const synthesizerUserQuery = createSynthesizerPrompt(userQuery, combinedToolOutput, toolCall.tool_name);
        
        const finalAnswerWithThinking = await llmService.generateContentWithHistory(chatHistory, synthesizerUserQuery, finalSystemPrompt, llmOptions);
        
        // Extract thinking from synthesizer response
        const thinkingMatch = finalAnswerWithThinking.match(/<thinking>([\s\S]*?)<\/thinking>/i);
        const thinking = thinkingMatch ? thinkingMatch[1].trim() : null;
        const finalAnswer = thinking ? finalAnswerWithThinking.replace(/<thinking>[\s\S]*?<\/thinking>\s*/i, '').trim() : finalAnswerWithThinking;

        return {
            finalAnswer,
            thinking,
            references: combinedReferences,
            sourcePipeline: pipeline,
        };
    } catch (error) {
        console.error(`[AgentService] Error executing tool '${toolCall.tool_name}':`, error);
        return { finalAnswer: `I tried to use a tool, but it failed. Error: ${error.message}.`, references: [], thinking: null, sourcePipeline: `agent-error-tool-failed` };
    }
}

module.exports = {
    processAgenticRequest,
};
```

`server/services/geminiService.js`

```javascript
// server/services/geminiService.js
const { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } = require('@google/generative-ai');

const FALLBACK_API_KEY = process.env.GEMINI_API_KEY;
const MODEL_NAME = "gemini-2.5-flash-lite-preview-06-17";

const DEFAULT_MAX_OUTPUT_TOKENS_CHAT = 940000;
const DEFAULT_MAX_OUTPUT_TOKENS_KG = 940000;

const baseSafetySettings = [
    { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH },
    { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH },
    { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH },
    { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH },
];

async function generateContentWithHistory(
    chatHistory,
    currentUserQuery,
    systemPromptText = null,
    options = {} // Now accepts { maxOutputTokens, apiKey }
) {
    const apiKeyToUse = options.apiKey || FALLBACK_API_KEY;

    if (!apiKeyToUse) {
        console.error("FATAL ERROR: Gemini API key is not available for this request. Ensure server's GEMINI_API_KEY is set or user provides one.");
        throw new Error("Gemini API key is missing. Please configure it.");
    }

    try {
        const genAI = new GoogleGenerativeAI(apiKeyToUse);

        if (typeof currentUserQuery !== 'string' || currentUserQuery.trim() === '') {
             throw new Error("currentUserQuery must be a non-empty string.");
        }

        const generationConfig = {
            temperature: 0.7,
            maxOutputTokens: options.maxOutputTokens || DEFAULT_MAX_OUTPUT_TOKENS_CHAT,
        };
        
        const model = genAI.getGenerativeModel({
            model: MODEL_NAME,
            systemInstruction: (systemPromptText && typeof systemPromptText === 'string' && systemPromptText.trim() !== '') ? 
                { parts: [{ text: systemPromptText.trim() }] } : undefined,
            safetySettings: baseSafetySettings,
        });

        const historyForStartChat = (chatHistory || [])
            .map(msg => ({
                 role: msg.role, 
                 parts: Array.isArray(msg.parts) ? msg.parts.map(part => ({ text: part.text || '' })) : [{text: msg.text || ''}] 
            }))
            .filter(msg => msg.role && msg.parts && msg.parts.length > 0 && typeof msg.parts[0].text === 'string');
        
        const chat = model.startChat({
            history: historyForStartChat,
            generationConfig: generationConfig,
        });

        console.log(`Sending message to Gemini. History sent: ${historyForStartChat.length}. System Prompt: ${!!systemPromptText}. Max Tokens: ${generationConfig.maxOutputTokens}`);
        // console.log(`Current User Query to sendMessage (first 100): "${currentUserQuery.substring(0,100)}..."`); // Can be very long

        // console.log("\n==================== START GEMINI FINAL INPUT ====================");
        // console.log("--- System Prompt Sent to Model ---");
        // console.log(systemPromptText || "N/A");
        // console.log("\n--- History Sent to Model ---");
        // console.log(JSON.stringify(historyForStartChat, null, 2));
        // console.log("\n--- Current User Query Sent to Model ---");
        // console.log(currentUserQuery);
        // console.log("==================== END GEMINI FINAL INPUT ====================\n");

        const result = await chat.sendMessage(currentUserQuery);
        const response = result.response;
        const candidate = response?.candidates?.[0];

        if (candidate && (candidate.finishReason === 'STOP' || candidate.finishReason === 'MAX_TOKENS')) {
            const responseText = candidate?.content?.parts?.[0]?.text || "";
            if (candidate.finishReason === 'MAX_TOKENS') {
                console.warn("Gemini response was truncated due to MAX_TOKENS limit.");
            }
            return responseText;
        } else {
             const finishReason = candidate?.finishReason || 'Unknown';
             const safetyRatings = candidate?.safetyRatings;
             console.warn("Gemini response was potentially blocked or had issues.", { finishReason, safetyRatings });
             let blockMessage = `AI response generation failed or was blocked.`;
             if (finishReason === 'SAFETY') {
                 blockMessage += ` Reason: SAFETY.`;
                 if (safetyRatings) {
                    const blockedCategories = safetyRatings.filter(r => r.blocked).map(r => r.category).join(', ');
                    if (blockedCategories) blockMessage += ` Blocked Categories: ${blockedCategories}.`;
                 }
             } else if (finishReason) {
                 blockMessage += ` Reason: ${finishReason}.`;
             }
             const error = new Error(blockMessage);
             error.status = 400;
             throw error;
        }
    } catch (error) {
        console.error("Gemini API Call Error:", error?.message || error);
        let clientMessage = "Failed to get response from AI service.";
        if (error.message?.includes("API key not valid")) {
            clientMessage = "Invalid API Key.";
        } else if (error.message?.includes("API key not found")) {
            clientMessage = "API Key not found";
        } else if (error.message?.includes("API_KEY_INVALID")) {
            clientMessage = "API Key not invalid. Please Provide the Valid one.";
        } else if (error.message?.includes("enabled this API recently")) {
            clientMessage = "Looks like new API key. Need some time to fully activate."
        } else if (error.message?.includes("billing account")) {
            clientMessage = "Billing account issue with the provided API Key.";
        } else if (error.message?.includes("blocked due to safety")) {
            clientMessage = "AI response blocked due to safety settings.";
        } else if (error.message?.includes("Invalid JSON payload")) {
            clientMessage = "Invalid request format sent to AI.";
        } else if (error.message?.includes("User location is not supported")) {
            clientMessage = "User location is not supported for this model.";
        } else if (error.message?.includes("model is overloaded")) {
            clientMessage = "The AI model is currently overloaded. Please try again in a moment.";
        } else if (error.status === 400) {
            clientMessage = `${error.message}`; 
        }
        const enhancedError = new Error(clientMessage);
        enhancedError.status = error.status || 500; 
        enhancedError.originalError = error; 
        throw enhancedError;
    }
};

module.exports = {
    generateContentWithHistory,
    DEFAULT_MAX_OUTPUT_TOKENS_KG 
};
```

`server/services/kgService.js`

```javascript
// server/services/kgService.js
const geminiService = require('./geminiService');
const ollamaService = require('./ollamaService');
const { v4: uuidv4 } = require('uuid');
const axios = require('axios');
const {
    KG_GENERATION_SYSTEM_PROMPT,
    KG_BATCH_USER_PROMPT_TEMPLATE
} = require('../config/promptTemplates');


function constructKgPromptForBatch(chunkTexts) {
    let formattedChunkTexts = "";
    chunkTexts.forEach((chunkText, index) => {
        formattedChunkTexts += `
--- START OF CHUNK ${index + 1} ---
${chunkText}
--- END OF CHUNK ${index + 1} ---
`;
    });
    return KG_BATCH_USER_PROMPT_TEMPLATE.replace('{BATCHED_CHUNK_TEXTS_HERE}', formattedChunkTexts);
}

async function _processBatchOfChunksForKg(batchOfChunkObjects, batchIndex, llmProvider, ollamaModel) {
    const logPrefix = `[KG Service Batch ${batchIndex}]`;

    const chunkTextsForPrompt = batchOfChunkObjects.map(chunk => chunk.text_content);

    if (chunkTextsForPrompt.length === 0) {
        console.log(`${logPrefix} No text content in this batch. Skipping.`);
        return [];
    }

    const userPromptForBatch = constructKgPromptForBatch(chunkTextsForPrompt);
    
    // For KG generation, the user prompt contains the data to be processed.
    // The system prompt contains the instructions on HOW to process it.
    const historyForLlm = [
        { role: 'user', parts: [{ text: "Please generate the knowledge graph fragments based on the provided text chunks and your system instructions." }] }
    ];

    try {
        console.log(`${logPrefix} Processing ${chunkTextsForPrompt.length} chunks for KG generation using ${llmProvider}.`);
        let responseText;

        if (llmProvider === 'ollama') {
            responseText = await ollamaService.generateContentWithHistory(
                historyForLlm,
                userPromptForBatch, // Pass the chunks as the "current query"
                KG_GENERATION_SYSTEM_PROMPT, // Pass the KG instructions as the system prompt
                { model: ollamaModel, maxOutputTokens: ollamaService.DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_KG }
            );
        } else { // Default to Gemini
            // --- THIS IS THE CORRECTED CALL ---
            responseText = await geminiService.generateContentWithHistory(
                historyForLlm,                      // Minimal history to kick off the chat
                userPromptForBatch,                 // The user prompt containing the document chunks to be analyzed
                KG_GENERATION_SYSTEM_PROMPT,        // The detailed instructions on how the LLM should behave
                { maxOutputTokens: geminiService.DEFAULT_MAX_OUTPUT_TOKENS_KG } // Pass maxOutputTokens correctly in the options object
            );
            // --- END CORRECTION ---
        }

        if (!responseText) {
            console.warn(`${logPrefix} Empty response from LLM for batch.`);
            return [];
        }

        let cleanedResponseText = responseText.trim();
        if (cleanedResponseText.startsWith("```json")) {
            cleanedResponseText = cleanedResponseText.substring(7);
            if (cleanedResponseText.endsWith("```")) {
                cleanedResponseText = cleanedResponseText.slice(0, -3);
            }
        } else if (cleanedResponseText.startsWith("```")) {
            cleanedResponseText = cleanedResponseText.substring(3);
            if (cleanedResponseText.endsWith("```")) {
                cleanedResponseText = cleanedResponseText.slice(0, -3);
            }
        }
        cleanedResponseText = cleanedResponseText.trim();
        
        const graphFragmentsArray = JSON.parse(cleanedResponseText);

        if (!Array.isArray(graphFragmentsArray)) {
            console.warn(`${logPrefix} LLM response was not a JSON array.`);
            return [];
        }

        if (graphFragmentsArray.length !== batchOfChunkObjects.length) {
            console.warn(`${logPrefix} Mismatch: Expected ${batchOfChunkObjects.length} KG fragments, but received ${graphFragmentsArray.length}.`);
        }
        
        const validFragments = graphFragmentsArray.filter(fragment =>
            fragment && typeof fragment === 'object' && Array.isArray(fragment.nodes) && Array.isArray(fragment.edges)
        );
        
        if (validFragments.length !== graphFragmentsArray.length) {
            console.warn(`${logPrefix} Some fragments from the LLM were malformed and discarded.`);
        }

        console.log(`${logPrefix} Successfully parsed ${validFragments.length} valid KG fragments.`);
        return validFragments;

    } catch (error) {
        console.error(`${logPrefix} Error processing batch:`, error.message);
        if (error.originalError) console.error(`${logPrefix} Original LLM error:`, error.originalError);
        return [];
    }
}


function _mergeGraphFragments(graphFragments) {
    console.log(`[KG Service] Merging ${graphFragments.length} graph fragments...`);
    const finalNodesMap = new Map();
    const finalEdgesSet = new Set();

    for (const fragment of graphFragments) {
        if (!fragment || !fragment.nodes || !fragment.edges) {
            console.warn("[KG Service Merge] Skipping invalid or null graph fragment.");
            continue;
        }
        
        for (const node of fragment.nodes) {
            if (!node || typeof node.id !== 'string' || !node.id.trim()) {
                console.warn("[KG Service Merge] Skipping invalid node (missing/empty ID):", node);
                continue;
            }
            const nodeId = node.id.trim();
            if (!finalNodesMap.has(nodeId)) {
                finalNodesMap.set(nodeId, { ...node, id: nodeId });
            } else {
                const existingNode = finalNodesMap.get(nodeId);
                if (node.description && typeof node.description === 'string' &&
                    (!existingNode.description || node.description.length > existingNode.description.length)) {
                    existingNode.description = node.description;
                }
                if (node.type && (!existingNode.type || existingNode.type === "generic" || existingNode.type.toLowerCase() === "unknown")) {
                    existingNode.type = node.type;
                }
                if (node.parent && !existingNode.parent) {
                    existingNode.parent = node.parent;
                }
            }
        }

        for (const edge of fragment.edges) {
            if (!edge || typeof edge.from !== 'string' || typeof edge.to !== 'string' || typeof edge.relationship !== 'string' ||
                !edge.from.trim() || !edge.to.trim() || !edge.relationship.trim()) {
                console.warn("[KG Service Merge] Skipping invalid edge (missing from/to/relationship or empty):", edge);
                continue;
            }
            const edgeKey = `${edge.from.trim()}|${edge.to.trim()}|${edge.relationship.trim().toUpperCase()}`;
            finalEdgesSet.add(edgeKey);
        }
    }

    const mergedNodes = Array.from(finalNodesMap.values());
    const mergedEdges = Array.from(finalEdgesSet).map(edgeKey => {
        const [from, to, relationship] = edgeKey.split('|');
        return { from, to, relationship };
    });

    console.log(`[KG Service Merge] Merged into ${mergedNodes.length} nodes and ${mergedEdges.length} edges.`);
    return { nodes: mergedNodes, edges: mergedEdges };
}

async function generateAndStoreKg(chunksForKg, userId, originalName, llmProvider, ollamaModel) {
    const logPrefix = `[KG Service Doc: ${originalName}, User: ${userId}]`;
    console.log(`${logPrefix} Starting KG generation with ${chunksForKg.length} initial chunks.`);

    if (!chunksForKg || chunksForKg.length === 0) {
        console.warn(`${logPrefix} No chunks provided for KG generation.`);
        return { success: true, message: "No chunks to process for KG.", finalKgNodesCount: 0, finalKgEdgesCount: 0 };
    }

    const allGraphFragments = [];
    const BATCH_SIZE = parseInt(process.env.KG_GENERATION_BATCH_SIZE) || 25;
    console.log(`${logPrefix} Using batch size: ${BATCH_SIZE}`);
    let batchIndex = 0;

    for (let i = 0; i < chunksForKg.length; i += BATCH_SIZE) {
        batchIndex++;
        const currentBatchOfChunks = chunksForKg.slice(i, i + BATCH_SIZE);
        
        const validChunksInBatch = currentBatchOfChunks.filter(chunk => chunk && chunk.text_content && chunk.text_content.trim() !== '');
        if (validChunksInBatch.length === 0) {
            console.log(`${logPrefix} Batch ${batchIndex} has no valid chunks with text. Skipping.`);
            continue;
        }
        
        console.log(`${logPrefix} Processing batch ${batchIndex} (chunks ${i} to ${Math.min(i + BATCH_SIZE - 1, chunksForKg.length - 1)}), ${validChunksInBatch.length} valid chunks.`);
        
        const fragmentsFromBatch = await _processBatchOfChunksForKg(validChunksInBatch, batchIndex, llmProvider, ollamaModel);
        if (fragmentsFromBatch && fragmentsFromBatch.length > 0) {
            allGraphFragments.push(...fragmentsFromBatch);
        } else {
            console.warn(`${logPrefix} Batch ${batchIndex} yielded no valid graph fragments.`);
        }
    }

    if (allGraphFragments.length === 0) {
        console.warn(`${logPrefix} No valid graph fragments were generated from any batch.`);
        return { success: true, message: "No KG data extracted from any document chunks.", finalKgNodesCount: 0, finalKgEdgesCount: 0 };
    }

    console.log(`${logPrefix} Generated a total of ${allGraphFragments.length} raw graph fragments. Merging...`);
    const finalKg = _mergeGraphFragments(allGraphFragments);
    
    if (!finalKg || finalKg.nodes.length === 0) {
        console.warn(`${logPrefix} Merged KG has no nodes. Nothing to store.`);
         return { success: true, message: "Merged KG was empty after processing all fragments.", finalKgNodesCount: 0, finalKgEdgesCount: 0 };
    }
    console.log(`${logPrefix} Merged KG successfully. Nodes: ${finalKg.nodes.length}, Edges: ${finalKg.edges.length}.`);

    const baseRagUrl = process.env.PYTHON_RAG_SERVICE_URL;
    if (!baseRagUrl) {
        return { success: false, message: "KG generated, but Python Service URL is not configured. KG not stored." };
    }
    const kgIngestionApiUrl = `${baseRagUrl.replace(/\/$/, '')}/kg`;

    console.log(`${logPrefix} Sending final merged KG to Ingestion API: ${kgIngestionApiUrl}`);
    try {
        const payload = {
            userId: userId,
            originalName: originalName,
            nodes: finalKg.nodes,
            edges: finalKg.edges
        };

        const serviceResponse = await axios.post(kgIngestionApiUrl, payload, {
            timeout: 300000
        });

        const responseData = serviceResponse.data;
        const API_SUCCESS_STATUS_VALUE = "completed";

        if (serviceResponse.status >= 200 && serviceResponse.status < 300 && responseData && responseData.status === API_SUCCESS_STATUS_VALUE) {
            const successMessage = `KG for '${originalName}' successfully processed by Ingestion API.`;
            console.log(`${logPrefix} ${successMessage}`);
            return {
                success: true, message: successMessage,
                finalKgNodesCount: finalKg.nodes.length, finalKgEdgesCount: finalKg.edges.length
            };
        } else {
            const failureMessage = `KG Ingestion API for '${originalName}' indicated failure. API Msg: ${responseData?.message || responseData?.error || 'No specific error from API.'}`;
            console.warn(`${logPrefix} ${failureMessage}`);
            return {
                success: false, message: failureMessage,
                finalKgNodesCount: finalKg.nodes.length, finalKgEdgesCount: finalKg.edges.length
            };
        }
    } catch (error) {
        const errorMsg = error.response?.data?.message || error.response?.data?.error || error.message || "Unknown error calling KG Ingestion API";
        console.error(`${logPrefix} Error calling KG Ingestion API:`, errorMsg);
        return {
            success: false, message: `KG generated, but error calling KG Ingestion API: ${errorMsg}`,
            finalKgNodesCount: finalKg.nodes.length, finalKgEdgesCount: finalKg.edges.length
        };
    }
}

module.exports = { generateAndStoreKg };
```

`server/services/ollamaService.js`

```javascript
//ollama service

// server/services/ollamaService.js
const axios = require('axios');

const SERVER_DEFAULT_OLLAMA_URL = process.env.OLLAMA_API_BASE_URL || 'https://angels-himself-fixtures-unknown.trycloudflare.com';
const DEFAULT_OLLAMA_MODEL = process.env.OLLAMA_DEFAULT_MODEL || 'qwen2.5:14b-instruct';

const DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_CHAT = 29000;
const DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_KG = 29000;

// This function formats history for the /api/chat endpoint
function formatHistoryForOllamaChat(chatHistory) {
    return chatHistory.map(msg => ({
        role: msg.role === 'model' ? 'assistant' : 'user',
        content: msg.parts?.[0]?.text || ''
    }));
}

async function generateContentWithHistory(
    chatHistory,
    currentUserQuery,
    systemPromptText = null,
    options = {}
) {
    const baseUrlToUse = options.ollamaUrl || SERVER_DEFAULT_OLLAMA_URL;
    const modelToUse = options.model || DEFAULT_OLLAMA_MODEL;
    const effectiveMaxOutputTokens = options.maxOutputTokens || DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_CHAT;
    
    const headers = { 'Content-Type': 'application/json' };
    if (options.apiKey) {
        headers['Authorization'] = `Bearer ${options.apiKey}`;
    }

    // --- THIS IS THE FIX ---
    // Decide which endpoint to use based on whether there's a real history.
    // Our Router call sends an empty history, so it will use /api/generate.
    // Real chat calls will have history and use /api/chat.
    let endpoint;
    let requestPayload;

    if (!chatHistory || chatHistory.length === 0) {
        // Use /api/generate for one-shot requests like the Router agent
        endpoint = `${baseUrlToUse}/api/generate`;
        console.log(`Ollama Service: Using /api/generate endpoint for one-shot request.`);
        requestPayload = {
            model: modelToUse,
            prompt: currentUserQuery, // The user query is the full prompt
            system: systemPromptText || "You are a helpful AI assistant.",
            stream: false,
            options: {
                temperature: options.temperature || 0.7,
                num_predict: effectiveMaxOutputTokens,
            }
        };
    } else {
        // Use /api/chat for actual conversations with history
        endpoint = `${baseUrlToUse}/api/chat`;
        console.log(`Ollama Service: Using /api/chat endpoint for conversation with history.`);
        const messages = formatHistoryForOllamaChat(chatHistory);
        messages.push({ role: 'user', content: currentUserQuery }); // Add the current query
        
        requestPayload = {
            model: modelToUse,
            messages: messages,
            stream: false,
            options: {
                temperature: options.temperature || 0.7,
                // num_predict is often not needed for /chat, but can be included
            }
        };
        // For /chat, the system prompt is part of the messages array if needed
        if (systemPromptText) {
             messages.unshift({ role: 'system', content: systemPromptText });
        }
    }
    // --- END OF FIX ---

    console.log(`Ollama Service: Sending request to ${endpoint} for model ${modelToUse}.`);

    console.log("\n==================== START OLLAMA FINAL INPUT ====================");
    console.log(`--- Endpoint: ${endpoint} ---`);
    console.log("--- Request Payload Sent to Model ---");
    console.log(JSON.stringify(requestPayload, null, 2));
    console.log("==================== END OLLAMA FINAL INPUT ====================\n");

    
    try {
        const response = await axios.post(endpoint, requestPayload, { 
            headers,
            timeout: 120000 
        });

        // Handle different response structures from /generate and /chat
        let responseText = '';
        if (response.data && response.data.response) { // from /api/generate
            responseText = response.data.response;
        } else if (response.data && response.data.message && response.data.message.content) { // from /api/chat
            responseText = response.data.message.content;
        } else {
            throw new Error("Ollama service returned an invalid or unrecognized response structure.");
        }

        return responseText.trim();
        
    } catch (error) {
        console.error("Ollama API Call Error:", error.message);
        const clientMessage = error.response?.data?.error || "Failed to get response from Ollama service.";
        const enhancedError = new Error(clientMessage);
        enhancedError.status = error.response?.status || 503;
        throw enhancedError;
    }
}

module.exports = {
    generateContentWithHistory,
    DEFAULT_OLLAMA_MODEL,
    DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_CHAT,
    DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_KG,
};
```

`server/services/summarizationService.js`

```javascript
// server/services/summarizationService.js
const geminiService = require('./geminiService');
const ollamaService = require('./ollamaService');

// This prompt is key. It instructs the LLM on how to create a good, cumulative summary.
const SUMMARIZATION_SYSTEM_PROMPT = `You are an expert conversation summarizer. Your task is to create a concise, yet comprehensive summary of the provided chat history between a User and an AI Assistant.

If an "Existing Summary" is provided, you MUST integrate the "New Messages" into it to create a single, updated, and coherent summary. Do not just append the new information; seamlessly weave it into the existing narrative.

The final summary MUST be in the third person.
Focus on capturing:
- The user's primary goals or questions.
- Key facts, concepts, or entities discussed.
- Important conclusions or resolutions reached.
- Any unresolved questions or next steps mentioned by the user.

Do NOT include conversational filler (e.g., "The user said hello"). The output should be a dense, information-rich paragraph.

Example of a good updated summary:
"Previously, the user, a PhD student, asked about 'Separation of Concerns'. In the latest exchange, they pivoted to inquiring about the specifics of Ohm's Law, and the AI provided the formula V=IR based on a document the user supplied. The user's current goal appears to be understanding foundational engineering concepts, moving from software to electrical principles."
`;

/**
 * Creates or updates a conversation summary.
 * @param {Array<Object>} messagesToSummarize - The array of new message objects to add to the summary.
 * @param {string} existingSummary - The existing summary from the database.
 * @param {string} llmProvider - The LLM provider to use ('gemini' or 'ollama').
 * @param {string} ollamaModel - The specific Ollama model if the provider is 'ollama'.
 * @returns {Promise<string>} The generated summary text.
 */
async function createOrUpdateSummary(messagesToSummarize, existingSummary, llmProvider, ollamaModel, userApiKey, userOllamaUrl) {
    if (!messagesToSummarize || messagesToSummarize.length === 0) {
        return existingSummary || "";
    }

    const newMessagesText = messagesToSummarize.map(msg => {
        const role = msg.role === 'model' ? 'Assistant' : 'User';
        const text = msg.parts?.[0]?.text || '';
        return `${role}: ${text}`;
    }).join('\n\n');

    let userPrompt = "";
    if (existingSummary && existingSummary.trim() !== "") {
        userPrompt = `Existing Summary:\n"""\n${existingSummary}\n"""\n\nNew Messages to integrate:\n"""\n${newMessagesText}\n"""\n\nPlease provide the new, updated summary.`;
    } else {
        userPrompt = `New Messages to summarize:\n"""\n${newMessagesText}\n"""\n\nPlease provide the summary.`;
    }

    const historyForLlm = [{ role: 'user', parts: [{ text: userPrompt }] }];

    console.log(`[SummarizationService] Requesting summary using ${llmProvider}.`);

    try {
        let summary;
        const llmOptions = { 
            apiKey: userApiKey,
            ollamaUrl: userOllamaUrl
        };
        if (llmProvider === 'ollama') {
            summary = await ollamaService.generateContentWithHistory(
                historyForLlm, SUMMARIZATION_SYSTEM_PROMPT, null, { ...llmOptions, model: ollamaModel }
            );
        } else {
            summary = await geminiService.generateContentWithHistory(
                historyForLlm, SUMMARIZATION_SYSTEM_PROMPT, null, llmOptions
            );
        }
        console.log(`[SummarizationService] Summary generated successfully.`);
        return summary.trim();
    } catch (error) {
        console.error(`[SummarizationService] Error generating summary: ${error.message}`);
        return existingSummary || "";
    }
}


module.exports = { createOrUpdateSummary };
```

`server/services/toolExecutionService.js`

```javascript
// server/services/toolExecutionService.js
const axios = require('axios');

const PYTHON_SERVICE_URL = process.env.PYTHON_RAG_SERVICE_URL;

async function queryPythonRagService(query, documentContextName, clientFilter = null, k = 5) {
    if (!PYTHON_SERVICE_URL) {
        throw new Error("RAG service is not configured on the server.");
    }
    const searchUrl = `${PYTHON_SERVICE_URL}/query`;
    
    const payload = {
        query: query,
        k: k,
        user_id: "agent_user", // The user is validated in Node.js; agent uses a generic ID for Python
        documentContextName: documentContextName || null
    };
    
    if (clientFilter) {
        payload.filter = clientFilter;
    }

    try {
        const response = await axios.post(searchUrl, payload, { timeout: 30000 });
        
        // --- THIS IS THE NEW LOGIC ---
        const relevantDocs = response.data?.retrieved_documents_list || [];
        
        const references = relevantDocs.map((doc, index) => ({
            number: index + 1,
            source: doc.metadata?.file_name || doc.metadata?.original_name || 'Unknown Document',
            content_preview: (doc.page_content || "").substring(0, 150) + "...",
        }));
        
        const toolOutput = relevantDocs.length > 0
            ? response.data.formatted_context_snippet
            : "No relevant context was found in the specified documents for this query.";
        
        // Return the consistent object format
        return { references, toolOutput };
        // --- END OF NEW LOGIC ---

    } catch (error) {
        const errorMsg = error.response?.data?.error || `Python Service Error: ${error.message}`;
        console.error(`[toolExecutionService] Error calling RAG service:`, errorMsg);
        throw new Error(errorMsg);
    }
}

async function queryKgService(query, documentName, userId) {
    if (!PYTHON_SERVICE_URL) {
        throw new Error("Knowledge Graph service is not configured on the server.");
    }
    // Assuming the Python endpoint for KG search is /query_kg
    const kgUrl = `${PYTHON_SERVICE_URL}/query_kg`; 
    try {
        const response = await axios.post(kgUrl, {
            query: query,
            document_name: documentName,
            user_id: userId,
        }, { timeout: 20000 });

        return {
            references: [], // KG search doesn't produce citable references in the same way
            toolOutput: response.data?.facts || "No specific facts were found in the knowledge graph for this query."
        };
    } catch (error) {
        const errorMsg = error.response?.data?.error || `KG Service Error: ${error.message}`;
        console.error(`[toolExecutionService] Error calling KG service:`, errorMsg);
        // Return a user-friendly message within the tool's output
        return {
            references: [],
            toolOutput: `Could not retrieve facts from knowledge graph: ${errorMsg}`
        };
    }
}

module.exports = {
    queryPythonRagService,
    queryKgService
};
```

`server/services/toolRegistry.js`

```javascript
// server/services/toolRegistry.js
const { performWebSearch } = require('./webSearchService.js');
const { queryPythonRagService, queryKgService } = require('./toolExecutionService.js');
const axios = require('axios');

async function queryAcademicService(query) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
    if (!pythonServiceUrl) {
        throw new Error("Academic search service is not configured on the server.");
    }
    const searchUrl = `${pythonServiceUrl}/academic_search`;
    
    try {
        const response = await axios.post(searchUrl, { query }, { timeout: 45000 });
        const papers = response.data?.results || [];
        
        const toolOutput = papers.length > 0
            ? "Found the following relevant academic papers:\n\n" + papers.map((p, index) => 
                `[${index + 1}] **${p.title || 'Untitled Paper'}**\n` +
                `   - Source: ${p.source || 'Unknown'}\n` +
                `   - URL: ${p.url || '#'}\n` +
                `   - Summary: ${p.summary ? p.summary.substring(0, 300) + '...' : 'No summary.'}`
              ).join('\n\n')
            : "No relevant academic papers were found for this query.";
            
        const references = papers.map((p, index) => ({
            number: index + 1,
            source: `${p.title || 'Untitled Paper'} (${p.source || 'N/A'})`,
            url: p.url || '#',
        }));

        return { references, toolOutput };

    } catch (error) {
        const errorMsg = error.response?.data?.error || `Academic Service Error: ${error.message}`;
        throw new Error(errorMsg);
    }
}

const availableTools = {
  web_search: {
    description: "Searches the internet for real-time, up-to-date information on current events, public figures, or general knowledge.",
    execute: async (params) => {
        const { toolOutput, references } = await performWebSearch(params.query);
        return { references, toolOutput: toolOutput || "No results found from web search." };
    },
    requiredParams: ['query'],
  },
  rag_search: {
    description: "Searches the content of a specific, user-provided document to answer questions based on its text.",
    execute: async (params, context) => {
        return await queryPythonRagService(params.query, context.documentContextName, context.filter);
    },
    requiredParams: ['query'],
  },
  kg_search: {
    description: "Finds structured facts and relationships within a document's pre-built knowledge graph. Use this to complement RAG search.",
     execute: async (params, context) => {
        const facts = await queryKgService(params.query, context.documentContextName, context.userId);
        return { references: [], toolOutput: facts };
    },
    requiredParams: ['query'],
  },
  academic_search: {
    description: "Finds academic papers, research articles, and scholarly publications from scientific databases.",
    execute: async (params) => {
        return await queryAcademicService(params.query);
    },
    requiredParams: ['query'],
  }
};

module.exports = { availableTools };
```

`server/services/totOrchestrator.js`

```javascript
// server/services/totOrchestrator.js

const { processAgenticRequest } = require('./agentService');
const geminiService = require('./geminiService');
const ollamaService = require('./ollamaService');
const { PLANNER_PROMPT_TEMPLATE, EVALUATOR_PROMPT_TEMPLATE } = require('../config/promptTemplates');


async function isQueryComplex(query) {
    const isComplex = (query.match(/\?/g) || []).length > 1 || query.split(' ').length > 20;
    console.log(`[ToT] Step 1: Complexity Gate. Query: "${query.substring(0, 30)}...". Decision: ${isComplex ? 'COMPLEX' : 'SIMPLE'}`);
    return isComplex;
}

async function generatePlans(query, requestContext) {
    console.log('[ToT] Step 2: Planner. Generating plans via LLM...');
    const { llmProvider, ...llmOptions } = requestContext;
    const llmService = llmProvider === 'ollama' ? ollamaService : geminiService;

    const plannerPrompt = PLANNER_PROMPT_TEMPLATE.replace("{userQuery}", query);

    try {
        const responseText = await llmService.generateContentWithHistory(
            [],
            plannerPrompt,
            "You are a planning agent.",
            llmOptions
        );
        const jsonMatch = responseText.match(/```(json)?\s*([\s\S]+?)\s*```/);
        const jsonString = jsonMatch ? jsonMatch[2] : responseText;
        const parsedResponse = JSON.parse(jsonString);

        if (parsedResponse.plans && Array.isArray(parsedResponse.plans) && parsedResponse.plans.length > 0) {
            console.log(`[ToT] Planner: Successfully generated ${parsedResponse.plans.length} plans.`);
            return parsedResponse.plans;
        }
    } catch (error) {
        console.error(`[ToT] Planner: LLM call failed or returned invalid JSON. Error: ${error.message}. Falling back to default plan.`);
    }

    return [{
        name: "Default Direct Search Plan",
        steps: [`Directly address the user's query: "${query}"`]
    }];
}

async function evaluatePlans(plans, query, requestContext) {
    console.log('[ToT] Step 3: Evaluator. Evaluating plans via LLM...');
    if (!plans || plans.length === 0) {
        throw new Error("No plans provided to evaluate.");
    }
    if (plans.length === 1) {
        console.log('[ToT] Evaluator: Only one plan available. Selecting it by default.');
        return plans[0];
    }

    const { llmProvider, ...llmOptions } = requestContext;
    const llmService = llmProvider === 'ollama' ? ollamaService : geminiService;
    const plansJsonString = JSON.stringify(plans, null, 2);

    const evaluatorPrompt = EVALUATOR_PROMPT_TEMPLATE
        .replace("{userQuery}", query)
        .replace("{plansJsonString}", plansJsonString);

    try {
        const responseText = await llmService.generateContentWithHistory(
            [],
            evaluatorPrompt,
            "You are an evaluating agent.",
            llmOptions
        );
        const jsonMatch = responseText.match(/```(json)?\s*([\s\S]+?)\s*```/);
        const jsonString = jsonMatch ? jsonMatch[2] : responseText;
        const parsedResponse = JSON.parse(jsonString);

        if (parsedResponse.best_plan_name) {
            const winningPlan = plans.find(p => p.name === parsedResponse.best_plan_name);
            if (winningPlan) {
                console.log(`[ToT] Evaluator: LLM selected winning plan: "${winningPlan.name}"`);
                return winningPlan;
            }
        }
    } catch (error) {
        console.error(`[ToT] Evaluator: LLM call failed or returned invalid JSON. Error: ${error.message}. Falling back to first plan.`);
    }
    
    console.log(`[ToT] Evaluator: Fallback selected. Winning plan: "${plans[0].name}"`);
    return plans[0];
}

async function executePlan(winningPlan, originalQuery, requestContext, streamCallback) {
    console.log('[ToT] Step 4: Executor. Starting execution of plan...');
    let collectedContexts = [];
    let collectedReferences = [];

    for (let i = 0; i < winningPlan.steps.length; i++) {
        const stepDescription = winningPlan.steps[i];
        const thought = `Executing Step ${i + 1}/${winningPlan.steps.length}: ${stepDescription}`;
        streamCallback({ type: 'thought', content: thought });
        console.log(`[ToT] Executor: ${thought}`);
        
        const agentResponse = await processAgenticRequest(
            originalQuery,
            [],
            `Fulfill this sub-task: "${stepDescription}"`,
            requestContext
        );

        collectedContexts.push(`--- Context from Step ${i + 1} (${agentResponse.sourcePipeline}) ---\n${agentResponse.finalAnswer}`);
        
        if (agentResponse.references && agentResponse.references.length > 0) {
            collectedReferences.push(...agentResponse.references);
        }
    }

    console.log(`[ToT] Step 4: Executor. All steps executed. Collected ${collectedReferences.length} references.`);
    return {
        finalContext: collectedContexts.join('\n\n'),
        allReferences: collectedReferences
    };
}

async function synthesizeFinalAnswer(originalQuery, finalContext, chatHistory, requestContext) {
    console.log('[ToT] Step 5: Synthesizer. Creating final response...');
    const { llmProvider, ...llmOptions } = requestContext;
    const llmService = llmProvider === 'ollama' ? ollamaService : geminiService;

    const synthesizerPrompt = `You are an expert AI Tutor. A multi-step reasoning process has been completed to gather comprehensive information. Your task is to synthesize all the provided context into a single, cohesive, and well-structured final answer for the user's original query.\n\n--- COLLECTED CONTEXT ---\n${finalContext}\n\n--- ORIGINAL USER QUERY ---\n${originalQuery}`;

    const finalAnswer = await llmService.generateContentWithHistory(
        chatHistory,
        synthesizerPrompt,
        requestContext.systemPrompt,
        llmOptions
    );
    return finalAnswer;
}

async function processQueryWithToT_Streaming(query, chatHistory, requestContext, streamCallback) {
    const allThoughts = [];
    const streamAndStoreThought = (content) => {
        streamCallback({ type: 'thought', content });
        allThoughts.push(content);
    };

    const isComplex = await isQueryComplex(query);

    if (!isComplex) {
        streamAndStoreThought("Query is straightforward. Generating a direct response.");
        const directResponse = await processAgenticRequest(query, chatHistory, requestContext.systemPrompt, requestContext);
        streamCallback({ type: 'final_answer', content: directResponse.finalAnswer });
        return { finalAnswer: directResponse.finalAnswer, thoughts: allThoughts, references: directResponse.references, sourcePipeline: directResponse.sourcePipeline };
    }

    streamAndStoreThought("Complex query detected. Initiating multi-step reasoning process...");
    
    const plans = await generatePlans(query, requestContext);
    streamAndStoreThought(`Generated ${plans.length} potential plans. Evaluating the best approach...`);
    
    const winningPlan = await evaluatePlans(plans, query, requestContext);
    streamAndStoreThought(`Best plan selected: "${winningPlan.name}". Beginning execution...`);

    const { finalContext, allReferences } = await executePlan(winningPlan, query, requestContext, streamCallback);
    streamAndStoreThought("All information gathered. Synthesizing final answer...");

    const finalAnswer = await synthesizeFinalAnswer(query, finalContext, chatHistory, requestContext);
    streamCallback({ type: 'final_answer', content: finalAnswer });
    
    console.log('--- ToT Streaming Orchestration Finished ---');
    return {
        finalAnswer,
        thoughts: allThoughts,
        references: allReferences,
        sourcePipeline: `tot-${requestContext.llmProvider}`
    };
}

module.exports = {
    processQueryWithToT_Streaming
};
```

`server/services/webSearchService.js`

```javascript
// server/services/webSearchService.js
const axios = require('axios');

async function performWebSearch(query) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;

    if (!pythonServiceUrl) {
        console.warn("[WebSearch Service] PYTHON_RAG_SERVICE_URL is not set. Web search is disabled.");
        // Throw an error so the agent knows the tool is unavailable
        throw new Error("Web search tool is not configured on the server.");
    }

    const searchUrl = `${pythonServiceUrl}/web_search`;

    try {
        console.log(`[WebSearch Service] Calling Python endpoint for search: ${searchUrl}`);
        const response = await axios.post(searchUrl, { query: query }, { timeout: 15000 });

        if (response.data && Array.isArray(response.data) && response.data.length > 0) {
            const topResults = response.data;
            
            const formattedResults = topResults.map((result, index) => {
                const title = result.title || 'No Title';
                const url = result.url || '#';
                const content = result.content ? result.content.replace(/[\n\r]+/g, ' ').trim() : 'No content preview.';
                return `[${index + 1}] Title: ${title}\nSource: ${url}\nContent: ${content}`;
            }).join('\n\n');

            return `[WEB SEARCH RESULTS]\n${formattedResults}`;
        } else {
            console.log(`[WebSearch Service] Python service returned no results for query: "${query}"`);
            return "Web search did not return any results for this query.";
        }
    } catch (error) {
        let errorMessage = `Error calling Python service for query "${query}": `;
        if (error.response) {
            errorMessage += `Status ${error.response.status} - ${JSON.stringify(error.response.data)}`;
        } else if (error.request) {
            errorMessage += `No response received from Python service at ${searchUrl}.`;
        } else {
            errorMessage += error.message;
        }
        console.error(errorMessage);
        // --- FIX: Throw the error to be caught by the agent service ---
        throw new Error(error.message);
    }
}

module.exports = { performWebSearch };
```

`server/utils/assetCleanup.js`

```javascript
const fs = require('fs').promises; // Use fs.promises for async operations
const path = require('path');

// Define constants relative to this file's location (server/utils)
const ASSETS_DIR = path.join(__dirname, '..', 'assets'); // Go up one level to server/assets
const BACKUP_DIR = path.join(__dirname, '..', 'backup_assets'); // Go up one level to server/backup_assets
const FOLDER_TYPES = ['docs', 'images', 'code', 'others']; // Folders within each user's asset dir

/**
 * Moves existing user asset folders (docs, images, code, others) to a timestamped
 * backup location and recreates empty asset folders for each user on server startup.
 */
async function performAssetCleanup() {
    console.log("\n--- Starting Asset Cleanup ---");
    try {
        // Ensure backup base directory exists
        await fs.mkdir(BACKUP_DIR, { recursive: true });

        // List potential user directories in assets
        let userDirs = [];
        try {
            userDirs = await fs.readdir(ASSETS_DIR);
        } catch (err) {
            if (err.code === 'ENOENT') {
                console.log("Assets directory doesn't exist yet, creating it and skipping cleanup.");
                await fs.mkdir(ASSETS_DIR, { recursive: true }); // Ensure assets dir exists
                console.log("--- Finished Asset Cleanup (No existing assets found) ---");
                return; // Nothing to clean up
            }
            throw err; // Re-throw other errors accessing assets dir
        }

        if (userDirs.length === 0) {
             console.log("Assets directory is empty. Skipping backup/move operations.");
             console.log("--- Finished Asset Cleanup (No user assets found) ---");
             return;
        }

        const timestamp = new Date().toISOString().replace(/[:.]/g, '-'); // Create a safe timestamp string

        for (const userName of userDirs) {
            const userAssetPath = path.join(ASSETS_DIR, userName);
            const userBackupPathBase = path.join(BACKUP_DIR, userName);
            const userTimestampBackupPath = path.join(userBackupPathBase, `backup_${timestamp}`);

            try {
                // Check if the item in assets is actually a directory
                const stats = await fs.stat(userAssetPath);
                if (!stats.isDirectory()) {
                    console.log(`  Skipping non-directory item in assets: ${userName}`);
                    continue;
                }

                console.log(`  Processing assets for user: [${userName}]`);
                let backupDirCreated = false; // Track if backup dir was created for this user/run
                let movedSomething = false; // Track if anything was actually moved

                // Process each defined folder type (docs, images, etc.)
                for (const type of FOLDER_TYPES) {
                    const sourceTypePath = path.join(userAssetPath, type);
                    try {
                        // Check if the source type directory exists before trying to move
                        await fs.access(sourceTypePath);

                        // If source exists, ensure the timestamped backup directory is ready
                        if (!backupDirCreated) {
                            await fs.mkdir(userTimestampBackupPath, { recursive: true });
                            backupDirCreated = true;
                            // console.log(`    Created backup directory: ${userTimestampBackupPath}`);
                        }

                        // Define the destination path in the backup folder
                        const backupTypePath = path.join(userTimestampBackupPath, type);
                        // console.log(`    Moving ${sourceTypePath} to ${backupTypePath}`);
                        // Move the existing type folder to the backup location
                        await fs.rename(sourceTypePath, backupTypePath);
                        movedSomething = true;

                    } catch (accessErr) {
                        // Ignore error if the source directory doesn't exist (ENOENT)
                        if (accessErr.code !== 'ENOENT') {
                            console.error(`    Error accessing source folder ${sourceTypePath}:`, accessErr.message);
                        }
                        // If ENOENT, the folder doesn't exist, nothing to move.
                    }

                    // Always ensure the empty type directory exists in the main assets folder
                    try {
                        // console.log(`    Ensuring empty directory: ${sourceTypePath}`);
                        await fs.mkdir(sourceTypePath, { recursive: true });
                    } catch (mkdirErr) {
                         console.error(`    Failed to recreate directory ${sourceTypePath}:`, mkdirErr.message);
                    }
                } // End loop through FOLDER_TYPES

                 if (movedSomething) {
                     console.log(`  Finished backup for user [${userName}] to backup_${timestamp}`);
                 } else {
                     console.log(`  No existing asset types found to backup for user [${userName}]`);
                 }


            } catch (userDirStatErr) {
                 // Error checking if the item in assets is a directory
                 console.error(`Error processing potential user asset directory ${userAssetPath}:`, userDirStatErr.message);
            }
        } // End loop through userDirs

        console.log("--- Finished Asset Cleanup ---");

    } catch (error) {
        // Catch errors related to backup dir creation or reading the main assets dir
        console.error("!!! Critical Error during Asset Cleanup process:", error);
    }
}

// Export the function to be used elsewhere
module.exports = { performAssetCleanup };

```

`server/utils/crypto.js`

```javascript
// server/utils/crypto.js
const crypto = require('crypto');

const ALGORITHM = 'aes-256-cbc';
const ENCRYPTION_KEY_BUFFER = Buffer.from(process.env.ENCRYPTION_SECRET, 'hex');
const IV_LENGTH = 16;

function encrypt(text) {
  if (!text) return null;
  if (!process.env.ENCRYPTION_SECRET || ENCRYPTION_KEY_BUFFER.length !== 32) {
    console.error("FATAL: ENCRYPTION_SECRET is not set correctly (must be 64 hex chars / 32 bytes). Cannot encrypt.");
    throw new Error("Encryption service is not properly configured.");
  }
  const iv = crypto.randomBytes(IV_LENGTH);
  const cipher = crypto.createCipheriv(ALGORITHM, ENCRYPTION_KEY_BUFFER, iv);
  let encrypted = cipher.update(text, 'utf8', 'hex');
  encrypted += cipher.final('hex');
  return iv.toString('hex') + ':' + encrypted;
}

function decrypt(text) {
  if (!text) return null;
  if (!process.env.ENCRYPTION_SECRET || ENCRYPTION_KEY_BUFFER.length !== 32) {
    console.error("FATAL: ENCRYPTION_SECRET is not set correctly (must be 64 hex chars / 32 bytes). Cannot decrypt.");
    throw new Error("Decryption service is not properly configured.");
  }
  try {
    const textParts = text.split(':');
    if (textParts.length !== 2) {
        console.error("Decryption failed: Invalid encrypted text format.");
        return null;
    }
    const iv = Buffer.from(textParts.shift(), 'hex');
    const encryptedText = Buffer.from(textParts.join(':'), 'hex');
    const decipher = crypto.createDecipheriv(ALGORITHM, ENCRYPTION_KEY_BUFFER, iv);
    let decrypted = decipher.update(encryptedText, 'hex', 'utf8');
    decrypted += decipher.final('utf8');
    
    // THE CONSOLE.LOG HAS BEEN REMOVED FOR SECURITY
    
    return decrypted.toString();
  } catch (error) {
    console.error("Decryption failed for text:", text, "Error:", error.message);
    return null; 
  }
}

module.exports = { encrypt, decrypt };
```

`server/utils/networkUtils.js`

```javascript
const os = require('os');

function getLocalIPs() {
    const interfaces = os.networkInterfaces();
    const ips = new Set(['localhost']); // Include localhost

    for (const iface of Object.values(interfaces)) {
        for (const addr of iface) {
            // Include IPv4 non-internal addresses
            if (addr.family === 'IPv4' && !addr.internal) {
                ips.add(addr.address);
            }
        }
    }
    return Array.from(ips);
}

function getPreferredLocalIP() {
    const ips = getLocalIPs();
    // Prioritize non-localhost, non-link-local (169.254) IPs
    // Often 192.168.* or 10.* or 172.16-31.* are common private ranges
    return ips.find(ip => !ip.startsWith('169.254.') && ip !== 'localhost' && (ip.startsWith('192.168.') || ip.startsWith('10.') || ip.match(/^172\.(1[6-9]|2[0-9]|3[0-1])\./))) ||
           ips.find(ip => !ip.startsWith('169.254.') && ip !== 'localhost') || // Any other non-link-local
           'localhost'; // Fallback
}

module.exports = { getLocalIPs, getPreferredLocalIP };

```

`server/workers/adminAnalysisWorker.js`

```javascript
// server/workers/adminAnalysisWorker.js
const { workerData, parentPort } = require('worker_threads');
const mongoose = require('mongoose');
const path = require('path');

const AdminDocument = require('../models/AdminDocument');
const connectDB = require('../config/db');
const geminiService = require('../services/geminiService');
const { ANALYSIS_PROMPTS } = require('../config/promptTemplates');

// Load .env variables from the server directory for the worker
require('dotenv').config({ path: path.resolve(__dirname, '..', '.env') });


async function performAdminDocAnalysis(adminDocumentId, originalName, textForAnalysis) {
    const logPrefix = `[AdminAnalysisWorker ${process.pid}, Doc: ${originalName}]`;
    console.log(`${logPrefix} Starting analysis. Text length: ${textForAnalysis ? textForAnalysis.length : 0}`);

    const analysisResults = { faq: "", topics: "", mindmap: "" };
    let allIndividualAnalysesSuccessful = true;

    // --- THIS IS THE FIX ---
    // The worker is a system process, so it must use the server's global API key.
    const serverApiKey = process.env.GEMINI_API_KEY;
    if (!serverApiKey) {
        console.error(`${logPrefix} FATAL: Server's GEMINI_API_KEY is not defined in the worker's environment.`);
        // Return a clear error message for all fields
        const errorMessage = "Error generating analysis: Server API key is not configured.";
        return { 
            success: false, 
            results: { faq: errorMessage, topics: errorMessage, mindmap: errorMessage }
        };
    }
    // --- END OF FIX ---

    async function generateSingleAnalysis(type, promptContentForLLM) {
        try {
            console.log(`${logPrefix} Generating ${type}...`);
            const historyForGemini = [{ role: 'user', parts: [{ text: "Perform the requested analysis based on the system instruction and provided document text." }] }];
            
            const generatedText = await geminiService.generateContentWithHistory(
                historyForGemini,
                promptContentForLLM,
                null, // No system prompt needed, it's in the user prompt template
                { apiKey: serverApiKey } // Explicitly pass the server's API key
            );

            if (!generatedText || typeof generatedText !== 'string' || generatedText.trim() === "") {
                console.warn(`${logPrefix} Gemini returned empty content for ${type}.`);
                return { success: false, content: `Notice: No content generated by the AI for ${type}.` };
            }
            console.log(`${logPrefix} ${type} generation successful.`);
            return { success: true, content: generatedText.trim() };
        } catch (error) {
            console.error(`${logPrefix} Error during ${type} generation: ${error.message}`);
            allIndividualAnalysesSuccessful = false;
            return { success: false, content: `Error generating ${type}: ${error.message.split('\n')[0].substring(0, 250)}` };
        }
    }

    if (!textForAnalysis || textForAnalysis.trim() === "") {
        console.warn(`${logPrefix} No text provided for analysis. Skipping generation.`);
        analysisResults.faq = "Skipped: No text content provided.";
        analysisResults.topics = "Skipped: No text content provided.";
        analysisResults.mindmap = "Skipped: No text content provided.";
    } else {
        const analysisPromises = [
            generateSingleAnalysis('FAQ', ANALYSIS_PROMPTS.faq.getPrompt(textForAnalysis)),
            generateSingleAnalysis('Topics', ANALYSIS_PROMPTS.topics.getPrompt(textForAnalysis)),
            generateSingleAnalysis('Mindmap', ANALYSIS_PROMPTS.mindmap.getPrompt(textForAnalysis))
        ];

        const [faqOutcome, topicsOutcome, mindmapOutcome] = await Promise.allSettled(analysisPromises);

        if (faqOutcome.status === 'fulfilled') {
            analysisResults.faq = faqOutcome.value.content;
            if (!faqOutcome.value.success) allIndividualAnalysesSuccessful = false;
        } else {
            analysisResults.faq = `Error generating FAQ: ${faqOutcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
            allIndividualAnalysesSuccessful = false;
        }

        if (topicsOutcome.status === 'fulfilled') {
            analysisResults.topics = topicsOutcome.value.content;
            if (!topicsOutcome.value.success) allIndividualAnalysesSuccessful = false;
        } else {
            analysisResults.topics = `Error generating Topics: ${topicsOutcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
            allIndividualAnalysesSuccessful = false;
        }

        if (mindmapOutcome.status === 'fulfilled') {
            analysisResults.mindmap = mindmapOutcome.value.content;
            if (!mindmapOutcome.value.success) allIndividualAnalysesSuccessful = false;
        } else {
            analysisResults.mindmap = `Error generating Mindmap: ${mindmapOutcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
            allIndividualAnalysesSuccessful = false;
        }
    }
    
    try {
        await AdminDocument.updateOne(
            { _id: adminDocumentId },
            {
                $set: {
                    "analysis.faq": analysisResults.faq,
                    "analysis.topics": analysisResults.topics,
                    "analysis.mindmap": analysisResults.mindmap,
                    "analysisUpdatedAt": new Date()
                }
            }
        );
        console.log(`${logPrefix} Analysis results stored in DB.`);
        return { success: allIndividualAnalysesSuccessful, message: `Analysis ${allIndividualAnalysesSuccessful ? 'completed' : 'completed with some failures'}.`, results: analysisResults };
    } catch (dbError) {
        console.error(`${logPrefix} DB Error storing analysis results:`, dbError);
        return { success: false, message: `DB Error storing analysis: ${dbError.message}`, results: analysisResults };
    }
}

async function run() {
    // ... (The run function that orchestrates the worker remains the same)
    const { adminDocumentId, originalName, textForAnalysis } = workerData;
    let dbConnected = false;
    let overallTaskSuccess = false;
    let finalMessageToParent = "Admin analysis worker encountered an issue.";

    try {
        await connectDB(process.env.MONGO_URI);
        dbConnected = true;
        const analysisServiceResult = await performAdminDocAnalysis(adminDocumentId, originalName, textForAnalysis);
        overallTaskSuccess = analysisServiceResult.success;
        finalMessageToParent = analysisServiceResult.message;
        if (parentPort) {
            parentPort.postMessage({
                success: overallTaskSuccess,
                originalName: originalName,
                adminDocumentId: adminDocumentId,
                message: finalMessageToParent
            });
        }
    } catch (error) {
        console.error(`[AdminAnalysisWorker] Critical error in worker:`, error);
        finalMessageToParent = error.message || "Unknown critical error.";
        if (parentPort) {
            parentPort.postMessage({ success: false, originalName, adminDocumentId, error: finalMessageToParent });
        }
    } finally {
        if (dbConnected) {
            await mongoose.disconnect();
        }
        console.log(`[AdminAnalysisWorker] Finished task for ${originalName}. Overall Success: ${overallTaskSuccess}`);
    }
}

run();
```

`server/workers/analysisWorker.js`

```javascript


// server/workers/analysisWorker.js
const { workerData, parentPort } = require('worker_threads');
const mongoose = require('mongoose');
const path = require('path');

const User = require('../models/User');
const connectDB = require('../config/db');
const geminiService = require('../services/geminiService');
const ollamaService = require('../services/ollamaService');
const { ANALYSIS_PROMPTS } = require('../config/promptTemplates');

require('dotenv').config({ path: path.resolve(__dirname, '..', '.env') });

async function performFullAnalysis(userId, originalName, textForAnalysis, llmProvider, ollamaModel, apiKey, ollamaUrl) {
    const logPrefix = `[Analysis Worker ${process.pid}, Doc: ${originalName}]`;
    console.log(`${logPrefix} Starting analysis. Using provider: ${llmProvider}`);

    const analysisResults = { faq: "", topics: "", mindmap: "" };
    let allIndividualAnalysesSuccessful = true;

    if (llmProvider === 'gemini' && !apiKey) {
        const errorMessage = "Error: Analysis failed because no valid user Gemini API key was provided to the worker.";
        console.error(`${logPrefix} ${errorMessage}`);
        return { 
            success: false, 
            results: { faq: errorMessage, topics: errorMessage, mindmap: errorMessage }
        };
    }

    async function generateSingleAnalysis(type, promptContentForLLM) {
        try {
            console.log(`${logPrefix} Generating ${type} for '${originalName}'.`);
            const historyForLLM = [{ role: 'user', parts: [{ text: "Perform the requested analysis based on the system instruction provided." }] }];
            
            const llmOptions = { 
                apiKey,
                ollamaUrl,
                model: ollamaModel,
                maxOutputTokens: ollamaService.DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_CHAT
            };

            const generatedText = llmProvider === 'ollama'
                ? await ollamaService.generateContentWithHistory(historyForLLM, promptContentForLLM, null, llmOptions)
                : await geminiService.generateContentWithHistory(historyForLLM, promptContentForLLM, null, llmOptions);

            if (!generatedText || typeof generatedText !== 'string' || generatedText.trim() === "") {
                console.warn(`${logPrefix} LLM returned empty content for ${type}.`);
                return { success: false, content: `Notice: No content generated for ${type}.` };
            }
            console.log(`${logPrefix} ${type} generation successful.`);
            return { success: true, content: generatedText.trim() };
        } catch (error) {
            console.error(`${logPrefix} Error during ${type} generation: ${error.message}`);
            allIndividualAnalysesSuccessful = false;
            return { success: false, content: `Error generating ${type}: ${error.message.substring(0, 250)}` };
        }
    }

    const analysisPromises = [
        generateSingleAnalysis('FAQ', ANALYSIS_PROMPTS.faq.getPrompt(textForAnalysis)),
        generateSingleAnalysis('Topics', ANALYSIS_PROMPTS.topics.getPrompt(textForAnalysis)),
        generateSingleAnalysis('Mindmap', ANALYSIS_PROMPTS.mindmap.getPrompt(textForAnalysis))
    ];
    const outcomes = await Promise.allSettled(analysisPromises);

    outcomes.forEach((outcome, index) => {
        const type = ['faq', 'topics', 'mindmap'][index];
        if (outcome.status === 'fulfilled') {
            analysisResults[type] = outcome.value.content;
            if (!outcome.value.success) allIndividualAnalysesSuccessful = false;
        } else {
            analysisResults[type] = `Error generating ${type}: ${outcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
            allIndividualAnalysesSuccessful = false;
        }
    });
    
    const finalAnalysisStatus = allIndividualAnalysesSuccessful ? "completed" : "failed_partial";
    try {
        await User.updateOne(
            { _id: userId, "uploadedDocuments.filename": originalName },
            {
                $set: {
                    "uploadedDocuments.$.analysis.faq": analysisResults.faq,
                    "uploadedDocuments.$.analysis.topics": analysisResults.topics,
                    "uploadedDocuments.$.analysis.mindmap": analysisResults.mindmap,
                    "uploadedDocuments.$.analysisStatus": finalAnalysisStatus,
                    "uploadedDocuments.$.analysisTimestamp": new Date()
                }
            }
        );
        console.log(`${logPrefix} Analysis results (Status: ${finalAnalysisStatus}) stored in DB.`);
        return { success: allIndividualAnalysesSuccessful, message: `Analysis ${allIndividualAnalysesSuccessful ? 'completed' : 'completed with some failures'}.` };
    } catch (dbError) {
        console.error(`${logPrefix} DB Error storing analysis results:`, dbError);
        return { success: false, message: `DB Error storing analysis: ${dbError.message}` };
    }
}

async function run() {
    const { userId, originalName, textForAnalysis, llmProvider, ollamaModel, apiKey, ollamaUrl } = workerData;
    let dbConnected = false;
    let overallTaskSuccess = false;
    let finalMessageToParent = "Analysis worker encountered an issue.";

    try {
        if (!process.env.MONGO_URI || !userId || !originalName) {
            throw new Error("Worker started with incomplete data (MONGO_URI, userId, or originalName missing).");
        }
        
        await connectDB(process.env.MONGO_URI);
        dbConnected = true;

        await User.updateOne(
            { _id: userId, "uploadedDocuments.filename": originalName },
            { $set: { "uploadedDocuments.$.analysisStatus": "processing" } }
        );

        if (!textForAnalysis || textForAnalysis.trim() === '') {
            await User.updateOne(
                { _id: userId, "uploadedDocuments.filename": originalName },
                { $set: { "uploadedDocuments.$.analysisStatus": "skipped_no_text", "uploadedDocuments.$.analysisTimestamp": new Date() } }
            );
            overallTaskSuccess = true;
            finalMessageToParent = "Analysis skipped: No text provided.";
        } else {
            const result = await performFullAnalysis(
                userId, originalName, textForAnalysis, llmProvider, ollamaModel, apiKey, ollamaUrl
            );
            overallTaskSuccess = result.success;
            finalMessageToParent = result.message;
        }

        if (parentPort) {
            parentPort.postMessage({ success: overallTaskSuccess, originalName, message: finalMessageToParent });
        }

    } catch (error) {
        console.error(`[Analysis Worker] Critical error for '${originalName}':`, error);
        finalMessageToParent = error.message;
        if (dbConnected && userId && originalName) {
            try {
                await User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: { "uploadedDocuments.$.analysisStatus": "failed_critical" } }
                );
            } catch (dbUpdateError) {
                console.error(`[Analysis Worker] Failed to update status to 'failed_critical':`, dbUpdateError);
            }
        }
        if (parentPort) {
            parentPort.postMessage({ success: false, originalName, error: finalMessageToParent });
        }
    } finally {
        if (dbConnected) {
            await mongoose.disconnect();
        }
        console.log(`[Analysis Worker] Finished task for ${originalName}. Success: ${overallTaskSuccess}`);
    }
}

run();
```

`server/workers/kgWorker.js`

```javascript
// server/workers/kgWorker.js
const { workerData, parentPort } = require('worker_threads');
const mongoose = require('mongoose');

const User = require('../models/User');
const connectDB = require('../config/db');
const kgService = require('../services/kgService');

async function runKgGeneration() {
    const { chunksForKg: allInitialChunks, userId, originalName, llmProvider, ollamaModel } = workerData;
    let dbConnected = false;
    let overallSuccess = false;
    let finalMessage = "KG processing encountered an issue.";
    const logPrefix = `[KG Worker ${process.pid}, Doc: ${originalName}]`;

    try {
        console.log(`${logPrefix} Received task. User: ${userId}, Initial Chunks: ${allInitialChunks ? allInitialChunks.length : 0}`);
        if (!process.env.MONGO_URI) throw new Error("MONGO_URI not set in KG worker environment.");
        if (!userId || !originalName) throw new Error("Missing userId or originalName in KG workerData.");

        await connectDB(process.env.MONGO_URI);
        dbConnected = true;
        console.log(`${logPrefix} DB Connected.`);

        await User.updateOne(
            { _id: userId, "uploadedDocuments.filename": originalName },
            { $set: { "uploadedDocuments.$.kgStatus": "processing" } }
        );
        console.log(`${logPrefix} Status set to 'processing'.`);

        if (!allInitialChunks || allInitialChunks.length === 0) {
            console.log(`${logPrefix} No chunks provided for KG generation. Marking as skipped.`);
            await User.updateOne(
                { _id: userId, "uploadedDocuments.filename": originalName },
                { $set: { "uploadedDocuments.$.kgStatus": "skipped_no_chunks", "uploadedDocuments.$.kgTimestamp": new Date() } }
            );
            finalMessage = "No chunks provided for KG generation.";
            overallSuccess = true; // Not a failure of this worker's process
        } else {
            const kgExtractionResult = await kgService.generateAndStoreKg(allInitialChunks, userId, originalName, llmProvider, ollamaModel);

            if (kgExtractionResult && kgExtractionResult.success) {
                await User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: {
                        "uploadedDocuments.$.kgStatus": "completed",
                        "uploadedDocuments.$.kgNodesCount": kgExtractionResult.finalKgNodesCount,
                        "uploadedDocuments.$.kgEdgesCount": kgExtractionResult.finalKgEdgesCount,
                        "uploadedDocuments.$.kgTimestamp": new Date()
                        }
                    }
                );
                overallSuccess = true;
                finalMessage = kgExtractionResult.message || "KG generation and storage completed successfully.";
                console.log(`${logPrefix} SUCCESS: ${finalMessage}`);
            } else {
                await User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: { "uploadedDocuments.$.kgStatus": "failed_extraction" } }
                );
                finalMessage = (kgExtractionResult && kgExtractionResult.message) ? kgExtractionResult.message : "KG detailed extraction or storage failed.";
                console.error(`${logPrefix} FAILED (Extraction/Store): ${finalMessage}`);
                overallSuccess = false;
            }
        }

        if (parentPort) {
            parentPort.postMessage({ success: overallSuccess, originalName, message: finalMessage });
        }

    } catch (error) {
        console.error(`${logPrefix} CRITICAL error:`, error.message, error.stack);
        finalMessage = error.message || "Unknown critical error in KG worker.";
        overallSuccess = false;
        if (dbConnected && userId && originalName) {
            try {
                await User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: { "uploadedDocuments.$.kgStatus": "failed_critical" } }
                );
            } catch (dbUpdateError) {
                console.error(`${logPrefix} DB update error on critical fail:`, dbUpdateError);
            }
        }
        if (parentPort) {
            parentPort.postMessage({ success: false, originalName, error: finalMessage });
        }
    } finally {
        if (dbConnected) {
            await mongoose.disconnect().catch(e => console.error(`${logPrefix} Error disconnecting DB:`, e));
            console.log(`${logPrefix} DB Disconnected.`);
        }
        console.log(`${logPrefix} Finished task. Overall Success: ${overallSuccess}`);
    }
}

runKgGeneration();
```

