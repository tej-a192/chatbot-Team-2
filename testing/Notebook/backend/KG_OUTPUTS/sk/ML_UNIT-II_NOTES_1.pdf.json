{
  "edges": [
    {
      "from": "Logistic Regression",
      "relationship": "has_subtopic",
      "to": "Ordinal Logistic Regression"
    },
    {
      "from": "BayesianPrinciple",
      "relationship": "related_to",
      "to": "WhyNaiveBayes"
    },
    {
      "from": "DisadvantagesOfNB",
      "relationship": "subtopic",
      "to": "NaiveBayesAlgorithm"
    },
    {
      "from": "Logistic Regression",
      "relationship": "has_subtopic",
      "to": "Multinomial Logistic Regression"
    },
    {
      "from": "Linear_Regression",
      "relationship": "subtopic_of",
      "to": "Simple_Linear_Regression"
    },
    {
      "from": "Linear_Models",
      "relationship": "contains",
      "to": "Linear_Regression"
    },
    {
      "from": "Decision Tree",
      "relationship": "has_subtopic",
      "to": "Disadvantages"
    },
    {
      "from": "Ranking Models",
      "relationship": "produces",
      "to": "Documents"
    },
    {
      "from": "BayesTheoremExplanation",
      "relationship": "subtopic",
      "to": "BayesianPrinciple"
    },
    {
      "from": "MNIST Dataset",
      "relationship": "contains",
      "to": "Test Set"
    },
    {
      "from": "HowDTAlgorithmWorks",
      "relationship": "subtopic",
      "to": "Step4"
    },
    {
      "from": "Supervised Learning",
      "relationship": "contains",
      "to": "Basic Methods"
    },
    {
      "from": "AdvantagesOfNB",
      "relationship": "subtopic",
      "to": "NaiveBayesAlgorithm"
    },
    {
      "from": "Naive_Bayes_Classifier",
      "relationship": "has_subtopic",
      "to": "Advantages_Naive_Bayes"
    },
    {
      "from": "Binary_Classification",
      "relationship": "related_to",
      "to": "Recall"
    },
    {
      "from": "NaiveAssumption",
      "relationship": "related_to",
      "to": "WhyNaiveBayes"
    },
    {
      "from": "Regression vs Classification",
      "relationship": "related_to",
      "to": "Logistic Regression"
    },
    {
      "from": "Basic Methods",
      "relationship": "subtopic",
      "to": "Support Vector Machines (SVM)"
    },
    {
      "from": "DecisionTreeTerminologies",
      "relationship": "related_to",
      "to": "SplittingProcess"
    },
    {
      "from": "HowDTAlgorithmWorks",
      "relationship": "subtopic",
      "to": "Step5"
    },
    {
      "from": "Basic Methods",
      "relationship": "subtopic",
      "to": "Decision Trees"
    },
    {
      "from": "DecisionTreeTerminologies",
      "relationship": "related_to",
      "to": "PruningProcess"
    },
    {
      "from": "DecisionTreeOverview",
      "relationship": "depends_on",
      "to": "CARTAlgorithm"
    },
    {
      "from": "Structured_Output_Prediction",
      "relationship": "contains",
      "to": "Sequence_Labeling"
    },
    {
      "from": "Multi_Class_Classification",
      "relationship": "contains",
      "to": "Training_Data"
    },
    {
      "from": "Supervised Learning",
      "relationship": "contains",
      "to": "Regression"
    },
    {
      "from": "HowDTAlgorithmWorks",
      "relationship": "subtopic",
      "to": "Step1"
    },
    {
      "from": "Learning_To_Rank",
      "relationship": "related_to",
      "to": "Documents"
    },
    {
      "from": "Positive Linear Relationship",
      "relationship": "subtopic",
      "to": "Regression Line"
    },
    {
      "from": "Linear_Regression",
      "relationship": "subtopic_of",
      "to": "Multiple_Linear_Regression"
    },
    {
      "from": "MNIST Dataset",
      "relationship": "used_in",
      "to": "Image Processing"
    },
    {
      "from": "Negative Linear Relationship",
      "relationship": "subtopic",
      "to": "Regression Line"
    },
    {
      "from": "HowDTAlgorithmWorks",
      "relationship": "subtopic",
      "to": "Step2"
    },
    {
      "from": "Decision Tree",
      "relationship": "has_subtopic",
      "to": "Advantages"
    },
    {
      "from": "Machine_Learning_Metrics",
      "relationship": "contains",
      "to": "Precision_Recall"
    },
    {
      "from": "Na√Øve Bayes Classifier Algorithm",
      "relationship": "related_to",
      "to": "Decision Tree"
    },
    {
      "from": "Linear Models",
      "relationship": "subtopic",
      "to": "Logistic Regression"
    },
    {
      "from": "Decision Tree Classification",
      "relationship": "related_to",
      "to": "KNN Algorithm"
    },
    {
      "from": "DecisionTreeTerminologies",
      "relationship": "related_to",
      "to": "LeafNode"
    },
    {
      "from": "Support Vector Machine (SVM)",
      "relationship": "has_subtopic",
      "to": "Linear SVM"
    },
    {
      "from": "Machine_Learning_Topics",
      "relationship": "related_to",
      "to": "Non_linear_SVM_classifier"
    },
    {
      "from": "Distance Based Methods",
      "relationship": "subtopic",
      "to": "K-Nearest Neighbors (KNN)"
    },
    {
      "from": "KNN Algorithm",
      "relationship": "has_subtopic",
      "to": "Disadvantages KNN"
    },
    {
      "from": "Linear Models",
      "relationship": "subtopic",
      "to": "Generalized Linear Models (GLM)"
    },
    {
      "from": "WhyNaiveBayes",
      "relationship": "subtopic",
      "to": "NaiveBayesAlgorithm"
    },
    {
      "from": "Learning_To_Rank",
      "relationship": "has_subtopic",
      "to": "Scoring_Function"
    },
    {
      "from": "Assumptions_LogReg",
      "relationship": "subtopic",
      "to": "Logistic_Regression"
    },
    {
      "from": "ExamplesOfNB",
      "relationship": "subtopic",
      "to": "NaiveBayesAlgorithm"
    },
    {
      "from": "Ranking Models",
      "relationship": "depends_on",
      "to": "Queries"
    },
    {
      "from": "DecisionTreeTerminologies",
      "relationship": "related_to",
      "to": "BranchSubtree"
    },
    {
      "from": "HowDTAlgorithmWorks",
      "relationship": "subtopic",
      "to": "Step3"
    },
    {
      "from": "Binary_Classification",
      "relationship": "depends_on",
      "to": "F1_Score"
    },
    {
      "from": "Learning_To_Rank",
      "relationship": "depends_on",
      "to": "Queries"
    },
    {
      "from": "Supervised Learning Technique",
      "relationship": "subtopic",
      "to": "Logistic Regression"
    },
    {
      "from": "Naive_Bayes_Classifier",
      "relationship": "has_subtopic",
      "to": "Applications_Naive_Bayes"
    },
    {
      "from": "Ranking Models",
      "relationship": "is_a_type_of",
      "to": "Supervised Learning"
    },
    {
      "from": "Support Vector Machine (SVM)",
      "relationship": "has_subtopic",
      "to": "Non-linear SVM"
    },
    {
      "from": "Naive_Bayes_Classifier",
      "relationship": "has_subtopic",
      "to": "Disadvantages_Naive_Bayes"
    },
    {
      "from": "ProbabilisticClassifier",
      "relationship": "depends_on",
      "to": "NaiveBayesAlgorithm"
    },
    {
      "from": "Linear Models",
      "relationship": "subtopic",
      "to": "Linear Regression"
    },
    {
      "from": "MNIST Dataset",
      "relationship": "contains",
      "to": "Training Set"
    },
    {
      "from": "Machine_Learning_Topics",
      "relationship": "subtopic",
      "to": "Binary_Classification"
    },
    {
      "from": "Binary_Classification",
      "relationship": "related_to",
      "to": "Precision"
    },
    {
      "from": "Machine_Learning_Metrics",
      "relationship": "contains",
      "to": "F1_Score"
    },
    {
      "from": "Non_linear_SVM_classifier",
      "relationship": "depends_on",
      "to": "Advantages_and_Disadvantages"
    },
    {
      "from": "Regression Line",
      "relationship": "subtopic",
      "to": "Linear Regression"
    },
    {
      "from": "Machine_Learning_Algorithms",
      "relationship": "contains",
      "to": "Naive_Bayes_Classifier"
    },
    {
      "from": "DecisionTreeTerminologies",
      "relationship": "related_to",
      "to": "ParentChildNodes"
    },
    {
      "from": "DecisionTreeTerminologies",
      "relationship": "related_to",
      "to": "RootNode"
    },
    {
      "from": "Multi_Class_Classification",
      "relationship": "contains",
      "to": "Prediction"
    },
    {
      "from": "Types_LogReg",
      "relationship": "subtopic",
      "to": "Logistic_Regression"
    },
    {
      "from": "Supervised Learning",
      "relationship": "contains",
      "to": "Classification"
    },
    {
      "from": "Machine_Learning",
      "relationship": "has_subtopic",
      "to": "Learning_To_Rank"
    },
    {
      "from": "Multiple Linear Regression",
      "relationship": "subtopic",
      "to": "Linear Regression"
    },
    {
      "from": "Equation_LogReg",
      "relationship": "subtopic",
      "to": "Logistic_Regression"
    },
    {
      "from": "Basic Methods",
      "relationship": "contains",
      "to": "Linear Models"
    },
    {
      "from": "Basic Methods",
      "relationship": "subtopic",
      "to": "Naive Bayes"
    },
    {
      "from": "Single Linear Regression",
      "relationship": "subtopic",
      "to": "Linear Regression"
    },
    {
      "from": "KNN Algorithm",
      "relationship": "has_subtopic",
      "to": "Advantages KNN"
    }
  ],
  "nodes": [
    {
      "description": "Field of study that uses algorithms and statistical models to enable machines to perform tasks without explicit instructions.",
      "id": "Machine Learning",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Type of machine learning where the model learns from labeled training data to make predictions.",
      "id": "Supervised Learning",
      "parent": "Machine Learning",
      "type": "subnode"
    },
    {
      "description": "Predicting a continuous value based on input features.",
      "id": "Regression",
      "parent": "Supervised Learning",
      "type": "subnode"
    },
    {
      "description": "Categorizing data into predefined classes.",
      "id": "Classification",
      "parent": "Supervised Learning",
      "type": "subnode"
    },
    {
      "description": "Fundamental techniques used in supervised learning tasks.",
      "id": "Basic Methods",
      "parent": "Supervised Learning",
      "type": "subnode"
    },
    {
      "description": "Algorithms that classify data based on distance metrics.",
      "id": "Distance Based Methods",
      "parent": "Basic Methods",
      "type": "subnode"
    },
    {
      "description": "Algorithm for classification and regression that predicts the output based on closest training samples.",
      "id": "K-Nearest Neighbors (KNN)",
      "parent": "Distance Based Methods",
      "type": "subnode"
    },
    {
      "description": "Hierarchical structure used to make decisions or classify data by splitting dataset into subsets.",
      "id": "Decision Trees",
      "parent": "Basic Methods",
      "type": "subnode"
    },
    {
      "description": "Probabilistic classifier based on applying Bayes' theorem with strong independence assumptions between the features.",
      "id": "Naive Bayes",
      "parent": "Basic Methods",
      "type": "subnode"
    },
    {
      "description": "Models that assume a linear relationship between input variables and output variable.",
      "id": "Linear Models",
      "parent": "Basic Methods",
      "type": "subnode"
    },
    {
      "description": "Statistical method for modeling the relationship between a dependent variable and one or more independent variables.",
      "id": "Linear Regression",
      "parent": "Linear Models",
      "type": "subnode"
    },
    {
      "description": "Method for predicting binary outcomes based on linear combination of input features.",
      "id": "Logistic Regression",
      "parent": "Linear Models",
      "type": "subnode"
    },
    {
      "description": "Extension of linear models that allows response variables to have error distribution other than normal.",
      "id": "Generalized Linear Models (GLM)",
      "parent": "Linear Models",
      "type": "subnode"
    },
    {
      "description": "Algorithm for classification and regression analysis by finding hyperplane that best separates data points.",
      "id": "Support Vector Machines (SVM)",
      "parent": "Basic Methods",
      "type": "subnode"
    },
    {
      "description": "A simple algorithm for classification that identifies the category of a new data point based on its proximity to existing categories.",
      "id": "KNN Algorithm",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Includes simplicity and robustness against noisy data.",
      "id": "Advantages KNN",
      "parent": "KNN Algorithm",
      "type": "subnode"
    },
    {
      "description": "Involves determining the value of K and high computational cost.",
      "id": "Disadvantages KNN",
      "parent": "KNN Algorithm",
      "type": "subnode"
    },
    {
      "description": "A supervised learning technique for classification that uses a tree-like model to make decisions based on features.",
      "id": "Decision Tree Classification",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Introduction to decision trees and their structure",
      "id": "DecisionTreeOverview",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Classification and Regression Tree algorithm used for building decision trees",
      "id": "CARTAlgorithm",
      "parent": "DecisionTreeOverview",
      "type": "subnode"
    },
    {
      "description": "Key terms related to decision tree structure and process",
      "id": "DecisionTreeTerminologies",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Starting point of the decision tree representing the entire dataset",
      "id": "RootNode",
      "parent": "DecisionTreeTerminologies",
      "type": "subnode"
    },
    {
      "description": "Final output node where further splitting is not possible",
      "id": "LeafNode",
      "parent": "DecisionTreeTerminologies",
      "type": "subnode"
    },
    {
      "description": "Division of decision nodes into sub-nodes based on conditions",
      "id": "SplittingProcess",
      "parent": "DecisionTreeTerminologies",
      "type": "subnode"
    },
    {
      "description": "A tree formed by splitting the main tree",
      "id": "BranchSubtree",
      "parent": "DecisionTreeTerminologies",
      "type": "subnode"
    },
    {
      "description": "Removal of unnecessary branches to simplify the decision tree",
      "id": "PruningProcess",
      "parent": "DecisionTreeTerminologies",
      "type": "subnode"
    },
    {
      "description": "Relationship between root and other nodes in a tree structure",
      "id": "ParentChildNodes",
      "parent": "DecisionTreeTerminologies",
      "type": "subnode"
    },
    {
      "description": "Steps involved in the decision tree algorithm",
      "id": "HowDTAlgorithmWorks",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Starting with the root node containing complete dataset",
      "id": "Step1",
      "parent": "HowDTAlgorithmWorks",
      "type": "subnode"
    },
    {
      "description": "Selecting the best attribute using Attribute Selection Measure (ASM)",
      "id": "Step2",
      "parent": "HowDTAlgorithmWorks",
      "type": "subnode"
    },
    {
      "description": "Dividing dataset into subsets based on possible values of selected attributes",
      "id": "Step3",
      "parent": "HowDTAlgorithmWorks",
      "type": "subnode"
    },
    {
      "description": "Creating decision tree node with the best attribute",
      "id": "Step4",
      "parent": "HowDTAlgorithmWorks",
      "type": "subnode"
    },
    {
      "description": "Repeating steps recursively until reaching a leaf node",
      "id": "Step5",
      "parent": "HowDTAlgorithmWorks",
      "type": "subnode"
    },
    {
      "description": "A decision-making tool that uses a tree-like model of decisions and their possible consequences",
      "id": "Decision Tree",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Simplicity in understanding and solving decision-related problems",
      "id": "Advantages",
      "parent": "Decision Tree",
      "type": "subnode"
    },
    {
      "description": "Complexity due to layers and potential overfitting issues",
      "id": "Disadvantages",
      "parent": "Decision Tree",
      "type": "subnode"
    },
    {
      "description": "Supervised learning algorithm for classification based on Bayes theorem",
      "id": "Na√Øve Bayes Classifier Algorithm",
      "parent": null,
      "type": "major"
    },
    {
      "description": "A probabilistic classifier used for quick predictions and classification tasks.",
      "id": "NaiveBayesAlgorithm",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Predicts based on the probability of an object belonging to a certain class.",
      "id": "ProbabilisticClassifier",
      "parent": "NaiveBayesAlgorithm",
      "type": "subnode"
    },
    {
      "description": "Includes applications like spam filtration, sentiment analysis, and article classification.",
      "id": "ExamplesOfNB",
      "parent": "NaiveBayesAlgorithm",
      "type": "subnode"
    },
    {
      "description": "Explains the naming due to its assumptions of feature independence and use of Bayes' Theorem.",
      "id": "WhyNaiveBayes",
      "parent": "NaiveBayesAlgorithm",
      "type": "subnode"
    },
    {
      "description": "Features are independent, contributing individually without dependency on each other.",
      "id": "NaiveAssumption",
      "parent": "WhyNaiveBayes",
      "type": "subnode"
    },
    {
      "description": "Relies on Bayes' Theorem for calculating probabilities based on prior knowledge.",
      "id": "BayesianPrinciple",
      "parent": "WhyNaiveBayes",
      "type": "subnode"
    },
    {
      "description": "Describes the formula and components of Bayes' theorem, including posterior, likelihood, prior, and marginal probability.",
      "id": "BayesTheoremExplanation",
      "parent": "BayesianPrinciple",
      "type": "subnode"
    },
    {
      "description": "Includes speed, ease of use, applicability to binary and multi-class problems, and performance in text classification.",
      "id": "AdvantagesOfNB",
      "parent": "NaiveBayesAlgorithm",
      "type": "subnode"
    },
    {
      "description": "Lacks ability to learn relationships between features due to independence assumption.",
      "id": "DisadvantagesOfNB",
      "parent": "NaiveBayesAlgorithm",
      "type": "subnode"
    },
    {
      "description": "Collection of algorithms used in machine learning",
      "id": "Machine_Learning_Algorithms",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Probabilistic classifier based on Bayes' theorem with strong independence assumptions between the features",
      "id": "Naive_Bayes_Classifier",
      "parent": "Machine_Learning_Algorithms",
      "type": "subnode"
    },
    {
      "description": "Popular choice for text classification problems",
      "id": "Advantages_Naive_Bayes",
      "parent": "Naive_Bayes_Classifier",
      "type": "subnode"
    },
    {
      "description": "Assumes features are independent, cannot learn relationships between them",
      "id": "Disadvantages_Naive_Bayes",
      "parent": "Naive_Bayes_Classifier",
      "type": "subnode"
    },
    {
      "description": "Used in credit scoring, medical data classification, real-time predictions, text classification",
      "id": "Applications_Naive_Bayes",
      "parent": "Naive_Bayes_Classifier",
      "type": "subnode"
    },
    {
      "description": "Models that use linear functions to predict outcomes",
      "id": "Linear_Models",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Simple algorithm for predictive analysis with continuous variables",
      "id": "Linear_Regression",
      "parent": "Linear_Models",
      "type": "subnode"
    },
    {
      "description": "Uses a single independent variable to predict the dependent variable",
      "id": "Simple_Linear_Regression",
      "parent": "Linear_Regression",
      "type": "subnode"
    },
    {
      "description": "Uses multiple independent variables to predict the dependent variable",
      "id": "Multiple_Linear_Regression",
      "parent": "Linear_Regression",
      "type": "subnode"
    },
    {
      "description": "Uses a single independent variable to predict the value of the dependent variable.",
      "id": "Single Linear Regression",
      "parent": "Linear Regression",
      "type": "subnode"
    },
    {
      "description": "Predicts dependent variable using more than one independent variables.",
      "id": "Multiple Linear Regression",
      "parent": "Linear Regression",
      "type": "subnode"
    },
    {
      "description": "Line showing relationship between dependent and independent variables.",
      "id": "Regression Line",
      "parent": "Linear Regression",
      "type": "subnode"
    },
    {
      "description": "Dependent variable increases as independent variable increases.",
      "id": "Positive Linear Relationship",
      "parent": "Regression Line",
      "type": "subnode"
    },
    {
      "description": "Dependent variable decreases as independent variable increases.",
      "id": "Negative Linear Relationship",
      "parent": "Regression Line",
      "type": "subnode"
    },
    {
      "description": "Technique used for predicting categorical outcomes based on input data.",
      "id": "Supervised Learning Technique",
      "parent": "Logistic Regression",
      "type": "subnode"
    },
    {
      "description": "Linear regression solves regression problems, logistic regression solves classification problems.",
      "id": "Regression vs Classification",
      "parent": "Logistic Regression",
      "type": "subnode"
    },
    {
      "description": "A machine learning algorithm for classification tasks",
      "id": "Logistic_Regression",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Dependent variable must be categorical and independent variables should not have multi-collinearity",
      "id": "Assumptions_LogReg",
      "parent": "Logistic_Regression",
      "type": "subnode"
    },
    {
      "description": "Derived from linear regression, transforming range to 0-1 using logistic function",
      "id": "Equation_LogReg",
      "parent": "Logistic_Regression",
      "type": "subnode"
    },
    {
      "description": "Binomial, Multinomial, and Ordinal types based on categories of dependent variables",
      "id": "Types_LogReg",
      "parent": "Logistic_Regression",
      "type": "subnode"
    },
    {
      "description": "Handles unordered categories of dependent variable",
      "id": "Multinomial Logistic Regression",
      "parent": "Logistic Regression",
      "type": "subnode"
    },
    {
      "description": "Handles ordered categories of dependent variable",
      "id": "Ordinal Logistic Regression",
      "parent": "Logistic Regression",
      "type": "subnode"
    },
    {
      "description": "Supervised learning algorithm for classification and regression",
      "id": "Support Vector Machine (SVM)",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Used for linearly separable data",
      "id": "Linear SVM",
      "parent": "Support Vector Machine (SVM)",
      "type": "subnode"
    },
    {
      "description": "Used for non-linearly separated data",
      "id": "Non-linear SVM",
      "parent": "Support Vector Machine (SVM)",
      "type": "subnode"
    },
    {
      "description": "Main topics in machine learning",
      "id": "Machine_Learning_Topics",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Classification into two distinct classes",
      "id": "Binary_Classification",
      "parent": "Machine_Learning_Topics",
      "type": "subnode"
    },
    {
      "description": "Support Vector Machine classifier for non-linear data",
      "id": "Non_linear_SVM_classifier",
      "parent": "Machine_Learning_Topics",
      "type": "subnode"
    },
    {
      "description": "Pros and cons of using SVM classifiers",
      "id": "Advantages_and_Disadvantages",
      "parent": "Non_linear_SVM_classifier",
      "type": "subnode"
    },
    {
      "description": "Measure of the accuracy of positive predictions in binary classification",
      "id": "Precision",
      "parent": "Binary_Classification",
      "type": "subnode"
    },
    {
      "description": "Ability to find all positive cases in a dataset",
      "id": "Recall",
      "parent": "Binary_Classification",
      "type": "subnode"
    },
    {
      "description": "Harmonic mean of precision and recall, balancing both metrics",
      "id": "F1_Score",
      "parent": "Binary_Classification",
      "type": "subnode"
    },
    {
      "description": "Metrics used to evaluate machine learning models.",
      "id": "Machine_Learning_Metrics",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Measures of a model's accuracy and completeness.",
      "id": "Precision_Recall",
      "parent": "Machine_Learning_Metrics",
      "type": "subnode"
    },
    {
      "description": "Classification where each input belongs to exactly one class from K possible classes.",
      "id": "Multi_Class_Classification",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Each feature vector is associated with a single class label.",
      "id": "Training_Data",
      "parent": "Multi_Class_Classification",
      "type": "subnode"
    },
    {
      "description": "Predicting the correct class for new inputs.",
      "id": "Prediction",
      "parent": "Multi_Class_Classification",
      "type": "subnode"
    },
    {
      "description": "Assigning structured outputs to inputs based on learned patterns.",
      "id": "Structured_Output_Prediction",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Tagging sequences of objects with corresponding labels.",
      "id": "Sequence_Labeling",
      "parent": "Structured_Output_Prediction",
      "type": "subnode"
    },
    {
      "description": "Database of handwritten digits used for training image processing systems.",
      "id": "MNIST_Database",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Database of handwritten digits used for training and testing in machine learning.",
      "id": "MNIST Dataset",
      "parent": null,
      "type": "major"
    },
    {
      "description": "60,000 examples of normalized and centered images.",
      "id": "Training Set",
      "parent": "MNIST Dataset",
      "type": "subnode"
    },
    {
      "description": "10,000 examples used for testing machine learning models.",
      "id": "Test Set",
      "parent": "MNIST Dataset",
      "type": "subnode"
    },
    {
      "description": "Field that uses MNIST dataset to process and analyze images.",
      "id": "Image Processing",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Type of supervised machine learning used for sorting data in an optimal order.",
      "id": "Ranking Models",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Input values for ranking algorithms, such as search queries or user interactions.",
      "id": "Queries",
      "parent": "Ranking Models",
      "type": "subnode"
    },
    {
      "description": "Output results associated with a query, to be ranked by relevance.",
      "id": "Documents",
      "parent": "Ranking Models",
      "type": "subnode"
    },
    {
      "description": "Field of study that uses algorithms to make predictions or decisions based on data.",
      "id": "Machine_Learning",
      "parent": null,
      "type": "major"
    },
    {
      "description": "Algorithm for predicting the relevance of documents given a query.",
      "id": "Learning_To_Rank",
      "parent": "Machine_Learning",
      "type": "subnode"
    },
    {
      "description": "Function that scores documents based on parameters for ranking relevancy.",
      "id": "Scoring_Function",
      "parent": "Learning_To_Rank",
      "type": "subnode"
    }
  ]
}