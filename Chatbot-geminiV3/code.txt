`code.txt`

```

```

`frontend/.env`

```
#REACT_APP_API_BASE_URL=http://localhost:5001/api
# OR for Vite:
VITE_API_BASE_URL=http://localhost:5001/api
VITE_ADMIN_USERNAME=admin
VITE_ADMIN_PASSWORD=admin123





```

`frontend/eslint.config.js`

```javascript
import js from '@eslint/js'
import globals from 'globals'
import reactHooks from 'eslint-plugin-react-hooks'
import reactRefresh from 'eslint-plugin-react-refresh'

export default [
  { ignores: ['dist'] },
  {
    files: ['**/*.{js,jsx}'],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
      parserOptions: {
        ecmaVersion: 'latest',
        ecmaFeatures: { jsx: true },
        sourceType: 'module',
      },
    },
    plugins: {
      'react-hooks': reactHooks,
      'react-refresh': reactRefresh,
    },
    rules: {
      ...js.configs.recommended.rules,
      ...reactHooks.configs.recommended.rules,
      'no-unused-vars': ['error', { varsIgnorePattern: '^[A-Z_]' }],
      'react-refresh/only-export-components': [
        'warn',
        { allowConstantExport: true },
      ],
    },
  },
]

```

`frontend/index.html`

```html
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI TUTOR</title>

    <script src="https://cdn.jsdelivr.net/npm/d3@6"></script>
    <script src="https://cdn.jsdelivr.net/npm/markmap-lib@latest"></script>
    <script src="https://cdn.jsdelivr.net/npm/markmap-view@latest"></script>
    <script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@latest"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@latest/dist/style.css">
    <script src="https://cdn.jsdelivr.net/npm/mermaid@latest/dist/mermaid.min.js"></script>
    
    <script>
      document.addEventListener('DOMContentLoaded', () => {
        if (typeof mermaid !== 'undefined') {
          mermaid.initialize({ startOnLoad: false, theme: 'neutral' }); 
          console.log("Mermaid.js initialized globally with 'neutral' theme via index.html.");
        } else {
          console.error("Mermaid.js not found on window after script load. Mermaid diagrams may not render.");
        }
      });
    </script>

  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.jsx"></script>
  </body>
</html>
```

`frontend/postcss.config.js`

```javascript
export default {
  plugins: {
    'postcss-nesting': {},
    tailwindcss: {},
    autoprefixer: {},
  },
}
```

`frontend/src/App.css`

```css
/* #root {
  max-width: 1280px;
  margin: 0 auto;
  padding: 2rem;
  text-align: center;
}

.logo {
  height: 6em;
  padding: 1.5em;
  will-change: filter;
  transition: filter 300ms;
}
.logo:hover {
  filter: drop-shadow(0 0 2em #646cffaa);
}
.logo.react:hover {
  filter: drop-shadow(0 0 2em #61dafbaa);
}

@keyframes logo-spin {
  from {
    transform: rotate(0deg);
  }
  to {
    transform: rotate(360deg);
  }
}

@media (prefers-reduced-motion: no-preference) {
  a:nth-of-type(2) .logo {
    animation: logo-spin infinite 20s linear;
  }
}

.card {
  padding: 2em;
}

.read-the-docs {
  color: #888;
} */

```

`frontend/src/App.jsx`

```javascript
// frontend/src/App.jsx
import React, { useState, useEffect, useCallback } from 'react';
import { BrowserRouter as Router, Routes, Route, Navigate, useNavigate, useLocation } from 'react-router-dom';

import { useAuth as useRegularAuth } from './hooks/useAuth.jsx'; // For regular user login/state
import { useAppState } from './contexts/AppStateContext.jsx';   // For isAdminSessionActive and other global states

// --- Regular User Components ---
import AuthModal from './components/auth/AuthModal.jsx';
import TopNav from './components/layout/TopNav.jsx';
import LeftPanel from './components/layout/LeftPanel.jsx';
import CenterPanel from './components/layout/CenterPanel.jsx';
import RightPanel from './components/layout/RightPanel.jsx';
import LeftCollapsedNav from './components/layout/LeftCollapsedNav.jsx';
import RightCollapsedNav from './components/layout/RightCollapsedNav.jsx';
import ChatHistoryModal from './components/chat/ChatHistoryModal.jsx';

// --- Admin Specific Components ---
import AdminDashboardPage from './components/admin/AdminDashboardPage.jsx'; // Make sure this exists
import AdminProtectedRoute from './components/admin/AdminProtectedRoute.jsx'; // You've updated this

// --- Services & Utils ---
import api from './services/api.js'; // For regular user API calls
import toast from 'react-hot-toast';
import { motion, AnimatePresence } from 'framer-motion';

// Main application layout for authenticated REGULAR users
function MainAppLayout() {
    const { user: regularUser, logout: regularUserLogout } = useRegularAuth();
    const {
        orchestratorStatus, // Assuming this is fetched and managed by App or AppStateContext
        currentSessionId,
        isLeftPanelOpen,
        isRightPanelOpen,
        setSessionId: setGlobalSessionId, // Renamed for clarity from AppStateContext
    } = useAppState();

    const [appStateMessages, setAppStateMessages] = useState([]); // Local to MainAppLayout
    const [appStateChatStatus, setAppStateChatStatus] = useState('Ready.'); // Local to MainAppLayout
    const [isHistoryModalOpen, setIsHistoryModalOpen] = useState(false);

    const handleRegularUserLogout = () => {
        regularUserLogout(); // Clears token and user in AuthContext
        setGlobalSessionId(null); // Clear session from AppStateContext
        localStorage.removeItem('aiTutorSessionId');
        setAppStateMessages([]);
        setAppStateChatStatus("Logged out. Please login.");
        toast.success("Logged out successfully.");
        // App.jsx routing will handle redirecting to show AuthModal if necessary
    };

    const handleNewChat = async () => {
        try {
            // Pass the current session ID to the backend so it can be summarized
            const data = await api.startNewSession(currentSessionId); 
            if (data && data.newSessionId) {
                setGlobalSessionId(data.newSessionId); // Use the new ID from the backend
                setAppStateMessages([]);
                setAppStateChatStatus("New chat started.");
                toast.success("New chat started!");
            } else {
                toast.error("Could not start new chat session.");
            }
        } catch (error) {
            toast.error(`Failed to start new chat: ${error.message}`);
        }
    };

    const handleSelectSessionFromHistory = (sessionId) => {
        if (sessionId && sessionId !== currentSessionId) {
            setGlobalSessionId(sessionId);
            // Chat history fetching will be triggered by useEffect watching currentSessionId
            toast.success(`Loading session...`);
        } else if (sessionId === currentSessionId) {
            toast.info("This session is already loaded.");
        }
        setIsHistoryModalOpen(false);
    };

    const { token: regularUserTokenValue } = useRegularAuth(); // Get token for API calls

    const fetchChatHistory = useCallback(async (sid) => {
        if (!sid || !regularUserTokenValue) {
            setAppStateMessages([]);
            setAppStateChatStatus(regularUserTokenValue ? "Start or select a chat." : "Please login.");
            return;
        }
        setAppStateChatStatus("Loading chat history...");
        try {
            // This API call now returns the full session object, including messages
            const sessionData = await api.getChatHistory(sid);
            const formattedMessages = (Array.isArray(sessionData.messages) ? sessionData.messages : []).map(msg => ({
                id: msg.id || msg._id || String(Math.random() + Date.now()),
                sender: msg.sender || (msg.role === 'model' ? 'bot' : 'user'),
                text: msg.parts?.[0]?.text || msg.text || '',
                thinking: msg.thinking, references: msg.references || [],
                timestamp: msg.timestamp || new Date().toISOString(),
                source_pipeline: msg.source_pipeline
            }));
            setAppStateMessages(formattedMessages);
            setAppStateChatStatus(formattedMessages.length > 0 ? "History loaded." : "Chat is empty.");
        } catch (error) {
            toast.error(`History load failed: ${error.message}`);
            setAppStateChatStatus("Error loading history.");
        }
    }, [regularUserTokenValue]); // Dependencies for fetchChatHistory

    useEffect(() => {
        if (currentSessionId && regularUserTokenValue) {
            fetchChatHistory(currentSessionId);
        } else if (!regularUserTokenValue) { // If regular user logs out
            setAppStateMessages([]);
            setAppStateChatStatus("Please login.");
        }
    }, [currentSessionId, regularUserTokenValue, fetchChatHistory]);

    // Assuming orchestratorStatus is fetched in the top-level App component
    // and passed down if MainAppLayout needs it directly for TopNav.
    // For simplicity, I'll pass it as a prop to MainAppLayout.

    return (
        <>
            <TopNav
                user={regularUser} // regularUser object from AuthContext (includes role if backend sends it)
                onLogout={handleRegularUserLogout}
                onNewChat={handleNewChat}
                onHistoryClick={() => setIsHistoryModalOpen(true)}
                orchestratorStatus={orchestratorStatus}
            />
            <div className="flex flex-1 overflow-hidden pt-16 bg-background-light dark:bg-background-dark">
                <AnimatePresence mode="wait">
                    {isLeftPanelOpen ? (
                        <motion.aside
                            key="left-panel-main"
                            initial={{ x: '-100%', opacity: 0 }}
                            animate={{ x: '0%', opacity: 1 }}
                            exit={{ x: '-100%', opacity: 0 }}
                            transition={{ type: 'spring', stiffness: 300, damping: 30 }}
                            className="w-full md:w-72 lg:w-80 xl:w-96 bg-surface-light dark:bg-surface-dark border-r border-border-light dark:border-border-dark overflow-y-auto p-3 sm:p-4 shadow-lg flex-shrink-0 custom-scrollbar"
                        >
                            <LeftPanel />
                        </motion.aside>
                    ) : (
                        <LeftCollapsedNav />
                    )}
                </AnimatePresence>

                <main className={`flex-1 flex flex-col overflow-hidden p-1 sm:p-2 md:p-4
                                 transition-all duration-300 ease-in-out
                                 ${isLeftPanelOpen ? 'lg:ml-0' : 'lg:ml-16 md:ml-14'}
                                 ${isRightPanelOpen ? 'lg:mr-0' : 'lg:mr-16 md:mr-14'}`}>
                    <CenterPanel
                        messages={appStateMessages}
                        setMessages={setAppStateMessages}
                        currentSessionId={currentSessionId}
                        chatStatus={appStateChatStatus}
                        setChatStatus={setAppStateChatStatus}
                    />
                </main>

                <AnimatePresence mode="wait">
                    {isRightPanelOpen ? (
                        <motion.aside
                            key="right-panel-main"
                            initial={{ x: '100%', opacity: 0 }}
                            animate={{ x: '0%', opacity: 1 }}
                            exit={{ x: '100%', opacity: 0 }}
                            transition={{ type: 'spring', stiffness: 300, damping: 30 }}
                            className="hidden md:flex md:flex-col md:w-72 lg:w-80 xl:w-96 bg-surface-light dark:bg-surface-dark border-l border-border-light dark:border-border-dark overflow-y-auto p-3 sm:p-4 shadow-lg flex-shrink-0 custom-scrollbar"
                        >
                            <RightPanel />
                        </motion.aside>
                    ) : (
                        <RightCollapsedNav />
                    )}
                </AnimatePresence>
            </div>
            <ChatHistoryModal
                isOpen={isHistoryModalOpen}
                onClose={() => setIsHistoryModalOpen(false)}
                onSelectSession={handleSelectSessionFromHistory}
            />
        </>
    );
}


// Main App Component - Handles top-level routing and auth state logic
function App() {
    const { token: regularUserToken, user: regularUser, loading: regularUserAuthLoading, setUser: setRegularUserInAuthContext } = useRegularAuth();
    const { theme, setSessionId: setGlobalSessionId, currentSessionId, isAdminSessionActive } = useAppState(); // Removed setIsAdminSessionActive as it's set by AuthModal

    const navigate = useNavigate();
    const location = useLocation();

    const [appInitializing, setAppInitializing] = useState(true);
    const [showAuthModal, setShowAuthModal] = useState(false);
    const [orchestratorStatus, setOrchestratorStatus] = useState({ status: "loading", message: "Connecting..." });

    // Effect for theme
    useEffect(() => {
        const rootHtmlElement = document.documentElement;
        rootHtmlElement.classList.remove('light', 'dark');
        rootHtmlElement.classList.add(theme);
        document.body.className = '';
        document.body.classList.add(theme === 'dark' ? 'bg-background-dark' : 'bg-background-light');
    }, [theme]);

    // Effect for orchestrator status
    useEffect(() => {
        api.getOrchestratorStatus().then(setOrchestratorStatus);
    }, []);

    // Effect for Authentication, Initialization, and Routing
    useEffect(() => {
        // console.log("App.jsx: Auth/Init Effect | regularUserAuthLoading:", regularUserAuthLoading, "| regularUserToken:", !!regularUserToken, "| regularUser:", regularUser, "| isAdminSessionActive:", isAdminSessionActive, "| Path:", location.pathname);

        // Prioritize admin session: if active, ensure they are on admin path
        if (isAdminSessionActive) {
            setAppInitializing(false); // Ensure loader is hidden
            setShowAuthModal(false);
            if (!location.pathname.startsWith('/admin')) {
                navigate('/admin/dashboard', { replace: true });
            }
            return;
        }

        // If admin session is not active, proceed with regular user auth logic
        if (regularUserAuthLoading) {
            // console.log("App.jsx: Regular user auth is loading...");
            setAppInitializing(true); // Show loader while regular auth context determines state
            return;
        }

        setAppInitializing(false); // Regular auth has finished loading

        if (regularUserToken && regularUser) {
            // Regular user is authenticated
            setShowAuthModal(false);
            if (location.pathname.startsWith('/admin')) {
                // A regular user tried to access an admin path, redirect them
                // console.log("App.jsx: Regular user on admin path, redirecting to /");
                navigate('/', { replace: true });
            } else if (!currentSessionId && !location.pathname.startsWith('/admin')) { // Only start session if not on admin path
                // console.log("App.jsx: Regular user logged in, no session, starting new one.");
                api.startNewSession(null).then(data => { // Pass null for no previous session
                    if (data && data.newSessionId) {
                        setGlobalSessionId(data.newSessionId);
                    }
                }).catch(err => {
                    toast.error("Failed to start initial session.");
                    console.error("App.jsx: Error starting initial session:", err);
                });
            }
        } else {
            // No regular user token/user, and not an admin session
            if (!location.pathname.startsWith('/admin')) {
                setShowAuthModal(true);
            }
        }
    }, [
        regularUserAuthLoading, regularUserToken, regularUser,
        isAdminSessionActive,
        currentSessionId, setGlobalSessionId,
        navigate, location.pathname
    ]);

    const handleAuthSuccess = (authDataFromModal) => {
        setShowAuthModal(false);
        if (authDataFromModal && !authDataFromModal.isAdminLogin && authDataFromModal.token) {
            // For a regular user, start a completely fresh session on successful login
            api.startNewSession(null).then(data => { // Pass null, as there's no previous session to summarize
                if (data && data.newSessionId) {
                    setGlobalSessionId(data.newSessionId);
                }
            });
            if (authDataFromModal.username && authDataFromModal._id && authDataFromModal.role) {
                setRegularUserInAuthContext({
                    id: authDataFromModal._id,
                    username: authDataFromModal.username,
                    role: authDataFromModal.role
                });
            }
        } else if (authDataFromModal && authDataFromModal.isAdminLogin) {
            // Admin "login" handled by AuthModal. useEffect will handle navigation.
        }
    };

    if (appInitializing) {
        return (
            <div className="fixed inset-0 flex flex-col items-center justify-center bg-background-light dark:bg-background-dark text-text-light dark:text-text-dark">
                <div className="animate-spin rounded-full h-12 w-12 border-t-4 border-b-4 border-primary mb-4"></div>
                <p className="text-xl">Initializing AI Tutor...</p>
            </div>
        );
    }

    return (
        <div className={`flex flex-col h-screen overflow-hidden font-sans ${theme}`}>
            <AnimatePresence>
                {showAuthModal && !regularUserToken && !isAdminSessionActive && !location.pathname.startsWith('/admin') && (
                    <AuthModal isOpen={showAuthModal} onClose={handleAuthSuccess} />
                )}
            </AnimatePresence>

            <Routes>
                <Route path="/admin/dashboard" element={
                    <AdminProtectedRoute>
                        <AdminDashboardPage />
                    </AdminProtectedRoute>
                } />

                <Route path="/*" element={
                    isAdminSessionActive ? <Navigate to="/admin/dashboard" replace /> :
                        (regularUserToken && regularUser) ? <MainAppLayout orchestratorStatus={orchestratorStatus} /> :
                            (location.pathname.startsWith('/admin')) ? <Navigate to="/" replace /> :
                                null
                } />
            </Routes>
        </div>
    );
}

// AppWrapper to provide Router context
function AppWrapper() {
    return (
        <Router>
            <App />
        </Router>
    );
}

export default AppWrapper;
```

`frontend/src/components/admin/AdminDashboardPage.jsx`

```javascript
// frontend/src/pages/AdminDashboardPage.jsx
import React, { useState, useEffect, useCallback, useRef } from 'react';
import { useNavigate } from 'react-router-dom';
import { useAppState } from '../../contexts/AppStateContext.jsx';
import * as adminApi from '../../services/adminApi.js';
import Button from '../core/Button.jsx';
import IconButton from '../core/IconButton.jsx';
import Modal from '../core/Modal.jsx';
import { UploadCloud, FileText, Trash2, Eye, LogOut, Loader2, AlertTriangle, CheckCircle, RefreshCw } from 'lucide-react';
import toast from 'react-hot-toast';
import { format } from 'date-fns'; // For formatting dates

// --- AdminDocumentUpload Component (child of AdminDashboardPage) ---
function AdminDocumentUpload({ onUploadSuccess }) {
    const [selectedFile, setSelectedFile] = useState(null);
    const [isUploading, setIsUploading] = useState(false);
    const fileInputRef = useRef(null);

    const handleFileChange = (e) => {
        if (isUploading) return;
        const file = e.target.files && e.target.files[0];
        if (file) setSelectedFile(file);
        else setSelectedFile(null);
    };

    const handleUpload = async () => {
        if (!selectedFile) {
            toast.error("Please select a file to upload.");
            return;
        }
        setIsUploading(true);
        const toastId = toast.loading(`Uploading "${selectedFile.name}"...`);
        const formData = new FormData();
        formData.append('file', selectedFile);

        try {
            const authHeaders = adminApi.getFixedAdminAuthHeaders(); // Get Basic Auth headers
            const response = await adminApi.uploadAdminDocument(formData, authHeaders);
            toast.success(response.message || `Admin document "${selectedFile.name}" uploaded. Analysis initiated.`, { id: toastId });
            onUploadSuccess(); // Callback to refresh document list in parent
            setSelectedFile(null);
            if (fileInputRef.current) fileInputRef.current.value = null;
        } catch (error) {
            // error.message now comes from makeAdminApiRequest's error handling
            toast.error(error.message || `Failed to upload admin document "${selectedFile.name}".`, { id: toastId });
        } finally {
            setIsUploading(false);
        }
    };

    return (
        <div className="card-base p-4 mb-6">
            <h2 className="text-lg font-semibold mb-3 text-text-light dark:text-text-dark">Upload New Admin Document</h2>
            <div className="flex flex-col sm:flex-row items-stretch sm:items-center gap-3">
                <input
                    type="file"
                    ref={fileInputRef}
                    onChange={handleFileChange}
                    className="input-field flex-grow text-sm p-2.5 min-h-[44px]"
                    accept=".pdf,.docx,.txt,.md" // Should match allowedAdminExtensions in backend multer
                    disabled={isUploading}
                />
                <Button
                    onClick={handleUpload}
                    isLoading={isUploading}
                    disabled={!selectedFile || isUploading}
                    leftIcon={<UploadCloud size={16} />}
                    size="md" // Consistent with other buttons
                    className="w-full sm:w-auto !py-2.5" // Tailwind class for padding
                >
                    Upload
                </Button>
            </div>
            {selectedFile && !isUploading && (
                <p className="text-xs mt-2 text-text-muted-light dark:text-text-muted-dark">
                    Selected: {selectedFile.name} ({(selectedFile.size / 1024).toFixed(1)} KB)
                </p>
            )}
        </div>
    );
}

// --- Main AdminDashboardPage Component ---
function AdminDashboardPage() {
    const { setIsAdminSessionActive } = useAppState(); // For admin logout
    const navigate = useNavigate();

    const [documents, setDocuments] = useState([]); // List of admin documents
    const [isLoading, setIsLoading] = useState(true); // Loading state for document list
    const [error, setError] = useState(''); // Error message for document list fetching

    const [isAnalysisModalOpen, setIsAnalysisModalOpen] = useState(false);
    const [currentDocForModal, setCurrentDocForModal] = useState(null); // Doc whose analysis is being viewed
    const [analysisContent, setAnalysisContent] = useState(null); // {faq, topics, mindmap}
    const [isLoadingAnalysis, setIsLoadingAnalysis] = useState(false); // Loading state for fetching analysis

    const adminLogoutHandler = () => {
        setIsAdminSessionActive(false); // Clear the admin session flag in AppState
        toast.success("Admin logged out.");
        navigate('/'); // Navigate to the main page (AuthModal will show if no regular user)
    };

    const fetchAdminDocs = useCallback(async (showLoadingToast = false) => {
        let toastId;
        if (showLoadingToast) {
            toastId = toast.loading("Refreshing document list...");
        } else {
            setIsLoading(true); // For initial load or non-toast refresh
        }
        setError('');
        try {
            const authHeaders = adminApi.getFixedAdminAuthHeaders();
            const response = await adminApi.getAdminDocuments(authHeaders);
            setDocuments(Array.isArray(response.documents) ? response.documents : []);
            if (showLoadingToast) toast.success("Document list refreshed.", { id: toastId });
        } catch (err) {
            const errorMessage = err.message || "Failed to fetch admin documents.";
            setError(errorMessage);
            if (showLoadingToast) toast.error(errorMessage, { id: toastId });
            else toast.error(errorMessage); // Show toast on initial load failure too
        } finally {
            if (!showLoadingToast) setIsLoading(false);
        }
    }, []); // No dependencies that change frequently, getFixedAdminAuthHeaders is stable

    useEffect(() => {
        fetchAdminDocs(); // Fetch documents when component mounts
    }, [fetchAdminDocs]);

    const handleDeleteDocument = async (serverFilename, originalName) => {
        if (!window.confirm(`Are you sure you want to delete admin document "${originalName}"? This action will remove its record and any associated analysis.`)) return;
        
        const toastId = toast.loading(`Deleting "${originalName}"...`);
        try {
            const authHeaders = adminApi.getFixedAdminAuthHeaders();
            await adminApi.deleteAdminDocument(serverFilename, authHeaders);
            toast.success(`Admin document "${originalName}" deleted.`, { id: toastId });
            fetchAdminDocs(); // Refresh the list
            if (isAnalysisModalOpen && currentDocForModal?.serverFilename === serverFilename) {
                setIsAnalysisModalOpen(false); // Close modal if the deleted doc was being viewed
            }
        } catch (err) {
            toast.error(err.message || `Failed to delete "${originalName}".`, { id: toastId });
        }
    };

    const handleViewAnalysis = async (doc) => {
        setCurrentDocForModal(doc);
        setAnalysisContent(null);      // Clear previous analysis
        setIsAnalysisModalOpen(true); // Open modal
        setIsLoadingAnalysis(true);   // Set loading state for analysis
        try {
            const authHeaders = adminApi.getFixedAdminAuthHeaders();
            const response = await adminApi.getAdminDocumentAnalysis(doc.serverFilename, authHeaders);
            setAnalysisContent(response.analysis); // response.analysis = {faq, topics, mindmap}
            // toast.success(`Analysis loaded for ${doc.originalName}`); // Optional success toast
        } catch (err) {
            toast.error(`Failed to load analysis for ${doc.originalName}: ${err.message}`);
            setAnalysisContent({ error: `Failed to load analysis: ${err.message}` }); // Show error in modal
        } finally {
            setIsLoadingAnalysis(false);
        }
    };

    const renderAnalysisModalContent = () => {
        if (!currentDocForModal) return null; // Should not happen if modal is open

        if (isLoadingAnalysis) {
            return <div className="p-6 text-center"><Loader2 className="animate-spin text-primary inline-block mr-2"/>Loading analysis content...</div>;
        }
        if (!analysisContent) {
            return <div className="p-4 text-text-muted-light dark:text-text-muted-dark">No analysis data currently available for this document. It might still be processing or was skipped.</div>;
        }
        if (analysisContent.error) {
            return <div className="p-4 text-red-500 dark:text-red-400 text-sm">Error: {analysisContent.error}</div>;
        }

        // Check if all analysis fields are effectively empty or placeholder messages
        const isEmpty = (str) => !str || str.trim() === "" || str.toLowerCase().startsWith("skipped:") || str.toLowerCase().startsWith("notice:");
        const allAnalysesEmpty = isEmpty(analysisContent.faq) && isEmpty(analysisContent.topics) && isEmpty(analysisContent.mindmap);

        if (allAnalysesEmpty) {
            return <div className="p-4 text-text-muted-light dark:text-text-muted-dark">Analysis processing may have been skipped or resulted in no content for all types.</div>;
        }

        return (
            <div className="space-y-3 max-h-[70vh] overflow-y-auto custom-scrollbar p-1 pr-2">
                {Object.entries(analysisContent).map(([key, value]) => {
                    const displayValue = (typeof value === 'string' && value.trim()) ? value : `No content generated for ${key}.`;
                    return (
                        <details key={key} className="text-xs rounded-md border border-border-light dark:border-border-dark bg-surface-light dark:bg-surface-dark" open>
                            <summary className="font-medium cursor-pointer capitalize p-2 bg-gray-50 dark:bg-gray-700/60 hover:bg-gray-100 dark:hover:bg-gray-600/60 rounded-t-md transition-colors">
                                {key.replace(/([A-Z])/g, ' $1').trim()} {/* e.g., mindmap -> Mind Map */}
                            </summary>
                            <pre className="p-2.5 bg-white dark:bg-gray-800 text-text-light dark:text-text-dark text-[0.7rem] max-h-60 overflow-y-auto custom-scrollbar whitespace-pre-wrap break-words rounded-b-md">
                                <code>{displayValue}</code>
                            </pre>
                        </details>
                    );
                })}
            </div>
        );
    };
    
    // --- Main JSX for AdminDashboardPage ---
    return (
        <div className="min-h-screen bg-background-light dark:bg-background-dark text-text-light dark:text-text-dark p-4 sm:p-6">
            <header className="flex items-center justify-between mb-6 pb-3 border-b border-border-light dark:border-border-dark">
                <h1 className="text-2xl font-bold">Admin Dashboard</h1>
                <div className="flex items-center gap-2">
                    <IconButton
                        icon={RefreshCw}
                        onClick={() => fetchAdminDocs(true)} // Pass true to show loading toast
                        title="Refresh Document List"
                        variant="ghost"
                        size="md"
                        className="text-text-muted-light dark:text-text-muted-dark hover:text-primary"
                    />
                    <Button onClick={adminLogoutHandler} variant="danger" size="sm" leftIcon={<LogOut size={16}/>}>
                        Logout Admin
                    </Button>
                </div>
            </header>

            <AdminDocumentUpload onUploadSuccess={() => fetchAdminDocs(false)} /> {/* Don't show toast for auto-refresh */}

            <div className="card-base p-0 sm:p-4">
                <h2 className="text-lg font-semibold mb-3 text-text-light dark:text-text-dark px-4 sm:px-0 pt-4 sm:pt-0">
                    Uploaded Admin Documents
                </h2>
                {isLoading && (
                    <div className="flex items-center justify-center p-6">
                        <Loader2 size={24} className="animate-spin text-primary mr-2" /> Loading documents...
                    </div>
                )}
                {error && (
                    <div className="p-3 my-3 mx-4 sm:mx-0 bg-red-500/10 border border-red-500/30 text-red-600 dark:text-red-300 rounded-md text-sm flex items-center gap-2">
                        <AlertTriangle size={18} /> {error}
                        <button onClick={() => fetchAdminDocs(true)} className="ml-auto text-xs underline hover:text-red-400">Retry</button>
                    </div>
                )}
                {!isLoading && !error && documents.length === 0 && (
                    <p className="text-center text-sm text-text-muted-light dark:text-text-muted-dark py-6 px-4 sm:px-0">
                        No admin documents uploaded yet.
                    </p>
                )}
                {!isLoading && !error && documents.length > 0 && (
                    <div className="overflow-x-auto custom-scrollbar">
                        <table className="w-full text-sm text-left">
                            <thead className="bg-gray-50 dark:bg-gray-800">
                                <tr>
                                    <th className="px-3 sm:px-4 py-2.5 font-medium">Original Name</th>
                                    <th className="px-3 sm:px-4 py-2.5 font-medium hidden md:table-cell">Uploaded</th>
                                    <th className="px-3 sm:px-4 py-2.5 font-medium">Analysis Status</th>
                                    <th className="px-3 sm:px-4 py-2.5 font-medium text-center">Actions</th>
                                </tr>
                            </thead>
                            <tbody>
                                {documents.map((doc) => (
                                    <tr key={doc.serverFilename} className="border-b border-border-light dark:border-border-dark hover:bg-gray-50/50 dark:hover:bg-gray-700/30 transition-colors">
                                        <td className="px-3 sm:px-4 py-2 truncate max-w-[150px] sm:max-w-xs" title={doc.originalName}>{doc.originalName}</td>
                                        <td className="px-3 sm:px-4 py-2 whitespace-nowrap hidden md:table-cell">
                                            {doc.uploadedAt ? format(new Date(doc.uploadedAt), 'MMM d, yyyy HH:mm') : 'N/A'}
                                        </td>
                                        <td className="px-3 sm:px-4 py-2">
                                            {(doc.hasFaq || doc.hasTopics || doc.hasMindmap) ? (
                                                <span className="flex items-center text-green-600 dark:text-green-400 text-xs">
                                                    <CheckCircle size={14} className="mr-1"/> Generated
                                                </span>
                                            ) : (
                                                doc.analysisUpdatedAt ? // If updated but still no content, means it was empty
                                                <span className="text-gray-500 dark:text-gray-400 text-xs">Empty/Skipped</span> :
                                                <span className="text-yellow-500 dark:text-yellow-400 text-xs">Pending</span>
                                            )}
                                        </td>
                                        <td className="px-1 sm:px-4 py-2 text-center whitespace-nowrap">
                                            <IconButton
                                                icon={Eye}
                                                title="View Analysis"
                                                size="sm"
                                                variant="ghost"
                                                className="text-primary hover:text-primary-dark dark:text-primary-light dark:hover:text-primary-darker mr-0.5 sm:mr-1"
                                                onClick={() => handleViewAnalysis(doc)}
                                                disabled={isLoadingAnalysis && currentDocForModal?.serverFilename === doc.serverFilename}
                                            />
                                            <IconButton
                                                icon={Trash2}
                                                title="Delete Document"
                                                size="sm"
                                                variant="ghost"
                                                className="text-red-500 hover:text-red-700 dark:text-red-400 dark:hover:text-red-300"
                                                onClick={() => handleDeleteDocument(doc.serverFilename, doc.originalName)}
                                            />
                                        </td>
                                    </tr>
                                ))}
                            </tbody>
                        </table>
                    </div>
                )}
            </div>

            <Modal
                isOpen={isAnalysisModalOpen}
                onClose={() => setIsAnalysisModalOpen(false)}
                title={`Analysis Results: ${currentDocForModal?.originalName || 'Document'}`}
                size="2xl"
            >
                {renderAnalysisModalContent()}
            </Modal>
        </div>
    );
}

export default AdminDashboardPage;
```

`frontend/src/components/admin/AdminProtectedRoute.jsx`

```javascript
// frontend/src/components/admin/AdminProtectedRoute.jsx
import React from 'react';
import { Navigate, Outlet, useLocation } from 'react-router-dom';
import { useAppState } from '../../contexts/AppStateContext.jsx'; // Using AppStateContext
import toast from 'react-hot-toast'; // Optional: for a message if redirecting

function AdminProtectedRoute({ children }) { // Accept children for different react-router-dom versions
    const { isAdminSessionActive } = useAppState(); // Get the admin session flag
    const location = useLocation();

    if (!isAdminSessionActive) {
        // If admin session is not active, redirect the user.
        // Redirecting to the main page ('/') is a common approach.
        // The main App component's logic will then likely show the AuthModal
        // if no regular user is logged in either.
        console.log("AdminProtectedRoute: Admin session not active. Redirecting from", location.pathname);
        toast.error("Admin access required. Please log in as admin."); // Optional feedback
        return <Navigate to="/" state={{ from: location }} replace />;
    }

    // If admin session is active, render the child components (the protected route's content)
    return children ? children : <Outlet />; // Outlet is for v6 nested routes, children for direct wrapping
}

export default AdminProtectedRoute;
```

`frontend/src/components/analysis/AnalysisTool.jsx`

```javascript
// frontend/src/components/analysis/AnalysisTool.jsx
import React, { useState } from 'react';
import api from '../../services/api.js'; // Assuming .js for services
import toast from 'react-hot-toast';
import MindmapViewer from './MindmapViewer.jsx';
import { ChevronDown, ChevronUp, Loader2, AlertTriangle } from 'lucide-react'; // Loader2 is imported once here
import * as LucideIcons from 'lucide-react'; // For dynamic icon selection by name
import { marked } from 'marked';
import Button from '../core/Button.jsx';
import IconButton from '../core/IconButton.jsx'; // Import IconButton
import { motion } from 'framer-motion'; // Import motion
import DOMPurify from 'dompurify';

marked.setOptions({
  breaks: true,
  gfm: true,
});

const createMarkup = (markdownText) => {
    if (!markdownText) return { __html: '' };
    const rawHtml = marked.parse(markdownText);
    const cleanHtml = DOMPurify.sanitize(rawHtml);
    return { __html: cleanHtml };
};

const escapeHtml = (unsafe) => { // Helper for <pre> tags if thinking content isn't markdown
    if (typeof unsafe !== 'string') return '';
    return unsafe
         .replace(/&/g, "&")
         .replace(/</g, "<")
         .replace(/>/g, ">")
         .replace(/"/g, '"')
         .replace(/'/g, "'");
};

function AnalysisTool({ toolType, title, iconName, selectedDocumentFilename }) {
    const [isOpen, setIsOpen] = useState(false);
    const [result, setResult] = useState(null);
    const [thinking, setThinking] = useState(null);
    const [isLoading, setIsLoading] = useState(false);
    const [error, setError] = useState('');
    const [isFetchingStored, setIsFetchingStored] = useState(false); // For fetching stored data


    // Dynamically select icon component based on iconName prop
    const IconComponent = LucideIcons[iconName] || LucideIcons.HelpCircle; // Default to HelpCircle if not found
    console.log('selectedDocumentFilename :::: ', selectedDocumentFilename);
    

    


    const handleRunAnalysis = async () => {
        if (!selectedDocumentFilename) {
            toast.error("Please select a document from the left panel first.");
            return;
        }
        setIsLoading(true);
        setError('');
        setResult(null);
        setThinking(null);
        const toastId = toast.loading(`Generating ${title} for ${selectedDocumentFilename}...`);

        try {
            
            const payload = { filename: selectedDocumentFilename, analysis_type: toolType };
            const response = await api.requestAnalysis(payload); // Mocked in V1
            setResult(response.content);
            setThinking(response.thinking);
            setIsOpen(true); 
            toast.success(`${title} generated (mock data)!`, { id: toastId });
        } catch (err) {
            const errorMessage = err.response?.data?.message || err.message || `Failed to generate ${title}.`;
            setError(errorMessage);
            toast.error(errorMessage, { id: toastId });
            console.error("AnalysisTool Error:", err);
        } finally {
            setIsLoading(false);
        }
    };

    return (
        <div className="card-base p-3"> {/* Use themed card style from index.css */}
            <div className="flex items-center justify-between">
                <button 
                    onClick={() => setIsOpen(!isOpen)}
                    className="flex items-center gap-2 text-sm font-medium text-text-light dark:text-text-dark focus:outline-none w-full text-left hover:text-primary dark:hover:text-primary-light transition-colors"
                    aria-expanded={isOpen}
                >
                    <IconComponent size={16} className="text-primary dark:text-primary-light flex-shrink-0" />
                    <span className="flex-grow">{title}</span>
                </button>
                <div className="flex items-center gap-1 flex-shrink-0">
                    <Button
                        onClick={handleRunAnalysis}
                        variant="primary" 
                        size="sm"
                        className="!px-3 !py-1 text-xs" // Override Button padding for smaller size
                        isLoading={isLoading} // Button component handles its own loader icon
                        disabled={isLoading || !selectedDocumentFilename}
                        title={!selectedDocumentFilename ? "Select a document first" : `Run ${title} Analysis`}
                    >
                       Run
                    </Button>
                    <IconButton 
                        icon={isOpen ? ChevronUp : ChevronDown} 
                        onClick={() => setIsOpen(!isOpen)} 
                        size="sm" 
                        variant="ghost"
                        className="p-1" // Ensure IconButton has padding if its default is too large
                        aria-label={isOpen ? "Collapse section" : "Expand section"}
                    />
                </div>
            </div>

            {isOpen && (
                <motion.div 
                    initial={{ height: 0, opacity: 0 }} 
                    animate={{ height: 'auto', opacity: 1 }} 
                    exit={{ height: 0, opacity: 0 }}
                    transition={{ duration: 0.2, ease: "easeInOut" }}
                    className="mt-2 pt-2 border-t border-border-light dark:border-border-dark overflow-hidden" 
                >
                    <div className="space-y-2"> {/* Added wrapper for consistent spacing */}
                        {isLoading && (
                            <p className="text-xs text-text-muted-light dark:text-text-muted-dark p-2 flex items-center gap-2">
                                <Loader2 size={14} className="animate-spin"/>Generating...
                            </p>
                        )}
                        {error && (
                            <div className="p-2 bg-red-500/10 border border-red-500/30 text-red-600 dark:text-red-300 rounded-md text-xs flex items-center gap-1">
                                <AlertTriangle size={14} /> {error}
                            </div>
                        )}
                        {thinking && !error && (
                            <details className="text-xs" open={!!result}> {/* Open if result is also present */}
                                <summary className="cursor-pointer text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light font-medium">
                                    AI Reasoning
                                </summary>
                                <pre className="mt-1 p-1.5 bg-gray-100 dark:bg-gray-900 rounded text-[0.7rem] max-h-28 overflow-y-auto custom-scrollbar whitespace-pre-wrap break-words">
                                    <code>{escapeHtml(thinking)}</code>
                                </pre>
                            </details>
                        )}
                        {result && !error && (
                            toolType === 'mindmap' ? (
                                <MindmapViewer markdownContent={result} />
                            ) : (
                                <div 
                                    className="prose prose-xs dark:prose-invert max-w-none text-text-light dark:text-text-dark p-1 max-h-60 overflow-y-auto custom-scrollbar text-[0.75rem] leading-relaxed"
                                    dangerouslySetInnerHTML={createMarkup(result)}
                                />
                            )
                        )}
                        {!isLoading && !result && !error && !selectedDocumentFilename && (
                             <p className="text-xs text-text-muted-light dark:text-text-muted-dark p-2">Select a document to run analysis.</p>
                        )}
                         {!isLoading && !result && !error && selectedDocumentFilename && (
                             <p className="text-xs text-text-muted-light dark:text-text-muted-dark p-2">Click "Run" to generate analysis.</p>
                        )}
                    </div>
                </motion.div>
            )}
        </div>
    );
}
export default AnalysisTool;
```

`frontend/src/components/analysis/AnalysisToolRunner.jsx`

```javascript
// frontend/src/components/analysis/AnalysisToolRunner.jsx
import React, { useState, useEffect, useCallback, useRef } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import api from '../../services/api.js'; // For user documents
import * as adminApi from '../../services/adminApi.js'; // For admin documents
import toast from 'react-hot-toast';
import { ChevronDown, ChevronUp, Loader2, Eye, AlertTriangle, Sparkles, HelpCircle as DefaultIcon, Download } from 'lucide-react';
import * as LucideIcons from 'lucide-react';
import Button from '../core/Button.jsx';
import IconButton from '../core/IconButton.jsx';
import Modal from '../core/Modal.jsx';
import { marked } from 'marked';
import MindmapViewer from './MindmapViewer.jsx';
import DOMPurify from 'dompurify';
import Prism from 'prismjs';
import { renderMathInHtml } from '../../utils/markdownUtils';
import { useAppState } from '../../contexts/AppStateContext.jsx';

marked.setOptions({
  breaks: true,
  gfm: true,
});

const createMarkup = (markdownText) => {
    if (!markdownText) return { __html: '' };
    let html = marked.parse(markdownText);
    html = renderMathInHtml(html);
    const cleanHtml = DOMPurify.sanitize(html, {
        USE_PROFILES: { html: true, mathMl: true, svg: true },
        ADD_TAGS: ['iframe'],
        ADD_ATTR: ['allow', 'allowfullscreen', 'frameborder', 'scrolling'],
    });
    return { __html: cleanHtml };
};

const localParseAnalysisOutput = (rawOutput) => {
    if (!rawOutput || typeof rawOutput !== 'string') {
        return { content: '', thinking: '' };
    }
    const thinkingMatch = rawOutput.match(/<thinking>([\s\S]*?)<\/thinking>/i);
    let thinkingText = '';
    let mainContent = rawOutput;

    if (thinkingMatch && thinkingMatch[1]) {
        thinkingText = thinkingMatch[1].trim();
        mainContent = rawOutput.replace(/<thinking>[\s\S]*?<\/thinking>\s*/i, '').trim();
    }
    return { content: mainContent, thinking: thinkingText };
};

const ENGAGEMENT_TEXTS = {
    faq: ["Analyzing FAQs...", "Identifying questions...", "Compiling answers..."],
    topics: ["Extracting topics...", "Identifying themes...", "Summarizing points..."],
    mindmap: ["Generating mind map...", "Structuring concepts...", "Visualizing..."],
    default: ["Processing...", "Thinking...", "Working on it..."]
};

const placeholderReasoningMessages = [
    "Retrieved stored analysis. No detailed AI reasoning provided.",
    "AI reasoning not available.",
    "Mock generation for",
    "Retrieved stored mindmap data. No specific thinking process recorded in content.",
    "Retrieved stored admin analysis entry, but content for this type was empty.", // Added for admin docs
    "Retrieved stored admin analysis." // Added for admin docs
];

// Added isTargetAdminDoc prop
function AnalysisToolRunner({ toolType, title, iconName, selectedDocumentFilename, isTargetAdminDoc }) {
    const [isSectionOpen, setIsSectionOpen] = useState(true);
    const [isDropdownOpen, setIsDropdownOpen] = useState(false);
    const [isLoading, setIsLoading] = useState(false);
    const [error, setError] = useState('');
    const [analysisContent, setAnalysisContent] = useState(null);
    const [aiReasoning, setAiReasoning] = useState(null);
    const [isModalOpen, setIsModalOpen] = useState(false);
    const [currentEngagementText, setCurrentEngagementText] = useState('');

    const IconComponent = LucideIcons[iconName] || DefaultIcon;
    const modalAnalysisContentRef = useRef(null);
    const aiReasoningContentRef = useRef(null);
    const mindmapViewerRef = useRef(null);
    const { theme: appTheme } = useAppState();

    useEffect(() => {
        let intervalId;
        if (isLoading) {
            const texts = ENGAGEMENT_TEXTS[toolType] || ENGAGEMENT_TEXTS.default;
            let textIndex = 0;
            setCurrentEngagementText(texts[0]);
            intervalId = setInterval(() => {
                textIndex = (textIndex + 1) % texts.length;
                setCurrentEngagementText(texts[textIndex]);
            }, 1800);
        } else {
            setCurrentEngagementText('');
        }
        return () => clearInterval(intervalId);
    }, [isLoading, toolType]);

    useEffect(() => { // Reset when selected document changes
        if (!selectedDocumentFilename) {
            setIsLoading(false); setError(''); setAnalysisContent(null);
            setAiReasoning(null); setIsDropdownOpen(false);
        } else {
             setAnalysisContent(null); setAiReasoning(null);
             setIsDropdownOpen(false); setError(''); setIsLoading(false);
        }
    }, [selectedDocumentFilename]);

    useEffect(() => { // Prism for modal content
        if (isModalOpen && analysisContent && toolType !== 'mindmap' && modalAnalysisContentRef.current) {
            const timer = setTimeout(() => {
                if (modalAnalysisContentRef.current) Prism.highlightAllUnder(modalAnalysisContentRef.current);
            }, 50);
            return () => clearTimeout(timer);
        }
    }, [isModalOpen, analysisContent, toolType]);

    useEffect(() => { // Prism for AI reasoning
        if (aiReasoningContentRef.current && aiReasoning && isDropdownOpen) {
            const timer = setTimeout(() => {
                if (aiReasoningContentRef.current) Prism.highlightAllUnder(aiReasoningContentRef.current);
            }, 0);
            return () => clearTimeout(timer);
        }
    }, [aiReasoning, isDropdownOpen]);

    const handleRunAnalysis = async () => {
        if (!selectedDocumentFilename) {
            toast.error("Please select a document first.");
            return;
        }
        setIsLoading(true); setError(''); setAnalysisContent(null);
        setAiReasoning(null); setIsDropdownOpen(false);

        const toastMessage = isTargetAdminDoc
            ? `Fetching stored ${title.toLowerCase()} for "${selectedDocumentFilename}"...`
            : `Generating ${title.toLowerCase()} for "${selectedDocumentFilename}"...`;
        const toastId = toast.loading(toastMessage);

        try {
            let response;
            if (isTargetAdminDoc) {
                console.log(`AnalysisToolRunner: Fetching ADMIN analysis for "${selectedDocumentFilename}", type: ${toolType}`);
                const authHeaders = adminApi.getFixedAdminAuthHeaders(); // Get admin auth
                // Fetches { originalName, serverFilename, analysis: {faq, topics, mindmap}, analysisUpdatedAt }
                const adminAnalysisData = await adminApi.getAdminDocumentAnalysisByOriginalName(selectedDocumentFilename, authHeaders);

                if (adminAnalysisData && adminAnalysisData.analysis && adminAnalysisData.analysis[toolType] !== undefined) {
                    const rawOutput = adminAnalysisData.analysis[toolType];
                    if (rawOutput === null || typeof rawOutput !== 'string' || rawOutput.trim() === "") {
                        // Content for this specific analysis type is empty or null
                         response = {
                            content: `Notice: No stored ${toolType} analysis found for admin document "${selectedDocumentFilename}". The admin might not have generated this specific analysis type yet, or it was empty.`,
                            thinking: "Retrieved stored admin analysis entry, but content for this type was empty."
                        };
                        toast.success(`No stored ${toolType} found for admin doc "${selectedDocumentFilename}".`, { id: toastId });
                    } else {
                        const parsed = localParseAnalysisOutput(rawOutput);
                        response = { content: parsed.content, thinking: parsed.thinking || "Retrieved stored admin analysis." };
                        toast.success(`Retrieved stored admin ${title} for "${selectedDocumentFilename}"!`, { id: toastId });
                    }
                } else {
                    throw new Error(`Admin analysis for type '${toolType}' not found or response format invalid for document "${selectedDocumentFilename}".`);
                }
            } else { // User document
                console.log(`AnalysisToolRunner: Requesting USER analysis for "${selectedDocumentFilename}", type: ${toolType}`);
                const payload = { filename: selectedDocumentFilename, analysis_type: toolType };
                response = await api.requestAnalysis(payload); // This uses the mock/frontend API for user docs
                // The success toast for user docs is handled inside api.requestAnalysis mock for now.
                // If it were a real API, we might add toast.success here.
                // For consistency with admin path:
                if (response && response.content && !response.content.startsWith("Error:")) {
                    toast.success(`${title} generated for "${selectedDocumentFilename}"!`, { id: toastId });
                } else {
                    toast.dismiss(toastId); // Dismiss loading if there was an issue caught below
                }
            }

            // Common response processing
            if (response) {
                if (response.content && response.content.trim() !== "" && !response.content.startsWith("Error:") && !response.content.startsWith("Notice:")) {
                    setAnalysisContent(response.content);
                } else if (response.content && (response.content.startsWith("Error:") || response.content.startsWith("Notice:"))) {
                    // If it's an error or notice, display it as content but also set error state
                    setAnalysisContent(response.content); // Display the error/notice in the content area
                    setError(response.content); // Also set the error state for styling/logging
                    if (response.content.startsWith("Error:")) {
                         if (toast.isActive(toastId)) toast.error(`Error in ${title}: ${response.content.substring(0, 100)}...`, { id: toastId });
                         else toast.error(`Error in ${title}: ${response.content.substring(0, 100)}...`);
                    }
                } else { // No content, but not an explicit error/notice in response.content
                    setAnalysisContent(`No content was returned for ${title}.`); // Display this
                    setError(`No content returned for ${title}.`);
                    if (toast.isActive(toastId)) toast.warn(`No content was generated for ${title}.`, { id: toastId });
                    else toast.warn(`No content was generated for ${title}.`);
                }

                if (response.thinking && response.thinking.trim() !== "") {
                    setAiReasoning(response.thinking);
                } else {
                    setAiReasoning(response.content ? "Retrieved analysis. No detailed AI reasoning provided." : "AI reasoning not available.");
                }
                setIsDropdownOpen(true);
            } else {
                throw new Error("Empty or invalid response from analysis service.");
            }
        } catch (err) {
            if (toast.isActive(toastId)) toast.dismiss(toastId);
            const errorMessage = err.message || `Failed to generate or fetch ${title}.`;
            setError(errorMessage);
            setAnalysisContent(`Error: ${errorMessage}`); // Display error in content area too
            toast.error(errorMessage);
            console.error(`Run ${title} Analysis Error:`, err);
            setIsDropdownOpen(false);
        } finally {
            setIsLoading(false);
        }
    };

    const handleDownloadMindmap = async (format = 'svg') => {
        if (mindmapViewerRef.current && mindmapViewerRef.current.getSvgElement) {
            const svgElement = mindmapViewerRef.current.getSvgElement();
            if (!svgElement) {
                toast.error("Mindmap SVG element not found or not rendered yet.");
                return;
            }
            const filenameBase = selectedDocumentFilename ? selectedDocumentFilename.split('.')[0] : 'mindmap';
            const filename = `${filenameBase}_${toolType}.${format}`;
            if (format === 'svg') {
                const serializer = new XMLSerializer();
                let svgString = serializer.serializeToString(svgElement);
                svgString = '<?xml version="1.0" standalone="no"?>\r\n' + svgString;
                const blob = new Blob([svgString], { type: 'image/svg+xml;charset=utf-8' });
                const url = URL.createObjectURL(blob);
                const link = document.createElement('a');
                link.href = url; link.download = filename; document.body.appendChild(link);
                link.click(); document.body.removeChild(link); URL.revokeObjectURL(url);
                toast.success("SVG downloaded!");
            } else if (format === 'png') {
                const pngToastId = toast.loading("Preparing PNG download...");
                try {
                    const { saveSvgAsPng } = await import('save-svg-as-png');
                    if (saveSvgAsPng) {
                        saveSvgAsPng(svgElement, filename, {
                            scale: 2, backgroundColor: appTheme === 'dark' ? '#1E293B' : '#FFFFFF'
                        });
                        toast.success("PNG download started!", { id: pngToastId });
                    } else { throw new Error("saveSvgAsPng function not found."); }
                } catch (e) {
                    console.error("Error loading/using save-svg-as-png:", e);
                    toast.error(`Failed to export PNG: ${e.message}.`, { id: pngToastId });
                }
            }
        } else {
            toast.error("Mindmap viewer not ready or SVG not available.");
        }
    };

    const renderModalContent = () => {
        if (isLoading && !analysisContent) {
            return <div className="flex items-center justify-center h-48">
                       <Loader2 size={32} className="animate-spin text-primary" />
                       <p className="ml-2 text-text-muted-light dark:text-text-muted-dark">Loading analysis...</p>
                   </div>;
        }
        // Display error directly if it's set and no other content (or if content is the error itself)
        if (error && (!analysisContent || analysisContent === error)) {
             return <p className="p-4 text-center text-red-500 dark:text-red-400">{error}</p>;
        }
        if (!analysisContent) {
            return <p className="p-4 text-center text-text-muted-light dark:text-text-muted-dark">No analysis content available to display.</p>;
        }
        if (toolType === 'mindmap') {
            return <div className="mindmap-modal-content-wrapper min-h-[60vh] h-[calc(70vh-80px)] flex justify-center items-center">
                       <MindmapViewer mermaidCode={analysisContent} ref={mindmapViewerRef} />
                   </div>;
        }
        return <div ref={modalAnalysisContentRef}
                    className="prose prose-sm dark:prose-invert max-w-none text-text-light dark:text-text-dark p-1 custom-scrollbar text-[0.8rem] leading-relaxed"
                    dangerouslySetInnerHTML={createMarkup(analysisContent)} />;
    };

    const showReasoning = aiReasoning && !placeholderReasoningMessages.some(msg => aiReasoning.includes(msg));

    return (
        <div className="card-base p-3">
            <div className="flex items-center justify-between">
                <div
                    className="flex items-center gap-2 text-sm font-medium text-text-light dark:text-text-dark focus:outline-none w-full text-left cursor-pointer hover:text-primary dark:hover:text-primary-light transition-colors"
                    onClick={() => setIsSectionOpen(!isSectionOpen)}
                    aria-expanded={isSectionOpen}
                >
                    <IconComponent size={16} className="text-primary dark:text-primary-light flex-shrink-0" />
                    <span className="flex-grow">{title}</span>
                </div>
                <div className="flex items-center gap-1 flex-shrink-0">
                    <Button
                        onClick={handleRunAnalysis} variant="primary" size="sm"
                        className="!px-3 !py-1 text-xs" isLoading={isLoading}
                        disabled={!selectedDocumentFilename || isLoading}
                        title={!selectedDocumentFilename ? "Select a document first" : `Run ${title} Analysis`}
                    >
                       {isLoading ? (currentEngagementText.split(' ')[0] || "...") : "Run"}
                    </Button>
                    <IconButton
                        icon={isSectionOpen ? ChevronUp : ChevronDown}
                        onClick={() => setIsSectionOpen(!isSectionOpen)} size="sm" variant="ghost"
                        className="p-1" aria-label={isSectionOpen ? "Collapse section" : "Expand section"}
                        disabled={isLoading && isSectionOpen}
                    />
                </div>
            </div>
            <AnimatePresence>
                {isSectionOpen && (
                    <motion.div
                        key="tool-section-content" initial={{ height: 0, opacity: 0 }}
                        animate={{ height: 'auto', opacity: 1 }} exit={{ height: 0, opacity: 0 }}
                        transition={{ duration: 0.25, ease: "easeInOut" }}
                        className="mt-2 pt-2 border-t border-border-light dark:border-border-dark overflow-hidden"
                    >
                        {isLoading && (
                            <div className="text-xs text-text-muted-light dark:text-text-muted-dark p-2 flex items-center justify-center gap-2 animate-fadeIn">
                                <Loader2 size={14} className="animate-spin"/> {currentEngagementText}
                            </div>
                        )}
                        {error && !isLoading && (!analysisContent || analysisContent === error) && ( // Show error only if no other content or content is the error
                            <div className="my-2 p-2 bg-red-500/10 border border-red-500/30 text-red-600 dark:text-red-300 rounded-md text-xs flex items-center gap-1">
                                <AlertTriangle size={14} /> {error.length > 150 ? error.substring(0,147) + "..." : error}
                            </div>
                        )}
                        {!isLoading && (analysisContent || aiReasoning) && isDropdownOpen && (
                            <motion.div
                                key="analysis-dropdown" initial={{ opacity: 0, y: -10 }}
                                animate={{ opacity: 1, y: 0 }} exit={{ opacity: 0, y: -10 }}
                                transition={{ duration: 0.2 }} className="mt-2 space-y-2"
                            >
                                {showReasoning && aiReasoning && (
                                    <details className="group text-xs rounded-md border border-border-light dark:border-border-dark bg-surface-light dark:bg-gray-800 shadow-sm">
                                        <summary className="flex items-center justify-between gap-1 p-2 cursor-pointer text-text-muted-light dark:text-text-muted-dark hover:bg-gray-50 dark:hover:bg-gray-700 transition-colors rounded-t-md">
                                            <span className="flex items-center gap-1.5 font-medium">
                                                <Sparkles size={14} className="text-accent" /> AI Reasoning
                                            </span>
                                            <ChevronDown size={16} className="group-open:rotate-180 transition-transform" />
                                        </summary>
                                        <div ref={aiReasoningContentRef}
                                            className="p-2.5 prose prose-xs dark:prose-invert max-w-none text-text-light dark:text-text-dark max-h-60 overflow-y-auto custom-scrollbar text-[0.75rem] leading-relaxed bg-gray-50 dark:bg-gray-900/50 rounded-b-md"
                                            dangerouslySetInnerHTML={createMarkup(aiReasoning)} />
                                    </details>
                                )}
                                {analysisContent && (!error || analysisContent !== error) && ( // Show view button if content is not the error message itself
                                     <Button
                                        onClick={() => setIsModalOpen(true)} variant="outline" size="sm" fullWidth
                                        leftIcon={<Eye size={14}/>}
                                        className="!py-1.5 text-xs border-primary/70 text-primary hover:bg-primary/10 dark:border-primary-light/70 dark:text-primary-light dark:hover:bg-primary-light/10"
                                    >View Full {title}</Button>
                                )}
                            </motion.div>
                        )}
                        {!isLoading && !isDropdownOpen && !error && (
                            <p className="text-xs text-text-muted-light dark:text-text-muted-dark p-2 text-center">
                                {selectedDocumentFilename ? `Click "Run" to ${isTargetAdminDoc ? 'fetch stored' : 'generate'} ${title.toLowerCase()} for "${selectedDocumentFilename}".` : "Select a document to enable analysis."}
                            </p>
                        )}
                    </motion.div>
                )}
            </AnimatePresence>
            <Modal
                isOpen={isModalOpen} onClose={() => setIsModalOpen(false)}
                title={`${title} for "${selectedDocumentFilename || 'document'}"`}
                size={toolType === 'mindmap' ? "3xl" : "xl"}
                footerContent={<>
                        {toolType === 'mindmap' && analysisContent && (
                            <><Button onClick={() => handleDownloadMindmap('svg')} variant="outline" size="sm" className="text-xs" leftIcon={<Download size={14}/>}>SVG</Button>
                             <div className="flex-grow"></div></>
                        )}
                        <Button onClick={() => setIsModalOpen(false)} variant="secondary" size="sm" className="text-xs">Close</Button>
                    </>}
            >
                <div className={`max-h-[70vh] overflow-y-auto custom-scrollbar p-1 pr-2 rounded-md shadow-inner ${toolType === 'mindmap' ? 'bg-transparent dark:bg-transparent' : 'bg-gray-50 dark:bg-gray-800'}`}>
                    {selectedDocumentFilename && (
                        <p className="text-xs text-text-muted-light dark:text-text-muted-dark mb-2 border-b border-border-light dark:border-border-dark pb-1.5">
                            Source Document: <strong>{selectedDocumentFilename}</strong>
                        </p>
                    )}
                    {renderModalContent()}
                </div>
            </Modal>
        </div>
    );
}
export default AnalysisToolRunner;
```

`frontend/src/components/analysis/MindmapViewer.jsx`

```javascript
// frontend/src/components/analysis/MindmapViewer.jsx
import React, { useEffect, useRef, useState, useImperativeHandle, forwardRef } from 'react';
import toast from 'react-hot-toast';
import { escapeHtml } from '../../utils/helpers.js'; // Import escapeHtml helper

const MindmapViewer = forwardRef(({ mermaidCode }, ref) => {
    const svgContainerRef = useRef(null);
    const [error, setError] = useState(null);
    const [isMermaidReady, setIsMermaidReady] = useState(false);
    const [isLoading, setIsLoading] = useState(false);
    const [uniqueId] = useState(() => `mermaid-graph-${Math.random().toString(36).substr(2, 9)}`);

    useImperativeHandle(ref, () => ({
        getSvgElement: () => {
            return svgContainerRef.current?.querySelector('svg');
        }
    }));

    useEffect(() => {
        if (typeof window.mermaid !== 'undefined') {
            setIsMermaidReady(true);
        } else {
            const intervalId = setInterval(() => {
                if (typeof window.mermaid !== 'undefined') {
                    setIsMermaidReady(true);
                    clearInterval(intervalId);
                }
            }, 100);
            return () => clearInterval(intervalId);
        }
    }, []);

    useEffect(() => {
        if (!isMermaidReady || !mermaidCode || !svgContainerRef.current) {
            if (svgContainerRef.current) svgContainerRef.current.innerHTML = '';
            setError(null);
            setIsLoading(false);
            return;
        }

        const renderMermaidDiagram = async () => {
            setIsLoading(true);
            setError(null);
            if (!svgContainerRef.current) {
                setIsLoading(false);
                return;
            }
            svgContainerRef.current.innerHTML = '<div class="flex justify-center items-center h-full w-full text-sm text-text-muted-light dark:text-text-muted-dark"><div class="animate-spin rounded-full h-6 w-6 border-t-2 border-b-2 border-primary mr-2"></div>Rendering diagram...</div>';
            
            let codeToRender = mermaidCode.trim();
            // Remove Markdown code fences: ```mermaid ... ``` or ``` ... ```
            // Regex explanation:
            // ^```         - Matches starting triple backticks
            // (?:mermaid\b)? - Optionally matches "mermaid" followed by a word boundary (case-insensitive due to i flag)
            // \s*          - Matches any whitespace (including newlines) after "mermaid" or ```
            // ([\s\S]*?)  - Captures the actual Mermaid code (non-greedy)
            // \s*          - Matches any whitespace before closing backticks
            // ```$         - Matches closing triple backticks at the end of the string
            // i            - Case-insensitive flag (for "mermaid" keyword)
            const fenceRegex = /^```(?:mermaid\b)?\s*([\s\S]*?)\s*```$/i;
            const match = codeToRender.match(fenceRegex);
            if (match && match[1]) {
                codeToRender = match[1].trim(); // Use the captured group
            }
            
            try {
                if (typeof window.mermaid === 'undefined') {
                    throw new Error("Mermaid library failed to load or initialize properly.");
                }

                const { svg, bindFunctions } = await window.mermaid.render(uniqueId, codeToRender);
                
                if (svgContainerRef.current) {
                    svgContainerRef.current.innerHTML = svg;
                    if (bindFunctions) {
                        bindFunctions(svgContainerRef.current);
                    }
                    const svgElement = svgContainerRef.current.querySelector('svg');
                    if (svgElement) {
                        svgElement.style.width = '100%';
                        svgElement.style.height = 'auto'; 
                        svgElement.style.maxWidth = '100%'; 
                        svgElement.style.display = 'block';
                    }
                }
            } catch (e) {
                console.error("Error rendering Mermaid diagram with input:", codeToRender, e);
                const errorMsg = e.message || "Failed to render mind map. Invalid Mermaid syntax?";
                setError(errorMsg);
                if (svgContainerRef.current) {
                    const codeSnippet = escapeHtml(codeToRender.substring(0, 200) + (codeToRender.length > 200 ? "..." : ""));
                    svgContainerRef.current.innerHTML = `<div class="p-4 text-center text-red-500 dark:text-red-400 text-xs break-all"><strong>Error rendering:</strong> ${escapeHtml(errorMsg)}<br><strong class='mt-2 block'>Input Code (first 200 chars):</strong><pre class='text-left text-xs bg-gray-100 dark:bg-gray-700 p-2 rounded mt-1 whitespace-pre-wrap'>${codeSnippet}</pre></div>`;
                }
            } finally {
                setIsLoading(false);
            }
        };

        const timer = setTimeout(renderMermaidDiagram, 100); 
        return () => clearTimeout(timer);
        
    }, [mermaidCode, uniqueId, isMermaidReady]);

    if (!isMermaidReady && !error) {
      return <div className="p-4 text-center text-text-muted-light dark:text-text-muted-dark text-xs">Waiting for Mermaid.js library...</div>;
    }
    if (error && (!isLoading || (svgContainerRef.current && svgContainerRef.current.innerHTML.includes('Error rendering')))) {
        return <div ref={svgContainerRef} className="mermaid-diagram-render-area w-full h-full flex justify-center items-center bg-gray-50 dark:bg-gray-800/50 p-2 rounded-md">
                {/* Error message will be injected by useEffect's catch block */}
               </div>;
    }
    
    if (isLoading) { 
         return <div ref={svgContainerRef} className="mermaid-diagram-render-area w-full h-full flex justify-center items-center bg-gray-50 dark:bg-gray-800/50 p-2 rounded-md">
            {/* Loading message is set by renderMermaidDiagram's initial innerHTML write */}
         </div>;
    }

    if (!mermaidCode && !error && isMermaidReady) { 
        return <p className="text-xs text-center text-text-muted-light dark:text-text-muted-dark p-4">No mind map data to display.</p>;
    }
    
    return (
        <div 
            ref={svgContainerRef} 
            className="mermaid-diagram-render-area w-full h-full flex justify-center items-center bg-gray-50 dark:bg-gray-800/50 p-2 rounded-md"
        >

        </div>
    );
});

export default MindmapViewer;
```

`frontend/src/components/analysis/RightPanel.jsx`

```javascript
// frontend/src/components/layout/RightPanel.jsx
import React, { useState } from 'react';
import { useAppState } from '../../contexts/AppStateContext';
import AnalysisTool from '../analysis/AnalysisTool.jsx'; // Added .jsx
import { PanelRightClose, ChevronDown, ChevronUp, Telescope } from 'lucide-react';
import IconButton from '../core/IconButton.jsx'; // Added .jsx
import { motion } from 'framer-motion';

function RightPanel() {
    const { setIsRightPanelOpen, selectedDocumentForAnalysis } = useAppState();
    const [isAnalyzerOpen, setIsAnalyzerOpen] = useState(true);

    const currentSelectedDocFilename = selectedDocumentForAnalysis?.originalName || null;

    return (
        <div className="flex flex-col h-full p-3 sm:p-4 bg-surface-light dark:bg-surface-dark text-text-light dark:text-text-dark custom-scrollbar">
            <div className="flex items-center justify-between mb-4 pb-2 border-b border-border-light dark:border-border-dark">
                <h2 className="text-base font-semibold">Advanced Analyzer</h2>
                <IconButton 
                    icon={PanelRightClose} 
                    onClick={() => setIsRightPanelOpen(false)} 
                    title="Close Analyzer Panel"
                    variant="ghost"
                    size="sm"
                    className="text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
                />
            </div>
            
            <button 
                onClick={() => setIsAnalyzerOpen(!isAnalyzerOpen)}
                className="w-full flex items-center justify-between px-3 py-2.5 text-sm font-medium text-left bg-gray-50 dark:bg-gray-800 hover:bg-gray-100 dark:hover:bg-gray-700 rounded-md focus:outline-none shadow-sm border border-border-light dark:border-border-dark mb-3"
            >
                <span className="flex items-center gap-2"><Telescope size={16} /> Analysis Tools</span>
                {isAnalyzerOpen ? <ChevronUp size={18} /> : <ChevronDown size={18} />}
            </button>

            {isAnalyzerOpen && (
                <motion.div 
                    initial={{ height: 0, opacity: 0 }} 
                    animate={{ height: 'auto', opacity: 1 }} 
                    exit={{ height: 0, opacity: 0 }}
                    transition={{ duration: 0.2, ease: "easeInOut" }}
                    className="flex-grow space-y-3 overflow-y-auto custom-scrollbar pr-1"
                >
                    {!currentSelectedDocFilename && (
                        <div className="p-4 text-xs text-center text-text-muted-light dark:text-text-muted-dark bg-gray-50 dark:bg-gray-800 rounded-md border border-dashed border-border-light dark:border-border-dark">
                            <p>Select a document from the left panel to enable analysis tools.</p>
                        </div>
                    )}
                    <AnalysisTool toolType="faq" title="FAQ Generator" iconName="HelpCircle" selectedDocumentFilename={currentSelectedDocFilename} />
                    <AnalysisTool toolType="topics" title="Key Topics Extractor" iconName="Tags" selectedDocumentFilename={currentSelectedDocFilename} />
                    <AnalysisTool toolType="mindmap" title="Mind Map Creator" iconName="GitFork" selectedDocumentFilename={currentSelectedDocFilename} />
                </motion.div>
            )}
        </div>
    );
}
export default RightPanel;
```

`frontend/src/components/auth/AuthModal.jsx`

```javascript
// frontend/src/components/auth/AuthModal.jsx
import React, { useState, useEffect } from 'react';
import { useNavigate } from 'react-router-dom'; // For admin navigation
import { useAuth } from '../../hooks/useAuth.jsx'; // For regular user login/signup
import { useAppState } from '../../contexts/AppStateContext.jsx'; // For setting admin session flag
import LLMSelection from './LLMSelection.jsx';
import api from '../../services/api.js'; // For regular user LLM config updates
import toast from 'react-hot-toast';
import { LogIn, UserPlus, X, Terminal, KeyRound, Link2, User as UserIcon, AlertCircle } from 'lucide-react';
import Button from '../core/Button.jsx';
import IconButton from '../core/IconButton.jsx';
import { motion } from 'framer-motion';

// Get admin credentials from .env (ensure VITE_ prefix for Vite)
const ADMIN_USERNAME_FRONTEND = import.meta.env.VITE_ADMIN_USERNAME || 'admin';
const ADMIN_PASSWORD_FRONTEND = import.meta.env.VITE_ADMIN_PASSWORD || 'admin123';

function AuthModal({ isOpen, onClose }) { // onClose expects authData or {isAdminLogin: true} or null
    const {
        login: regularUserLogin, // Renamed to avoid conflict
        signup: regularUserSignup, // Renamed
        devLogin,
        DEV_MODE_ALLOW_DEV_LOGIN,
        MOCK_DEV_USERNAME, MOCK_DEV_PASSWORD
    } = useAuth();
    const {
        selectedLLM: globalSelectedLLM,
        switchLLM: setGlobalLLM,
        setIsAdminSessionActive // Function from AppStateContext
    } = useAppState();
    const navigate = useNavigate();

    const [isLoginView, setIsLoginView] = useState(true);
    const [username, setUsername] = useState(DEV_MODE_ALLOW_DEV_LOGIN && isLoginView ? (MOCK_DEV_USERNAME || '') : '');
    const [password, setPassword] = useState(DEV_MODE_ALLOW_DEV_LOGIN && isLoginView ? (MOCK_DEV_PASSWORD || '') : '');
    const [localSelectedLLM, setLocalSelectedLLM] = useState(globalSelectedLLM || 'ollama');
    const [geminiApiKey, setGeminiApiKey] = useState('');
    const [ollamaApiUrl, setOllamaApiUrl] = useState('');

    const [error, setError] = useState('');
    const [loading, setLoading] = useState(false);
    const [devLoginLoading, setDevLoginLoading] = useState(false);

    useEffect(() => {
        if (isOpen) {
            setError('');
            // Reset username/password based on view, unless dev mode pre-fills for login
            if (isLoginView) {
                setUsername(DEV_MODE_ALLOW_DEV_LOGIN ? (MOCK_DEV_USERNAME || '') : '');
                setPassword(DEV_MODE_ALLOW_DEV_LOGIN ? (MOCK_DEV_PASSWORD || '') : '');
            } else { // Signup view
                setUsername('');
                setPassword('');
            }
            setLocalSelectedLLM(globalSelectedLLM || 'ollama');
            setGeminiApiKey('');
            setOllamaApiUrl('');
        }
    }, [isOpen, isLoginView, DEV_MODE_ALLOW_DEV_LOGIN, MOCK_DEV_USERNAME, MOCK_DEV_PASSWORD, globalSelectedLLM]);

    const handleLlmChange = (llm) => setLocalSelectedLLM(llm);

    const handleSubmit = async (e) => {
        e.preventDefault();
        if (!username.trim() || !password.trim()) {
            setError("Username and password are required.");
            toast.error("Username and password are required.");
            return;
        }

        setError('');
        setLoading(true);
        const toastId = toast.loading(isLoginView ? 'Logging in...' : 'Signing up...');

        // --- SPECIAL ADMIN LOGIN CHECK (FRONTEND ONLY) ---
        if (isLoginView && username.trim() === ADMIN_USERNAME_FRONTEND && password === ADMIN_PASSWORD_FRONTEND) {
            toast.dismiss(toastId);
            toast.success("Admin login successful!");
            setIsAdminSessionActive(true); // Notify AppState that admin is active
            
            // Option 1: Let App.jsx handle navigation based on isAdminSessionActive
            onClose({ isAdminLogin: true }); 

            // Option 2: Navigate directly from here (can sometimes cause issues if App.jsx also navigates)
            // navigate('/admin/dashboard', { replace: true }); 
            // if (typeof onClose === 'function') onClose({ isAdminLogin: true });


            setLoading(false);
            return; // Stop further processing for admin
        }
        // --- END SPECIAL ADMIN LOGIN CHECK ---

        // --- Regular user login/signup flow (calls backend API) ---
        try {
            let authDataResponse; // This will contain { token, _id, username, role, sessionId?, message }
            const apiPayload = { username: username.trim(), password };

            if (isLoginView) {
                authDataResponse = await regularUserLogin(apiPayload); // From AuthContext
            } else { // Signup view
                authDataResponse = await regularUserSignup(apiPayload); // From AuthContext
                
                // If signup is successful, update global LLM preference and save user-specific LLM config
                setGlobalLLM(localSelectedLLM);
                if (localSelectedLLM === 'gemini' && geminiApiKey.trim()) {
                    try {
                        await api.updateUserLLMConfig({ llmProvider: 'gemini', apiKey: geminiApiKey.trim() });
                    } catch (configErr) { toast.error(`Note: Could not save Gemini config: ${configErr.message}`);}
                }
                if (localSelectedLLM === 'ollama' && ollamaApiUrl.trim()) {
                    try {
                         await api.updateUserLLMConfig({ llmProvider: 'ollama', ollamaUrl: ollamaApiUrl.trim() });
                    } catch (configErr) { toast.error(`Note: Could not save Ollama config: ${configErr.message}`);}
                }
            }
            toast.dismiss(toastId);
            toast.success(authDataResponse.message || (isLoginView ? 'Login Successful!' : 'Signup Successful!'));
            if (typeof onClose === 'function') onClose(authDataResponse); // Pass full authData from AuthContext to App.jsx
        } catch (err) {
            toast.dismiss(toastId);
            // The `login` and `signup` functions from AuthContext should throw an error
            // that already contains a user-friendly message if possible.
            const errorMessage = err.response?.data?.message || err.message || `Failed: ${isLoginView ? 'login' : 'signup'}`;
            setError(errorMessage);
            toast.error(errorMessage);
        } finally { setLoading(false); }
    };

    const handleDevLogin = async () => {
        if (!devLogin) {
            toast.error("Dev Quick Login is not available in current setup.");
            return;
        }
        setDevLoginLoading(true); setError('');
        const toastId = toast.loading("Attempting Dev Quick Login...");
        try {
            const devAuthData = await devLogin(); // From AuthContext
            toast.dismiss(toastId);
            toast.success(devAuthData.message || "Dev Quick Login Successful!");
            if (typeof onClose === 'function') onClose(devAuthData);
        } catch(err) {
            toast.dismiss(toastId);
            const errorMessage = err.response?.data?.message || err.message || "Dev Quick Login encountered an error.";
            setError(errorMessage);
            toast.error(errorMessage);
        } finally {
            setDevLoginLoading(false);
        }
    };

    if (!isOpen) return null;

    const inputWrapperClass = "relative";
    const inputIconClass = "absolute left-3 top-1/2 -translate-y-1/2 h-5 w-5 text-text-muted-light dark:text-text-muted-dark pointer-events-none";
    const inputFieldStyledClass = "input-field pl-10 py-2.5 text-sm";

    return (
        <div className="fixed inset-0 bg-black/70 backdrop-blur-sm flex items-center justify-center z-50 p-4 animate-fadeIn">
            <motion.div 
                key="auth-modal-content"
                initial={{ opacity: 0, scale: 0.95, y: -10 }}
                animate={{ opacity: 1, scale: 1, y: 0 }}
                exit={{ opacity: 0, scale: 0.95, y: 10 }}
                transition={{ type: "spring", stiffness: 400, damping: 25 }}
                className="card-base p-6 sm:p-8 w-full max-w-md glass-effect" // Ensure `glass-effect` is defined in your CSS if you want it
            >
                <div className="flex justify-between items-center mb-6">
                    <h2 className="text-xl sm:text-2xl font-bold text-text-light dark:text-text-dark">
                        {isLoginView ? 'Welcome Back' : 'Create Your Account'}
                    </h2>
                    <IconButton 
                        icon={X} 
                        onClick={() => { if (typeof onClose === 'function') onClose(null); }} // Pass null if modal closed manually
                        variant="ghost" 
                        size="sm" 
                        title="Close" 
                        className="text-text-muted-light dark:text-text-muted-dark hover:text-red-500 dark:hover:text-red-400"
                    />
                </div>

                {error && (
                    <div className="mb-4 p-3 bg-red-500/10 border border-red-500/30 text-red-600 dark:text-red-300 rounded-md text-sm animate-fadeIn flex items-center gap-2">
                        <AlertCircle size={16}/>{error}
                    </div>
                )}

                <form onSubmit={handleSubmit} className="space-y-5">
                    <div className={inputWrapperClass}>
                        <UserIcon className={inputIconClass} />
                        <input 
                            type="text" 
                            id="auth-username" // More specific ID
                            className={inputFieldStyledClass} 
                            placeholder="Username" 
                            value={username} 
                            onChange={(e) => setUsername(e.target.value)} 
                            required 
                            disabled={loading || devLoginLoading}
                        />
                    </div>
                    <div className={inputWrapperClass}>
                        <KeyRound className={inputIconClass} />
                        <input 
                            type="password" 
                            id="auth-password" // More specific ID
                            className={inputFieldStyledClass} 
                            placeholder="Password (min. 6 characters)" 
                            value={password} 
                            onChange={(e) => setPassword(e.target.value)} 
                            required 
                            minLength="6" 
                            disabled={loading || devLoginLoading}
                        />
                    </div>

                    {!isLoginView && (
                        <div className="space-y-4 pt-2 animate-fadeIn">
                            <LLMSelection 
                                selectedLLM={localSelectedLLM} 
                                onLlmChange={handleLlmChange} 
                                disabled={loading || devLoginLoading}
                            />
                            {localSelectedLLM === 'gemini' && (
                                <div className="mt-3 space-y-1">
                                    <label htmlFor="geminiApiKeyModal" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark">Gemini API Key (Optional)</label>
                                    <div className={inputWrapperClass}>
                                        <KeyRound className={inputIconClass} />
                                        <input 
                                            type="password" 
                                            id="geminiApiKeyModal" 
                                            className={inputFieldStyledClass} 
                                            placeholder="Enter your Gemini API Key" 
                                            value={geminiApiKey} 
                                            onChange={(e) => setGeminiApiKey(e.target.value)} 
                                            disabled={loading || devLoginLoading}
                                        />
                                    </div>
                                </div>
                            )}
                            {localSelectedLLM === 'ollama' && (
                                <div className="mt-3 space-y-1">
                                    <label htmlFor="ollamaApiUrlModal" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark">Ollama API URL (Optional)</label>
                                     <div className={inputWrapperClass}>
                                        <Link2 className={inputIconClass} />
                                        <input 
                                            type="text" 
                                            id="ollamaApiUrlModal" 
                                            className={inputFieldStyledClass} 
                                            placeholder="Default: http://localhost:11434" 
                                            value={ollamaApiUrl} 
                                            onChange={(e) => setOllamaApiUrl(e.target.value)} 
                                            disabled={loading || devLoginLoading}
                                        />
                                    </div>
                                </div>
                            )}
                        </div>
                    )}

                    <Button 
                        type="submit" 
                        fullWidth 
                        isLoading={loading} 
                        disabled={devLoginLoading || loading} // Disable if either general loading or dev login loading
                        leftIcon={isLoginView ? <LogIn size={18}/> : <UserPlus size={18}/>} 
                        className="py-2.5 !text-base"
                    >
                        {isLoginView ? 'Login' : 'Sign Up'}
                    </Button>
                </form>

                <p className="mt-6 text-center text-sm">
                    <button 
                        onClick={() => { setIsLoginView(!isLoginView); setError(''); }}
                        className="font-medium text-primary hover:text-primary-dark dark:text-primary-light dark:hover:text-primary-darker transition-colors"
                        disabled={loading || devLoginLoading}
                    >
                        {isLoginView ? "Don't have an account? Sign Up" : "Already have an account? Login"}
                    </button>
                </p>

                {DEV_MODE_ALLOW_DEV_LOGIN && devLogin && (
                    <div className="mt-4 pt-4 border-t border-border-light dark:border-border-dark">
                        <Button
                            type="button" onClick={handleDevLogin} fullWidth 
                            className="bg-yellow-500 hover:bg-yellow-600 dark:bg-yellow-600 dark:hover:bg-yellow-700 !text-white dark:!text-gray-900 font-semibold py-2.5 !text-base"
                            leftIcon={<Terminal size={18} />}
                            isLoading={devLoginLoading} 
                            disabled={loading} 
                        >
                            Dev Quick Login
                        </Button>
                    </div>
                )}
            </motion.div>
        </div>
    );
}
export default AuthModal;
```

`frontend/src/components/auth/LLMSelection.jsx`

```javascript
// frontend/src/components/auth/LLMSelection.jsx
import React from 'react';
import { HardDrive, Cloud } from 'lucide-react';

function LLMSelection({ selectedLLM, onLlmChange, disabled = false }) {
    const llms = [
        { id: 'ollama', name: 'Ollama LLM', description: 'Local & Private. Requires Ollama running.', Icon: HardDrive },
        { id: 'gemini', name: 'Gemini LLM', description: 'Cloud-based by Google. API Key may be required.', Icon: Cloud },
    ];

    return (
        <div>
            <label className="block text-sm font-medium text-text-light dark:text-text-dark mb-2">
                Choose Your LLM Provider
            </label>
            <div className="grid grid-cols-1 sm:grid-cols-2 gap-3">
                {llms.map((llm) => {
                    const isSelected = selectedLLM === llm.id;
                    return (
                        <button
                            key={llm.id}
                            type="button"
                            onClick={() => onLlmChange(llm.id)}
                            disabled={disabled}
                            className={`p-4 border rounded-lg text-left transition-all duration-150 focus:outline-none group focus:ring-2 focus:ring-offset-2 dark:focus:ring-offset-surface-dark focus:ring-primary
                                ${isSelected 
                                    ? 'bg-primary dark:bg-primary border-primary dark:border-primary-dark ring-2 ring-primary dark:ring-primary-dark shadow-lg' 
                                    : 'bg-surface-light dark:bg-surface-dark border-border-light dark:border-border-dark hover:border-primary-light dark:hover:border-primary-dark hover:shadow-md'
                                }
                                ${disabled ? 'opacity-70 cursor-not-allowed' : ''}
                            `}
                        >
                            <div className="flex items-center mb-1">
                                <llm.Icon size={20} className={`mr-2 transition-colors 
                                    ${isSelected 
                                        ? 'text-white dark:text-blue-100' // High contrast for selected
                                        : 'text-text-muted-light dark:text-text-muted-dark group-hover:text-primary dark:group-hover:text-primary-light'}`} />
                                <span className={`font-semibold transition-colors 
                                    ${isSelected 
                                        ? 'text-white dark:text-white' // High contrast for selected
                                        : 'text-text-light dark:text-text-dark group-hover:text-primary dark:group-hover:text-primary-light'}`}>
                                    {llm.name}
                                </span>
                            </div>
                            <p className={`text-xs transition-colors 
                                ${isSelected 
                                    ? 'text-blue-100 dark:text-blue-200' // High contrast for selected
                                    : 'text-text-muted-light dark:text-text-muted-dark'}`}>
                                {llm.description}
                            </p>
                        </button>
                    );
                })}
            </div>
        </div>
    );
}

export default LLMSelection;
```

`frontend/src/components/chat/ChatHistory.jsx`

```javascript
// src/components/chat/ChatHistory.jsx
import React, { useRef, useEffect } from 'react';
import MessageBubble from './MessageBubble';
import { motion, AnimatePresence } from 'framer-motion';

function ChatHistory({ messages, isLoading }) {
    const chatHistoryRef = useRef(null);

    useEffect(() => {
        if (chatHistoryRef.current) {
            // Smart scroll: only scroll if user is already near the bottom
            const { scrollHeight, clientHeight, scrollTop } = chatHistoryRef.current;
            const isScrolledToBottom = scrollHeight - clientHeight <= scrollTop + 100; // 100px tolerance
            if (isScrolledToBottom) {
                chatHistoryRef.current.scrollTop = chatHistoryRef.current.scrollHeight;
            }
        }
    }, [messages]);

    return (
        <div ref={chatHistoryRef} className="flex-1 overflow-y-auto p-4 space-y-4 custom-scrollbar">
            <AnimatePresence initial={false}>
                {messages.map((msg, index) => ( // Ensure msg.id is unique and stable
                    <motion.div
                        key={msg.id || `msg-${index}-${msg.timestamp}`} // Fallback key if id is missing
                        layout
                        initial={{ opacity: 0, y: 20 }}
                        animate={{ opacity: 1, y: 0 }}
                        exit={{ opacity: 0, y: -10, transition: { duration: 0.15 } }}
                        transition={{ duration: 0.3, ease: "easeOut" }}
                    >
                        <MessageBubble
                            id={msg.id || `msg-${index}-${msg.timestamp}`} // Pass the ID
                            sender={msg.sender} // 'user' or 'bot'
                            text={msg.text}
                            thinking={msg.thinking}
                            references={msg.references}
                            timestamp={msg.timestamp}
                            sourcePipeline={msg.source_pipeline}
                        />
                    </motion.div>
                ))}
            </AnimatePresence>
            {isLoading && ( // Show typing indicator, even if no prior messages for immediate feedback
                 <motion.div 
                    layout
                    initial={{ opacity: 0, y: 10 }}
                    animate={{ opacity: 1, y: 0 }}
                    className="flex justify-start pl-2 mt-2"
                 >
                    <div className="message-bubble bot-message bg-surface-light dark:bg-surface-dark p-2 inline-flex items-center gap-1 rounded-lg shadow">
                        <span className="animate-pulseDot1 text-text-muted-light dark:text-text-muted-dark text-xs"></span>
                        <span className="animate-pulseDot2 text-text-muted-light dark:text-text-muted-dark text-xs"></span>
                        <span className="animate-pulseDot3 text-text-muted-light dark:text-text-muted-dark text-xs"></span>
                    </div>
                </motion.div>
            )}
        </div>
    );
}
export default ChatHistory;
```

`frontend/src/components/chat/ChatHistoryModal.jsx`

```javascript
// src/components/chat/ChatHistoryModal.jsx
import React, { useState, useEffect, useCallback } from 'react';
import api from '../../services/api';
import toast from 'react-hot-toast';
import { X, MessageSquareText, Loader2, AlertTriangle, Trash2 } from 'lucide-react'; // Added Trash2
import Modal from '../core/Modal.jsx';
import IconButton from '../core/IconButton.jsx'; // Import IconButton

const formatDate = (dateString) => {
    if (!dateString) return 'N/A';
    try {
        return new Date(dateString).toLocaleString(undefined, { 
            month: 'short', day: 'numeric', year: 'numeric', hour: '2-digit', minute: '2-digit' 
        });
    } catch (e) {
        return 'Invalid Date';
    }
};

function ChatHistoryModal({ isOpen, onClose, onSelectSession }) {
    const [sessions, setSessions] = useState([]);
    const [selectedSessionId, setSelectedSessionId] = useState(null);
    const [sessionMessages, setSessionMessages] = useState([]);
    const [loadingSessions, setLoadingSessions] = useState(false);
    const [loadingMessages, setLoadingMessages] = useState(false);
    const [error, setError] = useState('');

    const fetchSessions = useCallback(async () => {
        if (!isOpen) return; 
        setLoadingSessions(true);
        setError('');
        try {
            const data = await api.getChatSessions(); // Fetches { sessionId, preview, updatedAt, ... }
            setSessions(Array.isArray(data) ? data : []);
            if (data.length === 0) {
                toast.info("No past chat sessions found.");
            }
        } catch (err) {
            toast.error("Failed to load chat sessions.");
            setError(err.message || "Could not fetch sessions.");
        } finally {
            setLoadingSessions(false);
        }
    }, [isOpen]);

    useEffect(() => {
        if (isOpen) {
            fetchSessions();
            setSelectedSessionId(null); 
            setSessionMessages([]);
        }
    }, [isOpen, fetchSessions]); 

    const handleSessionSelectForPreview = async (sessionId) => {
        if (selectedSessionId === sessionId && sessionMessages.length > 0) return; 

        setSelectedSessionId(sessionId);
        setLoadingMessages(true);
        setSessionMessages([]); // Clear previous preview
        setError(''); 
        try {
            // api.getChatHistory returns the array of messages directly
            const messagesArray = await api.getChatHistory(sessionId); 
            // Map to the structure expected by the modal's display loop
            setSessionMessages(messagesArray.map(msg => ({
                id: msg.id || msg._id || `hist-${Date.now()}-${Math.random()}`,
                sender: msg.sender, // 'user' or 'bot'
                text: msg.text, // Main text content
                timestamp: msg.timestamp
                // No need for thinking/references in this preview
            })));
        } catch (err) {
            toast.error("Failed to load messages for this session.");
            setError(`Error loading messages: ${err.message}`);
        } finally {
            setLoadingMessages(false);
        }
    };

    const handleLoadSessionAndClose = () => {
        if (selectedSessionId) {
            onSelectSession(selectedSessionId); 
            onClose();
        } else {
            toast.error("Please select a session to load.");
        }
    };
    
    // Placeholder for delete functionality (implement with backend support later)
    const handleDeleteSession = async (sessionIdToDelete, e) => {
        e.stopPropagation(); // Prevent selecting the session
        if (!window.confirm(`Are you sure you want to delete session ${sessionIdToDelete.substring(0,8)}...? This action cannot be undone.`)) return;
        
        const toastId = toast.loading(`Deleting session ${sessionIdToDelete.substring(0,8)}... (mock)`);
        // try {
        //     await api.deleteChatSession(sessionIdToDelete); // You'll need to create this API endpoint
        //     toast.success("Session deleted.", { id: toastId });
        //     fetchSessions(); // Refresh list
        //     if (selectedSessionId === sessionIdToDelete) {
        //         setSelectedSessionId(null);
        //         setSessionMessages([]);
        //     }
        // } catch (err) {
        //     toast.error(`Failed to delete session: ${err.message}`, { id: toastId });
        // }
        setTimeout(() => { // Simulate API call
            toast.success(`Mock: Session ${sessionIdToDelete.substring(0,8)} would be deleted.`, { id: toastId });
            // setSessions(prev => prev.filter(s => s.sessionId !== sessionIdToDelete)); // Optimistic UI update
        }, 1000);

    };

    return (
        <Modal isOpen={isOpen} onClose={onClose} title="Chat History" size="2xl">
            <div className="flex flex-col md:flex-row gap-4 max-h-[70vh] h-[70vh]">
                <div className="w-full md:w-1/3 border-r border-border-light dark:border-border-dark pr-0 md:pr-2 overflow-y-auto custom-scrollbar">
                    <h3 className="text-sm font-semibold mb-2 text-text-light dark:text-text-dark px-1">Your Sessions</h3>
                    {loadingSessions && <div className="flex justify-center p-4"><Loader2 className="animate-spin text-primary" size={24}/></div>}
                    {!loadingSessions && error && !sessions.length && <div className="text-red-500 text-xs p-2">{error}</div>}
                    {!loadingSessions && !error && sessions.length === 0 && <p className="text-xs text-text-muted-light dark:text-text-muted-dark p-2">No past sessions found.</p>}
                    
                    <ul className="space-y-1">
                        {sessions.map(session => (
                            <li key={session.sessionId}
                                onClick={() => handleSessionSelectForPreview(session.sessionId)}
                                className={`p-2.5 rounded-md cursor-pointer text-xs transition-colors group relative hover:shadow-md
                                            ${selectedSessionId === session.sessionId 
                                                ? 'bg-primary text-white dark:bg-primary-dark shadow-lg ring-2 ring-primary-dark' 
                                                : 'bg-surface-light dark:bg-gray-800 hover:bg-gray-100 dark:hover:bg-gray-700 border border-transparent hover:border-primary-light'}`}
                            >
                                <div className="font-medium truncate" title={session.preview}>{session.preview || `Session ${session.sessionId.substring(0,8)}`}</div>
                                <div className={`text-[0.7rem] ${selectedSessionId === session.sessionId ? 'text-blue-100 dark:text-blue-200' : 'text-text-muted-light dark:text-text-muted-dark'}`}>
                                    {formatDate(session.updatedAt)} - {session.messageCount} msgs
                                </div>
                                <IconButton
                                    icon={Trash2}
                                    size="sm"
                                    variant="ghost"
                                    title="Delete session (Mock)"
                                    className="absolute top-1 right-1 p-1 text-red-400 hover:text-red-600 opacity-0 group-hover:opacity-100 transition-opacity !rounded-full hover:bg-red-500/10"
                                    onClick={(e) => handleDeleteSession(session.sessionId, e)}
                                />
                            </li>
                        ))}
                    </ul>
                </div>

                <div className="w-full md:w-2/3 flex flex-col overflow-hidden mt-4 md:mt-0">
                    <h3 className="text-sm font-semibold mb-2 text-text-light dark:text-text-dark">
                        {selectedSessionId ? `Preview: ${selectedSessionId.substring(0,8)}...` : "Session Preview"}
                    </h3>
                    <div className="flex-grow bg-gray-50 dark:bg-gray-800/50 p-3 rounded-md overflow-y-auto custom-scrollbar border border-border-light dark:border-border-dark">
                        {loadingMessages && <div className="flex justify-center p-4"><Loader2 className="animate-spin text-primary" size={24} /></div>}
                        {!selectedSessionId && !loadingMessages && (
                            <div className="flex flex-col items-center justify-center h-full text-text-muted-light dark:text-text-muted-dark text-sm">
                                <MessageSquareText size={40} className="mb-3 opacity-50" />
                                <p>Select a session from the left to view its messages.</p>
                            </div>
                        )}
                        {selectedSessionId && !loadingMessages && !error && sessionMessages.length === 0 && 
                            <p className="text-center text-sm text-text-muted-light dark:text-text-muted-dark p-4">No messages in this session.</p>
                        }
                        {selectedSessionId && !loadingMessages && error && 
                             <div className="flex flex-col items-center justify-center h-full text-red-500 dark:text-red-400 text-sm p-2">
                                <AlertTriangle size={30} className="mb-2"/> {error}
                            </div>
                        }
                        <div className="space-y-3">
                            {sessionMessages.map(msg => (
                                <div key={msg.id} 
                                     className={`p-2.5 rounded-lg shadow-sm w-fit max-w-[90%] text-xs
                                                ${msg.sender === 'user' 
                                                    ? 'bg-blue-500 text-white ml-auto' 
                                                    : 'bg-gray-200 text-gray-800 dark:bg-gray-700 dark:text-gray-100'}`}>
                                    <p className="font-semibold text-[0.7rem] mb-0.5">{msg.sender === 'user' ? 'You' : 'AI Tutor'}</p>
                                    <p className="whitespace-pre-wrap break-words">{msg.text}</p>
                                    <p className="text-[0.65rem] opacity-70 mt-1 text-right">{formatDate(msg.timestamp)}</p>
                                </div>
                            ))}
                        </div>
                    </div>
                </div>
            </div>
            <div className="mt-6 pt-4 border-t border-border-light dark:border-border-dark flex justify-end gap-3">
                <button 
                    onClick={onClose} 
                    className="btn-secondary !text-xs !py-1.5 !px-3" // Use your button classes
                >
                    Close
                </button>
                <button 
                    onClick={handleLoadSessionAndClose} 
                    className="btn-primary !text-xs !py-1.5 !px-3" // Use your button classes
                    disabled={!selectedSessionId || loadingMessages || loadingSessions}
                >
                    Load Selected Session
                </button>
            </div>
        </Modal>
    );
}
export default ChatHistoryModal;
```

`frontend/src/components/chat/ChatInput.jsx`

```javascript
// src/components/chat/ChatInput.jsx
import React, { useState, useEffect, useRef } from 'react';
import { Send, Mic, PlusCircle, Loader2, SearchCheck, SearchSlash, Brain } from 'lucide-react'; // Added Brain  
import { useWebSpeech } from '../../hooks/useWebSpeech';
import Button from '../core/Button.jsx'; 
import IconButton from '../core/IconButton.jsx';
import toast from 'react-hot-toast'; // Added toast import
import blueBrain from "./../../assets/blueBrain.svg"

function ChatInput({ 
    onSendMessage, 
    isLoading, 
    currentStatus, 
    useRag, 
    setUseRag,
    criticalThinkingEnabled, // New prop
    setCriticalThinkingEnabled // New prop
}) {
    const [inputValue, setInputValue] = useState('');
    const { transcript, listening, isSpeechSupported, startListening, stopListening, resetTranscript } = useWebSpeech();
    const textareaRef = useRef(null);

    useEffect(() => {
        if (transcript) {
            setInputValue(prev => prev + (prev ? " " : "") + transcript);
            resetTranscript(); 
        }
    }, [transcript, resetTranscript]);
    
    useEffect(() => {
        if (textareaRef.current) {
            textareaRef.current.style.height = 'auto';
            textareaRef.current.style.height = `${Math.min(textareaRef.current.scrollHeight, 128)}px`; // Max height 128px (max-h-32)
        }
    }, [inputValue]);

    const handleSubmit = (e) => {
        e.preventDefault();
        if (inputValue.trim() && !isLoading) {
            // MODIFIED: Explicitly pass criticalThinkingEnabled
            // The onSendMessage function (defined in parent) will need to handle this additional argument.
            onSendMessage(inputValue.trim(), criticalThinkingEnabled); 
            setInputValue('');
        }
    };

    const handleKeyDown = (e) => {
        if (e.key === 'Enter' && !e.shiftKey && !isLoading) {
            e.preventDefault(); // Prevent newline in textarea
            handleSubmit(e);
        }
    };

    const icon = criticalThinkingEnabled
    ? () => <img src={blueBrain} alt="Blue Brain" className="w-5 h-5" />
    : Brain;


    return (
        <div className="p-2 sm:p-3 border-t border-border-light dark:border-border-dark bg-surface-light dark:bg-surface-dark">
            <div className="text-xs text-text-muted-light dark:text-text-muted-dark mb-1.5 h-4 transition-opacity duration-300">
                {isLoading ? (
                    <span className="flex items-center gap-1"> 
                        <Loader2 size={12} className="animate-spin" /> {currentStatus || "Processing..."}
                    </span>
                ) : (
                    currentStatus || "Ready"
                )}
            </div>

            <form onSubmit={handleSubmit} className="flex items-end gap-2">
                <IconButton
                    icon={PlusCircle}
                    title="Attach file (Coming Soon)"
                    onClick={() => toast.info("Attachment feature coming soon!")}
                    variant="ghost"
                    size="md" 
                    className="p-2 text-text-muted-light dark:text-text-muted-dark hover:text-primary"
                    disabled={isLoading}
                />

                <textarea
                    ref={textareaRef}
                    value={inputValue}
                    onChange={(e) => setInputValue(e.target.value)}
                    onKeyDown={handleKeyDown}
                    placeholder="Type your message or ask a question..."
                    className="input-field flex-1 p-2.5 resize-none min-h-[44px] max-h-32 custom-scrollbar text-sm" 
                    rows="1"
                    disabled={isLoading}
                />

                {isSpeechSupported && (
                    <IconButton
                        icon={Mic}
                        onClick={() => listening ? stopListening() : startListening()}
                        title={listening ? "Stop listening" : "Start voice input"}
                        variant={listening ? "danger" : "ghost"} 
                        size="md"
                        className={`p-2 ${listening ? 'text-red-500 dark:text-red-400 animate-pulse' : 'text-text-muted-light dark:text-text-muted-dark hover:text-primary'}`}
                        disabled={isLoading}
                    />
                )}
                
                <IconButton
                    icon={useRag ? SearchCheck : SearchSlash}
                    onClick={() => setUseRag(!useRag)}
                    title={useRag ? "Disable RAG (Chat with LLM directly)" : "Enable RAG (Use your documents)"}
                    variant="ghost"
                    size="md"
                    className={`p-2 ${useRag ? 'text-green-500 dark:text-green-400' : 'text-text-muted-light dark:text-text-muted-dark hover:text-primary'}`}
                    disabled={isLoading}
                />

                {/* New Critical Thinking Toggle */}
               <IconButton
                    icon={icon}
                    onClick={() => setCriticalThinkingEnabled(!criticalThinkingEnabled)}
                    title={criticalThinkingEnabled ? "Disable Critical Thinking (KG)" : "Enable Critical Thinking (KG)"}
                    variant="ghost"
                    size="md"
                    className={`p-2 ${criticalThinkingEnabled ? 'text-purple-500 dark:text-purple-400' : 'text-text-muted-light dark:text-text-muted-dark hover:text-primary'}`}
                    disabled={isLoading}
                />


                <Button 
                    type="submit"
                    variant="primary"
                    size="md" 
                    className="!p-2.5" 
                    disabled={isLoading || !inputValue.trim()}
                    isLoading={isLoading && inputValue.trim()} 
                    title="Send message"
                >
                    {!isLoading || !inputValue.trim() ? <Send size={20} /> : null}
                </Button>
            </form>
        </div>
    );
}
export default ChatInput;
```

`frontend/src/components/chat/MessageBubble.jsx`

```javascript
// src/components/chat/MessageBubble.jsx
import React from 'react';
import { marked } from 'marked';
import { ChevronDown, Brain, Link as LinkIcon, Zap, Server, Volume2, StopCircle, ServerCrash } from 'lucide-react'; // Added Volume2, StopCircle, ServerCrash
import { useTextToSpeech } from '../../hooks/useTextToSpeech.js'; // Correct path
import IconButton from '../core/IconButton.jsx'; // Assuming IconButton is here

marked.setOptions({
  breaks: true,
  gfm: true,
  // sanitize: false, // Consider DOMPurify for production
});

const createMarkup = (markdownText) => {
    if (!markdownText) return { __html: '' };
    // Ensure marked is configured (or assume it's configured globally)
    const rawHtml = marked.parse(markdownText);
    return { __html: rawHtml };
};

const escapeHtml = (unsafe) => {
    if (typeof unsafe !== 'string') return '';
    return unsafe
         .replace(/&/g, "&") 
         .replace(/</g, "<")
         .replace(/>/g, ">")
         .replace(/"/g, '"')
         .replace(/'/g, "'");
};

function MessageBubble({ sender, text, thinking, references, timestamp, sourcePipeline, id: messageId }) { // Added messageId prop
    const isUser = sender === 'user';
    const { speak, cancel, isSpeaking: isCurrentlySpeakingThisBubble, isSupported: ttsIsSupported, currentlySpeakingUtterance } = useTextToSpeech();

    const formatTimestamp = (ts) => {
        if (!ts) return '';
        try {
            return new Date(ts).toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' });
        } catch (e) { return 'Invalid Time'; }
    };

    const getPipelineIcon = () => {
        if (!sourcePipeline) return null;
        const lowerPipeline = sourcePipeline.toLowerCase();
        if (lowerPipeline.includes('ollama')) return <Zap size={12} className="text-green-400" title="Ollama Powered" />;
        if (lowerPipeline.includes('gemini')) return <Server size={12} className="text-blue-400" title="Gemini Powered" />;
        if (lowerPipeline.includes('rag')) return <Zap size={12} className="text-purple-400" title="RAG Enhanced" />;
        if (lowerPipeline.includes('error')) return <ServerCrash size={12} className="text-red-400" title="Error" />;
        return null;
    };

    const handleToggleSpeech = () => {
        if (!ttsIsSupported || !text) return;

        // Check if the currently speaking utterance is from this message bubble
        // This is a simplified check; utteranceRef in hook isn't directly comparable by text value easily
        // For true robust tracking, the hook would need to manage which ID is speaking.
        // For now, if any message is speaking and it's this one that wants to stop, or a new one wants to start:
        if (isCurrentlySpeakingThisBubble) { // If this bubble instance thinks it's speaking
            cancel();
        } else {
            // The speak function in the hook already calls cancel() internally
            // to stop any other ongoing speech before starting a new one.
            speak({ text });
        }
    };
    
    // Determine if the global TTS is speaking *this* message.
    // This logic is tricky if the hook is per-instance.
    // The `isCurrentlySpeakingThisBubble` state from the hook instance helps here.
    // If `currentlySpeakingUtterance` from hook was the actual utterance object, we could compare.
    // For simplicity, `isCurrentlySpeakingThisBubble` (local to this hook instance) is our best bet.

    return (
        <div className={`flex flex-col ${isUser ? 'items-end' : 'items-start'} w-full group`}>
            <div 
                className={`message-bubble max-w-[85%] md:max-w-[75%] p-3 rounded-2xl shadow-md break-words ${
                    isUser 
                    ? 'bg-primary dark:bg-primary-dark text-white rounded-br-lg' 
                    : 'bg-surface-light dark:bg-surface-dark text-text-light dark:text-text-dark rounded-bl-lg border border-border-light dark:border-border-dark'
                }`}
            >
                {/* Main message content */}
                <div 
                    className="prose prose-sm dark:prose-invert max-w-none message-content leading-relaxed" 
                    dangerouslySetInnerHTML={createMarkup(text || '')} 
                />
                
                {/* Timestamp, Pipeline Icon, and TTS Button */}
                <div className="flex items-center justify-end mt-1.5 text-xs opacity-70 gap-2">
                    {!isUser && getPipelineIcon() && <span className="mr-1">{getPipelineIcon()}</span>}
                    <span>{formatTimestamp(timestamp)}</span>
                    {!isUser && ttsIsSupported && text && (
                        <IconButton
                            icon={isCurrentlySpeakingThisBubble ? StopCircle : Volume2}
                            onClick={handleToggleSpeech}
                            title={isCurrentlySpeakingThisBubble ? "Stop reading" : "Read aloud"}
                            size="sm" // Small icon button
                            variant="ghost"
                            className={`p-0.5 ${isCurrentlySpeakingThisBubble ? 'text-red-500' : 'text-text-muted-light dark:text-text-muted-dark hover:text-primary'}`}
                        />
                    )}
                </div>
            </div>

            {/* Metadata: Thinking and References for Bot Messages */}
            {!isUser && (thinking || (references && references.length > 0)) && (
                <div className="message-metadata-container max-w-[85%] md:max-w-[75%] mt-1.5 pl-2 space-y-1 opacity-0 group-hover:opacity-100 transition-opacity duration-200">
                    {thinking && thinking.trim() && (
                        <details className="group/details text-xs">
                            <summary className="flex items-center gap-1 cursor-pointer text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light transition-colors">
                                <Brain size={14} /> AI Reasoning
                                <ChevronDown size={14} className="group-open/details:rotate-180 transition-transform" />
                            </summary>
                            <pre className="mt-1 p-2 bg-gray-100 dark:bg-gray-800 rounded-md text-text-light dark:text-text-dark whitespace-pre-wrap break-all text-[0.7rem] max-h-32 overflow-y-auto custom-scrollbar">
                                <code>{escapeHtml(thinking)}</code>
                            </pre>
                        </details>
                    )}
                    {references && references.length > 0 && (
                        <details className="group/details text-xs" open>
                            <summary className="flex items-center gap-1 cursor-pointer text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light transition-colors">
                                <LinkIcon size={14} /> References
                                <ChevronDown size={14} className="group-open/details:rotate-180 transition-transform" />
                            </summary>
                            <ul className="mt-1 pl-1 space-y-0.5 text-[0.7rem]">
                                {references.map((ref, index) => (
                                    <li 
                                        key={index} 
                                        className="text-text-muted-light dark:text-text-muted-dark hover:text-text-light dark:hover:text-text-dark transition-colors truncate"
                                        title={`Preview: ${escapeHtml(ref.content_preview || '')}\nSource: ${escapeHtml(ref.source || '')}`}
                                    >
                                        <span className="font-semibold text-accent">[{ref.number}]</span> {escapeHtml(ref.source)}
                                    </li>
                                ))}
                            </ul>
                        </details>
                    )}
                </div>
            )}
        </div>
    );
}
export default MessageBubble;
```

`frontend/src/components/common/ThemeToggle.jsx`

```javascript
import React from 'react';
import { Sun, Moon } from 'lucide-react';
import { useTheme } from '../../hooks/useTheme';

function ThemeToggle() {
    const { theme, toggleTheme } = useTheme();

    return (
        <button
            onClick={toggleTheme}
            className="p-2 rounded-full text-text-muted-light dark:text-text-muted-dark hover:bg-gray-200 dark:hover:bg-gray-700 transition-colors focus:outline-none focus:ring-2 focus:ring-primary"
            aria-label={theme === 'light' ? 'Switch to dark theme' : 'Switch to light theme'}
        >
            {theme === 'light' ? <Moon size={20} /> : <Sun size={20} />}
        </button>
    );
}

export default ThemeToggle;
```

`frontend/src/components/core/Button.jsx`

```javascript
// src/components/core/Button.jsx
import React from 'react';
import { Loader2 } from 'lucide-react'; // For loading spinner

const Button = ({
    children,
    onClick,
    type = 'button',
    variant = 'primary', // 'primary', 'secondary', 'danger', 'outline', 'ghost'
    size = 'md', // 'sm', 'md', 'lg'
    leftIcon,
    rightIcon,
    isLoading = false,
    disabled = false,
    fullWidth = false,
    className = '',
    ...props
}) => {
    const baseStyles = "font-semibold rounded-lg focus:outline-none focus:ring-2 focus:ring-opacity-75 transition-all duration-150 ease-in-out flex items-center justify-center gap-2";

    const variantStyles = {
        primary: "bg-primary hover:bg-primary-dark text-white focus:ring-primary",
        secondary: "bg-secondary hover:bg-secondary-dark text-white focus:ring-secondary",
        danger: "bg-red-500 hover:bg-red-600 text-white focus:ring-red-500",
        outline: "border border-primary text-primary hover:bg-primary-light dark:hover:bg-opacity-10 focus:ring-primary",
        ghost: "text-primary hover:bg-primary-light dark:hover:bg-opacity-10 focus:ring-primary",
    };

    const sizeStyles = {
        sm: "px-3 py-1.5 text-xs",
        md: "px-4 py-2 text-sm",
        lg: "px-6 py-3 text-base",
    };

    const widthStyle = fullWidth ? "w-full" : "";
    const isDisabled = disabled || isLoading;
    const finalDisabledStyle = isDisabled ? "opacity-60 cursor-not-allowed" : "cursor-pointer";

    const spinnerSize = size === 'sm' ? 14 : (size === 'lg' ? 20 : 16);
    
    return (
        <button
            type={type}
            onClick={onClick}
            disabled={isDisabled} // Use the corrected variable
            className={`${baseStyles} ${variantStyles[variant]} ${sizeStyles[size]} ${widthStyle} ${finalDisabledStyle} ${className}`}
            {...props}
        >
            {isLoading && (
                <Loader2 size={spinnerSize} className="animate-spin" />
            )}
            {!isLoading && leftIcon && <span className="icon-left">{leftIcon}</span>}

            <span className={isLoading ? 'ml-2' : ''}>{children}</span>

            {!isLoading && rightIcon && <span className="icon-right">{rightIcon}</span>}
        </button>
    );
};

export default Button;
```

`frontend/src/components/core/IconButton.jsx`

```javascript
import React from 'react';
import { Loader2 } from 'lucide-react';

const IconButton = ({
    icon: Icon, // Pass the Lucide icon component directly
    onClick,
    variant = 'ghost', // 'ghost', 'outline', 'subtle'
    size = 'md', // 'sm', 'md', 'lg'
    isLoading = false,
    disabled = false,
    className = '',
    title, // For accessibility and tooltips
    ariaLabel,
    ...props
}) => {
    const baseStyles = "rounded-md focus:outline-none focus:ring-2 focus:ring-opacity-75 transition-colors duration-150 flex items-center justify-center";

    const variantStyles = {
        ghost: "text-text-muted-light dark:text-text-muted-dark hover:bg-gray-200 dark:hover:bg-gray-700 focus:ring-primary",
        outline: "border border-gray-300 dark:border-gray-600 text-text-muted-light dark:text-text-muted-dark hover:border-primary hover:text-primary focus:ring-primary",
        subtle: "bg-gray-100 dark:bg-gray-700 text-text-light dark:text-text-dark hover:bg-gray-200 dark:hover:bg-gray-600 focus:ring-primary",
        danger: "text-red-500 hover:bg-red-100 dark:hover:bg-red-900 focus:ring-red-500"
    };

    const sizeStyles = {
        sm: "p-1.5", // Icon size typically 14-16px
        md: "p-2",   // Icon size typically 18-20px
        lg: "p-2.5", // Icon size typically 22-24px
    };
    
    const iconSizeMap = {
        sm: 16,
        md: 20,
        lg: 24,
    };

    const disabledStyle = (disabled || isLoading) ? "opacity-50 cursor-not-allowed" : "cursor-pointer";

    return (
        <button
            type="button"
            onClick={onClick}
            disabled={disabled || isLoading}
            className={`${baseStyles} ${variantStyles[variant]} ${sizeStyles[size]} ${disabledStyle} ${className}`}
            title={title}
            aria-label={ariaLabel || title}
            {...props}
        >
            {isLoading ? (
                <Loader2 size={iconSizeMap[size]} className="animate-spin" />
            ) : (
                Icon && <Icon size={iconSizeMap[size]} />
            )}
        </button>
    );
};

export default IconButton;
```

`frontend/src/components/core/Modal.jsx`

```javascript
// src/components/core/Modal.jsx
import React, { useEffect, useRef } from 'react';
import { X } from 'lucide-react';
import { motion, AnimatePresence } from 'framer-motion';

const Modal = ({
    isOpen,
    onClose,
    title,
    children,
    footerContent,
    size = 'md', // 'sm', 'md', 'lg', 'xl', '2xl', '3xl', '4xl', '5xl', 'full'
    closeOnOverlayClick = true,
    initialFocusRef, // Optional ref for focusing an element inside the modal on open
}) => {
    const modalRef = useRef(null);

    // Handle Escape key for closing
    useEffect(() => {
        const handleEscapeKey = (event) => {
            if (event.key === 'Escape' && isOpen) {
                onClose();
            }
        };
        if (isOpen) {
            document.addEventListener('keydown', handleEscapeKey);
        }
        return () => {
            document.removeEventListener('keydown', handleEscapeKey);
        };
    }, [isOpen, onClose]);

    // Handle focus trapping and initial focus
    useEffect(() => {
        if (isOpen) {
            // Set focus to the initialFocusRef or the modal itself
            if (initialFocusRef && initialFocusRef.current) {
                initialFocusRef.current.focus();
            } else if (modalRef.current) {
                modalRef.current.focus(); // Fallback to modal itself
            }

            // Basic focus trapping (can be made more robust with a library)
            const focusableElements = modalRef.current?.querySelectorAll(
                'button, [href], input, select, textarea, [tabindex]:not([tabindex="-1"])'
            );
            if (focusableElements && focusableElements.length > 0) {
                const firstElement = focusableElements[0];
                const lastElement = focusableElements[focusableElements.length - 1];

                const onKeyDown = (e) => {
                    if (e.key === 'Tab') {
                        if (e.shiftKey) { // Shift + Tab
                            if (document.activeElement === firstElement) {
                                lastElement.focus();
                                e.preventDefault();
                            }
                        } else { // Tab
                            if (document.activeElement === lastElement) {
                                firstElement.focus();
                                e.preventDefault();
                            }
                        }
                    }
                };
                modalRef.current?.addEventListener('keydown', onKeyDown);
                return () => modalRef.current?.removeEventListener('keydown', onKeyDown);
            }
        }
    }, [isOpen, initialFocusRef]);


    const sizeClasses = {
        sm: 'max-w-sm',
        md: 'max-w-md',
        lg: 'max-w-lg',
        xl: 'max-w-xl',
        '2xl': 'max-w-2xl',
        '3xl': 'max-w-3xl',
        '4xl': 'max-w-4xl',
        '5xl': 'max-w-5xl',
        full: 'max-w-full h-full rounded-none sm:rounded-lg sm:max-h-[95vh]', // Special case for full screen like
    };

    const backdropVariants = {
        visible: { opacity: 1, transition: { duration: 0.2, ease: "easeOut" } },
        hidden: { opacity: 0, transition: { duration: 0.15, ease: "easeIn" } },
    };

    const modalVariants = {
        hidden: { y: "-30px", opacity: 0, scale: 0.98, transition: { duration: 0.15, ease: "easeIn" } },
        visible: { y: "0", opacity: 1, scale: 1, transition: { type: "spring", stiffness: 400, damping: 30, duration: 0.3 } },
        exit: { y: "30px", opacity: 0, scale: 0.98, transition: { duration: 0.2, ease: "easeIn" } }
    };

    if (!isOpen) return null;

    return (
        <AnimatePresence mode="wait">
            {isOpen && (
                <motion.div
                    key="modal-backdrop"
                    className="fixed inset-0 z-50 flex items-center justify-center p-4 bg-black/70 dark:bg-black/80 backdrop-blur-sm"
                    initial="hidden"
                    animate="visible"
                    exit="hidden"
                    variants={backdropVariants}
                    onClick={closeOnOverlayClick ? onClose : undefined}
                    aria-labelledby="modal-title" // For screen readers
                    role="dialog" // Role for the backdrop itself, more specific roles on content
                    aria-modal="true" // Indicate it's a modal overlaying other content
                >
                    <motion.div
                        key="modal-content-wrapper" // Changed key for potential AnimatePresence behavior
                        ref={modalRef}
                        tabIndex={-1} // Make the modal itself focusable for fallback
                        className={`bg-surface-light dark:bg-surface-dark rounded-lg shadow-xl w-full ${sizeClasses[size]} flex flex-col overflow-hidden
                                    ${size === 'full' ? '' : 'max-h-[90vh] sm:max-h-[85vh]'}`} 
                                    // Apply max-h unless it's 'full' size
                        role="document" // The actual dialog content
                        aria-modal="true"
                        aria-labelledby={title ? "modal-title-text" : undefined} // Point to title if exists
                        initial="hidden"
                        animate="visible"
                        exit="exit"
                        variants={modalVariants}
                        onClick={(e) => e.stopPropagation()} // Prevent closing when clicking inside modal
                    >
                        {/* Modal Header */}
                        <div className="flex items-center justify-between px-5 py-3.5 border-b border-border-light dark:border-border-dark sticky top-0 bg-surface-light dark:bg-surface-dark z-10 flex-shrink-0">
                            {title && (
                                <h2 id="modal-title-text" className="text-lg font-semibold text-text-light dark:text-text-dark truncate pr-4">
                                    {title}
                                </h2>
                            )}
                            <button
                                onClick={onClose}
                                className="p-1.5 rounded-full text-text-muted-light dark:text-text-muted-dark 
                                           hover:bg-gray-200/80 dark:hover:bg-gray-700/80 
                                           hover:text-red-500 dark:hover:text-red-400 
                                           focus:outline-none focus:ring-2 focus:ring-primary dark:focus:ring-primary-light focus:ring-offset-1 dark:focus:ring-offset-surface-dark"
                                aria-label="Close modal"
                            >
                                <X size={20} />
                            </button>
                        </div>

                        {/* Modal Body */}
                        <div className="px-5 py-4 overflow-y-auto flex-grow custom-scrollbar">
                            {children}
                        </div>

                        {/* Modal Footer */}
                        {footerContent && (
                            <div className="px-5 py-3.5 border-t border-border-light dark:border-border-dark flex justify-end gap-3 sticky bottom-0 bg-surface-light dark:bg-surface-dark z-10 flex-shrink-0">
                                {footerContent}
                            </div>
                        )}
                    </motion.div>
                </motion.div>
            )}
        </AnimatePresence>
    );
};

export default Modal;
```

`frontend/src/components/documents/DocumentList.jsx`

```javascript


// frontend/src/components/documents/DocumentList.jsx
import React, { useState, useEffect, useCallback } from 'react';
import api from '../../services/api.js'; // Mocked for V1
import toast from 'react-hot-toast';
import { FileText, Edit3, Trash2, Loader2, AlertTriangle, CheckCircle } from 'lucide-react';
import IconButton from '../core/IconButton.jsx'; // Make sure IconButton is imported
import { useAuth } from '../../hooks/useAuth.jsx';

// Props from LeftPanel: onSelectDocument is selectDocumentForAnalysis from AppStateContext
// selectedDocument is selectedDocumentForAnalysis from AppStateContext
function DocumentList({ onSelectDocument, selectedDocument }) {
  const [files, setFiles] = useState([]);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState('');

  const fetchFiles = useCallback(async () => {
    setLoading(true);
    setError('');
    try {
      
      const response = await api.getFiles(); // Returns { filenames: ["A.txt", "B.pdf"] }
      const filenames = Array.isArray(response.filenames) ? response.filenames : [];
      setFiles(filenames);
      
    } catch (err) {
      console.error("Failed to fetch files:", err);
      setError(err.message || "Failed to fetch files.");
      toast.error("Could not load documents.");
    } finally {
      setLoading(false);
    }
  }, []);



  useEffect(() => {
    fetchFiles();
  }, [fetchFiles]);

  const handleDelete = async (filename) => {
    if (!window.confirm(`Are you sure you want to delete "${filename}"?`)) return;
    const toastId = toast.loading(`Deleting ${filename}...`);
    try {
      await api.deleteFile(filename); // Assumes this works with filename
      toast.success(`${filename} deleted.`, { id: toastId });
      fetchFiles();
      if (selectedDocument === filename) {
        onSelectDocument(null);
      }
    } catch (err) {
      toast.error(`Delete failed: ${err.message}`, { id: toastId });
    }
  };

  if (loading) {
    return (
      <div className="flex items-center justify-center p-4 text-text-muted-light dark:text-text-muted-dark">
        <Loader2 size={20} className="animate-spin mr-2" /> Loading documents...
      </div>
    );
  }

  if (error) {
    return (
      <div className="p-3 bg-red-500/10 border border-red-500/30 text-red-600 dark:text-red-300 rounded-md text-sm flex items-center gap-2">
        <AlertTriangle size={18} /> {error}
        <button onClick={fetchFiles} className="ml-auto text-xs underline hover:text-red-400">Retry</button>
      </div>
    );
  }

  if (files.length === 0) {
    return <p className="text-center text-xs text-text-muted-light dark:text-text-muted-dark p-4">No documents uploaded.</p>;
  }

  return (
    <div className="space-y-1.5 text-xs custom-scrollbar pr-1">
      {files.map(filename => {
        const isSelected = selectedDocument === filename;

        return (
          <div
            key={filename}
            onClick={() => onSelectDocument(isSelected ? null : filename)}
            className={`p-2.5 bg-surface-light dark:bg-gray-800 border rounded-md flex items-center justify-between hover:shadow-md transition-all duration-150 cursor-pointer
                        ${isSelected
                          ? 'ring-2 ring-primary dark:ring-primary-light shadow-lg border-primary dark:border-primary-light'
                          : 'border-border-light dark:border-border-dark hover:border-gray-400 dark:hover:border-gray-500'}`}
            title={`Select ${filename}`}
          >
            <div className="flex items-center gap-2 truncate">
              {isSelected ? (
                <CheckCircle size={16} className="text-green-500 flex-shrink-0" />
              ) : (
                <FileText size={16} className="text-primary dark:text-primary-light flex-shrink-0" />
              )}
              <span className={`truncate ${isSelected ? 'font-semibold text-primary dark:text-primary-light' : 'text-text-light dark:text-text-dark'}`}>
                {filename}
              </span>
            </div>
            <div className="flex-shrink-0 flex items-center gap-0.5">
              <IconButton
                icon={Trash2}
                size="sm"
                variant="ghost"
                title="Delete"
                onClick={(e) => {
                  e.stopPropagation();
                  handleDelete(filename);
                }}
                className="text-red-500 hover:text-red-700 dark:text-red-400 dark:hover:text-red-300 p-1"
              />
            </div>
          </div>
        );
      })}
    </div>
  );
}


export default DocumentList;
```

`frontend/src/components/documents/DocumentUpload.jsx`

```javascript
// frontend/src/components/documents/DocumentUpload.jsx
import React, { useState, useRef, useEffect } from 'react';
import api from '../../services/api.js';
import toast from 'react-hot-toast';
import { UploadCloud, FileText, XCircle, Loader2, CheckCircle, AlertTriangle, Paperclip } from 'lucide-react';
import Button from '../core/Button.jsx'; // Your custom Button

// Define the states and corresponding button texts
const BUTTON_TEXT_STATES = {
    IDLE_NO_FILE: "Select a File",
    IDLE_FILE_SELECTED: "Upload Document",
    UPLOADING_BYTES: "Uploading file...", // Static text during byte transfer phase
    // Cycling messages after byte upload, while Node.js waits for Python
    EXTRACTING_CONTENT: "Extracting content...",
    CLEANING_TEXT: "Cleaning text...",
    ANALYZING_DOCUMENT: "Analyzing document...",
    // After Node.js 202 response (Python call finished from Node's perspective)
    FINALIZING_SUBMISSION: "Finalizing...",
    ERROR: "Upload Failed - Retry?", // Or simply "Upload Failed"
};

// Order for the first cycle of detailed processing messages on the button
const firstCycleButtonMessages = [
    BUTTON_TEXT_STATES.EXTRACTING_CONTENT,
    BUTTON_TEXT_STATES.CLEANING_TEXT,
    BUTTON_TEXT_STATES.ANALYZING_DOCUMENT,
];

// Order for subsequent looping cycles on the button
const loopCycleButtonMessages = [
    BUTTON_TEXT_STATES.CLEANING_TEXT, // Loop starts from "Cleaning..."
    BUTTON_TEXT_STATES.ANALYZING_DOCUMENT,
];

const MESSAGE_BUTTON_DISPLAY_DURATION_MS = 3000; // 3 seconds per message

function DocumentUpload({ onUploadSuccess }) {
    const [selectedFile, setSelectedFile] = useState(null);
    const [isProcessing, setIsProcessing] = useState(false);
    const [buttonText, setButtonText] = useState(BUTTON_TEXT_STATES.IDLE_NO_FILE);
    const [errorMessage, setErrorMessage] = useState('');
    const [dragActive, setDragActive] = useState(false); // For dropzone visual feedback

    const fileInputRef = useRef(null);
    const intervalRef = useRef(null);       // Stores the setInterval ID
    const messageIndexRef = useRef(0);    // Current index in the message array
    const currentMessageArrayRef = useRef(firstCycleButtonMessages); // Which array to use (first or loop)
    const isMountedRef = useRef(true);      // Track if component is mounted

    console.log(`[UploadFinalUX] Component Render/Re-render. isProcessing: ${isProcessing}, buttonText: "${buttonText}"`);

    // Effect for component mount and unmount
    useEffect(() => {
        isMountedRef.current = true;
        console.log("[UploadFinalUX] Component Mounted.");
        return () => {
            isMountedRef.current = false;
            if (intervalRef.current) {
                clearInterval(intervalRef.current);
                console.log("[UploadFinalUX] Component Unmounting - Cleared interval:", intervalRef.current);
            }
            console.log("[UploadFinalUX] Component Unmounted.");
        };
    }, []);

    // Effect to manage the cycling of button text messages
    useEffect(() => {
        const clearLocalInterval = (reason = "unspecified") => {
            if (intervalRef.current) {
                console.log(`[UploadFinalUX CycleEffect] Clearing interval (Reason: ${reason}). ID: ${intervalRef.current}`);
                clearInterval(intervalRef.current);
                intervalRef.current = null;
            }
        };

        console.log(`[UploadFinalUX CycleEffect] Evaluating. isProcessing: ${isProcessing}, buttonText: "${buttonText}"`);

        const isCurrentlyInCyclingState =
            buttonText === BUTTON_TEXT_STATES.EXTRACTING_CONTENT ||
            buttonText === BUTTON_TEXT_STATES.CLEANING_TEXT ||
            buttonText === BUTTON_TEXT_STATES.ANALYZING_DOCUMENT;

        if (isProcessing && isCurrentlyInCyclingState) {
            if (!intervalRef.current) { // Only start a new interval if one isn't already running
                console.log(`[UploadFinalUX CycleEffect] Starting new interval. Initial buttonText for cycle: "${buttonText}"`);

                // Determine which array and index to start/resume from
                if (buttonText === BUTTON_TEXT_STATES.EXTRACTING_CONTENT) {
                    currentMessageArrayRef.current = firstCycleButtonMessages;
                    messageIndexRef.current = 0; // Start from the beginning of the first cycle
                } else { // Resuming or starting mid-loop (e.g., if state was restored)
                    const loopIdx = loopCycleButtonMessages.indexOf(buttonText);
                    currentMessageArrayRef.current = loopCycleButtonMessages;
                    messageIndexRef.current = (loopIdx !== -1) ? loopIdx : 0;
                }
                // No need to setButtonText here, as it's already in a cycling state which triggered this.

                intervalRef.current = setInterval(() => {
                    if (!isMountedRef.current || !isProcessing) {
                        clearLocalInterval("component unmounted or no longer processing in interval");
                        return;
                    }

                    messageIndexRef.current++; // Advance to the next message in the current array
                    if (messageIndexRef.current >= currentMessageArrayRef.current.length) {
                        // Reached the end of the current message array, switch to loopCycleMessages
                        currentMessageArrayRef.current = loopCycleButtonMessages;
                        messageIndexRef.current = 0; // Reset index for the loop array
                        console.log("[UploadFinalUX Interval] Switched/Reset to loopCycleMessages. Next message index: 0");
                    }
                    
                    const nextButtonText = currentMessageArrayRef.current[messageIndexRef.current];
                    console.log(`[UploadFinalUX Interval] Setting buttonText to: "${nextButtonText}" (Index: ${messageIndexRef.current} in [${currentMessageArrayRef.current.join(', ')}])`);
                    if (isMountedRef.current) setButtonText(nextButtonText);

                }, MESSAGE_BUTTON_DISPLAY_DURATION_MS);
                console.log(`[UploadFinalUX CycleEffect] Interval started. ID: ${intervalRef.current}. Initial array: [${currentMessageArrayRef.current.join(', ')}]`);
            } else {
                console.log(`[UploadFinalUX CycleEffect] Interval already running for a cycling state. ID: ${intervalRef.current}`);
            }
        } else {
            // If not processing, or if buttonText is not one of the cycling states, clear any existing interval.
            if (intervalRef.current) {
                clearLocalInterval(`not processing or not in cycling state (Text: ${buttonText})`);
            } else {
                // console.log(`[UploadFinalUX CycleEffect] Conditions for cycling NOT met, and no active interval to clear.`);
            }
        }

        return () => { // Cleanup function for this useEffect
            // console.log(`[UploadFinalUX CycleEffect] Cleanup on dep change (isProcessing/buttonText). Current interval ID: ${intervalRef.current}`);
            clearLocalInterval("effect dependency change cleanup");
        };
    }, [isProcessing, buttonText]); // Key dependencies for managing the interval


    const handleFileChange = (e) => {
        console.log("[UploadFinalUX] handleFileChange triggered.");
        if (isProcessing) {
            console.log("[UploadFinalUX] handleFileChange: Currently processing, ignoring file change.");
            return;
        }
        const file = e.target.files && e.target.files[0];
        if (file) {
            setSelectedFile(file);
            setButtonText(BUTTON_TEXT_STATES.IDLE_FILE_SELECTED);
            setErrorMessage('');
            console.log("[UploadFinalUX] handleFileChange: File selected:", file.name);
        } else {
            console.log("[UploadFinalUX] handleFileChange: No file selected or selection cancelled.");
            resetState(); // Resets to IDLE_NO_FILE
        }
    };

    const handleDrag = (e) => { e.preventDefault(); e.stopPropagation(); if (isProcessing) return; if (e.type === "dragenter" || e.type === "dragover") setDragActive(true); else if (e.type === "dragleave") setDragActive(false); };
    const handleDrop = (e) => { e.preventDefault(); e.stopPropagation(); if (isProcessing) return; setDragActive(false); const file = e.dataTransfer.files && e.dataTransfer.files[0]; if (file) { setSelectedFile(file); setButtonText(BUTTON_TEXT_STATES.IDLE_FILE_SELECTED); setErrorMessage(''); console.log("[UploadFinalUX] handleDrop: File dropped:", file.name); } };

    const handleUpload = async () => {
    if (!selectedFile) {
        toast.error("Please select a file first.");
        return;
    }

    console.log("[UploadFinalUX] handleUpload: Starting upload for", selectedFile.name);
    setIsProcessing(true);
    setButtonText(BUTTON_TEXT_STATES.UPLOADING_BYTES);
    setErrorMessage("");

    // Reset cycling refs
    messageIndexRef.current = 0;
    currentMessageArrayRef.current = firstCycleButtonMessages;

    const formData = new FormData();
    formData.append("file", selectedFile);

    //  Fallback: if onUploadProgress never reaches 100%, force EXTRACTING_CONTENT after 500ms 
    const fallbackTimer = setTimeout(() => {
        if (
        isMountedRef.current &&
        isProcessing &&
        buttonText === BUTTON_TEXT_STATES.UPLOADING_BYTES
        ) {
        console.log(
            "[UploadFinalUX] handleUpload: Forcing EXTRACTING_CONTENT (fallback)."
        );
        setButtonText(BUTTON_TEXT_STATES.EXTRACTING_CONTENT);
        }
    }, 500);
    // 

    try {
        console.log("[UploadFinalUX] handleUpload: Calling api.uploadFile");
        await api.uploadFile(formData, (event) => {
        if (isMountedRef.current && isProcessing) {
            if (event.lengthComputable) {
            if (event.loaded === event.total) {
                if (buttonText !== BUTTON_TEXT_STATES.EXTRACTING_CONTENT) {
                console.log(
                    "[UploadFinalUX] onUploadProgress: 100% bytes sent. Setting EXTRACTING_CONTENT."
                );
                setButtonText(BUTTON_TEXT_STATES.EXTRACTING_CONTENT);
                }
                clearTimeout(fallbackTimer);
            }
            } else if (buttonText === BUTTON_TEXT_STATES.UPLOADING_BYTES) {
            console.log(
                "[UploadFinalUX] onUploadProgress: Not computable & still UPLOADING_BYTES. Setting EXTRACTING_CONTENT."
            );
            setButtonText(BUTTON_TEXT_STATES.EXTRACTING_CONTENT);
            clearTimeout(fallbackTimer);
            }
        }
        });

        console.log(
        "[UploadFinalUX] handleUpload: api.uploadFile resolved (Node.js 202 received)."
        );
        clearTimeout(fallbackTimer);

        if (isMountedRef.current && isProcessing) {
        console.log(
            "[UploadFinalUX] handleUpload: Setting buttonText to FINALIZING_SUBMISSION."
        );
        setButtonText(BUTTON_TEXT_STATES.FINALIZING_SUBMISSION);
        }

        if (onUploadSuccess) {
        onUploadSuccess({ originalname: selectedFile.name });
        }
        toast.success(`"${selectedFile.name}" submitted. Background tasks initiated.`);

        setTimeout(() => {
        if (isMountedRef.current) {
            console.log(
            "[UploadFinalUX] handleUpload: Timeout for resetState after FINALIZING_SUBMISSION."
            );
            resetState();
        }
        }, 1500);
    } catch (error) {
        clearTimeout(fallbackTimer);
        console.error("[UploadFinalUX] Upload failed in catch:", error);
        if (isMountedRef.current) {
        const msg =
            error.response?.data?.message || error.message || "Upload processing failed.";
        setErrorMessage(msg);
        setButtonText(BUTTON_TEXT_STATES.ERROR);
        setIsProcessing(false);
        toast.error(`Upload of "${selectedFile.name}" failed.`);
        }
    }
    };



    const resetState = () => {
        console.log("[UploadFinalUX] resetState called.");
        setSelectedFile(null);
        setButtonText(BUTTON_TEXT_STATES.IDLE_NO_FILE);
        setErrorMessage('');
        setIsProcessing(false); // This will trigger CycleEffect to clear interval
        if (fileInputRef.current) {
            fileInputRef.current.value = null;
        }
        setDragActive(false);
        messageIndexRef.current = 0;
        currentMessageArrayRef.current = firstCycleButtonMessages; // Reset for next cycle
        console.log("[UploadFinalUX] resetState: State reset complete.");
    };

    const isButtonUploadActuallyDisabled = !selectedFile || isProcessing;
    const UploadAreaIcon = Paperclip;

    return (
        <div className="mb-4 p-1">
            <label
                htmlFor="file-upload-input"
                onDragEnter={handleDrag}
                onDragLeave={handleDrag}
                onDragOver={handleDrag}
                onDrop={handleDrop}
                className={`flex flex-col items-center justify-center w-full h-36 px-4 transition-colors duration-200 ease-in-out
                            bg-surface-light dark:bg-gray-800
                            border-2 border-dashed rounded-lg cursor-pointer
                            border-border-light dark:border-border-dark
                            hover:border-primary dark:hover:border-primary-light
                            ${isProcessing ? "opacity-60 cursor-not-allowed" : ""}
                            ${dragActive ? "border-primary dark:border-primary-light ring-2 ring-primary dark:ring-primary-light bg-primary/10 dark:bg-primary-dark/20" : ""}`}
            >
                <div className="flex flex-col items-center justify-center text-center">
                    <UploadAreaIcon size={36} className={`mb-2 transition-colors ${dragActive ? 'text-primary dark:text-primary-light' : 'text-text-muted-light dark:text-text-muted-dark'}`} />
                    <p className="mb-1 text-xs sm:text-sm text-text-muted-light dark:text-text-muted-dark">
                        <span className="font-semibold text-primary dark:text-primary-light">Click to upload</span> or drag and drop
                    </p>
                    <p className="text-[0.7rem] sm:text-xs text-text-muted-light dark:text-text-muted-dark">PDF, DOCX, TXT, PPTX, code files</p>
                </div>
                <input ref={fileInputRef} id="file-upload-input" type="file" className="hidden" onChange={handleFileChange}
                       disabled={isProcessing}
                       accept=".pdf,.doc,.docx,.ppt,.pptx,.txt,.py,.js,.md,.html,.xml,.json,.csv,.log,.c,.cpp,.java" />
            </label>

            {selectedFile && (
                <div className="mt-2 p-2 bg-gray-100 dark:bg-gray-700 rounded-md flex items-center justify-between text-sm animate-fadeIn">
                    <div className="flex items-center gap-2 truncate">
                        {buttonText === BUTTON_TEXT_STATES.ERROR && errorMessage ?
                            <AlertTriangle size={18} className="text-red-500 flex-shrink-0" /> :
                            <FileText size={18} className="text-primary flex-shrink-0" />
                        }
                        <span className="truncate text-text-light dark:text-text-dark" title={selectedFile.name}>{selectedFile.name}</span>
                        <span className="text-text-muted-light dark:text-text-muted-dark text-xs whitespace-nowrap">
                            ({(selectedFile.size / 1024).toFixed(1)} KB)
                        </span>
                    </div>
                    {!isProcessing && buttonText !== BUTTON_TEXT_STATES.ERROR && (
                        <button onClick={resetState} className="text-red-500 hover:text-red-700 dark:hover:text-red-400 transition-colors p-1 rounded-full hover:bg-red-500/10">
                            <XCircle size={18} />
                        </button>
                    )}
                </div>
            )}

            {/* Error message display area (if any) */}
            {errorMessage && buttonText === BUTTON_TEXT_STATES.ERROR && (
                 <div className="mt-2 text-xs text-red-600 dark:text-red-400 p-2 bg-red-500/10 rounded-md flex justify-center items-center h-auto">
                    <AlertTriangle size={14} className="mr-1.5 flex-shrink-0" />
                    <span className="flex-grow text-center">{errorMessage.substring(0,100)}</span>
                 </div>
            )}

            <Button
                onClick={handleUpload}
                fullWidth
                className="mt-3 text-sm min-h-[38px]" // min-height to prevent button size jumping due to text length
                variant="primary"
                isLoading={isProcessing} // Button component shows its spinner when true
                disabled={isButtonUploadActuallyDisabled}
                leftIcon={!isProcessing && buttonText !== BUTTON_TEXT_STATES.ERROR ? <UploadCloud size={16} /> : null}
            >
                {/* The button's text is now directly from the buttonText state */}
                {buttonText}
            </Button>
        </div>
    );
}
export default DocumentUpload;
```

`frontend/src/components/documents/SubjectList.jsx`

```javascript
// frontend/src/components/documents/SubjectList.jsx
import React from 'react';
import { Library, CheckCircle, Loader2, AlertTriangle } from 'lucide-react'; // Added AlertTriangle

function SubjectList({
    subjects,           // Array of subject name strings
    selectedSubject,    // Currently selected subject name (string or null)
    onSelectSubject,    // Function to call when a subject is selected (passes subjectName or null)
    isLoading,          // Boolean to indicate if subjects are being fetched
    error               // String error message if fetching failed
}) {
    if (isLoading) {
        return (
            <div className="flex items-center justify-center p-4 text-text-muted-light dark:text-text-muted-dark text-xs">
                <Loader2 size={16} className="animate-spin mr-2" /> Loading subjects...
            </div>
        );
    }

    if (error) {
        return (
            <div className="p-2 my-1 bg-red-500/10 border border-red-500/30 text-red-600 dark:text-red-300 rounded-md text-xs flex items-center justify-center gap-1">
                <AlertTriangle size={14} /> {error}
            </div>
        );
    }

    if (!subjects || subjects.length === 0) {
        return <p className="text-center text-xs text-text-muted-light dark:text-text-muted-dark p-3">No subjects configured by admin yet.</p>;
    }

    return (
        <div className="space-y-1.5 text-xs custom-scrollbar pr-1 max-h-60 overflow-y-auto"> {/* Added max-h and overflow */}
            {/* Option to deselect/choose general chat */}
            <div
                onClick={() => onSelectSubject(null)} // Pass null to deselect
                className={`p-2.5 bg-surface-light dark:bg-gray-800 border rounded-md flex items-center justify-between hover:shadow-md transition-all duration-150 cursor-pointer
                            ${!selectedSubject // Highlighted if no subject is selected
                                ? 'ring-2 ring-primary dark:ring-primary-light shadow-lg border-primary dark:border-primary-light'
                                : 'border-border-light dark:border-border-dark hover:border-gray-400 dark:hover:border-gray-500'}`}
                title="Select General Chat (No Specific Subject)"
            >
                <div className="flex items-center gap-2 truncate">
                    {!selectedSubject ? (
                        <CheckCircle size={16} className="text-green-500 flex-shrink-0" />
                    ) : (
                        // Using a generic icon, or you can use a different one for "none"
                        <Library size={16} className="text-gray-400 dark:text-gray-500 flex-shrink-0" />
                    )}
                    <span className={`truncate ${!selectedSubject ? 'font-semibold text-primary dark:text-primary-light' : 'text-text-light dark:text-text-dark'}`}>
                        -- General Chat --
                    </span>
                </div>
            </div>

            {/* List of available subjects */}
            {subjects.map(subjectName => {
                const isSelected = selectedSubject === subjectName;
                return (
                    <div
                        key={subjectName}
                        onClick={() => onSelectSubject(isSelected ? null : subjectName)} // Toggle selection
                        className={`p-2.5 bg-surface-light dark:bg-gray-800 border rounded-md flex items-center justify-between hover:shadow-md transition-all duration-150 cursor-pointer
                                    ${isSelected
                                        ? 'ring-2 ring-primary dark:ring-primary-light shadow-lg border-primary dark:border-primary-light'
                                        : 'border-border-light dark:border-border-dark hover:border-gray-400 dark:hover:border-gray-500'}`}
                        title={`Select Subject: ${subjectName}`}
                    >
                        <div className="flex items-center gap-2 truncate">
                            {isSelected ? (
                                <CheckCircle size={16} className="text-green-500 flex-shrink-0" />
                            ) : (
                                <Library size={16} className="text-primary dark:text-primary-light flex-shrink-0" />
                            )}
                            <span className={`truncate ${isSelected ? 'font-semibold text-primary dark:text-primary-light' : 'text-text-light dark:text-text-dark'}`}>
                                {subjectName}
                            </span>
                        </div>
                        {/* No actions like delete for subjects from this view */}
                    </div>
                );
            })}
        </div>
    );
}

export default SubjectList;
```

`frontend/src/components/layout/CenterPanel.jsx`

```javascript
// src/components/layout/CenterPanel.jsx
import React, { useState, useEffect, useCallback } from 'react'; // Added useCallback
import ChatHistory from '../chat/ChatHistory';
import ChatInput from '../chat/ChatInput';
import api from '../../services/api';
import { useAuth as useRegularAuth } from '../../hooks/useAuth'; // Assuming useAuth is for regular users
import { useAppState } from '../../contexts/AppStateContext';
import toast from 'react-hot-toast';

function CenterPanel({ messages, setMessages, currentSessionId, chatStatus, setChatStatus }) {
    const { token: regularUserToken, user: regularUser } = useRegularAuth(); // Get token and user for regular auth
    const {
        selectedLLM,
        systemPrompt,
        selectedDocumentForAnalysis, // This is for RightPanel tools
        selectedSubject             // <<< Get the globally selected subject
    } = useAppState();

    const [useRag, setUseRag] = useState(true); // Default RAG to true, can be toggled by ChatInput
    const [isSending, setIsSending] = useState(false);
    const [criticalThinkingEnabled, setCriticalThinkingEnabled] = useState(false);

    const handleSendMessage = async (inputText, isCtEnabledFromInput) => {
        if (!inputText.trim() || !regularUserToken || !currentSessionId || isSending) {
            if (!currentSessionId) toast.error("No active session. Try 'New Chat'.");
            return;
        }

        const clientSideId = `user-${Date.now()}-${Math.random().toString(16).slice(2)}`;
        const userMessage = {
            id: clientSideId,
            sender: 'user',
            role: 'user', // For backend Gemini compatibility
            text: inputText.trim(),
            parts: [{ text: inputText.trim() }],
            timestamp: new Date().toISOString()
        };

        setMessages(prev => [...prev, userMessage]);
        setIsSending(true);

        let currentThinkingStatus = "Connecting to AI...";
        let ragContextNameForPayload = null;

        if (useRag) {
            // Prioritize selectedSubject for RAG context in chat
             ragContextNameForPayload = selectedSubject || selectedDocumentForAnalysis;

            if (ragContextNameForPayload) {
                currentThinkingStatus = `Using document "${ragContextNameForPayload}" & contacting ${selectedLLM.toUpperCase()}`;
            } else {
                currentThinkingStatus = `Contacting ${selectedLLM.toUpperCase()} (RAG - General Context)`;
            }
            if (isCtEnabledFromInput) {
                currentThinkingStatus += ` (CT requested)`;
            }
        } else { // Not using RAG
            currentThinkingStatus = `Contacting ${selectedLLM.toUpperCase()}`;
            if (isCtEnabledFromInput) currentThinkingStatus += ` (CT requested)`;
        }
        setChatStatus(currentThinkingStatus);

        const historyForBackend = messages.map(m => ({
            role: m.sender === 'bot' ? 'model' : 'user',
            parts: m.parts || [{ text: m.text }],
            timestamp: m.timestamp,
            ...(m.sender === 'bot' && {
                thinking: m.thinking,
                references: m.references,
                source_pipeline: m.source_pipeline
            })
        }));

        const payload = {
            query: inputText.trim(),
            history: historyForBackend,
            sessionId: currentSessionId,
            useRag: useRag,
            llmProvider: selectedLLM,
            systemPrompt: systemPrompt,
            criticalThinkingEnabled: isCtEnabledFromInput,
            documentContextName: ragContextNameForPayload, // <<< Use the determined RAG context name
            // 'filter' for RAG can be added here if you have a UI for it
        };

        try {
            console.log("CenterPanel: Sending payload to /api/chat/message:", payload);
            const response = await api.sendMessage(payload); // Regular user API call

            if (response && response.reply) {
                const aiReply = {
                    ...response.reply,
                    id: `bot-${Date.now()}-${Math.random().toString(16).slice(2)}`
                };
                setMessages(prev => [...prev, aiReply]);
                setChatStatus(`Responded via ${aiReply.source_pipeline || selectedLLM.toUpperCase()}.`);
            } else {
                throw new Error("Invalid or empty response structure from AI service.");
            }

        } catch (error) {
            console.error("Error sending message:", error);
            const errorText = error.response?.data?.message || error.message || 'Failed to get response from AI.';

            let errorReplyMessage;
            if (error.response?.data?.reply) { // If backend structures the error reply
                errorReplyMessage = {
                    ...error.response.data.reply,
                    id: `error-${Date.now()}-${Math.random().toString(16).slice(2)}`
                };
            } else {
                errorReplyMessage = {
                    id: `error-${Date.now()}-${Math.random().toString(16).slice(2)}`,
                    sender: 'bot',
                    role: 'model',
                    text: `Error: ${errorText}`,
                    parts: [{ text: `Error: ${errorText}` }],
                    timestamp: new Date().toISOString(),
                    thinking: "Error processing request.",
                    source_pipeline: "error-pipeline"
                };
            }
            setMessages(prev => [...prev, errorReplyMessage]);
            setChatStatus(`Error: ${errorText.substring(0, 70)}...`);
            toast.error(errorText);
        } finally {
            setIsSending(false);
        }
    };

    // Update chat status message based on selections
    useEffect(() => {
        if (!currentSessionId) {
            setChatStatus("Please login or start a new chat.");
        } else if (messages.length === 0 && !isSending) {
            if (selectedSubject) {
                setChatStatus(`Ready. Chatting with focus on subject: "${selectedSubject}".`);
            } else {
                setChatStatus("Ready. Send a message to start!");
            }
        }
        // If messages.length > 0 or isSending, the status is handled by handleSendMessage or API response
    }, [currentSessionId, messages.length, isSending, selectedSubject, setChatStatus]); // Added messages.length dependency

    return (
        <div className="flex flex-col h-full bg-background-light dark:bg-background-dark rounded-lg shadow-inner">
            {/* Welcome/Info display when chat is empty */}
            {messages.length === 0 && !isSending && currentSessionId && (
                 <div className="p-6 sm:p-8 text-center text-text-muted-light dark:text-text-muted-dark animate-fadeIn">
                    <h2 className="text-xl sm:text-2xl font-semibold mb-2 text-text-light dark:text-text-dark">
                        AI Engineering Tutor
                    </h2>
                    <p className="text-base sm:text-lg mb-3">Session ID: {currentSessionId.substring(0,8)}...</p>
                    <div className="text-xs sm:text-sm space-y-1">
                        <p>Current LLM: <span className="font-semibold text-accent">{selectedLLM.toUpperCase()}</span>.</p>
                        <p className="max-w-md mx-auto">
                            Assistant Mode: <span className="italic">"{systemPrompt.length > 60 ? systemPrompt.substring(0,60)+'...' : systemPrompt}"</span>
                        </p>
                        {selectedSubject && ( // <<< Display selected subject for chat context
                            <p className="mt-1 font-medium">
                                Chat Focus (Subject): <span className="text-indigo-500 dark:text-indigo-400">{selectedSubject}</span>
                            </p>
                        )}
                        {selectedDocumentForAnalysis && ( // This is for Right Panel analysis tools
                            <p className="mt-1">
                                Analysis Target (Right Panel): <span className="font-medium text-primary dark:text-primary-light">{selectedDocumentForAnalysis}</span>
                            </p>
                        )}
                        <p className="mt-1">
                            {useRag ?
                                <span>RAG is <span className="text-green-500 font-semibold">ON</span>.
                                    {selectedSubject ? ` Using context from "${selectedSubject}".` : " Using general knowledge."}
                                </span>
                                : <span>RAG is <span className="text-red-500 font-semibold">OFF</span>. Chatting directly.</span>}
                        </p>
                        <p>
                            {criticalThinkingEnabled ? <span>Critical Thinking (KG) is <span className="text-purple-500 font-semibold">ON</span>.</span>
                                  : <span>Critical Thinking (KG) is <span className="text-gray-500 font-semibold">OFF</span>.</span>}
                        </p>
                    </div>
                </div>
            )}

            <ChatHistory messages={messages} isLoading={isSending} />
            <ChatInput
                onSendMessage={handleSendMessage}
                isLoading={isSending}
                currentStatus={chatStatus} // Pass the managed chatStatus
                useRag={useRag}
                setUseRag={setUseRag}
                criticalThinkingEnabled={criticalThinkingEnabled}
                setCriticalThinkingEnabled={setCriticalThinkingEnabled}
            />
        </div>
    );
}
export default CenterPanel;
```

`frontend/src/components/layout/LeftCollapsedNav.jsx`

```javascript
// frontend/src/components/layout/LeftCollapsedNav.jsx
import React from 'react';
import { useAppState } from '../../contexts/AppStateContext.jsx';
import { Edit3, UploadCloud, FileText, ChevronRight, Settings2 } from 'lucide-react'; // Settings2 for fallback
import IconButton from '../core/IconButton.jsx'; 
import { motion } from 'framer-motion';

// Mapping icon names (or IDs) to Lucide components
const iconMap = {
    prompt: Edit3,       // Icon for "Custom Prompt"
    upload: UploadCloud, // Icon for "Upload Document"
    docs: FileText,      // Icon for "Document List"
};

function LeftCollapsedNav() {
    const { setIsLeftPanelOpen } = useAppState();

    // Define the items for the collapsed navigation bar
    const navItems = [
        { 
            id: 'prompt', 
            label: 'Custom Prompt', 
            iconName: 'prompt', // Matches key in iconMap
            action: () => { 
                setIsLeftPanelOpen(true); 
                // TODO: Optionally, also scroll to/focus the prompt section in LeftPanel
            } 
        },
        { 
            id: 'upload', 
            label: 'Upload Document', 
            iconName: 'upload', 
            action: () => { 
                setIsLeftPanelOpen(true);
                // TODO: Optionally, open LeftPanel and focus/highlight upload area
            } 
        },
        { 
            id: 'docs', 
            label: 'Document List', 
            iconName: 'docs', 
            action: () => { 
                setIsLeftPanelOpen(true); 
                // TODO: Optionally, open LeftPanel scrolled to document list
            } 
        },
    ];

    return (
        <motion.aside
            key="left-collapsed-nav" // Unique key for AnimatePresence
            initial={{ x: '-100%', opacity: 0 }}
            animate={{ x: '0%', opacity: 1 }}
            exit={{ x: '-100%', opacity: 0 }}
            transition={{ type: 'spring', stiffness: 300, damping: 30 }}
            // Styling for the thin vertical bar
            className="fixed left-0 top-16 bottom-0 z-30 w-14 sm:w-16 
                       bg-surface-light dark:bg-surface-dark 
                       border-r border-border-light dark:border-border-dark 
                       shadow-lg flex flex-col items-center py-3 space-y-2 custom-scrollbar"
        >
            {/* Button to open the full LeftPanel - Placed at the top */}
            <IconButton 
                icon={ChevronRight} 
                onClick={() => setIsLeftPanelOpen(true)} 
                title="Open Assistant Panel"
                ariaLabel="Open Assistant Panel"
                variant="ghost" 
                size="lg" // Make it prominent
                className="mb-2 text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
            />

            {/* Icons for different sections of LeftPanel */}
            {navItems.map(item => {
                const IconComponent = iconMap[item.iconName] || Settings2; // Fallback icon
                return (
                    <IconButton 
                        key={item.id}
                        icon={IconComponent}
                        onClick={item.action} // Action currently just opens the panel
                        title={item.label}
                        ariaLabel={item.label}
                        variant="ghost"
                        size="md" 
                        className="text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
                    />
                );
            })}
            {/* Add a flexible spacer if you want the open button pushed further down from items */}
            {/* <div className="flex-grow"></div> */}
        </motion.aside>
    );
}
export default LeftCollapsedNav;
```

`frontend/src/components/layout/LeftPanel.jsx`

```javascript
// frontend/src/components/layout/LeftPanel.jsx
import React, { useState, useEffect, useCallback } from 'react';
import { useAppState } from '../../contexts/AppStateContext.jsx';
import DocumentUpload from '../documents/DocumentUpload.jsx';
import DocumentList from '../documents/DocumentList.jsx';
import SubjectList from '../documents/SubjectList.jsx'; // <<< NEW IMPORT
import {
    PanelLeftClose, ChevronDown, ChevronUp, FilePlus, Settings2,
    Bot, BookOpen, Lightbulb, Library, Loader2, AlertTriangle // Added AlertTriangle
} from 'lucide-react';
import IconButton from '../core/IconButton.jsx';
import { motion, AnimatePresence } from 'framer-motion';
import toast from 'react-hot-toast';
import api from '../../services/api.js'; // Main API service

const PROMPT_PRESETS = [
     { id: 'friendly_tutor', name: 'Friendly Tutor', icon: Bot, text: "You are a friendly, patient, and encouraging tutor specializing in engineering and scientific topics for PhD students. Explain concepts clearly, break down complex ideas, use analogies, and offer positive reinforcement. Ask follow-up questions to ensure understanding." },
     { id: 'concept_explorer', name: 'Concept Explorer', icon: BookOpen, text: "You are an expert academic lecturer introducing a new, complex engineering or scientific concept. Your goal is to provide a deep, structured explanation. Define terms rigorously, outline the theory, provide relevant mathematical formulations (using Markdown), illustrative examples, and discuss applications or limitations pertinent to PhD-level research." },
     { id: 'knowledge_check', name: 'Knowledge Check', icon: Lightbulb, text: "You are assessing understanding of engineering/scientific topics. Ask targeted questions to test knowledge, identify misconceptions, and provide feedback on the answers. Start by asking the user what topic they want to be quizzed on." },
     { id: 'custom', name: 'Custom Prompt', icon: Settings2, text: "You are a helpful AI engineering tutor." }
];

function LeftPanel() {
    const {
        setIsLeftPanelOpen,
        systemPrompt, setSystemPrompt,
        selectDocumentForAnalysis, selectedDocumentForAnalysis,
        selectedSubject, setSelectedSubject // AppState context will handle setting this
    } = useAppState();

    const [isPromptSectionOpen, setIsPromptSectionOpen] = useState(true);
    const [isSubjectSectionOpen, setIsSubjectSectionOpen] = useState(true);
    const [isDocManagementOpen, setIsDocManagementOpen] = useState(true);

    const [selectedPresetId, setSelectedPresetId] = useState('custom');
    const [availableSubjects, setAvailableSubjects] = useState([]);      // State to hold fetched subjects
    const [isLoadingSubjects, setIsLoadingSubjects] = useState(false);   // Loading state for subjects
    const [subjectFetchError, setSubjectFetchError] = useState('');     // Error state for subjects
    const [docListKey, setDocListKey] = useState(Date.now()); // For user's own DocumentList refresh

    useEffect(() => {
        const matchedPreset = PROMPT_PRESETS.find(p => p.text === systemPrompt);
        setSelectedPresetId(matchedPreset ? matchedPreset.id : 'custom');
    }, [systemPrompt]);

    // Fetch subjects (admin document names) on component mount
    const fetchSubjects = useCallback(async () => {
        setIsLoadingSubjects(true);
        setSubjectFetchError(''); // Clear previous errors
        try {
            const response = await api.getSubjects(); // Calls /api/subjects
            // The backend returns { subjects: ["Subject 1", "Subject 2", ...] }
            setAvailableSubjects(Array.isArray(response.subjects) ? response.subjects : []);
            if (response.subjects.length === 0) {
                toast.info("No admin-defined subjects found to select for chat focus.");
            }
        } catch (error) {
            const errorMsg = error.response?.data?.message || error.message || "Failed to load available subjects.";
            toast.error(errorMsg);
            setSubjectFetchError(errorMsg); // Store error message for display
            console.error("Error fetching subjects:", error);
        } finally {
            setIsLoadingSubjects(false);
        }
    }, []);

    useEffect(() => {
        fetchSubjects();
    }, [fetchSubjects]);

    const handlePresetChange = (event) => {
        const presetId = event.target.value;
        setSelectedPresetId(presetId);
        const selectedPreset = PROMPT_PRESETS.find(p => p.id === presetId);
        if (selectedPreset) setSystemPrompt(selectedPreset.text);
    };

    const handleUploadSuccessForUserDocs = () => {
        setDocListKey(Date.now());
        toast.success("Your document list refreshed after upload.");
    };

    // setSelectedSubject from AppStateContext is passed directly to SubjectList's onSelectSubject prop.

    const SelectedPresetIcon = PROMPT_PRESETS.find(p => p.id === selectedPresetId)?.icon || Settings2;

    return (
        <div className="flex flex-col h-full">
            <div className="flex items-center justify-between mb-3 px-1 pt-1">
                <h2 className="text-sm font-semibold text-text-light dark:text-text-dark">Assistant Controls</h2>
                <IconButton
                    icon={PanelLeftClose}
                    onClick={() => setIsLeftPanelOpen(false)}
                    title="Close Assistant Panel"
                    variant="ghost" size="sm"
                    className="text-text-muted-light dark:text-text-muted-dark hover:text-primary"
                />
            </div>

            {/* Custom Prompt Section (Existing) */}
            <div className="mb-4">
                <button onClick={() => setIsPromptSectionOpen(!isPromptSectionOpen)} className="w-full flex items-center justify-between px-3 py-2.5 text-sm font-medium text-left text-text-light dark:text-text-dark bg-gray-50 dark:bg-gray-800 hover:bg-gray-100 dark:hover:bg-gray-700 rounded-md focus:outline-none shadow-sm border border-border-light dark:border-border-dark" aria-expanded={isPromptSectionOpen}>
                    <span className="flex items-center gap-2"><SelectedPresetIcon size={16} className="text-primary dark:text-primary-light" /> Custom Prompt</span>
                    {isPromptSectionOpen ? <ChevronUp size={18} /> : <ChevronDown size={18} />}
                </button>
                <AnimatePresence>
                    {isPromptSectionOpen && (
                        <motion.div key="prompt-section-content" initial={{ height: 0, opacity: 0 }} animate={{ height: 'auto', opacity: 1 }} exit={{ height: 0, opacity: 0 }} transition={{ duration: 0.2, ease: "easeInOut" }} className="mt-2 p-3 bg-surface-light dark:bg-surface-dark border border-border-light dark:border-border-dark rounded-md shadow-inner overflow-hidden">
                            <label htmlFor="prompt-preset-select" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark mb-1">Prompt Mode:</label>
                             <select id="prompt-preset-select" value={selectedPresetId} onChange={handlePresetChange} className="input-field mb-2 text-xs py-1.5">
                                 {PROMPT_PRESETS.map(preset => (<option key={preset.id} value={preset.id}>{preset.name}</option>))}
                             </select>
                             <label htmlFor="system-prompt-area" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark mb-1">System Prompt (Editable):</label>
                             <textarea id="system-prompt-area" value={systemPrompt} onChange={(e) => { setSystemPrompt(e.target.value); setSelectedPresetId('custom'); }} rows="5" className="input-field text-xs custom-scrollbar" placeholder="Enter system prompt..."/>
                        </motion.div>
                    )}
                </AnimatePresence>
            </div>

            {/* --- NEW: Select Subject Section --- */}
            <div className="mb-4">
                <button
                    onClick={() => setIsSubjectSectionOpen(!isSubjectSectionOpen)}
                    className="w-full flex items-center justify-between px-3 py-2.5 text-sm font-medium text-left text-text-light dark:text-text-dark bg-gray-50 dark:bg-gray-800 hover:bg-gray-100 dark:hover:bg-gray-700 rounded-md focus:outline-none shadow-sm border border-border-light dark:border-border-dark"
                    aria-expanded={isSubjectSectionOpen}
                >
                    <span className="flex items-center gap-2">
                        <Library size={16} className="text-primary dark:text-primary-light" /> Select Subject Focus
                    </span>
                    {isSubjectSectionOpen ? <ChevronUp size={18} /> : <ChevronDown size={18} />}
                </button>
                <AnimatePresence>
                    {isSubjectSectionOpen && (
                        <motion.div
                            key="subject-select-content"
                            initial={{ height: 0, opacity: 0 }}
                            animate={{ height: 'auto', opacity: 1 }}
                            exit={{ height: 0, opacity: 0 }}
                            transition={{ duration: 0.2, ease: "easeInOut" }}
                            className="mt-2 p-3 bg-surface-light dark:bg-surface-dark border border-border-light dark:border-border-dark rounded-md shadow-inner overflow-hidden"
                        >
                           {/* Using the new SubjectList component */}
                           <SubjectList
                                subjects={availableSubjects}
                                selectedSubject={selectedSubject}
                                onSelectSubject={setSelectedSubject} // Pass the setter from AppStateContext
                                isLoading={isLoadingSubjects}
                                error={subjectFetchError}
                           />
                        </motion.div>
                    )}
                </AnimatePresence>
            </div>

            {/* Document Management Section (For REGULAR USER's own documents) */}
            <div className="flex-grow flex flex-col overflow-hidden">
                <button onClick={() => setIsDocManagementOpen(!isDocManagementOpen)} className="w-full flex items-center justify-between px-3 py-2.5 text-sm font-medium text-left text-text-light dark:text-text-dark bg-gray-50 dark:bg-gray-800 hover:bg-gray-100 dark:hover:bg-gray-700 rounded-md focus:outline-none shadow-sm border border-border-light dark:border-border-dark mb-2" aria-expanded={isDocManagementOpen}>
                    <span className="flex items-center gap-2"><FilePlus size={16} className="text-primary dark:text-primary-light" /> My Documents (for Analysis Tools)</span>
                    {isDocManagementOpen ? <ChevronUp size={18} /> : <ChevronDown size={18} />}
                </button>
                <AnimatePresence>
                    {isDocManagementOpen && (
                        <motion.div key="doc-management-content" initial={{ height: 0, opacity: 0 }} animate={{ height: 'auto', opacity: 1 }} exit={{ height: 0, opacity: 0 }} transition={{ duration: 0.2, ease: "easeInOut" }} className="flex-grow flex flex-col overflow-hidden p-3 bg-surface-light dark:bg-surface-dark border border-border-light dark:border-border-dark rounded-md shadow-inner">
                            <DocumentUpload onUploadSuccess={handleUploadSuccessForUserDocs} />
                            <div className="mt-3 flex-grow overflow-y-auto custom-scrollbar">
                                <DocumentList
                                    key={docListKey}
                                    onSelectDocument={selectDocumentForAnalysis}
                                    selectedDocument={selectedDocumentForAnalysis}
                                />
                            </div>
                        </motion.div>
                    )}
                </AnimatePresence>
            </div>
        </div>
    );
}
export default LeftPanel;
```

`frontend/src/components/layout/LLMSelectionModal.jsx`

```javascript
// frontend/src/components/layout/LLMSelectionModal.jsx
import React, { useState, useEffect } from 'react';
import { useAppState } from '../../contexts/AppStateContext.jsx';
import api from '../../services/api.js'; // For V1, this is mocked
import toast from 'react-hot-toast';
import { X, Save, KeyRound, Link2, AlertCircle } from 'lucide-react';
import Modal from '../core/Modal.jsx'; // Using the generic Modal component
import Button from '../core/Button.jsx';
import LLMSelection from '../auth/LLMSelection.jsx';
import { motion } from 'framer-motion';

function LLMSelectionModal({ isOpen, onClose, currentLLM, onSelectLLM }) {
    // This component now acts as the content provider for the generic Modal
    const { switchLLM: setGlobalLLMPreference } = useAppState();
    
    const [locallySelectedLLM, setLocallySelectedLLM] = useState(currentLLM);
    const [geminiApiKeyInput, setGeminiApiKeyInput] = useState('');
    const [ollamaApiUrlInput, setOllamaApiUrlInput] = useState('');
    
    const [loading, setLoading] = useState(false);
    const [error, setError] = useState('');

    useEffect(() => {
        if (isOpen) {
            setLocallySelectedLLM(currentLLM); // Sync with global when modal opens
            setGeminiApiKeyInput(''); 
            setOllamaApiUrlInput(''); 
            setError('');
        }
    }, [isOpen, currentLLM]);

    const handleSavePreference = async () => {
        setLoading(true); 
        setError('');
        const toastId = toast.loading('Saving LLM preference...');
        try {
            const configData = { llmProvider: locallySelectedLLM };
            if (locallySelectedLLM === 'gemini' && geminiApiKeyInput.trim()) {
                configData.apiKey = geminiApiKeyInput.trim();
            }
            if (locallySelectedLLM === 'ollama' && ollamaApiUrlInput.trim()) {
                configData.ollamaUrl = ollamaApiUrlInput.trim();
            }
            
            await api.updateUserLLMConfig(configData); // Mocked in V1
            
            setGlobalLLMPreference(locallySelectedLLM); // Update global AppStateContext
            if(onSelectLLM) onSelectLLM(locallySelectedLLM); // Inform parent (TopNav) if needed

            toast.dismiss(toastId);
            toast.success(`LLM preference updated to ${locallySelectedLLM.toUpperCase()} (mocked).`);
            onClose(); // Close the modal
        } catch (err) {
            toast.dismiss(toastId);
            const errorMessage = err.response?.data?.message || err.message || 'Failed to update LLM preference.';
            setError(errorMessage);
            toast.error(errorMessage);
        } finally {
            setLoading(false);
        }
    };
    
    const inputWrapperClass = "relative";
    const inputIconClass = "absolute left-3 top-1/2 -translate-y-1/2 h-5 w-5 text-text-muted-light dark:text-text-muted-dark pointer-events-none";
    const inputFieldStyledClass = "input-field pl-10 py-2 text-sm";

    return (
         <Modal 
            isOpen={isOpen} 
            onClose={onClose} 
            title="Switch LLM Provider" 
            size="lg"
            footerContent={ // Pass footer buttons to the generic Modal
                <>
                    <Button variant="ghost" onClick={onClose} disabled={loading} className="text-sm">Cancel</Button>
                    <Button onClick={handleSavePreference} isLoading={loading} className="text-sm" leftIcon={<Save size={16}/>}>
                        Save Preference
                    </Button>
                </>
            }
        >
            {/* This is the children prop for the generic Modal */}
            <div className="space-y-5"> 
                <p className="text-sm text-text-muted-light dark:text-text-muted-dark">
                    Select your preferred Large Language Model. Your choice will be saved for future sessions. (V1 uses mock data regardless).
                </p>
                <LLMSelection 
                    selectedLLM={locallySelectedLLM} 
                    onLlmChange={setLocallySelectedLLM}
                    disabled={loading}
                />
                {locallySelectedLLM === 'gemini' && (
                    <motion.div 
                        key="gemini-config-modal" 
                        initial={{ opacity: 0, height: 0 }} animate={{ opacity: 1, height: 'auto' }} exit={{ opacity: 0, height: 0 }}
                        className="mt-4 space-y-1 overflow-hidden"
                    >
                        <label htmlFor="modalGeminiApiKey" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark mb-1">
                            Gemini API Key (Optional - Enter to update)
                        </label>
                        <div className={inputWrapperClass}>
                            <KeyRound className={inputIconClass} />
                            <input
                                type="password"
                                id="modalGeminiApiKey"
                                className={inputFieldStyledClass}
                                placeholder="Leave blank to use existing/default"
                                value={geminiApiKeyInput}
                                onChange={(e) => setGeminiApiKeyInput(e.target.value)}
                                disabled={loading}
                            />
                        </div>
                    </motion.div>
                )}
                {locallySelectedLLM === 'ollama' && (
                    <motion.div 
                        key="ollama-config-modal" 
                        initial={{ opacity: 0, height: 0 }} animate={{ opacity: 1, height: 'auto' }} exit={{ opacity: 0, height: 0 }}
                        className="mt-4 space-y-1 overflow-hidden"
                    >
                        <label htmlFor="modalOllamaUrl" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark mb-1">
                            Ollama API URL (Optional - Enter to update)
                        </label>
                         <div className={inputWrapperClass}>
                            <Link2 className={inputIconClass} />
                            <input
                                type="text"
                                id="modalOllamaUrl"
                                className={inputFieldStyledClass}
                                placeholder="Default (usually http://localhost:11434)"
                                value={ollamaApiUrlInput}
                                onChange={(e) => setOllamaApiUrlInput(e.target.value)}
                                disabled={loading}
                            />
                        </div>
                    </motion.div>
                )}
                {/* Corrected error display */}
                {error && (
                    <div className="p-3 mt-3 bg-red-500/10 border border-red-500/30 text-red-600 dark:text-red-300 rounded-md text-sm flex items-center gap-2 animate-fadeIn">
                        <AlertCircle size={18}/> {error}
                    </div>
                )}
            </div>
        </Modal>
    );
}

export default LLMSelectionModal;
```

`frontend/src/components/layout/RightCollapsedNav.jsx`

```javascript
// frontend/src/components/layout/RightCollapsedNav.jsx
import React from 'react';
import { useAppState } from '../../contexts/AppStateContext.jsx';
import { HelpCircle, GitFork, Tags, ChevronLeft } from 'lucide-react';
import IconButton from '../core/IconButton.jsx';
import { motion } from 'framer-motion';

const iconMap = {
    HelpCircle: HelpCircle,
    Tags: Tags,
    GitFork: GitFork,
};

function RightCollapsedNav() {
    const { setIsRightPanelOpen } = useAppState();

    const navItems = [
        { id: 'faq', label: 'FAQ Generator', iconName: 'HelpCircle', action: () => { setIsRightPanelOpen(true); /* TODO: set analysis type contextually */ } },
        { id: 'topics', label: 'Key Topics Extractor', iconName: 'Tags', action: () => { setIsRightPanelOpen(true); } },
        { id: 'mindmap', label: 'Mind Map Creator', iconName: 'GitFork', action: () => { setIsRightPanelOpen(true); } },
    ];

    return (
        <motion.aside
            key="right-collapsed-nav"
            initial={{ x: '100%', opacity: 0 }}
            animate={{ x: '0%', opacity: 1 }}
            exit={{ x: '100%', opacity: 0 }}
            transition={{ type: 'spring', stiffness: 300, damping: 30 }}
            className="fixed right-0 top-16 bottom-0 z-30 w-14 sm:w-16 bg-surface-light dark:bg-surface-dark border-l border-border-light dark:border-border-dark shadow-lg flex-col items-center py-3 space-y-2 hidden md:flex"
        >
            {/* Open Panel Button AT THE TOP */}
            <IconButton 
                icon={ChevronLeft} 
                onClick={() => setIsRightPanelOpen(true)} 
                title="Open Analyzer Panel"
                ariaLabel="Open Analyzer Panel"
                variant="ghost" 
                size="lg"
                className="mb-2 text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
            />
            {navItems.map(item => {
                 const Icon = iconMap[item.iconName] || HelpCircle;
                return (
                    <IconButton 
                        key={item.id}
                        icon={Icon}
                        onClick={item.action}
                        title={item.label}
                        ariaLabel={item.label}
                        variant="ghost"
                        size="md"
                        className="text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
                    />
                );
            })}
        </motion.aside>
    );
}
export default RightCollapsedNav;
```

`frontend/src/components/layout/RightPanel.jsx`

```javascript
// frontend/src/components/layout/RightPanel.jsx
import React, { useState } from 'react';
import { useAppState } from '../../contexts/AppStateContext';
import AnalysisToolRunner from '../analysis/AnalysisToolRunner.jsx';
import { PanelRightClose, ChevronDown, ChevronUp, Telescope } from 'lucide-react';
import IconButton from '../core/IconButton.jsx';
import { motion } from 'framer-motion';

function RightPanel() {
    const { setIsRightPanelOpen, selectedDocumentForAnalysis, selectedSubject } = useAppState();
    const [isAnalyzerOpen, setIsAnalyzerOpen] = useState(true);

    const currentSelectedDocFilename = selectedDocumentForAnalysis || null;
    // This correctly determines if the current analysis target is an admin-selected subject
    const isTargetAdminSubject = !!(selectedSubject && currentSelectedDocFilename && selectedSubject === currentSelectedDocFilename);

    return (
        <div className="flex flex-col h-full p-3 sm:p-4 bg-surface-light dark:bg-surface-dark text-text-light dark:text-text-dark custom-scrollbar">
            <div className="flex items-center justify-between mb-4 pb-2 border-b border-border-light dark:border-border-dark">
                <h2 className="text-base font-semibold">Advanced Analyzer</h2>
                <IconButton
                    icon={PanelRightClose}
                    onClick={() => setIsRightPanelOpen(false)}
                    title="Close Analyzer Panel"
                    variant="ghost"
                    size="sm"
                    className="text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
                />
            </div>

            <button
                onClick={() => setIsAnalyzerOpen(!isAnalyzerOpen)}
                className="w-full flex items-center justify-between px-3 py-2.5 text-sm font-medium text-left bg-gray-50 dark:bg-gray-800 hover:bg-gray-100 dark:hover:bg-gray-700 rounded-md focus:outline-none shadow-sm border border-border-light dark:border-border-dark mb-3"
            >
                <span className="flex items-center gap-2"><Telescope size={16} /> Analysis Tools</span>
                {isAnalyzerOpen ? <ChevronUp size={18} /> : <ChevronDown size={18} />}
            </button>

            {isAnalyzerOpen && (
                <motion.div
                    initial={{ height: 0, opacity: 0 }}
                    animate={{ height: 'auto', opacity: 1 }}
                    exit={{ height: 0, opacity: 0 }}
                    transition={{ duration: 0.2, ease: "easeInOut" }}
                    className="flex-grow space-y-3 overflow-y-auto custom-scrollbar pr-1"
                >
                    {!currentSelectedDocFilename && (
                        <div className="p-4 text-xs text-center text-text-muted-light dark:text-text-muted-dark bg-gray-50 dark:bg-gray-800 rounded-md border border-dashed border-border-light dark:border-border-dark">
                            <p>Select a document from the left panel to enable analysis tools.</p>
                        </div>
                    )}
                    {/* Pass isTargetAdminSubject as isTargetAdminDoc */}
                    <AnalysisToolRunner toolType="faq" title="FAQ Generator" iconName="HelpCircle" selectedDocumentFilename={currentSelectedDocFilename} isTargetAdminDoc={isTargetAdminSubject} />
                    <AnalysisToolRunner toolType="topics" title="Key Topics Extractor" iconName="Tags" selectedDocumentFilename={currentSelectedDocFilename} isTargetAdminDoc={isTargetAdminSubject} />
                    <AnalysisToolRunner toolType="mindmap" title="Mind Map Creator" iconName="GitFork" selectedDocumentFilename={currentSelectedDocFilename} isTargetAdminDoc={isTargetAdminSubject} />
                </motion.div>
            )}
        </div>
    );
}
export default RightPanel;
```

`frontend/src/components/layout/TopNav.jsx`

```javascript
// frontend/src/components/layout/TopNav.jsx
import React, { useState } from 'react';
import { useAuth } from '../../hooks/useAuth';
import { useAppState } from '../../contexts/AppStateContext';
import ThemeToggle from '../common/ThemeToggle.jsx';
import LLMSelectionModal from './LLMSelectionModal.jsx';
import { 
    LogOut, User, MessageSquare, History as HistoryIcon, Settings, Cpu, Zap, ServerCrash, Server 
} from 'lucide-react';
import toast from 'react-hot-toast';

function TopNav({ user: authUser, onLogout, onNewChat, onHistoryClick, orchestratorStatus }) { // Renamed user to authUser to avoid conflict
    const { selectedLLM, switchLLM } = useAppState();
    const [isLLMModalOpen, setIsLLMModalOpen] = useState(false);
    
    const getStatusIndicator = () => {
        if (!orchestratorStatus) return <div title="Status unavailable" className="w-4 h-4 bg-gray-400 rounded-full"></div>;
        if (orchestratorStatus.status === "ok") {
            return <Zap size={18} className="text-green-400 animate-pulse" title={`Backend Online: ${orchestratorStatus.message}`} />;
        } else if (orchestratorStatus.status === "loading") {
            return <div className="animate-spin rounded-full h-4 w-4 border-t-2 border-b-2 border-yellow-400" title="Connecting..."></div>;
        } else {
            return <ServerCrash size={18} className="text-red-400" title={`Backend Offline: ${orchestratorStatus.message}`} />;
        }
    };
    
    return (
        <>
            <nav className="fixed top-0 left-0 right-0 z-40 bg-surface-light dark:bg-surface-dark border-b border-border-light dark:border-border-dark shadow-sm h-16 flex items-center justify-between px-2 sm:px-4">
                <div className="flex items-center gap-2">
                    <a href="/" className="flex items-center gap-1.5 sm:gap-2 text-lg sm:text-xl font-semibold text-text-light dark:text-text-dark">
                        <Server size={24} className="text-primary dark:text-primary-light" />
                        <span className="hidden sm:inline">AI Tutor</span>
                    </a>
                </div>

                <div className="flex-1 flex justify-center px-2">
                    <div className="flex items-center gap-1 sm:gap-2">
                         <button
                            onClick={onNewChat} // Connected to App.jsx handleNewChat
                            className="flex items-center gap-1 px-2 py-1.5 text-xs sm:text-sm font-medium rounded-md text-text-light dark:text-text-dark bg-gray-100 dark:bg-gray-700 hover:bg-gray-200 dark:hover:bg-gray-600 transition-colors"
                            title="Start a new chat session"
                        >
                            <MessageSquare size={14} /> <span className="hidden sm:inline">New Chat</span>
                        </button>
                        <button
                            onClick={onHistoryClick} // Connected to App.jsx setIsHistoryModalOpen(true)
                            className="flex items-center gap-1 px-2 py-1.5 text-xs sm:text-sm font-medium rounded-md text-text-light dark:text-text-dark bg-gray-100 dark:bg-gray-700 hover:bg-gray-200 dark:hover:bg-gray-600 transition-colors"
                            title="View chat history"
                        >
                            <HistoryIcon size={14} /> <span className="hidden sm:inline">History</span>
                        </button>
                        <button
                            onClick={() => setIsLLMModalOpen(true)}
                            className="flex items-center gap-1 px-2 py-1.5 text-xs sm:text-sm font-medium rounded-md text-text-light dark:text-text-dark bg-gray-100 dark:bg-gray-700 hover:bg-gray-200 dark:hover:bg-gray-600 transition-colors"
                            title={`Switch LLM (Current: ${selectedLLM.toUpperCase()})`}
                        >
                            <Cpu size={14} /> <span className="hidden xs:inline">{selectedLLM.toUpperCase()}</span>
                        </button>
                    </div>
                </div>

                <div className="flex items-center gap-1.5 sm:gap-2">
                    {getStatusIndicator()}
                    <ThemeToggle />
                    <div className="relative group">
                        <button className="p-1.5 bg-primary-light dark:bg-primary-dark text-white rounded-full focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-offset-surface-light dark:focus:ring-offset-surface-dark focus:ring-primary">
                            <User size={18} />
                        </button>
                        <div className="absolute right-0 mt-2 w-48 bg-surface-light dark:bg-surface-dark rounded-md shadow-lg py-1 opacity-0 group-hover:opacity-100 focus-within:opacity-100 transition-opacity duration-150 ease-in-out transform scale-95 group-hover:scale-100 focus-within:scale-100 origin-top-right invisible group-hover:visible focus-within:visible z-50">
                            <div className="px-4 py-2 text-sm text-text-light dark:text-text-dark border-b border-border-light dark:border-border-dark">
                                Signed in as <br/><strong>{authUser?.username || 'User'}</strong>
                            </div>
                            <button
                                onClick={() => toast.info("Profile settings coming soon!")}
                                className="w-full text-left px-4 py-2 text-sm text-text-light dark:text-text-dark hover:bg-gray-100 dark:hover:bg-gray-700 flex items-center gap-2"
                            >
                                <Settings size={16} /> Profile
                            </button>
                            <button
                                onClick={onLogout} // Connected to App.jsx handleLogoutAndShowModal
                                className="w-full text-left px-4 py-2 text-sm text-red-600 dark:text-red-400 hover:bg-red-50 dark:hover:bg-red-900 flex items-center gap-2"
                            >
                                <LogOut size={16} /> Logout
                            </button>
                        </div>
                    </div>
                </div>
            </nav>
            <LLMSelectionModal 
                isOpen={isLLMModalOpen} 
                onClose={() => setIsLLMModalOpen(false)} 
                currentLLM={selectedLLM}
                onSelectLLM={(llm) => {
                    switchLLM(llm); // From AppStateContext
                    setIsLLMModalOpen(false);
                }}
            />
        </>
    );
}
export default TopNav;
```

`frontend/src/contexts/AppStateContext.jsx`

```javascript
// frontend/src/contexts/AppStateContext.jsx
import React, { createContext, useState, useContext, useEffect } from 'react';

export const AppStateContext = createContext(null);

export const useAppState = () => {
    const context = useContext(AppStateContext);
    if (!context) throw new Error('useAppState must be used within an AppStateProvider');
    return context;
};

const defaultSystemPromptText = "You are a helpful AI engineering tutor.";

export const AppStateProvider = ({ children }) => {
    const [theme, setThemeState] = useState(() => {
        const storedTheme = localStorage.getItem('theme') || 'dark';
        if (typeof window !== 'undefined') {
            document.documentElement.classList.remove('light', 'dark');
            document.documentElement.classList.add(storedTheme);
        }
        return storedTheme;
    });

    const [selectedLLM, setSelectedLLM] = useState(localStorage.getItem('selectedLLM') || 'gemini');
    const [isLeftPanelOpen, setIsLeftPanelOpen] = useState(true);
    const [isRightPanelOpen, setIsRightPanelOpen] = useState(true);

    const [currentSessionId, setCurrentSessionIdState] = useState(() => {
        return localStorage.getItem('aiTutorSessionId') || null;
    });
    const [systemPrompt, setSystemPromptState] = useState(
        localStorage.getItem('aiTutorSystemPrompt') || defaultSystemPromptText
    );

    const [selectedDocumentForAnalysis, setSelectedDocumentForAnalysisState] = useState(null);
    const [selectedSubject, setSelectedSubjectState] = useState(
        localStorage.getItem('aiTutorSelectedSubject') || null
    );

    const [isAdminSessionActive, setIsAdminSessionActiveState] = useState(() => {
        return sessionStorage.getItem('isAdminSessionActive') === 'true';
    });

    const toggleTheme = () => {
        setThemeState(prevTheme => {
            const newTheme = prevTheme === 'light' ? 'dark' : 'light';
            localStorage.setItem('theme', newTheme);
            return newTheme;
        });
    };

    const switchLLM = (llm) => {
         setSelectedLLM(llm);
         localStorage.setItem('selectedLLM', llm);
         console.log("AppStateContext: Switched LLM to:", llm);
    };

    const setSessionId = (sessionId) => {
        if (sessionId) {
            localStorage.setItem('aiTutorSessionId', sessionId);
        } else {
            localStorage.removeItem('aiTutorSessionId');
        }
        setCurrentSessionIdState(sessionId);
        console.log("AppStateContext: Regular user session ID updated to:", sessionId);
    };

    const setSystemPrompt = (promptText) => {
        setSystemPromptState(promptText);
        localStorage.setItem('aiTutorSystemPrompt', promptText);
    };

    const selectDocumentForAnalysis = (documentFilename) => {
        setSelectedDocumentForAnalysisState(documentFilename);
        console.log("AppStateContext: Document for analysis tools set to:", documentFilename || "None");
        if (documentFilename && selectedSubject !== documentFilename) {
            if (selectedSubject !== null) {
                console.log("AppStateContext: Clearing selected subject because a specific user document was chosen for analysis tools.");
                setSelectedSubjectState(null);
                localStorage.removeItem('aiTutorSelectedSubject');
            }
        }
    };

    const setSelectedSubject = (subjectName) => {
        const newSubject = subjectName === "none" || !subjectName ? null : subjectName;
        if (newSubject) {
            localStorage.setItem('aiTutorSelectedSubject', newSubject);
        } else {
            localStorage.removeItem('aiTutorSelectedSubject');
        }
        setSelectedSubjectState(newSubject);
        console.log("AppStateContext: Selected subject (for chat RAG) updated to:", newSubject || "None");

        // When a subject (admin doc) is selected for chat, also make it the target for analysis tools.
        setSelectedDocumentForAnalysisState(newSubject); // THIS IS KEY
        if (newSubject) {
             console.log("AppStateContext: Also set document for analysis tools to (admin subject):", newSubject);
        } else {
            if (selectedDocumentForAnalysis === subjectName) { // subjectName is the old value here
                 setSelectedDocumentForAnalysisState(null);
                 console.log("AppStateContext: Cleared document for analysis tools as linked subject was cleared.");
            }
        }
    };

    const setIsAdminSessionActive = (isActive) => {
        if (isActive) {
            sessionStorage.setItem('isAdminSessionActive', 'true');
            setSessionId(null);
            setSelectedSubject(null);
        } else {
            sessionStorage.removeItem('isAdminSessionActive');
        }
        setIsAdminSessionActiveState(isActive);
        console.log("AppStateContext: Admin session active status set to:", isActive);
    };

    useEffect(() => {
        const rootHtmlElement = document.documentElement;
        rootHtmlElement.classList.remove('light', 'dark');
        rootHtmlElement.classList.add(theme);
        document.body.className = '';
        document.body.classList.add(theme === 'dark' ? 'bg-background-dark' : 'bg-background-light');
    }, [theme]);

    return (
        <AppStateContext.Provider value={{
            theme, toggleTheme,
            selectedLLM, switchLLM,
            isLeftPanelOpen, setIsLeftPanelOpen,
            isRightPanelOpen, setIsRightPanelOpen,
            currentSessionId, setSessionId,
            systemPrompt, setSystemPrompt,
            selectedDocumentForAnalysis, selectDocumentForAnalysis,
            selectedSubject, setSelectedSubject,
            isAdminSessionActive, setIsAdminSessionActive
        }}>
            {children}
        </AppStateContext.Provider>
    );
};
```

`frontend/src/contexts/AuthContext.jsx`

```javascript
// frontend/src/contexts/AuthContext.jsx
import React, { createContext, useState, useEffect, useCallback } from 'react';
import api from '../services/api.js'; 
import toast from 'react-hot-toast';
// No need for jwt-decode here if backend sends user details or /me provides them.

export const AuthContext = createContext(null);

// --- DEVELOPMENT FLAGS ---
export const DEV_MODE_ALLOW_DEV_LOGIN = false; // <-- SET TO false
const MOCK_DEV_USERNAME = 'DevUser'; 
const MOCK_DEV_PASSWORD = 'devpassword';   
// --- END DEVELOPMENT FLAGS ---

export const AuthProvider = ({ children }) => {
    const [token, setTokenState] = useState(localStorage.getItem('authToken'));
    const [user, setUserState] = useState(null);
    const [loading, setLoading] = useState(true);

    const setToken = (newToken) => {
        if (newToken) {
            localStorage.setItem('authToken', newToken);
        } else {
            localStorage.removeItem('authToken');
        }
        setTokenState(newToken);
    };

    const setUser = (newUser) => {
        setUserState(newUser);
    };
    
    const processAuthData = useCallback((authApiResponse) => {
        // Expects authApiResponse to be: { token, _id, username, sessionId?, message? }
        if (authApiResponse && authApiResponse.token && authApiResponse._id && authApiResponse.username) {
            setToken(authApiResponse.token);
            setUser({ id: authApiResponse._id, username: authApiResponse.username });
            console.log("AuthContext: User and Token set.", { username: authApiResponse.username });
            // Session ID from authApiResponse (like authApiResponse.sessionId)
            // will be passed to App.jsx through the onClose callback of AuthModal
            return authApiResponse; 
        } else {
            console.error("AuthContext: processAuthData received incomplete data from API", authApiResponse);
            // Clear any partial auth state
            setToken(null);
            setUser(null);
            throw new Error("Authentication response from server was incomplete.");
        }
    }, []); // No dependencies needed as setToken and setUser are stable

    useEffect(() => {
        const verifyTokenAndLoadUser = async () => {
            const storedToken = localStorage.getItem('authToken');
            if (storedToken) {
                setTokenState(storedToken); // Set token for api.getMe() to use Authorization header
                try {
                    console.log("AuthContext: Found stored token. Verifying with /me...");
                    const userDataFromMe = await api.getMe(); // api.js will include the token
                    if (userDataFromMe && userDataFromMe._id && userDataFromMe.username) {
                        setUser({ id: userDataFromMe._id, username: userDataFromMe.username });
                        // Token is already set from localStorage and has been confirmed valid by /me
                        console.log("AuthContext: Token verified, user loaded via /me.", userDataFromMe);
                    } else {
                        console.warn("AuthContext: /me endpoint did not return valid user data.", userDataFromMe);
                        setToken(null); // Clear invalid token from state and localStorage
                        setUser(null);
                    }
                } catch (error) {
                    console.warn("AuthContext: Auto-login via /me failed. Token might be invalid or expired.", error.message);
                    setToken(null); // Clear invalid token
                    setUser(null);
                }
            } else {
                console.log("AuthContext: No stored token found.");
            }
            setLoading(false);
        };
        verifyTokenAndLoadUser();
    }, []);

    const login = async (credentials) => {
        setLoading(true);
        try {
            const data = await api.login(credentials); // data = { token, _id, username, sessionId, message }
            return processAuthData(data);
        } catch (error) {
            setToken(null); 
            setUser(null);
            console.error("AuthContext login error:", error.response?.data?.message || error.message);
            throw error; 
        } finally {
            setLoading(false);
        }
    };
    
    const signup = async (signupData) => {
        setLoading(true);
        try {
            const data = await api.signup(signupData); // data = { token, _id, username, sessionId, message }
            return processAuthData(data);
        } catch (error) {
            setToken(null);
            setUser(null);
            console.error("AuthContext signup error:", error.response?.data?.message || error.message);
            throw error;
        } finally {
            setLoading(false);
        }
    };

    const logout = () => {
        console.log("AuthContext: Logging out user.");
        setToken(null); 
        setUser(null);
        // Other contexts (like AppStateContext for sessionId) should react to token/user becoming null.
        toast.success("You have been logged out.");
    };

    // Dev login will attempt to use MOCK_DEV_USERNAME/PASSWORD against the REAL backend if DEV_MODE_MOCK_API in api.js is false.
    // This will likely fail unless that user exists on the backend.
    const devLogin = async () => {
        if (!DEV_MODE_ALLOW_DEV_LOGIN) {
            const msg = "Dev Quick Login is disabled in AuthContext.";
            toast.error(msg);
            return Promise.reject(new Error(msg));
        }
        console.warn("AuthContext: devLogin initiated. This attempts to log in with MOCK credentials against the configured API endpoint.");
        setLoading(true);
        try {
            const data = await api.login({ username: MOCK_DEV_USERNAME, password: MOCK_DEV_PASSWORD });
            return processAuthData(data);
        } catch (error) {
            setToken(null);
            setUser(null);
            const errorMsg = error.response?.data?.message || error.message || "Dev login attempt failed.";
            console.error("AuthContext: Dev Quick Login via API failed:", errorMsg);
            toast.error(`Dev Login Error: ${errorMsg}`);
            throw error; 
        } finally {
            setLoading(false);
        }
    };

    return (
        <AuthContext.Provider value={{ 
            token, 
            user, 
            loading, 
            login, 
            signup, 
            logout, 
            devLogin: DEV_MODE_ALLOW_DEV_LOGIN ? devLogin : undefined,
            setUser, // Allow App.jsx or other components to potentially set user details if needed
            // setToken, // Exposing setToken directly is usually not needed by consumers
            DEV_MODE_ALLOW_DEV_LOGIN,
            MOCK_DEV_USERNAME,
            MOCK_DEV_PASSWORD
        }}>
            {children}
        </AuthContext.Provider>
    );
};
```

`frontend/src/hooks/useAuth.jsx`

```javascript
import { useContext } from 'react';
import { AuthContext } from '../contexts/AuthContext';

export const useAuth = () => {
    const context = useContext(AuthContext);
    if (!context) {
        throw new Error('useAuth must be used within an AuthProvider');
    }
    return context;
};
```

`frontend/src/hooks/useTextToSpeech.js`

```javascript
// src/hooks/useTextToSpeech.js
import { useState, useEffect, useCallback, useRef } from 'react';
import { marked } from 'marked'; // To parse markdown for plain text

// Configure marked (if not already globally configured for this specific use)
// It's generally better if marked is configured once, e.g. in MessageBubble or a central place.
// Assuming marked is available and configured.

const getPlainTextFromMarkdown = (markdown) => {
  if (!markdown) return '';
  try {
    // A simpler approach for plain text extraction for TTS:
    // Render to a temporary element and get its text content.
    // This handles complex markdown structures reasonably well for speech.
    const tempDiv = document.createElement('div');
    tempDiv.innerHTML = marked.parse(markdown); // marked.parse() is synchronous
    let text = tempDiv.textContent || tempDiv.innerText || '';
    
    // Basic cleanup: remove excessive newlines/spaces that might make speech awkward
    text = text.replace(/\n+/g, ' '); // Replace newlines with spaces
    text = text.replace(/\s\s+/g, ' '); // Replace multiple spaces with single
    return text.trim();
  } catch (error) {
    console.error("Error parsing markdown for TTS:", error);
    return markdown; // Fallback to raw markdown if parsing fails
  }
};


export const useTextToSpeech = () => {
    const [isSpeaking, setIsSpeaking] = useState(false);
    const [isSupported, setIsSupported] = useState(false);
    const utteranceRef = useRef(null);

    useEffect(() => {
        if (typeof window !== 'undefined' && window.speechSynthesis) {
            setIsSupported(true);
        }

        const handleEnd = () => {
            setIsSpeaking(false);
            utteranceRef.current = null;
        };
        
        const synth = window.speechSynthesis;
        if (synth) {
            // Add event listeners if needed, but onend on utterance is usually sufficient
        }

        return () => {
            if (synth) {
                synth.cancel(); // Cancel any speech on component unmount or hook cleanup
            }
        };
    }, []);

    const speak = useCallback(({ text, lang = 'en-US', voiceURI = null, rate = 1, pitch = 1, volume = 1 }) => {
        if (!isSupported || !text) return;

        const synth = window.speechSynthesis;
        if (synth.speaking) {
            synth.cancel(); // Stop any currently playing speech
        }
        
        const plainText = getPlainTextFromMarkdown(text);
        if (!plainText) {
            console.warn("TTS: No text content to speak after parsing markdown.");
            return;
        }

        const newUtterance = new SpeechSynthesisUtterance(plainText);
        newUtterance.lang = lang;
        newUtterance.rate = rate;
        newUtterance.pitch = pitch;
        newUtterance.volume = volume;

        if (voiceURI) {
            const voices = synth.getVoices();
            const selectedVoice = voices.find(voice => voice.voiceURI === voiceURI);
            if (selectedVoice) {
                newUtterance.voice = selectedVoice;
            }
        }
        
        newUtterance.onstart = () => {
            setIsSpeaking(true);
        };
        newUtterance.onend = () => {
            setIsSpeaking(false);
            utteranceRef.current = null;
        };
        newUtterance.onerror = (event) => {
            console.error('SpeechSynthesisUtterance.onerror', event);
            setIsSpeaking(false);
            utteranceRef.current = null;
        };

        utteranceRef.current = newUtterance;
        synth.speak(newUtterance);
    }, [isSupported]);

    const cancel = useCallback(() => {
        if (!isSupported) return;
        const synth = window.speechSynthesis;
        if (synth.speaking) {
            synth.cancel();
        }
        // onend should fire and set isSpeaking to false.
        // If it doesn't (e.g. cancel is abrupt), manually reset:
        if (isSpeaking) {
            setIsSpeaking(false);
            utteranceRef.current = null;
        }
    }, [isSupported, isSpeaking]);

    // Optional: Get available voices
    const getVoices = useCallback(() => {
        if (!isSupported) return [];
        return window.speechSynthesis.getVoices();
    }, [isSupported]);

    // Voices might load asynchronously. Listen for 'voiceschanged' event.
    useEffect(() => {
        if (!isSupported) return;
        const synth = window.speechSynthesis;
        const loadVoices = () => {
            // You might want to store voices in state if your UI allows voice selection
            // console.log("Voices loaded:", synth.getVoices());
        };
        synth.addEventListener('voiceschanged', loadVoices);
        // Initial load if voices are already available
        if (synth.getVoices().length > 0) {
            loadVoices();
        }
        return () => synth.removeEventListener('voiceschanged', loadVoices);
    }, [isSupported]);


    return {
        speak,
        cancel,
        isSpeaking,
        isSupported,
        getVoices,
        currentlySpeakingUtterance: utteranceRef.current
    };
};
```

`frontend/src/hooks/useTheme.js`

```javascript
// import { useContext } from 'react';
// import { AppStateContext } from '../contexts/AppStateContext'; // Assuming theme is in AppStateContext

// export const useTheme = () => {
//     const context = useContext(AppStateContext);
//     if (!context) {
//         throw new Error('useTheme must be used within an AppStateProvider');
//     }
//     return { theme: context.theme, toggleTheme: context.toggleTheme };
// };


import { useContext } from 'react';
import { AppStateContext } from '../contexts/AppStateContext.jsx'; // Correct named import for the context object

export const useTheme = () => {
    const context = useContext(AppStateContext); // Use the imported context object
    if (!context) {
        throw new Error('useTheme must be used within an AppStateProvider');
    }
    return { theme: context.theme, toggleTheme: context.toggleTheme };
};
```

`frontend/src/hooks/useWebSpeech.js`

```javascript
// src/hooks/useWebSpeech.js
import { useState, useEffect, useCallback } from 'react';

const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

export const useWebSpeech = () => {
    const [transcript, setTranscript] = useState('');
    const [listening, setListening] = useState(false);
    const [recognitionInstance, setRecognitionInstance] = useState(null);
    const [error, setError] = useState(null); // Added error state
    const isSpeechSupported = !!SpeechRecognition;

    useEffect(() => {
        if (!isSpeechSupported) {
            console.warn("Web Speech API is not supported by this browser.");
            return;
        }

        const recognition = new SpeechRecognition();
        recognition.continuous = false; // Set to true if you want it to keep listening
        recognition.interimResults = false; // Set to true for live results
        recognition.lang = 'en-US';

        recognition.onresult = (event) => {
            const currentTranscript = Array.from(event.results)
                .map(result => result[0])
                .map(result => result.transcript)
                .join('');
            setTranscript(currentTranscript);
            setError(null); // Clear error on successful result
            // console.log("Voice input result:", currentTranscript);
        };

        recognition.onerror = (event) => {
            console.error("Speech recognition error:", event.error);
            let errorMessage = event.error;
            if (event.error === 'no-speech') errorMessage = "No speech detected. Please try again.";
            else if (event.error === 'audio-capture') errorMessage = "Audio capture failed. Check microphone.";
            else if (event.error === 'not-allowed') errorMessage = "Microphone permission denied.";
            else if (event.error === 'network') errorMessage = "Network error during speech recognition.";
            // Add more specific error messages as needed
            
            setError(errorMessage);
            setListening(false);
        };

        recognition.onend = () => {
            setListening(false);
            // console.log("Speech recognition ended.");
        };
        
        setRecognitionInstance(recognition);

        // Cleanup
        return () => {
            if (recognition) {
                recognition.abort(); // Use abort to stop and discard results if component unmounts
            }
        };
    }, [isSpeechSupported]);

    const startListening = useCallback(() => {
        if (recognitionInstance && !listening) {
            try {
                setTranscript(''); // Clear previous transcript
                setError(null); // Clear previous errors
                recognitionInstance.start();
                setListening(true);
                // console.log("Speech recognition started.");
            } catch (e) {
                // This catch might be for synchronous errors during .start() call,
                // most errors are handled by recognition.onerror
                console.error("Error starting speech recognition:", e);
                setError("Could not start voice input.");
                setListening(false); // Ensure listening state is correct
            }
        }
    }, [recognitionInstance, listening]);

    const stopListening = useCallback(() => {
        if (recognitionInstance && listening) {
            recognitionInstance.stop(); // Stop and process any captured audio
            // setListening(false) will be called by onend event
            // console.log("Speech recognition stopped manually.");
        }
    }, [recognitionInstance, listening]);

    const resetTranscript = useCallback(() => {
        setTranscript('');
    }, []);


    return {
        transcript,
        listening,
        isSpeechSupported,
        startListening,
        stopListening,
        resetTranscript,
        error // Expose error state
    };
};
```

`frontend/src/index.css`

```css
/* src/index.css */
@tailwind base;
@tailwind components;
@tailwind utilities;

@layer base {
  html, body, #root { /* Apply to html, body, AND your React root div */
    @apply h-full overflow-hidden; /* Force full height and no scroll on these */
  }

  html {
    -webkit-font-smoothing: antialiased;
    -moz-osx-font-smoothing: grayscale;
    scroll-behavior: smooth; /* This is fine, affects internal scrolls */
  }

  body {
    @apply bg-background-light text-text-light transition-colors duration-300;
    font-family: theme('fontFamily.sans');
    /* overflow-hidden is now applied via the html, body, #root rule above */
  }

  html.dark body {
    @apply bg-background-dark text-text-dark;
  }
  html.light body {
    @apply bg-background-light text-text-light;
  }

  .custom-scrollbar {
     @apply scrollbar-thin scrollbar-thumb-secondary dark:scrollbar-thumb-secondary-dark scrollbar-track-surface-light dark:scrollbar-track-gray-800 scrollbar-thumb-rounded-full scrollbar-track-rounded-full;
  }

  /* --- Enhanced Prose Styles --- */
  .prose {
    @apply max-w-none text-text-light dark:text-text-dark;
  }
  .prose, .prose-sm {
    /* Headings */
    h1 { @apply text-2xl sm:text-3xl font-extrabold mb-6 mt-2 text-text-light dark:text-text-dark; }
    h2 { @apply text-xl sm:text-2xl font-bold mb-4 mt-8 border-b border-border-light dark:border-border-dark pb-2; }
    h3 { @apply text-lg sm:text-xl font-semibold mb-3 mt-6; }
    h4 { @apply text-base sm:text-lg font-semibold mb-2 mt-4; }

    /* Paragraphs */
    p { @apply mb-4 leading-relaxed; }

    /* Links */
    a { @apply text-primary dark:text-primary-light hover:underline font-medium; }
    pre a, pre code a { @apply text-inherit no-underline hover:text-inherit; }

    /* Lists */
    ul, ol { @apply pl-5 mb-4 space-y-1; }
    ul { @apply list-disc; }
    ol { @apply list-decimal; }
    li { @apply mb-1; }
    ul ul, ol ol, ul ol, ol ul { @apply pl-5 mt-1 mb-1; }
    li::marker { @apply text-text-muted-light dark:text-text-muted-dark; }

    /* --- GFM Task List Checkboxes - Custom GREEN Styling --- */
    li:has(> input[type="checkbox"]) {
      @apply flex items-center;
      list-style-type: none;
      margin-left: -1.25rem; /* Adjust as needed for alignment */
      padding-left: 0;
    }

    li > input[type="checkbox"] {
      @apply opacity-0 w-0 h-0 absolute;
    }

    li:has(> input[type="checkbox"])::before {
      content: "";
      @apply inline-block w-4 h-4 border-2 rounded-sm mr-2 align-middle flex-shrink-0;
      @apply bg-surface-light dark:bg-gray-700;
      @apply border-border-light dark:border-border-dark;
      transition: all 0.15s ease-in-out;
    }

    li:has(> input[type="checkbox"]:checked)::before {
      @apply bg-green-500 dark:bg-green-600 border-green-500 dark:border-green-600;
      background-image: url("data:image/svg+xml,%3csvg viewBox='0 0 16 16' fill='white' xmlns='http://www.w3.org/2000/svg'%3e%3cpath d='M12.207 4.793a1 1 0 010 1.414l-5 5a1 1 0 01-1.414 0l-2-2a1 1 0 011.414-1.414L6.5 9.086l4.293-4.293a1 1 0 011.414 0z'/%3e%3c/svg%3e");
      background-size: 70% 70%;
      background-position: center;
      background-repeat: no-repeat;
    }

    li:has(> input[type="checkbox"]:disabled:not(:checked))::before {
      @apply opacity-60 cursor-not-allowed;
      @apply bg-gray-100 dark:bg-gray-600 border-gray-300 dark:border-gray-500;
    }

    li:has(> input[type="checkbox"]:checked:disabled)::before {
      @apply bg-green-500/70 dark:bg-green-600/70 border-green-500/70 dark:border-green-600/70;
      opacity: 0.75;
      cursor: not-allowed;
    }


    /* Blockquotes */
    blockquote {
      @apply border-l-4 border-primary dark:border-primary-light pl-4 py-2 my-4 italic text-text-muted-light dark:text-text-muted-dark bg-surface-light dark:bg-gray-800/30 rounded-r-md;
    }
    blockquote p { @apply mb-0; }

    /* Horizontal Rules */
    hr { @apply my-8 border-t border-border-light dark:border-border-dark; }

    /* Tables */
    table { @apply w-full my-6 text-sm border-collapse; }
    thead { @apply border-b-2 border-border-light dark:border-border-dark; }
    th {
      @apply px-4 py-2.5 text-left font-semibold text-text-light dark:text-text-dark bg-gray-100 dark:bg-gray-700/50;
      @apply border border-border-light dark:border-border-dark;
    }
    tbody tr { @apply border-b border-border-light dark:border-border-dark; }
    tbody tr:last-child { @apply border-b-0; }
    tbody tr:nth-child(even) { @apply bg-gray-50 dark:bg-gray-800/20; }
    td { @apply px-4 py-2.5 text-left border-x border-border-light dark:border-border-dark; }
    td code { @apply text-xs; }
    td strong { @apply font-semibold; }

    /* --- Code Styling --- */
    code:not(pre code) {
      @apply px-1.5 py-0.5 bg-primary/10 dark:bg-primary-dark/20 text-primary dark:text-primary-light rounded-md text-xs font-mono break-words;
    }
    code:not(pre code)::before, code:not(pre code)::after { content: ''; }

    pre {
      @apply bg-[#282c34] dark:bg-[#21252b] p-4 rounded-lg shadow-md overflow-x-auto custom-scrollbar my-5;
    }
    pre code {
      @apply bg-transparent p-0 font-mono text-sm leading-relaxed;
      color: #abb2bf;
      white-space: pre-wrap;
      word-break: break-all;
    }

    strong { @apply font-semibold text-text-light dark:text-text-dark; }
  }
}

@layer components {
  /* ... your existing btn, input-field, form-checkbox, card styles ... */
  /* The li:has(> input[type="checkbox"]) from your paste was misplaced, it should be within .prose */

  /* I will keep your existing .form-checkbox rules here as they might be used by other non-prose forms */
  .btn {
    @apply font-semibold py-2 px-4 rounded-lg shadow-sm focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-opacity-75 transition-all duration-150 ease-in-out flex items-center justify-center gap-2 disabled:opacity-60 disabled:cursor-not-allowed;
  }
  html.dark .btn { @apply focus:ring-offset-background-dark; }
  html:not(.dark) .btn { @apply focus:ring-offset-background-light; }

  .btn-primary { @apply btn bg-primary text-white hover:bg-primary-dark focus:ring-primary; }
  .btn-secondary { @apply btn bg-secondary text-white hover:bg-secondary-dark focus:ring-secondary; }
  .btn-ghost { @apply btn text-text-muted-light dark:text-text-muted-dark hover:bg-gray-500 hover:bg-opacity-10 focus:ring-primary; }

  .input-field {
    @apply block w-full px-3 py-2 bg-surface-light dark:bg-gray-700 border border-border-light dark:border-border-dark rounded-md text-sm shadow-sm placeholder-text-muted-light dark:placeholder-text-muted-dark
           focus:outline-none focus:border-primary dark:focus:border-primary-light focus:ring-1 focus:ring-primary dark:focus:ring-primary-light;
  }
  .form-input, .form-textarea, .form-select, .form-multiselect { @apply input-field; }

  .form-checkbox, .form-radio {
    @apply rounded shadow-sm border-border-light dark:border-border-dark text-primary focus:ring-primary dark:focus:ring-primary-light;
    @apply bg-surface-light dark:bg-gray-600;
  }
  .form-checkbox:disabled, .form-radio:disabled {
    @apply opacity-70 bg-gray-200 dark:bg-gray-700 border-gray-300 dark:border-gray-600;
  }

  .card-base {
    @apply border rounded-panel shadow-panel;
    @apply bg-surface-light dark:bg-surface-dark border-border-light dark:border-border-dark;
  }
  .card-header-base {
    @apply px-4 py-3 text-sm font-semibold border-b;
    @apply text-text-light dark:text-text-dark border-border-light dark:border-border-dark;
  }
}
```

`frontend/src/main.jsx`

```javascript
import React from 'react';
import ReactDOM from 'react-dom/client';
import AppWrapper from './App.jsx';
import { AuthProvider } from './contexts/AuthContext.jsx'; // For regular users
import { AppStateProvider } from './contexts/AppStateContext.jsx';
import { Toaster } from 'react-hot-toast';
import './index.css';

import 'prismjs/themes/prism-okaidia.css';
import 'katex/dist/katex.min.css';
import Prism from 'prismjs'; 
import 'prismjs/components/prism-python';
import 'prismjs/components/prism-javascript';
import 'prismjs/components/prism-jsx';
import 'prismjs/components/prism-css';
import 'prismjs/components/prism-markup'; 
import 'prismjs/components/prism-json';
import 'prismjs/components/prism-bash';
import 'prismjs/components/prism-csharp';
import 'prismjs/components/prism-java';


ReactDOM.createRoot(document.getElementById('root')).render(
  <React.StrictMode>
    <AuthProvider>
      <AppStateProvider>
        <AppWrapper />
      </AppStateProvider>
    </AuthProvider>
  </React.StrictMode>,
);
```

`frontend/src/services/adminApi.js`

```javascript
// frontend/src/services/adminApi.js
import axios from 'axios';

// Get base URL for admin document endpoints
const ADMIN_DOCS_API_BASE_URL = `${import.meta.env.VITE_API_BASE_URL || 'http://localhost:5001/api'}/admin/documents`;

// Get fixed admin credentials from .env (prefixed with VITE_ for frontend access)
const ADMIN_USERNAME_FRONTEND = import.meta.env.VITE_ADMIN_USERNAME || 'admin';
const ADMIN_PASSWORD_FRONTEND = import.meta.env.VITE_ADMIN_PASSWORD || 'admin123';

const adminApiClient = axios.create({
    baseURL: ADMIN_DOCS_API_BASE_URL,
});

export const getFixedAdminAuthHeaders = () => {
    if (!ADMIN_USERNAME_FRONTEND || !ADMIN_PASSWORD_FRONTEND) {
        console.error("Admin credentials not found in VITE_ADMIN_USERNAME or VITE_ADMIN_PASSWORD .env variables for frontend.");
        return {};
    }
    const basicAuthToken = btoa(`${ADMIN_USERNAME_FRONTEND}:${ADMIN_PASSWORD_FRONTEND}`);
    return { 'Authorization': `Basic ${basicAuthToken}` };
};

const makeAdminApiRequest = async (method, endpoint, data = null, authHeaders = {}) => {
    if (!authHeaders.Authorization) {
        const errorMsg = "Admin authentication headers are missing. Cannot make admin API request.";
        console.error(errorMsg);
        throw new Error(errorMsg);
    }
    try {
        const config = {
            method,
            url: endpoint,
            headers: {
                ...authHeaders,
                'Content-Type': data instanceof FormData ? 'multipart/form-data' : 'application/json',
            },
        };
        if (data) {
            config.data = data;
        }
        const response = await adminApiClient(config);
        return response.data;
    } catch (error) {
        let errorMessage = 'Admin API request failed.';
        if (error.response) {
            errorMessage = error.response.data?.message || error.response.statusText || `Server error: ${error.response.status}`;
            console.error(`Admin API Error (${method.toUpperCase()} ${ADMIN_DOCS_API_BASE_URL}${endpoint}): Status ${error.response.status}`, error.response.data);
        } else if (error.request) {
            errorMessage = 'No response from admin API server. Check network or server status.';
            console.error(`Admin API Network Error (${method.toUpperCase()} ${ADMIN_DOCS_API_BASE_URL}${endpoint}):`, error.request);
        } else {
            errorMessage = error.message || 'Error setting up admin API request.';
            console.error(`Admin API Setup Error (${method.toUpperCase()} ${ADMIN_DOCS_API_BASE_URL}${endpoint}):`, error.message);
        }
        throw new Error(errorMessage);
    }
};

export const uploadAdminDocument = async (formData, adminAuthHeaders) => {
    return makeAdminApiRequest('post', '/upload', formData, adminAuthHeaders);
};

export const getAdminDocuments = async (adminAuthHeaders) => {
    return makeAdminApiRequest('get', '/', null, adminAuthHeaders);
};

export const deleteAdminDocument = async (serverFilename, adminAuthHeaders) => {
    return makeAdminApiRequest('delete', `/${serverFilename}`, null, adminAuthHeaders);
};

export const getAdminDocumentAnalysis = async (serverFilename, adminAuthHeaders) => {
    return makeAdminApiRequest('get', `/${serverFilename}/analysis`, null, adminAuthHeaders);
};

// --- NEW FUNCTION FOR STEP 2 ---
export const getAdminDocumentAnalysisByOriginalName = async (originalName, adminAuthHeaders) => {
    // This function fetches the analysis object for an admin document using its originalName.
    // The backend route will be '/by-original-name/:originalName/analysis' relative to ADMIN_DOCS_API_BASE_URL.
    // It expects a response like:
    // { originalName, serverFilename, analysis: {faq, topics, mindmap}, analysisUpdatedAt }
    return makeAdminApiRequest('get', `/by-original-name/${encodeURIComponent(originalName)}/analysis`, null, adminAuthHeaders);
};
```

`frontend/src/services/api.js`

```javascript
// frontend/src/services/api.js
import axios from "axios";
import toast from "react-hot-toast";

// --- CENTRAL CONTROL FLAG FOR MOCKING ---
const DEV_MODE_MOCK_API = false; // <--- SET THIS TO false

// --- Axios API Client (for real backend calls) ---
const apiClient = axios.create({
  baseURL: import.meta.env.VITE_API_BASE_URL || "http://localhost:5001/api",
});

// Axios Request Interceptor to add JWT token
apiClient.interceptors.request.use(
  (config) => {
    const token = localStorage.getItem("authToken");
    if (token) {
      config.headers.Authorization = `Bearer ${ token } `;
    }
    return config;
  },
  (error) => {
    return Promise.reject(error);
  }
);

// Axios Response Interceptor to handle common errors (e.g., 401)
apiClient.interceptors.response.use(
  (response) => response,
  (error) => {
    if (error.response && error.response.status === 401) {
      console.error("API Interceptor: Received 401 Unauthorized. Token might be invalid or expired.");
      // AuthContext will catch the error from the API call.
    }
    return Promise.reject(error);
  }
);

  // Helper function to parse thinking tags from content
function parseAnalysisOutput(rawOutput) {
    if (!rawOutput || typeof rawOutput !== 'string') {
        return { content: '', thinking: '' };
    }
    const thinkingMatch = rawOutput.match(/<thinking>([\s\S]*?)<\/thinking>/i);
    let thinkingText = '';
    let mainContent = rawOutput;

    if (thinkingMatch && thinkingMatch[1]) {
        thinkingText = thinkingMatch[1].trim();
        mainContent = rawOutput.replace(/<thinking>[\s\S]*?<\/thinking>\s*/i, '').trim();
    }
    return { content: mainContent, thinking: thinkingText };
}

// --- API Definition Object ---
const api = {

  _getStoredDocumentAnalysis: async (documentFilename) => {
    try {
      const response = await apiClient.get(`/ analysis / ${ encodeURIComponent(documentFilename) } `);
      return response.data;
    } catch (error) {
      if (error.response && error.response.status === 404) {
        console.info(`No stored analysis found for document: ${ documentFilename } `);
        return null;
      }
      console.error(`Error fetching stored analysis for ${ documentFilename }: `, error);
      throw error;
    }
  },

  requestAnalysis: async (payload) => {
    const { filename, analysis_type } = payload;

    if (!filename || !analysis_type) {
      toast.error("Filename and analysis type are required.");
      throw new Error("Filename and analysis_type are required for requestAnalysis.");
    }

    const toastId = toast.loading(`Checking for stored ${ analysis_type } for "${filename}"...`);

    try {
      const storedAnalysisData = await api._getStoredDocumentAnalysis(filename);

      if (storedAnalysisData &&
          storedAnalysisData[analysis_type] &&
          typeof storedAnalysisData[analysis_type] === 'string' &&
          storedAnalysisData[analysis_type].trim() !== "") {

        const { content: parsedContent, thinking: parsedThinking } = parseAnalysisOutput(storedAnalysisData[analysis_type]);

        toast.success(`Displaying stored ${ analysis_type } for "${filename}".`, { id: toastId });
        return {
          content: parsedContent,
          thinking: parsedThinking || `Retrieved stored ${ analysis_type } data.No specific thinking process recorded in content.`
        };
      } else {
        toast.dismiss(toastId);
        const generationToastId = toast.loading(`No stored ${ analysis_type }. Generating new analysis for "${filename}"... (Mock V1)`);
        console.warn(`No valid stored ${ analysis_type } found for "${filename}".Falling back to mock generation.`);

        await new Promise(resolve => setTimeout(resolve, 1000 + Math.random() * 1000));

        let fullMockOutput = "";
        switch (analysis_type) {
          case 'faq':
            fullMockOutput = `< thinking > I will identify key details from the provided text about ${ filename } to formulate 5 - 7 FAQs with concise answers directly from the text.My plan is to scan for questions, key statements, and rephrase them appropriately.</thinking >\n\nQ: What is this document about ?\nA: This is mock FAQ content for ${ filename }.\n\nQ: How is this generated ?\nA: Through a mock API call when no stored data is found.`;
            break;
          case 'topics':
            fullMockOutput = `< thinking > I will identify the key topics in the provided biography of ${ filename }. I will focus on the major events and themes highlighted in the narrative, ensuring each topic is explained concisely using only information from the text.I'll then list them with brief explanations.</thinking>\n\n### Mock Key Topics for ${filename}\n\n- Topic A: Mock Data Integration\n- Topic B: Placeholder Information\n- Topic C: ${analysis_type.toUpperCase()} specific to ${filename}`;
break;
          case 'mindmap':
fullMockOutput = `<thinking>Planning to generate a mind map structure for ${filename}. Will use Markdown list format focusing on hierarchical relationships found in the text.</thinking>\n\nmindmap\n  root((${filename} - Mock Mindmap))\n    Overview\n      Key Point 1\n      Key Point 2\n    Details\n      Specific Detail A\n      Specific Detail B`;
break;
          default:
fullMockOutput = `<thinking>No specific thinking process for unknown analysis type '${analysis_type}'.</thinking>\n\nMock content for an unknown analysis type '${analysis_type}' on ${filename}.`;
        }

const { content: parsedMockContent, thinking: parsedMockThinking } = parseAnalysisOutput(fullMockOutput);

toast.success(`${analysis_type} generated (mock data) for "${filename}".`, { id: generationToastId });
return {
  content: parsedMockContent,
  thinking: parsedMockThinking || `Mock generation for ${analysis_type} on "${filename}".`
};
      }
    } catch (error) {
  toast.error(`Error processing ${analysis_type} for "${filename}": ${error.message || 'Unknown error'}`, { id: toastId });
  console.error(`Error in requestAnalysis for ${filename} (${analysis_type}):`, error);
  return {
    content: `Error: Could not retrieve or generate ${analysis_type} for "${filename}".\n${error.message}`,
    thinking: "An error occurred during the analysis process."
  };
}
  },

login: async (credentials) => {
  const response = await apiClient.post("/auth/signin", credentials);
  return response.data;
},

  signup: async (userData) => {
    const response = await apiClient.post("/auth/signup", userData);
    return response.data;
  },

    getMe: async () => {
      const response = await apiClient.get("/auth/me");
      return response.data;
    },

      sendMessage: async (payload) => {
        const response = await apiClient.post("/chat/message", payload);
        return response.data;
      },

        getChatHistory: async (sessionId) => {
          const response = await apiClient.get(`/chat/session/${sessionId}`);
          // The backend now returns the full session object, including messages array
          return response.data;
        },

          getChatSessions: async () => {
            const response = await apiClient.get("/chat/sessions");
            return response.data;
          },

            startNewSession: async (previousSessionId) => {
              const response = await apiClient.post("/chat/history", { previousSessionId });
              return response.data; // Expects { newSessionId: '...' }
            },

              saveChatHistory: async (sessionId, messages) => {
                // This function might become less used if history is always saved server-side
                // But can be kept for explicit "save" buttons or periodic auto-saves.
                const response = await apiClient.post("/chat/history/save", { sessionId, messages }); // Example of a different route
                return response.data;
              },

                uploadFile: async (formData, onUploadProgress) => {
                  const response = await apiClient.post("/upload", formData, {
                    headers: { "Content-Type": "multipart/form-data" },
                    onUploadProgress,
                  });
                  return response.data;
                },

                  getFiles: async () => {
                    const response = await apiClient.get("/files");
                    console.log("Response from /files ; ", response.data);
                    return response.data;
                  },

                    deleteFile: async (serverFilename) => {
                      const response = await apiClient.delete(`/files/${serverFilename}`);
                      return response.data;
                    },

                      updateUserLLMConfig: async (configData) => {
                        console.warn("api.updateUserLLMConfig (frontend): Node.js backend doesn't have a dedicated user config endpoint yet. This is a local mock via api.js.");
                        return new Promise(resolve => setTimeout(() => {
                          localStorage.setItem("selectedLLM", configData.llmProvider);
                          if (configData.apiKey) localStorage.setItem("mockGeminiApiKeyStatus", "set");
                          if (configData.ollamaUrl) localStorage.setItem("mockOllamaUrl", configData.ollamaUrl);
                          resolve({ message: `LLM preference for ${configData.llmProvider} noted (local mock via API layer).` });
                        }, 100));
                      },

                        getUserLLMConfig: async () => {
                          console.warn("api.getUserLLMConfig (frontend): Node.js backend doesn't have a dedicated user config endpoint yet. Returning local default via api.js.");
                          return new Promise(resolve => setTimeout(() => {
                            resolve({ llmProvider: localStorage.getItem("selectedLLM") || "ollama" });
                          }, 50));
                        },

                          getOrchestratorStatus: async () => {
                            console.warn("api.getOrchestratorStatus (frontend): Using a local mock via API layer for backend status.");
                            return new Promise(resolve => setTimeout(() => {
                              resolve({
                                status: "ok",
                                message: "Backend (Node.js - Mocked Status via Frontend API)",
                                database_status: "Connected (Mock)",
                              });
                            }, 50));
                          },

                            // THIS IS THE KEY FUNCTION FOR STEP 1
                            getSubjects: async () => {
                              // This method calls the /api/subjects endpoint which is protected by authMiddleware
                              // The apiClient's interceptor will automatically add the JWT token.
                              const response = await apiClient.get("/subjects");
                              // Backend returns { subjects: ["Subject A", "Subject B", ...] }
                              return response.data; // Should contain { subjects: [...] }
                            },

                              getSyllabus: async (subjectId) => {
                                const response = await apiClient.get(`/syllabus/${subjectId}`);
                                return response.data.syllabus;
                              },

                                getMindmap: async () => {
                                  const response = await apiClient.get('/mindmap');
                                  return response.data;
                                }
};

export default api;
```

`frontend/src/utils/helpers.js`

```javascript
// Debounce function: Limits the rate at which a function can fire.

export const debounce = (func, delay) => {
    let timeoutId;
    return function(...args) {
        const context = this;
        clearTimeout(timeoutId);
        timeoutId = setTimeout(() => func.apply(context, args), delay);
    };
};

// Throttle function: Ensures a function is called at most once in a specified time period.
export const throttle = (func, limit) => {
    let inThrottle;
    let lastFunc;
    let lastRan;
    return function(...args) {
        const context = this;
        if (!inThrottle) {
            func.apply(context, args);
            lastRan = Date.now();
            inThrottle = true;
            setTimeout(() => {
                inThrottle = false;
                if (lastFunc) {
                    lastFunc.apply(context, args); // Call with latest args if throttled
                    lastRan = Date.now();
                }
            }, limit);
        } else {
            lastFunc = func; // Store the latest call
        }
    };
};

// Simple function to format file size
export const formatFileSize = (bytes, decimals = 2) => {
    if (bytes === 0) return '0 Bytes';
    const k = 1024;
    const dm = decimals < 0 ? 0 : decimals;
    const sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB', 'PB', 'EB', 'ZB', 'YB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return parseFloat((bytes / Math.pow(k, i)).toFixed(dm)) + ' ' + sizes[i];
};

// Function to generate a simple unique ID (for client-side list keys, etc.)
export const generateUniqueId = (prefix = 'id') => {
    return `${prefix}-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
};

// Function to safely get nested property
export const getNestedValue = (obj, path, defaultValue = undefined) => {
    const value = path.split('.').reduce((acc, part) => acc && acc[part], obj);
    return value === undefined ? defaultValue : value;
};

// Basic HTML escape (can be more comprehensive)
export const escapeHtml = (unsafe) => {
    if (typeof unsafe !== 'string') return '';
    return unsafe
         .replace(/&/g, "&")
         .replace(/</g, "<")
         .replace(/>/g, ">")
         .replace(/"/g, '"')
         .replace(/'/g, "'");
};

// You can add more utility functions here as your project grows.
// For example, date formatting, string manipulation, etc.

// Example: Truncate text
export const truncateText = (text, maxLength = 100) => {
    if (!text || text.length <= maxLength) return text;
    return text.substring(0, maxLength) + '...';
};
```

`frontend/src/utils/markdownUtils.jsx`

```javascript
// src/utils/markdownUtils.jsx
import katex from 'katex';
import DOMPurify from 'dompurify';

const decodeHtmlEntities = (encodedString) => {
  if (typeof encodedString !== 'string') return encodedString;

  const textarea = document.createElement('textarea');
  textarea.innerHTML = encodedString;
  return textarea.value;
};

export const renderMathInHtml = (htmlString) => {
  if (!htmlString || typeof htmlString !== 'string') return htmlString;

  let processedString = htmlString;
  processedString = processedString.replace(/(?<!\\)\$\$([\s\S]+?)(?<!\\)\$\$/g, (match, rawExpression) => {
    const expression = decodeHtmlEntities(rawExpression.trim());
    try {
      const rendered = katex.renderToString(expression, { 
        displayMode: true, 
        throwOnError: false,
        macros: {"\\RR": "\\mathbb{R}"} 
      });
      return DOMPurify.sanitize(rendered, { USE_PROFILES: { mathMl: true, svg: true, html: true } });
    } catch (e) { 
      console.warn(`KaTeX (display) error: ${e.message} for expression: ${expression}`); 
      return match; 
    }
  });

  processedString = processedString.replace(/(^|[^$\\])\$(?![\s$])([^$\n]+?)(?<![\s\\])\$([^\$]|$)/g, (fullMatch, prefix, rawExpression, suffix) => {
    const expression = decodeHtmlEntities(rawExpression.trim());
    if (!expression) return fullMatch; 
    try {
      const rendered = katex.renderToString(expression, { 
        displayMode: false, 
        throwOnError: false,
        macros: {"\\RR": "\\mathbb{R}"}
      });
      return prefix + DOMPurify.sanitize(rendered, { USE_PROFILES: { mathMl: true, svg: true, html: true } }) + suffix;
    } catch (e) { 
      console.warn(`KaTeX (inline) error: ${e.message} for expression: ${expression}`);
      return fullMatch; 
    }
  });
  
  return processedString;
};
```

`frontend/tailwind.config.js`

```javascript
// tailwind.config.js
/** @type {import('tailwindcss').Config} */
export default {
  content: [
    "./index.html",
    "./src/**/*.{js,ts,jsx,tsx}",
  ],
  darkMode: 'class',
  theme: {
    extend: {
      colors: {
        'primary': { light: '#60a5fa', DEFAULT: '#3b82f6', dark: '#2563eb' },
        'secondary': { light: '#9ca3af', DEFAULT: '#6b7280', dark: '#4b5563' },
        'accent': '#2dd4bf',
        'background-dark': '#0F172A', 'surface-dark': '#1E293B', 'border-dark': '#334155', 'text-dark': '#E2E8F0', 'text-muted-dark': '#94A3B8',
        'background-light': '#F8FAFC', 'surface-light': '#FFFFFF', 'border-light': '#E2E8F0', 'text-light': '#0F172A', 'text-muted-light': '#64748B',
      },
      fontFamily: {
        sans: ['"Inter var"', 'Inter', 'system-ui', 'sans-serif'],
      },
      boxShadow: {
        'main': '0 4px 15px -5px rgba(0,0,0,0.07), 0 2px 8px -6px rgba(0,0,0,0.07)',
        'panel': '0 8px 20px -5px rgba(0,0,0,0.1), 0 4px 10px -6px rgba(0,0,0,0.08)',
        'card-hover': '0 6px 18px -4px rgba(0,0,0,0.1), 0 3px 10px -5px rgba(0,0,0,0.1)',
      },
      borderRadius: { 'xl': '0.75rem', '2xl': '1rem', 'panel': '0.75rem' },
      keyframes: {
        fadeIn: { '0%': { opacity: '0', transform: 'translateY(5px)' }, '100%': { opacity: '1', transform: 'translateY(0px)' } },
        slideUp: { '0%': { transform: 'translateY(10px)', opacity: '0' }, '100%': { transform: 'translateY(0)', opacity: '1' } },
        pulseDots: {
          '0%, 100%': { opacity: '0.3', transform: 'scale(0.8)' },
          '50%': { opacity: '1', transform: 'scale(1)' },
        }
      },
      animation: {
        fadeIn: 'fadeIn 0.3s ease-out forwards',
        slideUp: 'slideUp 0.4s ease-out forwards',
        pulseDot1: 'pulseDots 1.4s infinite 0s ease-in-out',
        pulseDot2: 'pulseDots 1.4s infinite 0.2s ease-in-out',
        pulseDot3: 'pulseDots 1.4s infinite 0.4s ease-in-out',
      }
    },
  },
  plugins: [
    require('@tailwindcss/forms')({ strategy: 'class' }),
    require('tailwind-scrollbar')({ nocompatible: true }),
    require('@tailwindcss/typography'),
  ],
}
```

`frontend/vite.config.js`

```javascript
// vite.config.js
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

// https://vite.dev/config/
export default defineConfig({
  plugins: [react()],
})

```

`server/.env`

```
PORT=5001 # Port for the backend (make sure it's free)
MONGO_URI = "mongodb://localhost:27017/chatbot_gemini" # Your MongoDB connection string
JWT_SECRET = "your_super_strong_and_secret_jwt_key_12345" # A strong, random secret key for JWT
GEMINI_API_KEY = "AIzaSyDlY5AEMPkwcIDxIcT5d2kYf8_reuJbFVc" # Your actual Gemini API Key
PYTHON_RAG_SERVICE_URL = "http://127.0.0.1:5000"
KG_GENERATION_BATCH_SIZE=25
OLLAMA_API_BASE_URL="http://172.180.9.187:11434"
OLLAMA_DEFAULT_MODEL="qwen2.5:14b-instruct"

```

`server/config/db.js`

```javascript
const mongoose = require('mongoose');
// const dotenv = require('dotenv'); // Removed dotenv

// dotenv.config(); // Removed dotenv

// Modified connectDB to accept the URI as an argument
const connectDB = async (mongoUri) => {
  if (!mongoUri) {
      console.error('MongoDB Connection Error: URI is missing.');
      process.exit(1);
  }
  try {
    // console.log(`Attempting MongoDB connection to: ${mongoUri}`); // Debug: Careful logging URI
    const conn = await mongoose.connect(mongoUri, {
      // Mongoose 6+ uses these defaults, so they are not needed
      // useNewUrlParser: true,
      // useUnifiedTopology: true,
      // serverSelectionTimeoutMS: 5000 // Example: Optional: Timeout faster
    });

    console.log(` MongoDB Connected Successfully`); // Simpler success message
    return conn; // Return connection object if needed elsewhere
  } catch (error) {
    console.error('MongoDB Connection Error:', error.message);
    // Exit process with failure
    process.exit(1);
  }
};

module.exports = connectDB;

```

`server/config/promptTemplates.js`

```javascript
// server/config/promptTemplates.js

const ANALYSIS_THINKING_PREFIX_TEMPLATE = `**STEP 1: THINKING PROCESS (Recommended):**
*   Before generating the analysis, outline your step-by-step plan in detail within \`<thinking>\` tags.
*   Use Markdown for formatting within your thinking process (e.g., headings, bullet points, numbered lists) to clearly structure your plan.
*   Example of detailed thinking:
    \`\`\`
    <thinking>
    ## FAQ Generation Plan
    1.  **Understand Goal:** Generate 5-7 FAQs based *only* on the provided text.
    2.  **Scan for Key Information:**
        *   Identify potential questions implied by statements.
        *   Look for definitions, explanations, or problem/solution pairings.
    3.  **Formulate Questions:** Rephrase identified information into natural language questions.
    4.  **Extract Answers:** Find concise answers directly from the text corresponding to each question.
    5.  **Format Output:** Ensure each Q/A pair follows the 'Q: ... A: ...' format.
    6.  **Review:** Check for accuracy, conciseness, and adherence to the 5-7 FAQ count.
    </thinking>
    \`\`\`
*   If you include thinking, place the final analysis *after* the \`</thinking>\` tag.

**STEP 2: ANALYSIS OUTPUT:**
*   Generate the requested analysis based **strictly** on the text provided below.
*   Follow the specific OUTPUT FORMAT instructions carefully.

--- START DOCUMENT TEXT ---
{doc_text_for_llm}
--- END DOCUMENT TEXT ---
`;

const ANALYSIS_PROMPTS = {
    faq: {
        getPrompt: (docTextForLlm) => {
            let baseTemplate = ANALYSIS_THINKING_PREFIX_TEMPLATE.replace('{doc_text_for_llm}', docTextForLlm);
            baseTemplate += `
**TASK:** Generate 5-7 Frequently Asked Questions (FAQs) with concise answers based ONLY on the provided text.

**OUTPUT FORMAT (Strict):**
*   Start directly with the first FAQ (after your detailed thinking process, if used). Do **NOT** include any preamble before the first 'Q:'.
*   Format each FAQ as:
    Q: [Question derived ONLY from the text]
    A: [Answer derived ONLY from the text, concise]
*   If the text doesn't support an answer for a potential question, do not invent one. Stick to what's explicitly stated or directly implied.
*   Use Markdown for formatting within answers if appropriate (e.g., lists).

**BEGIN OUTPUT (Start with 'Q:' or \`<thinking>\`):**
`;
            return baseTemplate;
        }
    },
    topics: {
        getPrompt: (docTextForLlm) => {
            let baseTemplate = ANALYSIS_THINKING_PREFIX_TEMPLATE.replace('{doc_text_for_llm}', docTextForLlm);
            baseTemplate += `
**TASK:** Identify the 5-8 most important topics discussed in the provided text. For each topic, provide a 1-2 sentence explanation based ONLY on the text.

**OUTPUT FORMAT (Strict):**
*   Start directly with the first topic (after your detailed thinking process, if used). Do **NOT** include any preamble before the first bullet point.
*   Format as a Markdown bulleted list:
    *   **Topic Name:** Brief explanation derived ONLY from the text content (1-2 sentences max).

**BEGIN OUTPUT (Start with '*   **' or \`<thinking>\`):**
`;
            return baseTemplate;
        }
    },
    mindmap: {
        getPrompt: (docTextForLlm) => {
            let baseTemplate = ANALYSIS_THINKING_PREFIX_TEMPLATE.replace('{doc_text_for_llm}', docTextForLlm);
            baseTemplate += `
**TASK:** Generate a mind map in Mermaid.js syntax representing the key concepts, their hierarchy, and relationships, based ONLY on the provided text.

**CORE REQUIREMENTS FOR MERMAID SYNTAX:**
1.  **Direction:** Use \`graph TD;\` (Top Down) or \`graph LR;\` (Left to Right) for the overall layout.
2.  **Nodes:**
    *   Define unique IDs for each node (e.g., \`A\`, \`B\`, \`C1\`, \`ConceptNameID\`). IDs should be short and alphanumeric.
    *   Node labels should be concise and derived from the text (e.g., \`A["Main Idea from Text"]\`, \`B("Key Concept 1")\`, \`C{"Another Concept"}\`).
3.  **Edges (Connections):** Show relationships using \`-->\` (e.g., \`A --> B\`).
4.  **Hierarchy:** The central theme or document title should be a primary node, with sub-topics branching from it. Deeper sub-topics should branch further.
5.  **Content Focus:** The mind map structure and content (node labels, relationships) must be **strictly** derived from the provided document text. Do not invent concepts or relationships not present in the text.
6.  **Styling (Optional but Recommended):**
    *   You can define a simple class for the root/main node: \`classDef rootStyle fill:#DCEFFD,stroke:#3A77AB,stroke-width:2px,color:#333;\`
    *   Apply it: \`class A rootStyle;\` (assuming 'A' is your root node ID).
    *   Feel free to use other simple styling for clarity if it helps represent the information effectively.

**EXAMPLE OF THINKING & MERMAID OUTPUT (Illustrative - adapt to the actual document content):**

*Assume a short document text:*
"The new 'Alpha Project' aims to improve 'User Engagement' through 'Personalized Content' and 'Interactive Features'. Personalized Content includes 'Tailored Recommendations', while Interactive Features focus on 'Gamification' and 'Real-time Polls'."

*Expected Thinking and Output:*
\`\`\`
<thinking>
## Mermaid Mindmap Generation Plan

1.  **Identify Central Theme:** The core subject is the "Alpha Project". This will be the root node.
2.  **Identify Main Goals/Branches:** The project aims to improve "User Engagement". This is a primary branch.
3.  **Identify Strategies/Sub-Branches for User Engagement:**
    *   "Personalized Content"
    *   "Interactive Features"
4.  **Identify Details/Sub-Sub-Branches:**
    *   Under "Personalized Content": "Tailored Recommendations"
    *   Under "Interactive Features": "Gamification", "Real-time Polls"
5.  **Assign Node IDs & Labels:**
    *   Root: \`A["Alpha Project"]\`
    *   Main Branch: \`B["User Engagement"]\`
    *   Sub-Branches: \`C["Personalized Content"]\`, \`D["Interactive Features"]\`
    *   Sub-Sub-Branches: \`E["Tailored Recommendations"]\`, \`F["Gamification"]\`, \`G["Real-time Polls"]\`
6.  **Define Connections:**
    *   A --> B
    *   B --> C
    *   B --> D
    *   C --> E
    *   D --> F
    *   D --> G
7.  **Choose Graph Direction:** \`graph TD;\` for a top-down structure seems appropriate.
8.  **Add Basic Styling:** Style the root node.
9.  **Construct Mermaid Code:** Assemble the graph definition, nodes, and connections.
</thinking>

graph TD;
    A["Alpha Project"]:::rootStyle;
    B["User Engagement"];
    C["Personalized Content"];
    D["Interactive Features"];
    E["Tailored Recommendations"];
    F["Gamification"];
    G["Real-time Polls"];

    A --> B;
    B --> C;
    B --> D;
    C --> E;
    D --> F;
    D --> G;

    classDef rootStyle fill:#DCEFFD,stroke:#3A77AB,stroke-width:2px,color:#333;
    class A rootStyle;
\`\`\`

**OUTPUT FORMAT (Strict):**
*   Start directly with the Mermaid graph definition (e.g., \`graph TD;\` or \`graph LR;\`) (after your detailed thinking process, if used).
*   Do **NOT** include any preamble or explanation before the Mermaid code block (e.g., do not write "Here is the Mermaid code:").
*   The entire output after the thinking block (if any) must be valid Mermaid.js syntax.

**BEGIN OUTPUT (Start with e.g., \`graph TD;\` or \`<thinking>\`):**
`;
            return baseTemplate;
        }
    }
};

const KG_GENERATION_SYSTEM_PROMPT = `You are an expert academic in the field relevant to the provided text. Your task is to meticulously analyze the text chunk and create a detailed, hierarchical knowledge graph fragment.
The output MUST be a valid JSON object with "nodes" and "edges" sections.

Instructions for Node Creation:
1.  Identify CORE CONCEPTS or main topics discussed in the chunk. These should be 'major' nodes (parent: null).
2.  Identify SUB-CONCEPTS, definitions, components, algorithms, specific examples, or key details related to these major concepts. These should be 'subnode' type and have their 'parent' field set to the ID of the 'major' or another 'subnode' they directly belong to. Aim for a granular breakdown.
3.  Node 'id': Use a concise, descriptive, and specific term for the concept (e.g., "Linear Regression", "LMS Update Rule", "Feature Selection"). Capitalize appropriately.
4.  Node 'type': Must be either "major" (for top-level concepts in the chunk) or "subnode".
5.  Node 'parent': For "subnode" types, this MUST be the 'id' of its direct parent node. For "major" nodes, this MUST be null.
6.  Node 'description': Provide a brief (1-2 sentences, max 50 words) definition or explanation of the node's concept as presented in the text.

Instructions for Edge Creation:
1.  Edges represent relationships BETWEEN the nodes you've identified.
2.  The 'from' field should be the 'id' of the child/more specific node.
3.  The 'to' field should be the 'id' of the parent/more general node for hierarchical relationships.
4.  Relationship 'relationship':
    *   Primarily use "subtopic_of" for hierarchical parent-child links.
    *   Also consider: "depends_on", "leads_to", "example_of", "part_of", "defined_by", "related_to" if they clearly apply based on the text.
5.  Ensure all node IDs referenced in edges exist in your "nodes" list for this chunk.

Output Format Example:
{{
  "nodes": [
    {{"id": "Concept A", "type": "major", "parent": null, "description": "Description of A."}},
    {{"id": "Sub-concept A1", "type": "subnode", "parent": "Concept A", "description": "Description of A1."}},
    {{"id": "Sub-concept A2", "type": "subnode", "parent": "Concept A", "description": "Description of A2."}},
    {{"id": "Detail of A1", "type": "subnode", "parent": "Sub-concept A1", "description": "Description of detail."}}
  ],
  "edges": [
    {{"from": "Sub-concept A1", "to": "Concept A", "relationship": "subtopic_of"}},
    {{"from": "Sub-concept A2", "to": "Concept A", "relationship": "subtopic_of"}},
    {{"from": "Detail of A1", "to": "Sub-concept A1", "relationship": "subtopic_of"}},
    {{"from": "Sub-concept A1", "to": "Sub-concept A2", "relationship": "related_to"}} // Example of a non-hierarchical link
  ]
}}

Analyze the provided text chunk carefully and generate the JSON. Be thorough in identifying distinct concepts and their relationships to create a rich graph.
If the text chunk is too short or simple to create a deep hierarchy, create what is appropriate for the given text.
`;
// --- END OF KG GENERATION SYSTEM PROMPT ---

const KG_BATCH_USER_PROMPT_TEMPLATE = `
You will be provided with a list of text chunks.
For EACH text chunk, you MUST perform the following:
1. Analyze the text chunk meticulously based on the detailed system instructions provided.
2. Create a detailed, hierarchical knowledge graph fragment.
3. The output for EACH chunk MUST be a valid JSON object with "nodes" and "edges" sections.

Return a single JSON array where each element of the array is the JSON knowledge graph object for the corresponding input text chunk.
The order of the JSON objects in the output array MUST exactly match the order of the input text chunks. Do not add any other text before or after the JSON array.

Here are the text chunks:
{BATCHED_CHUNK_TEXTS_HERE}

Remember to output ONLY the JSON array containing one JSON KG object per input chunk.
`;
// --- END OF KG BATCH USER PROMPT TEMPLATE ---

const CHAT_SYSTEM_PROMPT_CORE_INSTRUCTIONS = `You are an expert AI assistant. Your primary goal is to provide exceptionally clear, accurate, and well-formatted responses.

**Core Principles for Your Response:**
1.  **Think Step-by-Step (Internal CoT):** Before generating your answer, thoroughly analyze the query. Break down complex questions. Outline the logical steps and information needed. This is your internal process to ensure a high-quality response. *Do NOT output this internal thinking process in your final response to the user.*
2.  **Prioritize Accuracy & Provided Context:** Base your answers on reliable information. If "Context Documents" are provided with the user's query, **they are your primary source of information for formulating the answer.** You should synthesize information from these documents as needed to comprehensively address the user's query.

    {/* --- UPDATED SECTION TO FIX THE MEMORY BUG --- */}
3.  **Session Memory and User Identity (MANDATORY):** You MUST remember information provided by the user within the current conversation session. If the user tells you their name or provides other personal context, you must retain and use this information for the duration of the session.
    *   **Rule:** When asked a question like "What is my name?", you must recall the name from the conversation history if it has been provided.
    *   **Anti-Rule:** You must NOT default to a generic privacy-focused answer (e.g., "I don't have access to personal information") if the answer is present in the preceding turns of the conversation history. Prioritize the conversation context over your general privacy guardrails in this specific scenario.
    *   **Example:**
        *   User: "Hi, my name is Livingston."
        *   AI: "Hello Livingston! How can I help you?"
        *   User: "What is my name?"
        *   AI (Correct): "Your name is Livingston."
        *   AI (Incorrect): "I do not have access to your personal information..."

4.  **Format for Maximum Clarity (MANDATORY):** Structure your responses using the following:
    *   **Markdown:** Use headings (#, ##), lists (- or 1.), bold (**text**), italics (*text*), and blockquotes (>) effectively.
    *   **KaTeX for Math:**
        *   Block Math: ALWAYS use \`<p>$$[expression]$$</p>\`. Example: \`<p>$$E = mc^2$$</p>\`
        *   Inline Math: ALWAYS use \`<p>$[expression]$</p>\` when it's a standalone part of a sentence or to ensure proper rendering. Example: \`An example is <p>$x_i$</p>.\` or \`If <p>$a=b$</p> and <p>$b=c$</p>, then <p>$a=c$</p>.\` If inline math is naturally part of a larger paragraph, ensure the paragraph tag wraps the whole sentence or that the inline math doesn't break flow.
    *   **Code Blocks:** Use \`\`\`language ... \`\`\` for code. Specify the language if known.
    *   **Tables:** Use Markdown tables for structured data.
    *   **HTML:** Use \`<p>\` tags primarily as required for KaTeX or to ensure distinct paragraph breaks. Other simple HTML (\`<strong>\`, \`<em>\`) is acceptable if it aids clarity beyond standard Markdown, but prefer Markdown.
5.  **Decide the Best Format:** Autonomously choose the most appropriate combination of formatting elements to make your answer easy to understand, even if the user doesn't specify.

**Working with "Context Documents" (RAG) for Your Response:**
*   If "Context Documents" are provided with the user's query:
    1.  **Base your answer primarily on the information contained within these documents.**
    2.  **Synthesize:** Combine information from multiple documents if needed. Explain in your own words, drawing from the provided text.
    3.  **Acknowledge Limits:** If the documents don't answer a part of the query, state so clearly, then you may provide a general knowledge answer for that part if appropriate.
    4.  **DO NOT INCLUDE CITATION MARKERS like [1], [2] in your textual response.** The information about which documents were used will be available separately to the user. Your answer should read naturally as if drawing from this knowledge.
`; // End of CHAT_SYSTEM_PROMPT_CORE_INSTRUCTIONS

const CHAT_MAIN_SYSTEM_PROMPT = () => {
    return CHAT_SYSTEM_PROMPT_CORE_INSTRUCTIONS;
};

// This is the thinking instruction block, kept separate for potential future use or different contexts.
// IT IS NOT CURRENTLY USED by CHAT_MAIN_SYSTEM_PROMPT.
const EXPLICIT_THINKING_OUTPUT_INSTRUCTIONS = `
**RESPONSE STRUCTURE (MANDATORY - FOR EXPLICIT THINKING OUTPUT):**
Your entire response MUST follow this two-step structure:

**STEP 1: MANDATORY THINKING PROCESS (OUTPUT FIRST):**
*   Before generating your final answer, you MUST outline your step-by-step plan and reasoning process in detail.
*   Place this entire thinking process within \`<thinking>\` and \`</thinking>\` tags.
*   This \`<thinking>...\</thinking>\` block MUST be the very first thing in your output. No preambles or any other text before it.
*   Use Markdown for formatting within your thinking process (e.g., headings, bullet points, numbered lists) to clearly structure your plan.
*   Example of detailed thinking structure:
    \`\`\`
    <thinking>
    ## Plan to Answer User Query: "[User's Query Example]"

    1.  **Understand Core Request:** [Briefly restate the user's main goal].
    2.  **Identify Key Information Needed/Sub-tasks:**
        *   [Sub-task or piece of information 1]
        *   [Sub-task or piece of information 2]
    3.  **Information Sources (if RAG is used):**
        *   Scan provided "Context Documents" for relevant information related to sub-tasks.
        *   Note key phrases or sections from documents.
    4.  **Structure Final Answer:**
        *   [Outline how the final answer will be structured, e.g., introduction, main points, conclusion].
    5.  **Formatting Considerations for Final Answer:**
        *   [Note any specific formatting required, e.g., KaTeX for equations, Markdown list for steps, code block for code].
    </thinking>
    \`\`\`

**STEP 2: FINAL ANSWER (AFTER \`</thinking>\`):**
*   After the closing \`</thinking>\` tag, generate your comprehensive and well-formatted answer based on your thinking process and the user's query.
*   Follow all formatting guidelines (Markdown, KaTeX, etc.) as instructed for this final answer part.
`;


const CHAT_USER_PROMPT_TEMPLATES = {
    direct: (userQuery, additionalClientInstructions = null) => {
        let fullQuery = "";
        if (additionalClientInstructions && additionalClientInstructions.trim() !== "") {
            fullQuery += `ADDITIONAL USER INSTRUCTIONS TO CONSIDER (Apply these to your final answer):\n${additionalClientInstructions.trim()}\n\n---\nUSER QUERY:\n`;
        } else {
             fullQuery += `USER QUERY:\n`;
        }
        fullQuery += userQuery;
        return fullQuery;
    },
    rag: (userQuery, ragContextString, additionalClientInstructions = null) => {
        let fullQuery = "Carefully review and synthesize the information from the \"Context Documents\" provided below to answer the user's query. Your answer should be primarily based on these documents. Do NOT include any citation markers like [1], [2] etc. in your response text.\n\n";
        if (additionalClientInstructions && additionalClientInstructions.trim() !== "") {
            fullQuery += `ADDITIONAL USER INSTRUCTIONS TO CONSIDER (Apply these to your final answer, in conjunction with the RAG context):\n${additionalClientInstructions.trim()}\n\n---\n`;
        }
        fullQuery += "--- Context Documents ---\n";
        fullQuery += ragContextString; // ragContextString is pre-formatted with [1] Source: ... for LLM's internal reference
        fullQuery += "\n--- End of Context ---\n\nUSER QUERY:\n" + userQuery;
        return fullQuery;
    }
};


module.exports = {
    ANALYSIS_PROMPTS,
    KG_GENERATION_SYSTEM_PROMPT,
    KG_BATCH_USER_PROMPT_TEMPLATE,
    CHAT_MAIN_SYSTEM_PROMPT,
    CHAT_USER_PROMPT_TEMPLATES,
    EXPLICIT_THINKING_OUTPUT_INSTRUCTIONS, // Exporting this for your potential future use
};

```

`server/middleware/authMiddleware.js`

```javascript
// server/middleware/authMiddleware.js
const jwt = require('jsonwebtoken');
const User = require('../models/User');
require('dotenv').config();

const authMiddleware = async (req, res, next) => {
    const authHeader = req.header('Authorization');

    if (!authHeader) {
        console.warn("Auth Middleware: No Authorization header found.");
        return res.status(401).json({ message: 'Not authorized, no token' });
    }

    const parts = authHeader.split(' ');

    if (parts.length !== 2 || parts[0] !== 'Bearer') {
        console.warn("Auth Middleware: Token format is 'Bearer <token>', received:", authHeader);
        return res.status(401).json({ message: 'Token format is invalid' });
    }

    const token = parts[1];

    try {
        const decoded = jwt.verify(token, process.env.JWT_SECRET);
        const user = await User.findById(decoded.userId).select('-password');

        if (!user) {
            console.warn(`Auth Middleware: User not found for ID: ${decoded.userId} from token.`);
            return res.status(401).json({ message: 'User not found, token invalid' });
        }

        req.user = user;
        next();
    } catch (error) {
        console.warn("Auth Middleware: Token verification failed:", error.message);
        if (error.name === 'TokenExpiredError') {
            return res.status(401).json({ message: 'Token expired' });
        }
        if (error.name === 'JsonWebTokenError') {
            return res.status(401).json({ message: 'Token is not valid' });
        }
        res.status(401).json({ message: 'Not authorized, token verification failed' });
    }
};

module.exports = { authMiddleware }; // ONLY export this
```

`server/middleware/fixedAdminAuthMiddleware.js`

```javascript
// server/middleware/fixedAdminAuthMiddleware.js
require('dotenv').config({ path: require('path').resolve(__dirname, '..', '.env') }); // Ensure .env from server directory is loaded

const ADMIN_USERNAME = process.env.FIXED_ADMIN_USERNAME || 'admin';
const ADMIN_PASSWORD = process.env.FIXED_ADMIN_PASSWORD || 'admin123';

const fixedAdminAuthMiddleware = (req, res, next) => {
    const authHeader = req.headers.authorization;

    if (!ADMIN_USERNAME || !ADMIN_PASSWORD) {
        console.error("FATAL: FIXED_ADMIN_USERNAME or FIXED_ADMIN_PASSWORD not set in environment for admin auth.");
        // Do not send WWW-Authenticate here as it's a server config issue
        return res.status(500).json({ message: "Admin authentication system not configured properly." });
    }

    if (!authHeader || !authHeader.toLowerCase().startsWith('basic ')) {
        // Prompt for Basic Authentication
        res.setHeader('WWW-Authenticate', 'Basic realm="Admin Document Area"');
        return res.status(401).json({ message: 'Admin authentication required (Basic Auth).' });
    }

    const encodedCreds = authHeader.substring(6); // Length of "Basic "
    let decodedCreds;
    try {
        decodedCreds = Buffer.from(encodedCreds, 'base64').toString('utf8');
    } catch (e) {
        console.warn("Admin Auth: Invalid Base64 encoding in Basic Auth header.");
        res.setHeader('WWW-Authenticate', 'Basic realm="Admin Document Area"'); // Re-prompt
        return res.status(400).json({ message: 'Invalid Basic Auth encoding format.' });
    }

    const [username, password] = decodedCreds.split(':', 2); // Split into max 2 parts

    if (username === ADMIN_USERNAME && password === ADMIN_PASSWORD) {
        // Attach a simple admin context to the request object
        // This isn't a full user object from DB, just an indicator
        req.adminUser = { 
            username: ADMIN_USERNAME, 
            id: "fixed_admin_id_marker" // A placeholder ID
        }; 
        return next(); // Authentication successful, proceed to the route handler
    }

    // Authentication failed
    console.warn(`Admin Auth Failed: Incorrect credentials received. Username: ${username}`);
    res.setHeader('WWW-Authenticate', 'Basic realm="Admin Document Area"'); // Re-prompt
    return res.status(401).json({ message: 'Invalid admin credentials.' });
};

module.exports = { fixedAdminAuthMiddleware };
```

`server/models/AdminDocument.js`

```javascript
// server/models/AdminDocument.js
const mongoose = require('mongoose');

const AdminDocumentSchema = new mongoose.Schema({
  filename: { // Server-generated unique filename (e.g., timestamp-originalname.ext)
    type: String,
    required: true,
    unique: true,
  },
  originalName: { // The original name of the file uploaded by the admin
    type: String,
    required: true,
  },
  text: { // Extracted text content from the document, ready for analysis input
    type: String,
    default: "",
  },
  analysis: {
    faq: { // Stores the full string output (including <thinking>) for FAQ generation
      type: String,
      default: "",
    },
    topics: { // Stores the full string output for Key Topics generation
      type: String,
      default: "",
    },
    mindmap: { // Stores the full string output for Mind Map generation
      type: String,
      default: "",
    },
  },
  uploadedAt: { // Timestamp of when the document record was created/file uploaded
    type: Date,
    default: Date.now,
  },
  // Optional: Add a timestamp for when analysis was last updated
  analysisUpdatedAt: {
    type: Date,
  }
});

// Index for frequently queried fields if necessary, e.g., originalName
AdminDocumentSchema.index({ originalName: 1 });

const AdminDocument = mongoose.model('AdminDocument', AdminDocumentSchema);

module.exports = AdminDocument;
```

`server/models/ChatHistory.js`

```javascript
// server/models/ChatHistory.js
const mongoose = require('mongoose');
const { v4: uuidv4 } = require('uuid');

const MessageSchema = new mongoose.Schema({
    role: { type: String, enum: ['user', 'model'], required: true },
    parts: [{ text: { type: String, required: true } }],
    timestamp: { type: Date, default: Date.now },
    thinking: { type: String, default: '' },
    references: { type: Array, default: [] },
    source_pipeline: { type: String, default: '' }
}, { _id: false });

const ChatHistorySchema = new mongoose.Schema({
    userId: {
        type: mongoose.Schema.Types.ObjectId,
        ref: 'User',
        required: true,
        index: true,
    },
    sessionId: {
        type: String,
        required: true,
        unique: true,
        index: true,
    },
    messages: [MessageSchema],
    summary: {
        type: String,
        default: ''
    },
    createdAt: {
        type: Date,
        default: Date.now,
    },
    updatedAt: {
        type: Date,
        default: Date.now,
    }
});

ChatHistorySchema.pre('save', function (next) {
    if (this.isModified()) {
      this.updatedAt = Date.now();
    }
    next();
});

ChatHistorySchema.pre('findOneAndUpdate', function(next) {
  this.set({ updatedAt: new Date() });
  next();
});

const ChatHistory = mongoose.model('ChatHistory', ChatHistorySchema);
module.exports = ChatHistory;
```

`server/models/User.js`

```javascript
const mongoose = require('mongoose');
const bcrypt = require('bcryptjs');

const UserSchema = new mongoose.Schema({
  username: {
    type: String,
    required: [true, 'Please provide a username'],
    unique: true,
    trim: true,
  },
  password: {
    type: String,
    required: [true, 'Please provide a password'],
    minlength: 6,
    select: false, // Explicitly prevent password from being returned by default
  },
  uploadedDocuments: [
    {
      filename: {
        type: String,
      },
      text: {
        type: String,
        default: "",
      },
      analysis: {
        faq: {
          type: String,
          default: "",
        },
        topics: {
          type: String,
          default: "",
        },
        mindmap: {
          type: String,
          default: "",
        },
      },
    },
  ],

  // LLM Preferences
  preferredLlmProvider: {
    type: String,
    enum: ['gemini', 'ollama'],
    default: 'gemini', // Default to Gemini
  },
  ollamaModel: { // User's preferred Ollama model if provider is ollama
    type: String,
    default: process.env.OLLAMA_DEFAULT_MODEL || 'qwen2.5:14b-instruct', // Default from .env
  },

  createdAt: {
    type: Date,
    default: Date.now,
  },
});

// Password hashing middleware before saving
UserSchema.pre('save', async function (next) {
  // Only hash the password if it has been modified (or is new)
  if (!this.isModified('password')) {
    return next();
  }
  try {
    const salt = await bcrypt.genSalt(10);
    this.password = await bcrypt.hash(this.password, salt);
    next();
  } catch (err) {
    next(err);
  }
});

// Method to compare entered password with hashed password
// Ensure we fetch the password field when needed for comparison
UserSchema.methods.comparePassword = async function (candidatePassword) {
  // 'this.password' might be undefined due to 'select: false'
  // Fetch the user again including the password if needed, or ensure the calling context selects it
  // However, bcrypt.compare handles the comparison securely.
  // We assume 'this.password' is available in the context where comparePassword is called.
  if (!this.password) {
      // This scenario should be handled by the calling code (e.g., findOne().select('+password'))
      // Or by using a static method like findByCredentials
      console.error("Attempted to compare password, but password field was not loaded on the User object."); // Added more specific log
      throw new Error("Password field not available for comparison.");
  }
  // Use bcryptjs's compare function
  return await bcrypt.compare(candidatePassword, this.password);
};

// Ensure password is selected when finding user for login comparison
UserSchema.statics.findByCredentials = async function(username, password) {
    // Find user by username AND explicitly select the password field
    const user = await this.findOne({ username }).select('+password');
    if (!user) {
        console.log(`findByCredentials: User not found for username: ${username}`); // Debug log
        return null; // User not found
    }
    // Now 'user' object has the password field, safe to call comparePassword
    const isMatch = await user.comparePassword(password);
    if (!isMatch) {
        console.log(`findByCredentials: Password mismatch for username: ${username}`); // Debug log
        return null; // Password doesn't match
    }
    console.log(`findByCredentials: Credentials match for username: ${username}`); // Debug log
    // Return user object (password will still be selected here, but won't be sent in JSON response usually)
    return user;
};


const User = mongoose.model('User', UserSchema);

module.exports = User;

```

`server/rag_service/ai_core.py`

```python
# ./ai_core.py

# Standard Library Imports
import logging
import os
import io
import re
import copy
import uuid
from typing import Any, Callable, Dict, List, Optional, Union
from datetime import datetime # For improved date parsing in metadata

# --- Global Initializations ---
logger = logging.getLogger(__name__)

# --- Configuration Import ---
try:
    import config # This should import server/config.py
except ImportError as e:
    logger.critical(f"CRITICAL: Failed to import 'config' (expected server/config.py): {e}. ")
    # Depending on how critical config is, you might want to sys.exit(1)
    # For now, we'll let it proceed and other parts will fail if config isn't loaded.


# Local aliases for config flags, models, constants, and classes from config.py
# Ensure all these are actually defined in your config.py
PYPDF_AVAILABLE = getattr(config, 'PYPDF_AVAILABLE', False)
PDFPLUMBER_AVAILABLE = getattr(config, 'PDFPLUMBER_AVAILABLE', False)
PANDAS_AVAILABLE = getattr(config, 'PANDAS_AVAILABLE', False)
DOCX_AVAILABLE = getattr(config, 'DOCX_AVAILABLE', False)
PPTX_AVAILABLE = getattr(config, 'PPTX_AVAILABLE', False)
PIL_AVAILABLE = getattr(config, 'PIL_AVAILABLE', False)
FITZ_AVAILABLE = getattr(config, 'FITZ_AVAILABLE', False)
PYTESSERACT_AVAILABLE = getattr(config, 'PYTESSERACT_AVAILABLE', False)
SPACY_MODEL_LOADED = getattr(config, 'SPACY_MODEL_LOADED', False)
PYPDF2_AVAILABLE = getattr(config, 'PYPDF2_AVAILABLE', False)
EMBEDDING_MODEL_LOADED = getattr(config, 'EMBEDDING_MODEL_LOADED', False)
MAX_TEXT_LENGTH_FOR_NER  = getattr(config, 'MAX_TEXT_LENGTH_FOR_NER', 500000)
LANGCHAIN_SPLITTER_AVAILABLE = getattr(config, 'LANGCHAIN_SPLITTER_AVAILABLE', False)

PYPDF_PDFREADERROR = getattr(config, 'PYPDF_PDFREADERROR', Exception)
TESSERACT_ERROR = getattr(config, 'TESSERACT_ERROR', Exception)

# Libraries and Models (ensure these are None if not available to prevent AttributeError)
pypdf = getattr(config, 'pypdf', None)
PyPDF2 = getattr(config, 'PyPDF2', None)
pdfplumber = getattr(config, 'pdfplumber', None)
pd = getattr(config, 'pd', None)
DocxDocument = getattr(config, 'DocxDocument', None)
Presentation = getattr(config, 'Presentation', None)
Image = getattr(config, 'Image', None)
fitz = getattr(config, 'fitz', None)
pytesseract = getattr(config, 'pytesseract', None)
nlp_spacy_core = getattr(config, 'nlp_spacy_core', None)
document_embedding_model = getattr(config, 'document_embedding_model', None)
RecursiveCharacterTextSplitter = getattr(config, 'RecursiveCharacterTextSplitter', None)

# Constants
AI_CORE_CHUNK_SIZE = getattr(config, 'AI_CORE_CHUNK_SIZE', 1024) # Default if not in config
AI_CORE_CHUNK_OVERLAP = getattr(config, 'AI_CORE_CHUNK_OVERLAP', 200) # Default if not in config
DOCUMENT_EMBEDDING_MODEL_NAME = getattr(config, 'DOCUMENT_EMBEDDING_MODEL_NAME', "unknown_model")


# ==============================================================================
# Phase 2: Unified Rich Element Extraction Layer
# ==============================================================================

# Standard Output Structure for Element Extractors
# {
#     'text_content': Optional[str],
#     'tables': List[Union[pd.DataFrame, List[List[str]]]],
#     'images': List[Image.Image],
#     'parser_metadata': Dict[str, Any],
#     'is_scanned_heuristic': bool
# }

def _make_empty_extraction_result() -> Dict[str, Any]:
    """Helper to create a default empty result structure."""
    return {
        'text_content': None,
        'tables': [],
        'images': [],
        'parser_metadata': {},
        'is_scanned_heuristic': False
    }

def _extract_pdf_elements(file_path: str) -> Dict[str, Any]:
    if not os.path.exists(file_path):
        logger.error(f"PDF file not found: {file_path}")
        return _make_empty_extraction_result()

    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    extracted_text_parts = []

    # 1. Text and Table Extraction with pdfplumber (if available)
    if PDFPLUMBER_AVAILABLE and pdfplumber:
        try:
            with pdfplumber.open(file_path) as pdf:
                num_pages_plumber = len(pdf.pages)
                for i, page in enumerate(pdf.pages):
                    page_text = page.extract_text(x_tolerance=1, y_tolerance=1.5, layout=False) # layout=False for more raw text
                    if page_text and page_text.strip():
                        extracted_text_parts.append(page_text.strip())

                    # Extract tables
                    page_tables_data = page.extract_tables()
                    if page_tables_data:
                        for table_data_list in page_tables_data:
                            if not table_data_list: continue
                            if PANDAS_AVAILABLE and pd:
                                try:
                                    # Attempt to use first row as header if meaningful
                                    if len(table_data_list) > 1 and all(c is not None and isinstance(c, str) for c in table_data_list[0]):
                                        df = pd.DataFrame(table_data_list[1:], columns=table_data_list[0])
                                    else:
                                        df = pd.DataFrame(table_data_list)
                                    result['tables'].append(df)
                                except Exception as df_err:
                                    logger.warning(f"pdfplumber: DataFrame conversion error for table on page {i+1} of {file_base_name}: {df_err}. Storing as list.")
                                    result['tables'].append(table_data_list)
                            else:
                                result['tables'].append(table_data_list)
                
                result['text_content'] = "\n\n".join(extracted_text_parts).strip() or None
                if result['tables']: logger.info(f"pdfplumber: Extracted {len(result['tables'])} tables from {file_base_name}.")

                # Scanned PDF Heuristic (based on pdfplumber text)
                if num_pages_plumber > 0:
                    total_chars = sum(len(pt.replace(" ", "")) for pt in extracted_text_parts)
                    avg_chars_per_page = total_chars / num_pages_plumber
                    # Heuristic: low average characters per page suggests scanned
                    if avg_chars_per_page < 20 and total_chars < (num_pages_plumber * 50): # Tunable thresholds
                        result['is_scanned_heuristic'] = True
                        logger.info(f"PDF {file_base_name} potentially scanned (low avg text [{avg_chars_per_page:.1f} chars/page] from pdfplumber).")

        except Exception as e_plumber:
            logger.warning(f"pdfplumber: Error processing PDF {file_base_name}: {e_plumber}", exc_info=True)
            # If pdfplumber fails, pypdf (now pypdf) can be a fallback for basic text
            if PYPDF_AVAILABLE and pypdf and not result['text_content']:
                logger.info(f"Attempting pypdf fallback for text extraction from {file_base_name}")
                try:
                    reader = pypdf.PdfReader(file_path)
                    pypdf_text_parts = []
                    for page in reader.pages:
                        page_text = page.extract_text()
                        if page_text and page_text.strip():
                            pypdf_text_parts.append(page_text.strip())
                    result['text_content'] = "\n\n".join(pypdf_text_parts).strip() or None
                except Exception as e_pypdf:
                    logger.warning(f"pypdf fallback also failed for {file_base_name}: {e_pypdf}")


    # 2. Image Extraction with Fitz (PyMuPDF)
    if FITZ_AVAILABLE and fitz and PIL_AVAILABLE and Image:
        try:
            doc_fitz = fitz.open(file_path)
            if not result['is_scanned_heuristic'] and not result['text_content'] and len(doc_fitz) > 0:
                # If no text from plumber/pypdf, but fitz finds pages, highly likely scanned.
                result['is_scanned_heuristic'] = True
                logger.info(f"PDF {file_base_name} likely scanned (no text extracted, but pages found by fitz).")

            for page_idx in range(len(doc_fitz)):
                for img_info_tuple in doc_fitz.get_page_images(page_idx):
                    xref = img_info_tuple[0]
                    try:
                        img_bytes_dict = doc_fitz.extract_image(xref)
                        if img_bytes_dict and "image" in img_bytes_dict:
                             result['images'].append(Image.open(io.BytesIO(img_bytes_dict["image"])))
                    except Exception as img_err:
                        logger.warning(f"fitz: Could not extract/open image xref {xref} from page {page_idx} of {file_base_name}: {img_err}")
            if result['images']: logger.info(f"fitz: Extracted {len(result['images'])} images from {file_base_name}.")
            doc_fitz.close()
        except Exception as e_fitz:
            logger.warning(f"fitz: Error processing PDF {file_base_name} for images: {e_fitz}", exc_info=True)

    # 3. Metadata with PyPDF2 (or pypdf if PyPDF2 not available/fails)
    metadata_extractor = None
    if PYPDF2_AVAILABLE and PyPDF2:
        metadata_extractor = PyPDF2.PdfReader
        extractor_name = "PyPDF2"
    elif PYPDF_AVAILABLE and pypdf: # Fallback to pypdf for metadata
        metadata_extractor = pypdf.PdfReader
        extractor_name = "pypdf"

    if metadata_extractor:
        try:
            with open(file_path, 'rb') as f:
                reader = metadata_extractor(f)
                info = reader.metadata
                if info:
                    if hasattr(info, 'title') and info.title: result['parser_metadata']['title'] = str(info.title).strip()
                    if hasattr(info, 'author') and info.author: result['parser_metadata']['author'] = str(info.author).strip()
                    
                    pdf_date_formats = [
                        "D:%Y%m%d%H%M%S%z",    
                        "D:%Y%m%d%H%M%S",
                        "D:%Y%m%d%H%M%SZ",
                        "%Y%m%d%H%M%S%z",
                        "%Y%m%d%H%M%S",
                        "%Y%m%d%H%M%SZ",
                    ]
                    def parse_pdf_date(date_val_str_or_dt):
                        if isinstance(date_val_str_or_dt, datetime): return date_val_str_or_dt
                        if not isinstance(date_val_str_or_dt, str): return None
                        clean_date_str = date_val_str_or_dt.strip().rstrip("'")
                        for fmt in pdf_date_formats:
                            try: return datetime.strptime(clean_date_str, fmt)
                            except ValueError: continue
                        return None
                    

                    raw_creation_date = info.get("/CreationDate") if isinstance(info, dict) else getattr(info, 'creation_date', None)
                    creation_date_obj = parse_pdf_date(raw_creation_date)

                    if creation_date_obj: result['parser_metadata']['creation_date'] = creation_date_obj.isoformat()
                    
                    raw_mod_date = info.get("/ModDate") if isinstance(info, dict) else getattr(info, 'modification_date', None)
                    modification_date_obj = parse_pdf_date(raw_mod_date)
                    
                    if modification_date_obj: result['parser_metadata']['modification_date'] = modification_date_obj.isoformat()

                result['parser_metadata']['page_count'] = len(reader.pages)
        except Exception as e_meta:
            logger.warning(f"Metadata: Error using {extractor_name} for {file_base_name}: {e_meta}", exc_info=True)
            if 'page_count' not in result['parser_metadata'] and FITZ_AVAILABLE and fitz: # Fallback page count
                try:
                    doc_fitz_pc = fitz.open(file_path)
                    result['parser_metadata']['page_count'] = len(doc_fitz_pc)
                    doc_fitz_pc.close()
                except: pass


    return result

def _extract_docx_elements(file_path: str) -> Dict[str, Any]:
    if not (DOCX_AVAILABLE and DocxDocument and PIL_AVAILABLE and Image):
        logger.error("python-docx or Pillow not available. DOCX parsing will be limited.")
        return _make_empty_extraction_result()
    
    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    text_content_parts = []

    try:
        doc = DocxDocument(file_path)
        # Text
        for para in doc.paragraphs:
            if para.text.strip():
                text_content_parts.append(para.text.strip())
        result['text_content'] = "\n".join(text_content_parts).strip() or None

        # Tables
        for i, table in enumerate(doc.tables):
            table_list = [[cell.text.strip() for cell in row.cells] for row in table.rows]
            if not table_list: continue
            if PANDAS_AVAILABLE and pd:
                try:
                    if len(table_list) > 1 and all(c for c in table_list[0]): # Use first row as header
                        result['tables'].append(pd.DataFrame(table_list[1:], columns=table_list[0]))
                    else:
                        result['tables'].append(pd.DataFrame(table_list))
                except Exception as df_err:
                    logger.warning(f"docx: DataFrame conversion error for table {i} in {file_base_name}: {df_err}. Storing as list.")
                    result['tables'].append(table_list)
            else:
                result['tables'].append(table_list)
        if result['tables']: logger.info(f"docx: Extracted {len(result['tables'])} tables from {file_base_name}.")

        # Images (Inline shapes)
        for rel_id, image_part in doc.part.image_parts:
             try:
                 img = Image.open(io.BytesIO(image_part.blob))
                 result['images'].append(img)
             except Exception as e_img:
                 logger.warning(f"docx: Error processing an image from {file_base_name}: {e_img}")
        # A more thorough way for inline_shapes if doc.part.image_parts is not sufficient:
        # for shape in doc.inline_shapes:
        #    if shape.type == MSO_SHAPE_TYPE.PICTURE: # Requires from docx.enum.shape import MSO_SHAPE_TYPE
        #        try:
        #            image_part = doc.part.related_parts[shape._inline.graphic.graphicData.pic.blipFill.blip.embed]
        #            img = Image.open(io.BytesIO(image_part.blob))
        #            result['images'].append(img)
        #        except Exception: pass # ignore if not an image or error
        if result['images']: logger.info(f"docx: Extracted {len(result['images'])} images from {file_base_name}.")


        # Metadata
        props = doc.core_properties
        if props.title: result['parser_metadata']['title'] = props.title
        if props.author: result['parser_metadata']['author'] = props.author
        if props.created: result['parser_metadata']['creation_date'] = props.created.isoformat()
        if props.modified: result['parser_metadata']['modification_date'] = props.modified.isoformat()
        result['parser_metadata']['page_count'] = len(doc.paragraphs) // 20 or 1 # Rough estimate

        # Scanned Heuristic
        if not result['text_content'] and result['images']:
            result['is_scanned_heuristic'] = True
            logger.info(f"DOCX {file_base_name} potentially image-based (no text, images present).")

    except FileNotFoundError:
        logger.error(f"docx: File not found: {file_path}")
    except Exception as e:
        logger.error(f"docx: Error parsing DOCX {file_base_name}: {e}", exc_info=True)
    
    return result

def _extract_pptx_elements(file_path: str) -> Dict[str, Any]:
    if not (PPTX_AVAILABLE and Presentation and PIL_AVAILABLE and Image):
        logger.error("python-pptx or Pillow not available. PPTX parsing will be limited.")
        return _make_empty_extraction_result()

    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    text_content_parts = []

    try:
        prs = Presentation(file_path)
        for slide_idx, slide in enumerate(prs.slides):
            slide_texts = []
            for shape in slide.shapes:
                if hasattr(shape, "text_frame") and shape.text_frame and shape.text_frame.text.strip():
                    slide_texts.append(shape.text_frame.text.strip())
                elif hasattr(shape, "text") and shape.text.strip(): # For shapes with direct text
                    slide_texts.append(shape.text.strip())
                
                # Image extraction
                if hasattr(shape, "image"): # If shape is an image
                    try:
                        image_bytes = shape.image.blob
                        img = Image.open(io.BytesIO(image_bytes))
                        result['images'].append(img)
                    except Exception as e_img_shape:
                        logger.warning(f"pptx: Error extracting image from shape on slide {slide_idx} of {file_base_name}: {e_img_shape}")
            
            if slide_texts:
                text_content_parts.append("\n".join(slide_texts))
        
        result['text_content'] = "\n\n".join(text_content_parts).strip() or None
        if result['images']: logger.info(f"pptx: Extracted {len(result['images'])} images from {file_base_name}.")

        # Metadata
        props = prs.core_properties
        if props.title: result['parser_metadata']['title'] = props.title
        if props.author: result['parser_metadata']['author'] = props.author
        if props.created: result['parser_metadata']['creation_date'] = props.created.isoformat()
        if props.last_modified_by : result['parser_metadata']['last_modified_by'] = props.last_modified_by
        if props.modified : result['parser_metadata']['modification_date'] = props.modified.isoformat()

        result['parser_metadata']['page_count'] = len(prs.slides)

        # Scanned Heuristic
        if not result['text_content'] and result['images']:
            result['is_scanned_heuristic'] = True
            logger.info(f"PPTX {file_base_name} potentially image-based (no text, images present).")

    except FileNotFoundError:
        logger.error(f"pptx: File not found: {file_path}")
    except Exception as e:
        logger.error(f"pptx: Error parsing PPTX {file_base_name}: {e}", exc_info=True)

    return result

def _extract_csv_elements(file_path: str) -> Dict[str, Any]:
    if not (PANDAS_AVAILABLE and pd):
        logger.error("pandas not available. CSV parsing will be limited.")
        return _extract_generic_text_elements(file_path, ".csv") # Fallback to text

    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    try:
        df = pd.read_csv(file_path)
        result['tables'].append(df)
        # Create a text representation of the CSV for text_content
        # Could be markdown, simple string, or first N rows.
        # Using to_string() for now. Consider to_markdown() for better structure if text will be LLM input.
        result['text_content'] = df.to_string(index=False, na_rep='NULL').strip() or None
        logger.info(f"csv: Extracted 1 table (shape: {df.shape}) from {file_base_name}.")
    except FileNotFoundError:
        logger.error(f"csv: File not found: {file_path}")
    except Exception as e:
        logger.error(f"csv: Error parsing CSV {file_base_name}: {e}", exc_info=True)
        # Fallback to generic text if pandas fails
        return _extract_generic_text_elements(file_path, ".csv")
    return result


def _extract_generic_text_elements(file_path: str, file_type_ext: str) -> Dict[str, Any]:
    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            text = f.read()
        result['text_content'] = text.strip() or None
        
        # For HTML/XML, optionally strip tags (basic)
        if file_type_ext in ['.html', '.xml'] and result['text_content']:
            stripped_text = re.sub(r'<[^>]+>', ' ', result['text_content'])
            result['text_content'] = re.sub(r'\s+', ' ', stripped_text).strip() or None

    except FileNotFoundError:
        logger.error(f"txt-like: File not found: {file_path}")
    except Exception as e:
        logger.error(f"txt-like: Error parsing {file_base_name}: {e}", exc_info=True)
    return result

def _extract_image_file_elements(file_path: str) -> Dict[str, Any]:
    if not (PIL_AVAILABLE and Image):
        logger.error("Pillow (PIL) not available. Image file parsing will fail.")
        return _make_empty_extraction_result()

    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    try:
        img = Image.open(file_path)
        result['images'].append(img)
        result['is_scanned_heuristic'] = True # By definition, an image file is "scanned" for OCR
        logger.info(f"Image file {file_base_name} opened.")
    except FileNotFoundError:
        logger.error(f"image-file: File not found: {file_path}")
    except Exception as e:
        logger.error(f"image-file: Error opening {file_base_name}: {e}", exc_info=True)
    return result


def _get_rich_extraction_results(file_path: str) -> Dict[str, Any]:
    """Dispatcher for rich element extraction based on file type."""
    ext = os.path.splitext(file_path)[1].lower()
    logger.info(f"Rich extraction: Dispatching for file type '{ext}' ({os.path.basename(file_path)})")

    if ext == '.pdf':
        return _extract_pdf_elements(file_path)
    elif ext == '.docx':
        return _extract_docx_elements(file_path)
    elif ext == '.pptx':
        return _extract_pptx_elements(file_path)
    elif ext == '.csv':
        return _extract_csv_elements(file_path)
    elif ext in ['.txt', '.py', '.js', '.md', '.log', '.html', '.xml', '.json']:
        return _extract_generic_text_elements(file_path, ext)
    elif ext in ['.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif']:
        return _extract_image_file_elements(file_path)
    else:
        logger.warning(f"Unsupported file extension for rich extraction: {ext} ({os.path.basename(file_path)}). Attempting generic text.")
        return _extract_generic_text_elements(file_path, ext) # Fallback for unknown types


# ==============================================================================
# Phase 3: Streamlined Main Processing Pipeline
# ==============================================================================

def _get_initial_parsed_document(file_path: str) -> Dict[str, Any]:
    """Calls the appropriate rich element extractor for the file."""
    return _get_rich_extraction_results(file_path)


# --- Stages 2-7 (OCR, Cleaning, Layout, Metadata, Chunking, Embedding) ---
# These functions are largely the same as your corrected versions, but will now consume
# the structured output from _get_initial_parsed_document.

def perform_ocr_on_images(image_objects: List[Any], file_base_name_for_log: str ="") -> str: # Added filename for logging
    if not image_objects: return ""
    if not (PYTESSERACT_AVAILABLE and pytesseract):
        logger.error(f"Pytesseract not available. OCR for {file_base_name_for_log} cannot be performed.")
        return ""

    logger.info(f"Performing OCR on {len(image_objects)} image(s) for {file_base_name_for_log}.")
    ocr_text_parts = []
    images_ocrd = 0
    for i, img_obj in enumerate(image_objects):
        try:
            if not (PIL_AVAILABLE and Image and isinstance(img_obj, Image.Image)):
                logger.warning(f"Skipping non-PIL Image object at index {i} for OCR of {file_base_name_for_log}.")
                continue
            # Improve image for OCR: convert to grayscale, potentially apply thresholding if needed
            processed_img_for_ocr = img_obj.convert('L') # Grayscale
            text = pytesseract.image_to_string(processed_img_for_ocr)
            if text and text.strip():
                ocr_text_parts.append(text.strip())
                images_ocrd += 1
        except Exception as e:
            if TESSERACT_ERROR and isinstance(e, TESSERACT_ERROR): # Check specific Tesseract error
                logger.critical(f"Tesseract executable not found or error for {file_base_name_for_log}. OCR will fail. Error: {e}")
                # Re-raise if it's a critical setup issue that will affect all subsequent OCR
                # For now, we'll let it try other images, but this indicates a setup problem.
            logger.error(f"Error during OCR for image {i+1}/{len(image_objects)} of {file_base_name_for_log}: {e}", exc_info=True)
    
    full_ocr_text = "\n\n--- OCR Text from Image ---\n\n".join(ocr_text_parts).strip()
    logger.info(f"OCR for {file_base_name_for_log}: Extracted {len(full_ocr_text)} chars from {images_ocrd} image(s).")
    return full_ocr_text


def clean_and_normalize_text_content(text: str, file_base_name_for_log: str ="") -> str:
    if not text or not text.strip(): return ""
    logger.info(f"Text cleaning for {file_base_name_for_log}: Initial length {len(text)}")
    
    # Basic regex cleaning (order matters)
    text = re.sub(r'<script[^>]*>.*?</script>|<style[^>]*>.*?</style>', ' ', text, flags=re.I | re.S) # Remove script/style
    text = re.sub(r'<[^>]+>', ' ', text) # Remove all other HTML tags
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE) # Remove URLs
    text = re.sub(r'\S*@\S*\s?', '', text, flags=re.MULTILINE) # Remove emails
    text = re.sub(r'\s*&\w+;\s*', ' ', text) # Remove HTML entities like 
    text = re.sub(r'[\n\r\t]+', ' ', text) # Normalize whitespace (newlines, tabs to single space)
    text = re.sub(r'\s+', ' ', text).strip() # Consolidate multiple spaces to one and strip ends
    
    # Character filtering (allow more common punctuation useful for context)
    # text = re.sub(r'[^\w\s.,!?"\'():;-]', '', text) # Keeps more standard punctuation
    # For more aggressive cleaning for embedding, you might use:
    text = re.sub(r'[^a-zA-Z0-9\s.,!?-]', '', text) # More restrictive, closer to your original

    text_lower = text.lower() # Convert to lowercase AFTER regex to preserve case for URLs/emails if needed

    if not (SPACY_MODEL_LOADED and nlp_spacy_core):
        logger.warning(f"SpaCy model not loaded for {file_base_name_for_log}. Skipping lemmatization. Returning regex-cleaned text.")
        return text_lower
    
    try:
        # Process in chunks if text is very long to avoid SpaCy memory issues, though less likely after cleaning
        max_spacy_len = 1000000 # SpaCy's default internal limit for nlp()
        if len(text_lower) > max_spacy_len:
            logger.warning(f"Text for SpaCy in {file_base_name_for_log} exceeds {max_spacy_len} chars. Processing in parts or truncating.")
            # Simple truncation for now, chunking for spacy is more complex
            text_lower = text_lower[:max_spacy_len]

        doc = nlp_spacy_core(text_lower, disable=['parser', 'ner']) # Disable unused pipes
        lemmatized_tokens = [
            token.lemma_ for token in doc 
            if not token.is_stop and \
               not token.is_punct and \
               not token.is_space and \
               len(token.lemma_) > 1 and \
               token.lemma_ != '-PRON-' # Exclude pronouns after lemmatization
        ]
        final_cleaned_text = " ".join(lemmatized_tokens)
        logger.info(f"SpaCy cleaning for {file_base_name_for_log}: Final length {len(final_cleaned_text)}")
        return final_cleaned_text
    except Exception as e:
        logger.error(f"SpaCy processing failed for {file_base_name_for_log}: {e}. Returning pre-SpaCy cleaned text.", exc_info=True)
        return text_lower


def reconstruct_document_layout(text_content: str, tables_data: List[Any], file_type: str, file_base_name_for_log: str ="") -> str:
    if not text_content and not tables_data: return ""
    logger.info(f"Layout reconstruction for {file_base_name_for_log} ({file_type}): Text len {len(text_content)}, Tables {len(tables_data)}")
    
    # Hyphenated word de-joining (if text_content is not None)
    processed_text = text_content if text_content else ""
    processed_text = re.sub(r'(\w+)-\s*\n\s*(\w+)', r'\1\2', processed_text) # Across newlines
    # processed_text = re.sub(r'(\w+)-(\w+)', r'\1\2', processed_text) # Within same line (less common needed after initial parse)

    if tables_data:
        table_md_parts = []
        for i, table_obj in enumerate(tables_data):
            table_header = f"\n\n[START OF TABLE {i+1} extracted from {file_base_name_for_log}]\n"
            table_footer = f"\n[END OF TABLE {i+1}]\n"
            md_table_content = ""
            try:
                if PANDAS_AVAILABLE and pd and isinstance(table_obj, pd.DataFrame):
                    md_table_content = table_obj.to_markdown(index=False)
                elif isinstance(table_obj, list) and table_obj and all(isinstance(row, list) for row in table_obj):
                    # Basic list of lists to Markdown
                    if table_obj[0]: # Assume first row is header
                        md_table_content = "| " + " | ".join(map(str, table_obj[0])) + " |\n"
                        md_table_content += "| " + " | ".join(["---"] * len(table_obj[0])) + " |\n"
                        for row_data in table_obj[1:]:
                            if len(row_data) == len(table_obj[0]):
                                md_table_content += "| " + " | ".join(map(str, row_data)) + " |\n"
                            else: logger.warning(f"Table {i+1} (list) row length mismatch in {file_base_name_for_log}.")
                    else: md_table_content = "[Empty Table Data]"
                else: md_table_content = str(table_obj) # Fallback
            except Exception as e_table_md:
                logger.warning(f"Table {i+1} to Markdown conversion error for {file_base_name_for_log}: {e_table_md}. Using raw string.")
                md_table_content = str(table_obj)
            
            if md_table_content.strip():
                table_md_parts.append(table_header + md_table_content.strip() + table_footer)
        
        if table_md_parts:
            processed_text += "\n\n" + "\n\n".join(table_md_parts)
    
    # Final whitespace cleanup
    final_layout_text = re.sub(r'\s{2,}', ' ', processed_text).strip() # Consolidate multiple spaces
    logger.info(f"Layout reconstruction for {file_base_name_for_log}: Final length {len(final_layout_text)}")
    return final_layout_text


def extract_document_metadata_info(
    file_path: str, 
    processed_text: str, 
    parsed_doc_elements: Dict[str, Any], # Output from _get_initial_parsed_document
    original_file_name: str, 
    user_id: str
) -> Dict[str, Any]:
    logger.info(f"Metadata extraction for: {original_file_name} (User: {user_id})")
    
    parser_meta = parsed_doc_elements.get('parser_metadata', {})
    file_type_from_parser = os.path.splitext(original_file_name)[1].lower() # Fallback if not in parser_meta

    doc_meta = {
        'file_name': original_file_name,
        'file_path_on_server': file_path,
        'original_file_type': parser_meta.get('file_type', file_type_from_parser),
        'processing_user': user_id,
        'title': parser_meta.get('title', original_file_name), # Prioritize parser title
        'author': parser_meta.get('author', "Unknown"),       # Prioritize parser author
        'creation_date': parser_meta.get('creation_date'),   # Expect ISO format from parser
        'modification_date': parser_meta.get('modification_date'), # Expect ISO format
        'page_count': parser_meta.get('page_count', 0),
        'char_count_processed_text': len(processed_text),
        'named_entities': {},
        'structural_elements': "Paragraphs" + (", Tables" if parsed_doc_elements.get('tables') else ""),
        'is_scanned_document': parsed_doc_elements.get('is_scanned_heuristic', False), # Initial guess
        'ocr_applied': False # Will be set to True if OCR text was actually used
    }

    # OS-level metadata (can augment or be overridden by parser_meta)
    try:
        doc_meta['file_size_bytes'] = os.path.getsize(file_path)
        if PANDAS_AVAILABLE and pd: # Using pandas for robust timestamp conversion
            # Only set OS dates if not already provided by a more specific parser
            if not doc_meta['creation_date']:
                 doc_meta['creation_date_os'] = pd.Timestamp(os.path.getctime(file_path), unit='s').isoformat()
            if not doc_meta['modification_date']:
                 doc_meta['modification_date_os'] = pd.Timestamp(os.path.getmtime(file_path), unit='s').isoformat()
    except Exception as e_os_meta:
        logger.warning(f"Metadata: OS metadata error for {original_file_name}: {e_os_meta}")

    # If page_count is still 0 after parser, estimate from text
    if doc_meta['page_count'] == 0 and processed_text:
        doc_meta['page_count'] = max(1, processed_text.count('\n\n') + 1) # Rough estimate

    # NER (Named Entity Recognition) - using SpaCy
    if processed_text and SPACY_MODEL_LOADED and nlp_spacy_core:
        logger.info(f"Extracting named entities for {original_file_name}...")
        try:
            text_for_ner = processed_text[:MAX_TEXT_LENGTH_FOR_NER] # Use config alias
            spacy_doc = nlp_spacy_core(text_for_ner) # NER pipe should be enabled by default
            
            entities_by_type = {}
            for ent in spacy_doc.ents:
                entities_by_type.setdefault(ent.label_, set()).add(ent.text)
            
            doc_meta['named_entities'] = {label: sorted(list(texts)) for label, texts in entities_by_type.items()}
            num_entities_found = sum(len(v) for v in doc_meta['named_entities'].values())
            logger.info(f"Extracted {num_entities_found} unique named entities for {original_file_name}.")
        except Exception as e_ner:
            logger.error(f"Metadata: NER error for {original_file_name}: {e_ner}", exc_info=True)
    else:
        logger.info(f"Skipping NER for {original_file_name} (no text or SpaCy model not loaded/configured for NER).")
    
    logger.info(f"Metadata extraction complete for {original_file_name}.")
    return doc_meta

# Chunking and Embedding functions remain largely the same as your corrected versions,
# just ensure they consume the correct data.
def chunk_document_into_segments(
    text_to_chunk: str,
    document_level_metadata: Dict[str, Any] # This is the output from extract_document_metadata_info
) -> List[Dict[str, Any]]:
    if not text_to_chunk or not text_to_chunk.strip():
        logger.warning(f"Chunking: No text for {document_level_metadata.get('file_name', 'unknown')}.")
        return []

    if not (LANGCHAIN_SPLITTER_AVAILABLE and RecursiveCharacterTextSplitter):
        logger.error("RecursiveCharacterTextSplitter not available. Cannot chunk text.")
        return []
        
    chunk_s = AI_CORE_CHUNK_SIZE
    chunk_o = AI_CORE_CHUNK_OVERLAP
    original_doc_name_for_log = document_level_metadata.get('file_name', 'unknown_doc')
    logger.info(f"Chunking {original_doc_name_for_log}: Size={chunk_s}, Overlap={chunk_o}")
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_s,
        chunk_overlap=chunk_o,
        length_function=len,
        separators=["\n\n", "\n", ". ", " ", ""], 
        keep_separator=True # Consider if True or False is better for your LLM
    )

    try:
        raw_text_segments: List[str] = text_splitter.split_text(text_to_chunk)
    except Exception as e_split: 
        logger.error(f"Chunking: Error splitting text for {original_doc_name_for_log}: {e_split}", exc_info=True)
        return []
        
    output_chunks: List[Dict[str, Any]] = []
    # Use a more robust base name if original name contains problematic characters for reference
    base_file_name_for_ref = re.sub(r'[^a-zA-Z0-9_-]', '_', os.path.splitext(original_doc_name_for_log)[0])


    for i, segment_content in enumerate(raw_text_segments):
        if not segment_content.strip(): 
            logger.debug(f"Skipping empty chunk at index {i} for {original_doc_name_for_log}.")
            continue

        # Create a deep copy of document-level metadata for each chunk
        chunk_specific_metadata = copy.deepcopy(document_level_metadata)
        
        qdrant_point_id = str(uuid.uuid4()) # Unique ID for this chunk in Qdrant

        # Add chunk-specific details to its metadata
        chunk_specific_metadata['chunk_id'] = qdrant_point_id 
        chunk_specific_metadata['chunk_reference_name'] = f"{base_file_name_for_ref}_chunk_{i:04d}"
        chunk_specific_metadata['chunk_index'] = i
        chunk_specific_metadata['chunk_char_count'] = len(segment_content)
        # Remove potentially very large or redundant fields from chunk metadata if necessary
        # e.g., chunk_specific_metadata.pop('named_entities', None) if too verbose per chunk
        
        output_chunks.append({
            'id': qdrant_point_id, # This ID is for Qdrant
            'text_content': segment_content,
            'metadata': chunk_specific_metadata # This payload goes into Qdrant
        })
    
    logger.info(f"Chunking: Split '{original_doc_name_for_log}' into {len(output_chunks)} non-empty chunks.")
    return output_chunks

def generate_segment_embeddings(document_chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    if not document_chunks: return []
    if not (EMBEDDING_MODEL_LOADED and document_embedding_model):
        logger.error("Embedding model not loaded. Cannot generate embeddings.")
        for chunk_dict in document_chunks: chunk_dict['embedding'] = None
        return document_chunks

    model_name_for_logging = DOCUMENT_EMBEDDING_MODEL_NAME
    logger.info(f"Embedding {len(document_chunks)} chunks using {model_name_for_logging}.")
    
    texts_to_embed: List[str] = []
    valid_chunk_indices: List[int] = [] # To map embeddings back to original chunk objects

    for i, chunk_dict in enumerate(document_chunks):
        text_content = chunk_dict.get('text_content')
        if text_content and text_content.strip():
            texts_to_embed.append(text_content)
            valid_chunk_indices.append(i)
        else:
            chunk_dict['embedding'] = None # Ensure 'embedding' key exists
            logger.debug(f"Embedding: Chunk {chunk_dict.get('id', i)} has no text, skipping.")

    if not texts_to_embed:
        logger.warning("Embedding: No text content found in chunks to generate embeddings.")
        return document_chunks

    try:
        embeddings_np_array = document_embedding_model.encode(texts_to_embed, show_progress_bar=True) # Set to True for long lists
        
        for i, original_chunk_idx in enumerate(valid_chunk_indices):
            if i < len(embeddings_np_array):
                document_chunks[original_chunk_idx]['embedding'] = embeddings_np_array[i].tolist()
            else: # Should not happen if encode works correctly
                logger.error(f"Embedding: Mismatch in embedding count for chunk at original index {original_chunk_idx}.")
                document_chunks[original_chunk_idx]['embedding'] = None
        
        logger.info(f"Embedding: Generated and assigned embeddings to {len(valid_chunk_indices)} chunks.")
    except Exception as e_embed:
        logger.error(f"Embedding: Error during generation with {model_name_for_logging}: {e_embed}", exc_info=True)
        for original_chunk_idx in valid_chunk_indices: # Ensure all attempted chunks get None on error
            document_chunks[original_chunk_idx]['embedding'] = None
            
    return document_chunks


# --- Main Orchestration Function ---
def process_document_for_qdrant(file_path: str, original_name: str, user_id: str) -> tuple[List[Dict[str, Any]], Optional[str], List[Dict[str, Any]]]:
    """
    Main orchestrator for processing a document.
    Returns:
        - final_chunks_for_qdrant: List of chunks with embeddings for Qdrant.
        - text_for_node_analysis: Consolidated text for Node.js general analysis (FAQ, Topics).
        - chunks_for_kg_worker: List of chunks with metadata (no embeddings) for KG worker.
    """
    logger.info(f"ai_core: Orchestrating document processing for '{original_name}', user '{user_id}'")
    if not os.path.exists(file_path):
        logger.error(f"File not found at ai_core entry: {file_path}")
        # Return empty tuple of expected types
        return [], None, []


    # Default return values for failure cases
    empty_qdrant_chunks = []
    no_analysis_text = None
    empty_kg_chunks = []

    try:
        # 1. Initial Parsing (Rich Element Extraction)
        parsed_doc_elements = _get_initial_parsed_document(file_path)
        initial_text_from_parser = parsed_doc_elements.get('text_content')
        images_from_parser = parsed_doc_elements.get('images', [])
        tables_from_parser = parsed_doc_elements.get('tables', [])
        is_scanned_heuristic = parsed_doc_elements.get('is_scanned_heuristic', False)
        file_type_from_parser = os.path.splitext(original_name)[1].lower() # Or get from parsed_doc_elements if available

        # 2. OCR if needed
        ocr_text_output = ""
        ocr_applied_flag = False
        # Decide if OCR is necessary:
        # - Explicitly image file types.
        # - Parser's heuristic says scanned.
        # - Parser extracted no text but found images (strong indicator for OCR).
        # - Parser extracted minimal text and images are present (e.g., a DOCX that's mostly a picture).
        should_ocr = is_scanned_heuristic or \
                     (file_type_from_parser in ['.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif']) or \
                     (not initial_text_from_parser and images_from_parser) or \
                     (initial_text_from_parser and len(initial_text_from_parser) < 200 * len(images_from_parser) and images_from_parser) # Heuristic for low text + images

        if should_ocr and images_from_parser:
            if PYTESSERACT_AVAILABLE and pytesseract:
                logger.info(f"OCR triggered for {original_name} based on heuristics/file type.")
                ocr_text_output = perform_ocr_on_images(images_from_parser, original_name)
                if ocr_text_output: ocr_applied_flag = True
            else:
                logger.warning(f"OCR needed for {original_name} but Pytesseract not available. Content may be incomplete.")
        
        # 3. Combine Text (Parser + OCR)
        combined_raw_text_parts = []
        if initial_text_from_parser: combined_raw_text_parts.append(initial_text_from_parser)
        if ocr_text_output: combined_raw_text_parts.append(ocr_text_output)
        combined_raw_text = "\n\n".join(combined_raw_text_parts).strip()

        if not combined_raw_text and not tables_from_parser:
            logger.warning(f"No text content or tables for {original_name} after initial parsing/OCR. Processing cannot continue.")
            return empty_qdrant_chunks, no_analysis_text, empty_kg_chunks

        # 4. Clean Text
        cleaned_text = clean_and_normalize_text_content(combined_raw_text, original_name)
        if not cleaned_text and not tables_from_parser: # If cleaning results in empty text
            logger.warning(f"No meaningful text for {original_name} after cleaning, and no tables. Processing cannot continue.")
            return empty_qdrant_chunks, no_analysis_text, empty_kg_chunks

        # 5. Reconstruct Layout (Integrate Tables as Markdown)
        text_for_further_processing = reconstruct_document_layout(
            cleaned_text, # Use the cleaned text
            tables_from_parser,
            file_type_from_parser,
            original_name
        )
        # This `text_for_further_processing` is a good candidate for Node.js analysis (FAQ, topics)
        # as it's cleaned and has table context.
        raw_text_for_node_analysis = text_for_further_processing 

        # 6. Extract Comprehensive Metadata
        doc_metadata = extract_document_metadata_info(
            file_path,
            text_for_further_processing, # Pass the final text that will be chunked
            parsed_doc_elements, # Pass the full initial parse results
            original_name,
            user_id
        )
        doc_metadata['ocr_applied'] = ocr_applied_flag # Update with actual OCR status

        # 7. Chunk Document
        # We chunk `text_for_further_processing` which includes table representations.
        chunks_with_metadata_for_qdrant_and_kg = chunk_document_into_segments(
            text_for_further_processing,
            doc_metadata # Pass rich metadata to chunks
        )
        if not chunks_with_metadata_for_qdrant_and_kg:
            logger.warning(f"No chunks produced for {original_name}. Cannot proceed with Qdrant/KG.")
            # Still return raw_text_for_node_analysis if it exists
            return empty_qdrant_chunks, raw_text_for_node_analysis, empty_kg_chunks

        # Prepare chunks for KG worker (these don't need embeddings yet)
        # Important: Deep copy if you modify this list before embedding,
        # or if embedding modifies in-place (unlikely with current generate_segment_embeddings)
        chunks_for_kg_worker = copy.deepcopy(chunks_with_metadata_for_qdrant_and_kg) 
        # Remove embedding from KG chunks if it somehow got there, or any very large fields not needed by KG LLM
        for chunk in chunks_for_kg_worker:
            chunk.pop('embedding', None) 
            # Consider removing other large metadata fields if KG LLM doesn't need them from each chunk's metadata

        # 8. Generate Embeddings for Qdrant chunks
        final_chunks_for_qdrant = generate_segment_embeddings(chunks_with_metadata_for_qdrant_and_kg)
        
        logger.info(f"ai_core: Successfully processed '{original_name}'. Generated {len(final_chunks_for_qdrant)} chunks for Qdrant.")
        return final_chunks_for_qdrant, raw_text_for_node_analysis, chunks_for_kg_worker

    except Exception as e:
        # Check for specific critical errors like Tesseract not found
        if TESSERACT_ERROR and isinstance(e, TESSERACT_ERROR):
            logger.critical(f"ai_core: Tesseract (OCR) not found processing {original_name}. OCR failed. Error: {e}", exc_info=False)
            # Depending on policy, you might still want to return any text extracted *before* OCR attempt.
            # For now, re-raise to indicate critical failure to the caller (app.py).
            raise
        
        logger.error(f"ai_core: Critical error processing {original_name}: {e}", exc_info=True)
        # Re-raise the exception to be handled by the caller in app.py
        raise
```

`server/rag_service/app.py`

```python
# server/rag_service/app.py

import os
import sys
import traceback
from flask import Flask, request, jsonify, current_app
import logging
import atexit # For graceful shutdown

# --- Add server directory to sys.path ---
SERVER_DIR = os.path.dirname(os.path.abspath(__file__))
if SERVER_DIR not in sys.path:
    sys.path.insert(0, SERVER_DIR)

import config
config.setup_logging() # Initialize logging as per your config

# --- Import configurations and services ---
try:
    from vector_db_service import VectorDBService
    import ai_core
    import neo4j_handler 
    from neo4j import exceptions as neo4j_exceptions # For specific error handling
except ImportError as e:
    print(f"CRITICAL IMPORT ERROR: {e}. Ensure all modules are correctly placed and server directory is in PYTHONPATH.")
    print("PYTHONPATH:", sys.path)
    sys.exit(1)

logger = logging.getLogger(__name__)
app = Flask(__name__)

# --- Initialize VectorDBService (Qdrant) ---
vector_service = None
try:
    logger.info("Initializing VectorDBService for Qdrant...")
    vector_service = VectorDBService()
    vector_service.setup_collection()
    app.vector_service = vector_service
    logger.info("VectorDBService initialized and Qdrant collection setup successfully.")
except Exception as e:
    logger.critical(f"Failed to initialize VectorDBService or setup Qdrant collection: {e}", exc_info=True)
    app.vector_service = None

# --- Initialize Neo4j Driver (via handler) ---
try:
    neo4j_handler.init_driver() # Initialize Neo4j driver on app start
except Exception as e:
    logger.critical(f"Neo4j driver failed to initialize on startup: {e}. KG endpoints will likely fail.")
    # Depending on how critical Neo4j is, you might sys.exit(1) here.

# Register Neo4j driver close function for app exit
atexit.register(neo4j_handler.close_driver)


# --- Helper for Error Responses ---
def create_error_response(message, status_code=500, details=None):
    log_message = f"API Error ({status_code}): {message}"
    if details:
        log_message += f" | Details: {details}"
    current_app.logger.error(log_message)
    response_payload = {"error": message}
    if details and status_code != 500:
        response_payload["details"] = details
    return jsonify(response_payload), status_code

# === API Endpoints ===

@app.route('/health', methods=['GET'])
def health_check():
    current_app.logger.info("--- Health Check Request ---")
    # ... (Qdrant health check part from your existing code) ...
    status_details = {
        "status": "error",
        "qdrant_service": "not_initialized",
        "qdrant_collection_name": config.QDRANT_COLLECTION_NAME,
        "qdrant_collection_status": "unknown",
        "document_embedding_model": config.DOCUMENT_EMBEDDING_MODEL_NAME,
        "query_embedding_model": config.QUERY_EMBEDDING_MODEL_NAME,
        "neo4j_service": "not_initialized_via_handler", # Updated message
        "neo4j_connection": "unknown"
    }
    http_status_code = 503

    # Qdrant Check
    if not vector_service:
        status_details["qdrant_service"] = "failed_to_initialize"
    else:
        status_details["qdrant_service"] = "initialized"
        try:
            vector_service.client.get_collection(collection_name=vector_service.collection_name)
            status_details["qdrant_collection_status"] = "exists_and_accessible"
        except Exception as e:
            status_details["qdrant_collection_status"] = f"error_accessing_collection: {str(e)}"
            current_app.logger.error(f"Health check: Error accessing Qdrant collection: {e}", exc_info=False)
    
    # Neo4j Check
    neo4j_ok, neo4j_conn_status = neo4j_handler.check_neo4j_connectivity()
    if neo4j_ok:
        status_details["neo4j_service"] = "initialized_via_handler"
        status_details["neo4j_connection"] = "connected"
    else:
        status_details["neo4j_service"] = "initialization_failed_or_handler_error"
        status_details["neo4j_connection"] = neo4j_conn_status


    if status_details["qdrant_service"] == "initialized" and \
       status_details["qdrant_collection_status"] == "exists_and_accessible" and \
       neo4j_ok: # Check the boolean return from neo4j_handler
        status_details["status"] = "ok"
        http_status_code = 200
        current_app.logger.info("Health check successful (Qdrant & Neo4j).")
    else:
        current_app.logger.warning(f"Health check issues found: Qdrant service: {status_details['qdrant_service']}, Qdrant collection: {status_details['qdrant_collection_status']}, Neo4j service: {status_details['neo4j_service']}, Neo4j connection: {status_details['neo4j_connection']}")
        
    return jsonify(status_details), http_status_code

@app.route('/add_document', methods=['POST'])
def add_document_qdrant():
    # ... (your existing /add_document endpoint logic)
    # This remains unchanged as it deals with Qdrant.
    current_app.logger.info("--- /add_document Request (Qdrant) ---")
    if not request.is_json:
        return create_error_response("Request must be JSON", 400)

    if not vector_service:
        return create_error_response("VectorDBService (Qdrant) is not available.", 503)

    data = request.get_json()
    user_id = data.get('user_id')
    file_path = data.get('file_path')
    original_name = data.get('original_name')

    if not all([user_id, file_path, original_name]):
        return create_error_response("Missing required fields: user_id, file_path, original_name", 400)

    current_app.logger.info(f"Processing file: '{original_name}' (Path: '{file_path}') for user: '{user_id}' for Qdrant")

    if not os.path.exists(file_path):
        current_app.logger.error(f"File not found at server path: {file_path}")
        return create_error_response(f"File not found at server path: {file_path}", 404)

    try:
        current_app.logger.info(f"Calling ai_core to process document: '{original_name}' for Qdrant")
        # ai_core.process_document_for_qdrant returns: processed_chunks_with_embeddings, raw_text_for_node_analysis, chunks_with_metadata
        processed_chunks_with_embeddings, raw_text_for_node_analysis, chunks_with_metadata_for_kg = ai_core.process_document_for_qdrant(
            file_path=file_path,
            original_name=original_name,
            user_id=user_id
        )
        
        num_chunks_added_to_qdrant = 0
        processing_status = "processed_no_content_for_qdrant"

        if processed_chunks_with_embeddings:
            current_app.logger.info(f"ai_core generated {len(processed_chunks_with_embeddings)} chunks for '{original_name}'. Adding to Qdrant.")
            num_chunks_added_to_qdrant = app.vector_service.add_processed_chunks(processed_chunks_with_embeddings)
            if num_chunks_added_to_qdrant > 0:
                processing_status = "added_to_qdrant"
            else:
                processing_status = "processed_qdrant_chunks_not_added"
        elif raw_text_for_node_analysis:
             current_app.logger.info(f"ai_core produced no processable Qdrant chunks for '{original_name}', but raw text was extracted.")
             processing_status = "processed_for_analysis_only_no_qdrant"
        else:
            current_app.logger.warning(f"ai_core produced no Qdrant chunks and no raw text for '{original_name}'.")
            return jsonify({
                "message": f"Processed '{original_name}' but no content was extracted for Qdrant or analysis.",
                "status": "no_content_extracted",
                "filename": original_name,
                "user_id": user_id,
                "num_chunks_added_to_qdrant": 0,
                "raw_text_for_analysis": ""
            }), 200

        response_payload = {
            "message": f"Successfully processed '{original_name}' for Qdrant. Status: {processing_status}.",
            "status": "added",
            "filename": original_name,
            "user_id": user_id,
            "num_chunks_added_to_qdrant": num_chunks_added_to_qdrant,
            "raw_text_for_analysis": raw_text_for_node_analysis if raw_text_for_node_analysis is not None else "",
            "chunks_with_metadata": chunks_with_metadata_for_kg # Pass this to Node.js for KG worker
        }
        current_app.logger.info(f"Successfully processed '{original_name}' for Qdrant. Returning raw text and Qdrant status.")
        return jsonify(response_payload), 201

    except FileNotFoundError as e:
        current_app.logger.error(f"Add Document (Qdrant) Error for '{original_name}' - FileNotFoundError: {e}", exc_info=True)
        return create_error_response(f"File not found during Qdrant processing: {str(e)}", 404)
    except config.TESSERACT_ERROR:
        current_app.logger.critical(f"Add Document (Qdrant) Error for '{original_name}' - Tesseract (OCR) not found.")
        return create_error_response("OCR engine (Tesseract) not found or not configured correctly on the server.", 500)
    except ValueError as e:
        current_app.logger.error(f"Add Document (Qdrant) Error for '{original_name}' - ValueError: {e}", exc_info=True)
        return create_error_response(f"Configuration or data error for Qdrant: {str(e)}", 400)
    except Exception as e:
        current_app.logger.error(f"Add Document (Qdrant) Error for '{original_name}' - Unexpected Exception: {e}\n{traceback.format_exc()}", exc_info=True)
        return create_error_response(f"Failed to process document '{original_name}' for Qdrant due to an internal error.", 500)


@app.route('/query', methods=['POST'])
def search_qdrant_documents_and_get_kg(): # Renamed for clarity
    current_app.logger.info("--- /query Request (Qdrant Search + Optional KG Retrieval) ---")
    if not request.is_json:
        return create_error_response("Request must be JSON", 400)

    if not vector_service: # Assuming vector_service is your initialized VectorDBService instance
        return create_error_response("VectorDBService (Qdrant) is not available.", 503)
    
    data = request.get_json()
    current_app.logger.info(f"--- /query RAW REQUEST DATA: {data} ---") # Log raw request
    
    query_text = data.get('query')
    user_id_from_request = data.get('user_id')
    k = data.get('k', config.QDRANT_DEFAULT_SEARCH_K)
    filter_payload_from_request = data.get('filter') # This is the Qdrant filter from client
    documentContextName = data.get('documentContextName') # For specific document filtering
    use_kg_for_critical_thinking = data.get('use_kg_critical_thinking', False) 
    
    current_app.logger.info(f"KG Critical Thinking Requested: {use_kg_for_critical_thinking}")
    if documentContextName:
        current_app.logger.info(f"Document Context Name for filtering: '{documentContextName}'")
    if filter_payload_from_request:
        current_app.logger.info(f"Client-provided filter payload: {filter_payload_from_request}")


    # Check Neo4j driver availability ONLY if KG is requested
    if use_kg_for_critical_thinking:
        try:
            neo4j_handler.get_driver_instance() 
        except ConnectionError: 
            current_app.logger.error("Neo4j driver unavailable but KG was requested.")
            return create_error_response("Knowledge Graph service (Neo4j) is not available, but KG retrieval was requested.", 503)
        except Exception as e: 
            current_app.logger.error(f"Error checking Neo4j driver availability: {e}")
            return create_error_response(f"Error initializing Knowledge Graph service: {str(e)}", 503)


    if not query_text:
        return create_error_response("Missing 'query' field in request body", 400)
    if not user_id_from_request:
        return create_error_response("Missing 'user_id' field in request body", 400)

    try:
        k = int(k)
    except ValueError:
        return create_error_response("'k' must be an integer", 400)

    # --- Qdrant Filter Setup (Revised Logic) ---
    qdrant_filters = None 

    try:
        from qdrant_client import models as qdrant_models
    except ImportError:
        current_app.logger.error("qdrant_client library is not installed. Cannot build filters.")
        return create_error_response("Internal server error: Qdrant client library missing.", 500)

    must_conditions = [] # List to hold all conditions to be ANDed

    # 1. Add filter from `documentContextName` if provided
    if documentContextName:
        current_app.logger.info(f"Condition for documentContextName: '{documentContextName}' on field 'file_name' will be added to 'must' conditions.")
        must_conditions.append(qdrant_models.FieldCondition(
            key="file_name",  # IMPORTANT: This key MUST match the field name in your Qdrant payload
            match=qdrant_models.MatchValue(value=documentContextName)
        ))

    # 2. Add filters from `filter_payload_from_request` if provided
    #    (assuming it's a simple key-value dict for FieldConditions)
    if filter_payload_from_request and isinstance(filter_payload_from_request, dict):
        current_app.logger.info(f"Processing Qdrant filters from client payload (simple key-value): {filter_payload_from_request}")
        for key, value in filter_payload_from_request.items():
            if isinstance(key, str) and isinstance(value, (str, int, float, bool)):
                 current_app.logger.info(f"Condition for client filter: key='{key}', value='{value}' will be added to 'must' conditions.")
                 must_conditions.append(qdrant_models.FieldCondition(key=key, match=qdrant_models.MatchValue(value=value)))
            else:
                current_app.logger.warning(f"Skipping invalid client filter condition: key='{key}', value='{value}'. Key must be string, value must be primitive.")

    # 3. Construct the final qdrant_filters object if any conditions were added
    if must_conditions:
        qdrant_filters = qdrant_models.Filter(must=must_conditions)
        try:
            filter_dict_for_log = qdrant_filters.model_dump() # Try Pydantic V2 method
        except AttributeError:
            try:
                filter_dict_for_log = qdrant_filters.dict() # Try Pydantic V1 method
            except AttributeError:
                filter_dict_for_log = str(qdrant_filters) # Fallback
        current_app.logger.info(f"Final Qdrant filter to be applied: {filter_dict_for_log}")
    else:
        current_app.logger.info("No Qdrant filter explicitly provided or derived for this query.")
    
    current_app.logger.info(f"Performing Qdrant search for user '{user_id_from_request}', query (first 50): '{query_text[:50]}...' with k={k}")

    try:
        # 1. Perform Qdrant Search
        qdrant_retrieved_docs, formatted_context_snippet, qdrant_docs_map = vector_service.search_documents(
            query=query_text,
            k=k,
            filter_conditions=qdrant_filters # Pass the combined filters
        )

        # 2. Conditionally Prepare KG Retrieval based on Qdrant results
        knowledge_graphs_data = {} 
        
        if use_kg_for_critical_thinking and qdrant_retrieved_docs:
            current_app.logger.info("KG retrieval is ENABLED and Qdrant returned documents.")
            unique_doc_names_for_kg = set()
            for doc_obj in qdrant_retrieved_docs:
                doc_payload = doc_obj.payload if hasattr(doc_obj, 'payload') else doc_obj.metadata
                
                doc_name_for_kg = None
                if documentContextName: 
                    doc_name_for_kg = documentContextName
                else: 
                    doc_name_for_kg = doc_payload.get('documentName', doc_payload.get('original_name', doc_payload.get('file_name')))
                
                if doc_name_for_kg:
                    unique_doc_names_for_kg.add(doc_name_for_kg)
                else:
                    qdrant_doc_id = doc_obj.id if hasattr(doc_obj, 'id') else doc_payload.get('qdrant_id', 'N/A')
                    current_app.logger.warning(f"Qdrant doc payload missing document identifier for chunk ID {qdrant_doc_id}. Cannot fetch KG.")
            
            current_app.logger.info(f"Found {len(unique_doc_names_for_kg)} unique document(s) in Qdrant results to fetch KGs for: {list(unique_doc_names_for_kg)}")

            for doc_name in unique_doc_names_for_kg:
                try:
                    current_app.logger.info(f"Fetching KG for document '{doc_name}' (User: {user_id_from_request})")
                    kg_content = neo4j_handler.get_knowledge_graph(user_id_from_request, doc_name)
                    if kg_content and (kg_content.get("nodes") or kg_content.get("edges")): 
                        knowledge_graphs_data[doc_name] = kg_content
                        current_app.logger.info(f"Successfully retrieved KG for '{doc_name}'. Nodes: {len(kg_content.get('nodes',[]))}, Edges: {len(kg_content.get('edges',[]))}")
                    else:
                        current_app.logger.info(f"No KG data found in Neo4j for document '{doc_name}' (User: {user_id_from_request}).")
                        knowledge_graphs_data[doc_name] = {"nodes": [], "edges": [], "message": "KG not found or contains no data"}
                except Exception as kg_err: 
                    current_app.logger.error(f"Error retrieving KG for document '{doc_name}': {kg_err}", exc_info=True)
                    knowledge_graphs_data[doc_name] = {"nodes": [], "edges": [], "error": f"Failed to retrieve KG: {str(kg_err)}"}
        elif not use_kg_for_critical_thinking:
            current_app.logger.info("KG retrieval is DISABLED by request.")
        elif not qdrant_retrieved_docs:
            current_app.logger.info("KG retrieval was requested, but no documents were found by Qdrant. Skipping KG fetch.")


        # 3. Construct Final Response Payload
        response_payload = {
            "query": query_text,
            "k_requested": k,
            "user_id_processed": user_id_from_request,
            "qdrant_filter_applied": { 
                "client_filter": filter_payload_from_request, # What was received
                "document_context_filter": documentContextName # What was received
            },
            "qdrant_results_count": len(qdrant_retrieved_docs),
            "formatted_context_snippet": formatted_context_snippet,
            "retrieved_documents_map": qdrant_docs_map,
            "retrieved_documents_list": [doc.to_dict() for doc in qdrant_retrieved_docs],
            "knowledge_graphs": knowledge_graphs_data, 
            "kg_retrieval_attempted": use_kg_for_critical_thinking and bool(qdrant_retrieved_docs)
        }
        
        log_message_kg_part = "and KGs" if use_kg_for_critical_thinking and any(v.get("nodes") or v.get("edges") for v in knowledge_graphs_data.values() if isinstance(v,dict)) else ("and KG retrieval was SKIPPED" if not use_kg_for_critical_thinking else "and no KGs found/retrieved")
        current_app.logger.info(f"Qdrant search {log_message_kg_part} successful. Returning {len(qdrant_retrieved_docs)} Qdrant docs.")
        return jsonify(response_payload), 200

    except ConnectionError as ce:
        current_app.logger.error(f"Service connection error during /query processing: {ce}", exc_info=True)
        return create_error_response(f"A dependent service is unavailable: {str(ce)}", 503)
    except Exception as e:
        # import traceback # Ensure traceback is imported if you use .format_exc()
        current_app.logger.error(f"/query processing failed: {e}\n{traceback.format_exc()}", exc_info=True)
        return create_error_response(f"Error during query processing: {str(e)}", 500)



@app.route('/delete_qdrant_document_data', methods=['DELETE']) # Ensure this route is defined
def delete_qdrant_data_route():
    current_app.logger.info("--- DELETE /delete_qdrant_document_data Request ---")
    if not request.is_json:
        return create_error_response("Request must be JSON", 400)

    if not vector_service:
        return create_error_response("VectorDBService (Qdrant) is not available.", 503)

    data = request.get_json()
    user_id = data.get('user_id')
    document_name = data.get('document_name') 

    if not user_id or not document_name:
        return create_error_response("Missing 'user_id' or 'document_name' in request body.", 400)

    try:
        # This assumes you have a method 'delete_document_vectors' in your vector_service
        result = vector_service.delete_document_vectors(user_id, document_name) 
        
        if result.get("success"):
            return jsonify({"message": result.get("message", "Qdrant vectors for document processed for deletion.")}), 200
        else:
            return create_error_response(result.get("message", "Failed to delete Qdrant vectors."), 500) # Or a more specific code
            
    except ConnectionError as ce:
        current_app.logger.error(f"Qdrant connection error during /delete_qdrant_document_data for user {user_id}, doc {document_name}: {ce}", exc_info=True)
        return create_error_response(f"Qdrant service connection error: {str(ce)}", 503)
    except Exception as e:
        current_app.logger.error(f"/delete_qdrant_document_data for user {user_id}, doc {document_name} failed: {e}", exc_info=True)
        return create_error_response(f"Error during Qdrant data deletion: {str(e)}", 500)

# === KG (Neo4j) Endpoints ===

@app.route('/kg', methods=['POST'])
def add_or_update_kg_route():
    current_app.logger.info("--- POST /kg Request (Neo4j Ingestion) ---")
    if not request.is_json:
        return create_error_response("Request must be JSON", 400)

    data = request.get_json()
    user_id = data.get('userId') # Key from Node.js
    original_name = data.get('originalName') # Key from Node.js
    nodes = data.get('nodes')
    edges = data.get('edges')

    if not all([user_id, original_name, isinstance(nodes, list), isinstance(edges, list)]):
        missing_fields = []
        if not user_id: missing_fields.append("userId")
        if not original_name: missing_fields.append("originalName")
        if not isinstance(nodes, list): missing_fields.append("nodes (must be a list)")
        if not isinstance(edges, list): missing_fields.append("edges (must be a list)")
        return create_error_response(f"Missing or invalid fields: {', '.join(missing_fields)}", 400,
                                     details=f"Received: userId type {type(user_id)}, originalName type {type(original_name)}, nodes type {type(nodes)}, edges type {type(edges)}")

    logger.info(f"Attempting to ingest KG for user '{user_id}', document '{original_name}'. Nodes: {len(nodes)}, Edges: {len(edges)}")

    try:
        result = neo4j_handler.ingest_knowledge_graph(user_id, original_name, nodes, edges)
        if result["success"]:
            return jsonify({
                "message": result["message"],
                "userId": user_id,
                "documentName": original_name, # Consistent key name
                "nodes_affected": result["nodes_affected"],
                "edges_affected": result["edges_affected"],
                "status": "completed" # Status field as expected by Node.js
            }), 201
        else: # Should not happen if ingest_knowledge_graph raises on error
            return create_error_response(result.get("message", "KG ingestion failed."), 500)
            
    except ConnectionError as e:
        logger.error(f"Neo4j connection error during KG ingestion for '{original_name}': {e}", exc_info=True)
        return create_error_response(f"Neo4j connection error: {str(e)}. Please check service.", 503)
    except neo4j_exceptions.Neo4jError as e:
        logger.error(f"Neo4jError during KG ingestion for '{original_name}': {e}", exc_info=True)
        return create_error_response(f"Neo4j database error: {e.message}", 500)
    except Exception as e:
        logger.error(f"Unexpected error during KG ingestion for '{original_name}': {e}\n{traceback.format_exc()}", exc_info=True)
        return create_error_response(f"Failed to ingest Knowledge Graph: {str(e)}", 500)


@app.route('/kg/<user_id>/<path:document_name>', methods=['GET']) # Use <path:document_name> to allow slashes
def get_kg_route(user_id, document_name):
    current_app.logger.info(f"--- GET /kg/{user_id}/{document_name} Request (Neo4j Retrieval) ---")

    # Basic sanitization (you might want more robust URL segment sanitization if needed)
    sanitized_user_id = user_id.replace("..","").strip()
    sanitized_document_name = document_name.replace("..","").strip()

    if not sanitized_user_id or not sanitized_document_name:
        return create_error_response("User ID and Document Name URL parameters are required and cannot be empty.", 400)

    logger.info(f"Retrieving KG for user '{sanitized_user_id}', document '{sanitized_document_name}'.")

    try:
        kg_data = neo4j_handler.get_knowledge_graph(sanitized_user_id, sanitized_document_name)

        if kg_data is None: # Handler returns None if not found
            logger.info(f"No KG data found for user '{sanitized_user_id}', document '{sanitized_document_name}'.")
            return create_error_response("Knowledge Graph not found for the specified user and document.", 404)

        logger.info(f"Successfully retrieved KG for document '{sanitized_document_name}'. Nodes: {len(kg_data.get('nodes',[]))}, Edges: {len(kg_data.get('edges',[]))}")
        return jsonify(kg_data), 200

    except ConnectionError as e:
        logger.error(f"Neo4j connection error during KG retrieval: {e}", exc_info=True)
        return create_error_response(f"Neo4j connection error: {str(e)}. Please check service.", 503)
    except neo4j_exceptions.Neo4jError as e:
        logger.error(f"Neo4jError during KG retrieval: {e}", exc_info=True)
        return create_error_response(f"Neo4j database error: {e.message}", 500)
    except Exception as e:
        logger.error(f"Unexpected error during KG retrieval: {e}\n{traceback.format_exc()}", exc_info=True)
        return create_error_response(f"Failed to retrieve Knowledge Graph: {str(e)}", 500)


@app.route('/kg/<user_id>/<path:document_name>', methods=['DELETE']) # Use <path:document_name>
def delete_kg_route(user_id, document_name):
    current_app.logger.info(f"--- DELETE /kg/{user_id}/{document_name} Request (Neo4j Deletion) ---")

    sanitized_user_id = user_id.replace("..","").strip()
    sanitized_document_name = document_name.replace("..","").strip()

    if not sanitized_user_id or not sanitized_document_name:
        return create_error_response("User ID and Document Name URL parameters are required and cannot be empty.", 400)

    logger.info(f"Attempting to delete KG for user '{sanitized_user_id}', document '{sanitized_document_name}'.")

    try:
        deleted = neo4j_handler.delete_knowledge_graph(sanitized_user_id, sanitized_document_name)
        if deleted:
            logger.info(f"Knowledge Graph for document '{sanitized_document_name}' (User: {sanitized_user_id}) deleted successfully.")
            return jsonify({"message": "Knowledge Graph deleted successfully."}), 200
        else:
            logger.info(f"No Knowledge Graph found for document '{sanitized_document_name}' (User: {sanitized_user_id}) to delete.")
            return create_error_response("Knowledge Graph not found for deletion.", 404)

    except ConnectionError as e:
        logger.error(f"Neo4j connection error during KG deletion: {e}", exc_info=True)
        return create_error_response(f"Neo4j connection error: {str(e)}. Please check service.", 503)
    except neo4j_exceptions.Neo4jError as e:
        logger.error(f"Neo4jError during KG deletion: {e}", exc_info=True)
        return create_error_response(f"Neo4j database error: {e.message}", 500)
    except Exception as e:
        logger.error(f"Unexpected error during KG deletion: {e}\n{traceback.format_exc()}", exc_info=True)
        return create_error_response(f"Failed to delete Knowledge Graph: {str(e)}", 500)


if __name__ == '__main__':
    logger.info(f"--- Starting RAG API Service (with KG) on port {config.API_PORT} ---")
    logger.info(f"Qdrant Host: {config.QDRANT_HOST}, Port: {config.QDRANT_PORT}, Collection: {config.QDRANT_COLLECTION_NAME}")
    logger.info(f"Neo4j URI: {config.NEO4J_URI}, User: {config.NEO4J_USERNAME}, DB: {config.NEO4J_DATABASE}")
    logger.info(f"Document Embedding Model (ai_core): {config.DOCUMENT_EMBEDDING_MODEL_NAME} (Dim: {config.DOCUMENT_VECTOR_DIMENSION})")
    logger.info(f"Query Embedding Model (vector_db_service): {config.QUERY_EMBEDDING_MODEL_NAME} (Dim: {config.QUERY_VECTOR_DIMENSION})")
    
    app.run(host='0.0.0.0', port=config.API_PORT, debug=True) # debug=True for development
```

`server/rag_service/config.py`

```python
# server/config.py
import os
import logging

#  Logging Configuration 
logger = logging.getLogger(__name__)
LOGGING_LEVEL_NAME = os.getenv('LOGGING_LEVEL', 'INFO').upper()
LOGGING_LEVEL      = getattr(logging, LOGGING_LEVEL_NAME, logging.INFO)
LOGGING_FORMAT     = '%(asctime)s - %(levelname)s - [%(name)s:%(lineno)d] - %(message)s'

# === Base Directory ===
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
logger.info(f"[Config] Base Directory: {BASE_DIR}")



def setup_logging():
    """Configure logging across the app."""
    root_logger = logging.getLogger()
    if not root_logger.handlers:  # prevent duplicate handlers
        handler = logging.StreamHandler()
        formatter = logging.Formatter(LOGGING_FORMAT)
        handler.setFormatter(formatter)
        root_logger.addHandler(handler)
        root_logger.setLevel(LOGGING_LEVEL)

    logging.getLogger("urllib3").setLevel(logging.WARNING)
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logging.getLogger("faiss.loader").setLevel(logging.WARNING)
    logging.getLogger(__name__).info(f"Logging initialized at {LOGGING_LEVEL_NAME}")

NEO4J_URI = os.getenv("NEO4J_URI", "bolt://localhost:7687")
NEO4J_USERNAME = os.getenv("NEO4J_USERNAME", "neo4j")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD", "password") # IMPORTANT: Change this default or use ENV VAR!
NEO4J_DATABASE = os.getenv("NEO4J_DATABASE", "neo4j")
# === Embedding Model Configuration ===
DEFAULT_DOC_EMBED_MODEL = 'mixedbread-ai/mxbai-embed-large-v1'
DOCUMENT_EMBEDDING_MODEL_NAME = os.getenv('DOCUMENT_EMBEDDING_MODEL_NAME', DEFAULT_DOC_EMBED_MODEL)
MAX_TEXT_LENGTH_FOR_NER = int(os.getenv("MAX_TEXT_LENGTH_FOR_NER", 500000))
logger.info(f"[Config] Document Embedding Model: {DOCUMENT_EMBEDDING_MODEL_NAME}")

# Model dimension mapping
_MODEL_TO_DIM_MAPPING = {
    'mixedbread-ai/mxbai-embed-large-v1': 1024,
    'BAAI/bge-large-en-v1.5': 1024,
    'all-MiniLM-L6-v2': 384,
    'sentence-transformers/all-mpnet-base-v2': 768,
}
_FALLBACK_DIM = 768

DOCUMENT_VECTOR_DIMENSION = int(os.getenv(
    "DOCUMENT_VECTOR_DIMENSION",
    _MODEL_TO_DIM_MAPPING.get(DOCUMENT_EMBEDDING_MODEL_NAME, _FALLBACK_DIM)
))
logger.info(f"[Config] Document Vector Dimension: {DOCUMENT_VECTOR_DIMENSION}")

# === AI Core Chunking Config ===
AI_CORE_CHUNK_SIZE = int(os.getenv("AI_CORE_CHUNK_SIZE", 512))
AI_CORE_CHUNK_OVERLAP = int(os.getenv("AI_CORE_CHUNK_OVERLAP", 100))
logger.info(f"[Config] Chunk Size: {AI_CORE_CHUNK_SIZE}, Overlap: {AI_CORE_CHUNK_OVERLAP}")

# === SpaCy Configuration ===
SPACY_MODEL_NAME = os.getenv('SPACY_MODEL_NAME', 'en_core_web_sm')
logger.info(f"[Config] SpaCy Model: {SPACY_MODEL_NAME}")

# === Qdrant Configuration ===
QDRANT_HOST = os.getenv("QDRANT_HOST", "localhost")
QDRANT_PORT = int(os.getenv("QDRANT_PORT", 6333))
QDRANT_COLLECTION_NAME = os.getenv("QDRANT_COLLECTION_NAME", "my_qdrant_rag_collection")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY", None)
QDRANT_URL = os.getenv("QDRANT_URL", None)

QDRANT_COLLECTION_VECTOR_DIM = DOCUMENT_VECTOR_DIMENSION
logger.info(f"[Config] Qdrant Vector Dimension: {QDRANT_COLLECTION_VECTOR_DIM}")

# === Query Embedding Configuration ===
QUERY_EMBEDDING_MODEL_NAME = os.getenv("QUERY_EMBEDDING_MODEL_NAME", DOCUMENT_EMBEDDING_MODEL_NAME)
QUERY_VECTOR_DIMENSION = int(os.getenv(
    "QUERY_VECTOR_DIMENSION",
    _MODEL_TO_DIM_MAPPING.get(QUERY_EMBEDDING_MODEL_NAME, _FALLBACK_DIM)
))

if QUERY_VECTOR_DIMENSION != QDRANT_COLLECTION_VECTOR_DIM:
    logger.info(f"[ Config Warning] Query vector dim ({QUERY_VECTOR_DIMENSION}) != Qdrant dim ({QDRANT_COLLECTION_VECTOR_DIM})")
    # Optionally enforce consistency
    # raise ValueError("Query and Document vector dimensions do not match!")
else:
    logger.info(f"[Config] Query Model: {QUERY_EMBEDDING_MODEL_NAME}")
    logger.info(f"[Config] Query Vector Dimension: {QUERY_VECTOR_DIMENSION}")

QDRANT_DEFAULT_SEARCH_K = int(os.getenv("QDRANT_DEFAULT_SEARCH_K", 5))
QDRANT_SEARCH_MIN_RELEVANCE_SCORE = float(os.getenv("QDRANT_SEARCH_MIN_RELEVANCE_SCORE", 0.1))

# === API Port Configuration ===
API_PORT = int(os.getenv('API_PORT', 5000))
logger.info(f"[Config] API Running Port: {API_PORT}")

# === Optional: Tesseract OCR Path (uncomment if used) ===
# TESSERACT_CMD = os.getenv('TESSERACT_CMD')
# if TESSERACT_CMD:
#     import pytesseract
#     pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD
#     logger.info(f"[Config] Tesseract Path: {TESSERACT_CMD}")


#  Library Availability Flags 
try:
    import pypdf
    PYPDF_AVAILABLE      = True
    PYPDF_PDFREADERROR   = pypdf.errors.PdfReadError
except ImportError:
    PYPDF_AVAILABLE      = False
    PYPDF_PDFREADERROR   = Exception

try:
    from docx import Document as DocxDocument
    DOCX_AVAILABLE       = True
except ImportError:
    DOCX_AVAILABLE       = False
    DocxDocument         = None

try:
    from pptx import Presentation
    PPTX_AVAILABLE       = True
except ImportError:
    PPTX_AVAILABLE       = False
    Presentation         = None

try:
    import pdfplumber
    PDFPLUMBER_AVAILABLE = True
except ImportError:
    PDFPLUMBER_AVAILABLE = False
    pdfplumber           = None

try:
    import pandas as pd
    PANDAS_AVAILABLE     = True
except ImportError:
    PANDAS_AVAILABLE     = False
    pd                   = None

try:
    from PIL import Image
    PIL_AVAILABLE        = True
except ImportError:
    PIL_AVAILABLE        = False
    Image                = None

try:
    import fitz
    FITZ_AVAILABLE       = True
except ImportError:
    FITZ_AVAILABLE       = False
    fitz                 = None

try:
    import pytesseract
    PYTESSERACT_AVAILABLE = True
    TESSERACT_ERROR       = pytesseract.TesseractNotFoundError
except ImportError:
    PYTESSERACT_AVAILABLE = False
    pytesseract           = None
    TESSERACT_ERROR       = Exception

try:
    import PyPDF2
    PYPDF2_AVAILABLE      = True
except ImportError:
    PYPDF2_AVAILABLE      = False
    PyPDF2                = None

#  Optional: Preload SpaCy & Embedding Model 

TESSERACT_CMD = os.getenv('TESSERACT_CMD', r'C:\Program Files\Tesseract-OCR\tesseract.exe')

if PYTESSERACT_AVAILABLE and pytesseract:
    pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD
    logger.info(f"[Config] Tesseract Path set to: {TESSERACT_CMD}")

try:
    import spacy
    SPACY_LIB_AVAILABLE = True
    nlp_spacy_core      = spacy.load(SPACY_MODEL_NAME)
    SPACY_MODEL_LOADED  = True
except Exception as e:
    SPACY_LIB_AVAILABLE = False
    nlp_spacy_core      = None
    SPACY_MODEL_LOADED  = False
    logger.warning(f"Failed to load SpaCy model '{SPACY_MODEL_NAME}': {e}")

try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_LIB_AVAILABLE = True
    document_embedding_model = SentenceTransformer(DOCUMENT_EMBEDDING_MODEL_NAME)
    EMBEDDING_MODEL_LOADED = True
except Exception as e:
    SENTENCE_TRANSFORMERS_LIB_AVAILABLE = False
    document_embedding_model = None
    EMBEDDING_MODEL_LOADED = False
    logger.warning(f"Failed to load Sentence transformers: {e}")

try:
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    LANGCHAIN_SPLITTER_AVAILABLE = True
except ImportError:
    LANGCHAIN_SPLITTER_AVAILABLE = False
    RecursiveCharacterTextSplitter = None # Placeholder
```

`server/rag_service/file_parser.py`

```python
# server/rag_service/file_parser.py
import os
try:
    import pypdf
except ImportError:
    print("pypdf not found, PDF parsing will fail. Install with: pip install pypdf")
    pypdf = None # Set to None if not installed

try:
    from docx import Document as DocxDocument
except ImportError:
    print("python-docx not found, DOCX parsing will fail. Install with: pip install python-docx")
    DocxDocument = None

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.documents import Document as LangchainDocument
from rag_service import config # Import from package
import logging

# Configure logger for this module
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO) # Or DEBUG for more details
handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
if not logger.hasHandlers():
    logger.addHandler(handler)


def parse_pdf(file_path):
    """Extracts text content from a PDF file using pypdf."""
    if not pypdf: return None # Check if library loaded
    text = ""
    try:
        reader = pypdf.PdfReader(file_path)
        num_pages = len(reader.pages)
        # logger.debug(f"Reading {num_pages} pages from PDF: {os.path.basename(file_path)}")
        for i, page in enumerate(reader.pages):
            try:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n" # Add newline between pages
            except Exception as page_err:
                 logger.warning(f"Error extracting text from page {i+1} of {os.path.basename(file_path)}: {page_err}")
        # logger.debug(f"Extracted {len(text)} characters from PDF.")
        return text.strip() if text.strip() else None # Return None if empty after stripping
    except FileNotFoundError:
        logger.error(f"PDF file not found: {file_path}")
        return None
    except pypdf.errors.PdfReadError as pdf_err:
        logger.error(f"Error reading PDF {os.path.basename(file_path)} (possibly corrupted or encrypted): {pdf_err}")
        return None
    except Exception as e:
        logger.error(f"Unexpected error parsing PDF {os.path.basename(file_path)}: {e}", exc_info=True)
        return None

def parse_docx(file_path):
    """Extracts text content from a DOCX file."""
    if not DocxDocument: return None # Check if library loaded
    try:
        doc = DocxDocument(file_path)
        text = "\n".join([para.text for para in doc.paragraphs if para.text.strip()])
        # logger.debug(f"Extracted {len(text)} characters from DOCX.")
        return text.strip() if text.strip() else None
    except Exception as e:
        logger.error(f"Error parsing DOCX {os.path.basename(file_path)}: {e}", exc_info=True)
        return None

def parse_txt(file_path):
    """Reads text content from a TXT file (or similar plain text like .py, .js)."""
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            text = f.read()
        # logger.debug(f"Read {len(text)} characters from TXT file.")
        return text.strip() if text.strip() else None
    except Exception as e:
        logger.error(f"Error parsing TXT {os.path.basename(file_path)}: {e}", exc_info=True)
        return None

# Add PPTX parsing (requires python-pptx)
try:
    from pptx import Presentation
    PPTX_SUPPORTED = True
    def parse_pptx(file_path):
        """Extracts text content from a PPTX file."""
        text = ""
        try:
            prs = Presentation(file_path)
            for slide in prs.slides:
                for shape in slide.shapes:
                    if hasattr(shape, "text"):
                        shape_text = shape.text.strip()
                        if shape_text:
                            text += shape_text + "\n" # Add newline between shape texts
            # logger.debug(f"Extracted {len(text)} characters from PPTX.")
            return text.strip() if text.strip() else None
        except Exception as e:
            logger.error(f"Error parsing PPTX {os.path.basename(file_path)}: {e}", exc_info=True)
            return None
except ImportError:
    PPTX_SUPPORTED = False
    logger.warning("python-pptx not installed. PPTX parsing will be skipped.")
    def parse_pptx(file_path):
        logger.warning(f"Skipping PPTX file {os.path.basename(file_path)} as python-pptx is not installed.")
        return None


def parse_file(file_path):
    """Parses a file based on its extension, returning text content or None."""
    _, ext = os.path.splitext(file_path)
    ext = ext.lower()
    logger.debug(f"Attempting to parse file: {os.path.basename(file_path)} (Extension: {ext})")

    if ext == '.pdf':
        return parse_pdf(file_path)
    elif ext == '.docx':
        return parse_docx(file_path)
    elif ext == '.pptx':
        return parse_pptx(file_path) # Use the conditional function
    elif ext in ['.txt', '.py', '.js', '.md', '.log', '.csv', '.html', '.xml', '.json']: # Expand text-like types
        return parse_txt(file_path)
    # Add other parsers here if needed (e.g., for .doc, .xls)
    elif ext == '.doc':
        # Requires antiword or similar external tool, more complex
        logger.warning(f"Parsing for legacy .doc files is not implemented: {os.path.basename(file_path)}")
        return None
    else:
        logger.warning(f"Unsupported file extension for parsing: {ext} ({os.path.basename(file_path)})")
        return None

def chunk_text(text, file_name, user_id):
    """Chunks text and creates Langchain Documents with metadata."""
    if not text or not isinstance(text, str):
        logger.warning(f"Invalid text input for chunking (file: {file_name}). Skipping.")
        return []

    # Use splitter configured in config.py
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=config.CHUNK_SIZE,
        chunk_overlap=config.CHUNK_OVERLAP,
        length_function=len,
        is_separator_regex=False, # Use default separators
        # separators=["\n\n", "\n", " ", ""] # Default separators
    )

    try:
        chunks = text_splitter.split_text(text)
        if not chunks:
             logger.warning(f"Text splitting resulted in zero chunks for file: {file_name}")
             return []

        documents = []
        for i, chunk in enumerate(chunks):
             # Ensure chunk is not just whitespace before creating Document
             if chunk and chunk.strip():
                 documents.append(
                     LangchainDocument(
                         page_content=chunk,
                         metadata={
                             'userId': user_id, # Store user ID
                             'documentName': file_name, # Store original filename
                             'chunkIndex': i # Store chunk index for reference
                         }
                     )
                 )
        if documents:
            logger.info(f"Split '{file_name}' into {len(documents)} non-empty chunks.")
        else:
            logger.warning(f"No non-empty chunks created for file: {file_name} after splitting.")
        return documents
    except Exception as e:
        logger.error(f"Error during text splitting for file {file_name}: {e}", exc_info=True)
        return [] # Return empty list on error

```

`server/rag_service/neo4j_handler.py`

```python
# server/rag_service/neo4j_handler.py

import logging
from neo4j import GraphDatabase, exceptions as neo4j_exceptions
import config # Assumes config.py is in the same directory or python path is set correctly

logger = logging.getLogger(__name__)

# --- Neo4j Driver Management ---
_neo4j_driver = None

def init_driver():
    """Initializes the Neo4j driver instance."""
    global _neo4j_driver
    if _neo4j_driver is not None:
        try: # Check if existing driver is still connected
            _neo4j_driver.verify_connectivity()
            logger.info("Neo4j driver already initialized and connected.")
            return
        except Exception:
            logger.warning("Existing Neo4j driver lost connection or failed verification. Re-initializing.")
            if _neo4j_driver:
                _neo4j_driver.close()
            _neo4j_driver = None # Force re-initialization

    try:
        _neo4j_driver = GraphDatabase.driver(
            config.NEO4J_URI,
            auth=(config.NEO4J_USERNAME, config.NEO4J_PASSWORD)
        )
        _neo4j_driver.verify_connectivity()
        logger.info(f"Neo4j driver initialized. Connected to: {config.NEO4J_URI} (DB: {config.NEO4J_DATABASE})")
    except neo4j_exceptions.ServiceUnavailable:
        logger.critical(f"Failed to connect to Neo4j at {config.NEO4J_URI}. Ensure Neo4j is running and accessible.")
        _neo4j_driver = None
    except neo4j_exceptions.AuthError:
        logger.critical(f"Neo4j authentication failed for user '{config.NEO4J_USERNAME}'. Check credentials.")
        _neo4j_driver = None
    except Exception as e:
        logger.critical(f"An unexpected error occurred while initializing Neo4j driver: {e}", exc_info=True)
        _neo4j_driver = None

def get_driver_instance():
    """Returns the active Neo4j driver instance, initializing if necessary."""
    if _neo4j_driver is None:
        init_driver()
    if _neo4j_driver is None: # Check again after trying to init
        raise ConnectionError("Neo4j driver is not available. Initialization failed.")
    return _neo4j_driver

def close_driver():
    """Closes the Neo4j driver instance if it exists."""
    global _neo4j_driver
    if _neo4j_driver:
        _neo4j_driver.close()
        _neo4j_driver = None
        logger.info("Neo4j driver closed.")

def check_neo4j_connectivity():
    """Checks if the Neo4j driver can connect."""
    try:
        driver = get_driver_instance() # This will try to init if not already
        driver.verify_connectivity()
        return True, "connected"
    except Exception as e:
        logger.warning(f"Neo4j connectivity check failed: {str(e)}")
        return False, f"disconnected_or_error: {str(e)}"

# --- Private Transaction Helper Functions ---
def _execute_read_tx(tx_function, *args, **kwargs):
    driver = get_driver_instance()
    with driver.session(database=config.NEO4J_DATABASE) as session:
        return session.execute_read(tx_function, *args, **kwargs)

def _execute_write_tx(tx_function, *args, **kwargs):
    driver = get_driver_instance()
    with driver.session(database=config.NEO4J_DATABASE) as session:
        return session.execute_write(tx_function, *args, **kwargs)

# --- Private Transactional Cypher Functions ---
def _delete_kg_transactional(tx, user_id, document_name):
    logger.info(f"Neo4j TX: Deleting KG for user '{user_id}', document '{document_name}'")
    query = (
        "MATCH (n:KnowledgeNode {userId: $userId, documentName: $documentName}) "
        "DETACH DELETE n"
    )
    result = tx.run(query, userId=user_id, documentName=document_name)
    summary = result.consume()
    deleted_count = summary.counters.nodes_deleted + summary.counters.relationships_deleted
    logger.info(f"Neo4j TX: Deleted {summary.counters.nodes_deleted} nodes and {summary.counters.relationships_deleted} relationships for '{document_name}'.")
    return deleted_count > 0

def _add_nodes_transactional(tx, nodes_param, user_id, document_name):
    logger.info(f"Neo4j TX: Adding/merging {len(nodes_param)} nodes for user '{user_id}', document '{document_name}'")
    # Ensure nodes have a type, default to "concept" if not provided
    # And llm_parent_id for parent from LLM's perspective
    processed_nodes = []
    for node_data in nodes_param:
        # Ensure ID is a string and not empty
        if not isinstance(node_data.get("id"), str) or not node_data.get("id").strip():
            logger.warning(f"Skipping node with invalid or missing ID: {node_data}")
            continue
        
        processed_node = {
            "id": node_data["id"].strip(), # Use the LLM's 'id' as 'nodeId'
            "type": node_data.get("type", "concept"), # Default type
            "description": node_data.get("description", ""),
            "llm_parent_id": node_data.get("parent", None) # Store the 'parent' from LLM
        }
        processed_nodes.append(processed_node)

    if not processed_nodes:
        logger.warning("No valid nodes to process after filtering.")
        return 0

    query = (
        "UNWIND $nodes_data as node_props "
        "MERGE (n:KnowledgeNode {nodeId: node_props.id, userId: $userId, documentName: $documentName}) "
        "ON CREATE SET n.type = node_props.type, "
        "              n.description = node_props.description, "
        "              n.llm_parent_id = node_props.llm_parent_id, "
        "              n.userId = $userId, " # Ensure userId is set on create
        "              n.documentName = $documentName " # Ensure documentName is set on create
        "ON MATCH SET n.type = node_props.type, " # Update existing nodes too
        "             n.description = node_props.description, "
        "             n.llm_parent_id = node_props.llm_parent_id "
        "RETURN count(n) as nodes_affected"
    )
    result = tx.run(query, nodes_data=processed_nodes, userId=user_id, documentName=document_name)
    count = result.single()[0] if result.peek() else 0
    logger.info(f"Neo4j TX: Affected (created or merged) {count} nodes for '{document_name}'.")
    return count

def _add_edges_transactional(tx, edges_param, user_id, document_name):
    logger.info(f"Neo4j TX: Adding/merging {len(edges_param)} edges for user '{user_id}', document '{document_name}'")
    if not edges_param:
        logger.info("Neo4j TX: No edges provided to add.")
        return 0
        
    # Filter out invalid edges
    valid_edges = []
    for edge_data in edges_param:
        if not (isinstance(edge_data.get("from"), str) and edge_data.get("from").strip() and
                isinstance(edge_data.get("to"), str) and edge_data.get("to").strip() and
                isinstance(edge_data.get("relationship"), str) and edge_data.get("relationship").strip()):
            logger.warning(f"Skipping invalid edge data: {edge_data}")
            continue
        valid_edges.append({
            "from": edge_data["from"].strip(),
            "to": edge_data["to"].strip(),
            "relationship": edge_data["relationship"].strip().upper().replace(" ", "_") # Sanitize relationship type
        })

    if not valid_edges:
        logger.warning("No valid edges to process after filtering.")
        return 0

    # Cypher query to create relationships. Note: relationship type is dynamic using brackets.
    # We use MERGE to avoid duplicate relationships with the same type between the same nodes.
    # Relationship properties are set using SET.
    query = (
        "UNWIND $edges_data as edge_props "
        "MATCH (startNode:KnowledgeNode {nodeId: edge_props.from, userId: $userId, documentName: $documentName}) "
        "MATCH (endNode:KnowledgeNode {nodeId: edge_props.to, userId: $userId, documentName: $documentName}) "
        "CALL apoc.merge.relationship(startNode, edge_props.relationship, {}, {type: edge_props.relationship}, endNode) YIELD rel "
        # MERGE (startNode)-[r:HAS_RELATIONSHIP]->(endNode) " # Simpler, but cannot set type dynamically easily.
        # "SET r.type = edge_props.relationship "
        "RETURN count(rel) as edges_affected"
    )
    # Note: The above MERGE using apoc.merge.relationship is more robust for dynamic relationship types.
    # If APOC is not available, a simpler MERGE (startNode)-[r:REL {type:edge_props.relationship}]->(endNode) would work.
    # Or create relationships with a generic type like :RELATED_TO and store the specific type as a property.
    # For this example, assuming APOC for dynamic relationship types. If not, adjust the query.
    # Simpler, if APOC is not available (relationship type becomes a property of a generic :RELATED_TO relationship):
    simple_query = (
        "UNWIND $edges_data as edge_props "
        "MATCH (startNode:KnowledgeNode {nodeId: edge_props.from, userId: $userId, documentName: $documentName}) "
        "MATCH (endNode:KnowledgeNode {nodeId: edge_props.to, userId: $userId, documentName: $documentName}) "
        "MERGE (startNode)-[r:RELATED_TO {type: edge_props.relationship}]->(endNode) "
        "RETURN count(r) as edges_affected"
    )
    # Let's use the simpler query for broader compatibility without APOC.
    
    result = tx.run(simple_query, edges_data=valid_edges, userId=user_id, documentName=document_name)
    count = result.single()[0] if result.peek() else 0
    logger.info(f"Neo4j TX: Affected (created or merged) {count} relationships for '{document_name}'.")
    return count

def _get_kg_transactional(tx, user_id, document_name):
    logger.info(f"Neo4j TX: Retrieving KG for user '{user_id}', document '{document_name}'")
    nodes_query = (
        "MATCH (n:KnowledgeNode {userId: $userId, documentName: $documentName}) "
        "RETURN n.nodeId AS id, n.type AS type, n.description AS description, n.llm_parent_id AS parent"
    )
    nodes_result = tx.run(nodes_query, userId=user_id, documentName=document_name)
    # Convert Neo4j records to dictionaries
    nodes_data = [dict(record) for record in nodes_result]

    edges_query = (
        "MATCH (startNode:KnowledgeNode {userId: $userId, documentName: $documentName})"
        "-[r:RELATED_TO]->" # Using the generic relationship type from the simple_query
        "(endNode:KnowledgeNode {userId: $userId, documentName: $documentName}) "
        "RETURN startNode.nodeId AS from, endNode.nodeId AS to, r.type AS relationship"
    )
    edges_result = tx.run(edges_query, userId=user_id, documentName=document_name)
    edges_data = [dict(record) for record in edges_result]

    logger.info(f"Neo4j TX: Retrieved {len(nodes_data)} nodes and {len(edges_data)} edges for '{document_name}'.")
    return {"nodes": nodes_data, "edges": edges_data}


# --- Public Service Functions ---
def ingest_knowledge_graph(user_id: str, document_name: str, nodes: list, edges: list) -> dict:
    """
    Deletes existing KG for the document and ingests new nodes and edges.
    Returns a summary of operations.
    """
    try:
        logger.info(f"Attempting to delete old KG (if any) for document '{document_name}' (User: {user_id}).")
        _execute_write_tx(_delete_kg_transactional, user_id, document_name)
        logger.info(f"Old KG (if any) deleted for '{document_name}'. Proceeding with ingestion.")

        nodes_affected = 0
        if nodes and len(nodes) > 0:
            nodes_affected = _execute_write_tx(_add_nodes_transactional, nodes, user_id, document_name)
        
        edges_affected = 0
        if edges and len(edges) > 0:
            edges_affected = _execute_write_tx(_add_edges_transactional, edges, user_id, document_name)

        message = "Knowledge Graph successfully ingested/updated."
        logger.info(f"{message} Doc: '{document_name}', User: '{user_id}'. Nodes: {nodes_affected}, Edges: {edges_affected}")
        return {
            "success": True,
            "message": message,
            "nodes_affected": nodes_affected,
            "edges_affected": edges_affected
        }
    except Exception as e:
        logger.error(f"Error during KG ingestion for document '{document_name}', user '{user_id}': {e}", exc_info=True)
        raise # Re-raise to be caught by the route handler

def get_knowledge_graph(user_id: str, document_name: str) -> dict:
    """
    Retrieves the knowledge graph for a given user and document name.
    """
    try:
        kg_data = _execute_read_tx(_get_kg_transactional, user_id, document_name)
        if not kg_data["nodes"] and not kg_data["edges"]:
            logger.info(f"No KG data found for user '{user_id}', document '{document_name}'.")
            return None # Indicate not found
        return kg_data
    except Exception as e:
        logger.error(f"Error retrieving KG for document '{document_name}', user '{user_id}': {e}", exc_info=True)
        raise

def delete_knowledge_graph(user_id: str, document_name: str) -> bool:
    """
    Deletes the knowledge graph for a given user and document name.
    Returns True if data was deleted, False otherwise.
    """
    try:
        was_deleted = _execute_write_tx(_delete_kg_transactional, user_id, document_name)
        return was_deleted
    except Exception as e:
        logger.error(f"Error deleting KG for document '{document_name}', user '{user_id}': {e}", exc_info=True)
        raise
```

`server/rag_service/requirements.txt`

```
flask
requests
faiss-cpu # or faiss-gpu
langchain
langchain-huggingface
pypdf
PyPDF2
python-docx
python-dotenv
ollama # Keep if using Ollama embeddings
python-pptx # Added for PPTX parsing
uuid
langchain-community
pdfplumber
fitz # PyMuPDF for PDF parsing
pytesseract
nltk
spacy-layout
pandas
numpy
typing
pytesseract # OCR
pillow
qdrant-client
neo4j
sentence_transformers
spacy
opencv-python



```

`server/rag_service/vector_db_service.py`

```python
import uuid
import logging
from typing import List, Dict, Tuple, Optional, Any

from qdrant_client import QdrantClient, models
from sentence_transformers import SentenceTransformer

# Assuming vector_db_service.py and config.py are in the same package directory (e.g., rag_service/)
# and you run your application as a module (e.g., python -m rag_service.main_app)
# or have otherwise correctly set up the Python path.
import config # Changed to relative import

# Configure basic logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class Document: # For search result formatting
    def __init__(self, page_content: str, metadata: dict):
        self.page_content = page_content
        self.metadata = metadata

    def to_dict(self):
        return {"page_content": self.page_content, "metadata": self.metadata}

class VectorDBService:
    def __init__(self):
        logger.info("Initializing VectorDBService...")
        logger.info(f"  Qdrant Host: {config.QDRANT_HOST}, Port: {config.QDRANT_PORT}, URL: {config.QDRANT_URL}")
        logger.info(f"  Collection: {config.QDRANT_COLLECTION_NAME}")
        logger.info(f"  Query Embedding Model: {config.QUERY_EMBEDDING_MODEL_NAME}")
        
        # The vector dimension for the Qdrant collection is defined by the DOCUMENT embedding model
        # This is set in config.QDRANT_COLLECTION_VECTOR_DIM
        self.vector_dim = config.QDRANT_COLLECTION_VECTOR_DIM
        logger.info(f"  Service expects Vector Dim for Qdrant collection: {self.vector_dim} (from document model config)")

        if config.QDRANT_URL:
            self.client = QdrantClient(
                url=config.QDRANT_URL,
                api_key=config.QDRANT_API_KEY,
                timeout=30
            )
        else:
            self.client = QdrantClient(
                host=config.QDRANT_HOST,
                port=config.QDRANT_PORT,
                api_key=config.QDRANT_API_KEY,
                timeout=30
            )

        try:
            # This model is for encoding search queries.
            # Its output dimension MUST match self.vector_dim (QDRANT_COLLECTION_VECTOR_DIM).
            logger.info(f"  Loading query embedding model: '{config.QUERY_EMBEDDING_MODEL_NAME}'")
            self.model = SentenceTransformer(config.QUERY_EMBEDDING_MODEL_NAME)
            model_embedding_dim = self.model.get_sentence_embedding_dimension()
            logger.info(f"  Query model loaded. Output dimension: {model_embedding_dim}")

            if model_embedding_dim != self.vector_dim:
                error_msg = (
                    f"CRITICAL DIMENSION MISMATCH: Query model '{config.QUERY_EMBEDDING_MODEL_NAME}' "
                    f"outputs embeddings of dimension {model_embedding_dim}, but the Qdrant collection "
                    f"is configured for dimension {self.vector_dim} (derived from document model: "
                    f"'{config.DOCUMENT_EMBEDDING_MODEL_NAME}'). Search functionality will fail. "
                    "Ensure query and document models produce compatible embedding dimensions, "
                    "or environment variables for dimensions are correctly set."
                )
                logger.error(error_msg)
                raise ValueError(error_msg) # Critical error, stop initialization
            else:
                logger.info(f"  Query model output dimension ({model_embedding_dim}) matches "
                            f"Qdrant collection dimension ({self.vector_dim}).")

        except Exception as e:
            logger.error(f"Error initializing SentenceTransformer model '{config.QUERY_EMBEDDING_MODEL_NAME}' for query encoding: {e}", exc_info=True)
            raise # Re-raise to prevent service startup with a non-functional query encoder

        self.collection_name = config.QDRANT_COLLECTION_NAME
        # No ThreadPoolExecutor needed here if document encoding is external

    def _recreate_qdrant_collection(self):
        logger.info(f"Attempting to (re)create collection '{self.collection_name}' with vector size {self.vector_dim}.")
        try:
            self.client.recreate_collection(
                collection_name=self.collection_name,
                vectors_config=models.VectorParams(
                    size=self.vector_dim,
                    distance=models.Distance.COSINE,
                ),
            )
            logger.info(f"Collection '{self.collection_name}' (re)created successfully.")
        except Exception as e_recreate:
            logger.error(f"Failed to (re)create collection '{self.collection_name}': {e_recreate}", exc_info=True)
            raise

    def setup_collection(self):
        try:
            collection_info = self.client.get_collection(collection_name=self.collection_name)
            logger.info(f"Collection '{self.collection_name}' already exists.")
            
            # Handle different Qdrant client versions for accessing vector config
            current_vectors_config = None
            if hasattr(collection_info.config.params, 'vectors'): # For simple vector config
                if isinstance(collection_info.config.params.vectors, models.VectorParams):
                     current_vectors_config = collection_info.config.params.vectors
                elif isinstance(collection_info.config.params.vectors, dict): # For named vectors
                    # Assuming default unnamed vector or first one if named
                    default_vector_name = '' # Common for single vector setup
                    if default_vector_name in collection_info.config.params.vectors:
                        current_vectors_config = collection_info.config.params.vectors[default_vector_name]
                    elif collection_info.config.params.vectors: # Get first one if default not found
                        current_vectors_config = next(iter(collection_info.config.params.vectors.values()))

            if not current_vectors_config:
                 logger.error(f"Could not determine vector configuration for existing collection '{self.collection_name}'. Recreating.")
                 self._recreate_qdrant_collection()
            elif current_vectors_config.size != self.vector_dim:
                logger.warning(f"Collection '{self.collection_name}' vector size {current_vectors_config.size} "
                               f"differs from service's expected {self.vector_dim}. Recreating.")
                self._recreate_qdrant_collection()
            elif current_vectors_config.distance != models.Distance.COSINE: # Ensure distance is also checked
                logger.warning(f"Collection '{self.collection_name}' distance {current_vectors_config.distance} "
                               f"differs from expected {models.Distance.COSINE}. Recreating.")
                self._recreate_qdrant_collection()
            else:
                logger.info(f"Collection '{self.collection_name}' configuration is compatible (Size: {current_vectors_config.size}, Distance: {current_vectors_config.distance}).")

        except Exception as e: # Broad exception for Qdrant client errors
            # More specific check for "Not found" type errors
            if "not found" in str(e).lower() or \
               (hasattr(e, 'status_code') and e.status_code == 404) or \
               " " in str(e).lower(): # "Lucky" in Bengali, seems to be part of an error message you encountered
                 logger.info(f"Collection '{self.collection_name}' not found. Attempting to create...")
            else:
                 logger.warning(f"Error checking collection '{self.collection_name}': {type(e).__name__} - {e}. Attempting to (re)create anyway...")
            self._recreate_qdrant_collection()

    def add_processed_chunks(self, processed_chunks: List[Dict[str, Any]]) -> int:
        if not processed_chunks:
            logger.warning("add_processed_chunks received an empty list. No points to upsert.")
            return 0

        points_to_upsert = []
        doc_name_for_logging = "Unknown Document"

        for chunk_data in processed_chunks:
            point_id = chunk_data.get('id', str(uuid.uuid4()))
            vector = chunk_data.get('embedding')
            
            payload = chunk_data.get('metadata', {}).copy()
            payload['chunk_text_content'] = chunk_data.get('text_content', '')

            if not doc_name_for_logging or doc_name_for_logging == "Unknown Document":
                doc_name_for_logging = payload.get('original_name', payload.get('document_name', "Unknown Document"))

            if not vector:
                logger.warning(f"Chunk with ID '{point_id}' from '{doc_name_for_logging}' is missing 'embedding'. Skipping.")
                continue
            if not isinstance(vector, list) or not all(isinstance(x, (float, int)) for x in vector): # Allow int too, SentenceTransformer can return float32 which might be int-like in lists
                logger.warning(f"Chunk with ID '{point_id}' from '{doc_name_for_logging}' has an invalid 'embedding' format. Skipping.")
                continue
            if len(vector) != self.vector_dim:
                logger.error(f"Chunk with ID '{point_id}' from '{doc_name_for_logging}' has embedding dimension {len(vector)}, "
                             f"but collection expects {self.vector_dim}. Skipping. "
                             f"Ensure ai_core's document embedding model ('{config.DOCUMENT_EMBEDDING_MODEL_NAME}') "
                             f"output dimension matches configuration.")
                continue

            points_to_upsert.append(models.PointStruct(
                id=point_id,
                vector=[float(v) for v in vector], # Ensure all are floats for Qdrant
                payload=payload
            ))

        if not points_to_upsert:
            logger.warning(f"No valid points constructed from processed_chunks for document: {doc_name_for_logging}.")
            return 0

        try:
            self.client.upsert(collection_name=self.collection_name, points=points_to_upsert, wait=True) # wait=True can be useful for debugging
            logger.info(f"Successfully upserted {len(points_to_upsert)} chunks for document: {doc_name_for_logging} into Qdrant.")
            return len(points_to_upsert)
        except Exception as e:
            logger.error(f"Error upserting processed chunks to Qdrant for document: {doc_name_for_logging}: {e}", exc_info=True)
            raise

    def search_documents(self, query: str, k: int = -1, filter_conditions: Optional[models.Filter] = None) -> Tuple[List[Document], str, Dict]:
        # Use default k from config if not provided or invalid
        if k <= 0:
            k_to_use = config.QDRANT_DEFAULT_SEARCH_K
        else:
            k_to_use = k

        context_docs = []
        formatted_context_text = "No relevant context was found in the available documents."
        context_docs_map = {}

        logger.info(f"Searching with query (first 50 chars): '{query[:50]}...', k: {k_to_use}")
        if filter_conditions:
            try: filter_dict = filter_conditions.dict()
            except AttributeError: # For older Pydantic versions
                try: filter_dict = filter_conditions.model_dump()
                except AttributeError: filter_dict = str(filter_conditions) # Fallback
            logger.info(f"Applying filter: {filter_dict}")
        else:
            logger.info("No filter applied for search.")

        try:
            query_embedding = self.model.encode(query).tolist()
            logger.debug(f"Generated query_embedding (length: {len(query_embedding)}, first 5 dims: {query_embedding[:5]})")

            search_results = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_embedding,
                query_filter=filter_conditions,
                limit=k_to_use,
                with_payload=True,
                score_threshold=config.QDRANT_SEARCH_MIN_RELEVANCE_SCORE # Apply score threshold directly in search
            )
            logger.info(f"Qdrant client.search returned {len(search_results)} results (after score threshold).")

            if not search_results:
                return context_docs, formatted_context_text, context_docs_map

            for idx, point in enumerate(search_results):
                # Score threshold is already applied by Qdrant if score_threshold parameter is used.
                # If not using score_threshold in client.search, uncomment this:
                # if point.score < config.QDRANT_SEARCH_MIN_RELEVANCE_SCORE:
                #     logger.debug(f"Skipping point ID {point.id} with score {point.score:.4f} (below threshold {config.QDRANT_SEARCH_MIN_RELEVANCE_SCORE})")
                #     continue

                payload = point.payload
                content = payload.get("chunk_text_content", payload.get("text_content", payload.get("chunk_text", "")))

                retrieved_metadata = payload.copy()
                retrieved_metadata["qdrant_id"] = point.id
                retrieved_metadata["score"] = point.score

                doc = Document(page_content=content, metadata=retrieved_metadata)
                context_docs.append(doc)

            # Format context and citations
            formatted_context_parts = []
            for i, doc_obj in enumerate(context_docs):
                citation_index = i + 1
                doc_meta = doc_obj.metadata
                # Use more robust fetching of metadata keys
                display_subject = doc_meta.get("title", doc_meta.get("subject", "Unknown Subject")) # Prefer title for subject
                doc_name = doc_meta.get("original_name", doc_meta.get("file_name", "N/A"))
                page_num_info = f" (Page: {doc_meta.get('page_number', 'N/A')})" if doc_meta.get('page_number') else "" # Add page number if available
                
                content_preview = doc_obj.page_content[:200] + "..." if len(doc_obj.page_content) > 200 else doc_obj.page_content

                formatted = (f"[{citation_index}] Score: {doc_meta.get('score', 0.0):.4f} | "
                             f"Source: {doc_name}{page_num_info} | Subject: {display_subject}\n"
                             f"Content: {content_preview}") # Show content preview
                formatted_context_parts.append(formatted)

                context_docs_map[str(citation_index)] = {
                    "subject": display_subject,
                    "document_name": doc_name,
                    "page_number": doc_meta.get("page_number"),
                    "content_preview": content_preview, # Store preview
                    "full_content": doc_obj.page_content, # Store full content for potential later use
                    "score": doc_meta.get("score", 0.0),
                    "qdrant_id": doc_meta.get("qdrant_id"),
                    "original_metadata": doc_meta # Store all original metadata from payload
                }
            if formatted_context_parts:
                formatted_context_text = "\n\n---\n\n".join(formatted_context_parts)
            else:
                formatted_context_text = "No sufficiently relevant context was found after filtering."

        except Exception as e:
            logger.error(f"Qdrant search/RAG error: {e}", exc_info=True)
            formatted_context_text = "Error retrieving context due to an internal server error."

        return context_docs, formatted_context_text, context_docs_map
    
    # Add this method to the VectorDBService class in vector_db_service.py

    def delete_document_vectors(self, user_id: str, document_name: str) -> Dict[str, Any]:
        logger.info(f"Attempting to delete vectors for document: '{document_name}', user: '{user_id}' from Qdrant collection '{self.collection_name}'.")
        
        # These metadata keys must match what's stored during ingestion from ai_core.py
        # 'processing_user' was the user_id passed to ai_core
        # 'file_name' was the original_name passed to ai_core
        qdrant_filter = models.Filter(
            must=[
                models.FieldCondition(
                    key="processing_user", # The metadata field storing the user ID
                    match=models.MatchValue(value=user_id)
                ),
                models.FieldCondition(
                    key="file_name", # The metadata field storing the original document name
                    match=models.MatchValue(value=document_name)
                )
            ]
        )
        
        try:
            # Optional: Count points before deleting for logging/confirmation
            # count_response = self.client.count(collection_name=self.collection_name, count_filter=qdrant_filter)
            # num_to_delete = count_response.count
            # logger.info(f"Qdrant: Found {num_to_delete} points matching criteria for document '{document_name}', user '{user_id}'.")

            # if num_to_delete == 0:
            #     logger.info(f"Qdrant: No points found to delete for document '{document_name}', user '{user_id}'.")
            #     return {"success": True, "message": "No matching vectors found in Qdrant to delete.", "deleted_count": 0}

            delete_result = self.client.delete(
                collection_name=self.collection_name,
                points_selector=models.FilterSelector(filter=qdrant_filter),
                wait=True # Make it synchronous
            )
            
            # Check the status of the delete operation
            # delete_result should be an UpdateResult object
            if delete_result.status == models.UpdateStatus.COMPLETED or delete_result.status == models.UpdateStatus.ACKNOWLEDGED:
                # The actual number of deleted points isn't directly returned by filter-based delete.
                # We can infer it was successful if no error.
                # For a precise count, you'd need to list IDs by filter, then delete by IDs.
                logger.info(f"Qdrant delete operation for document '{document_name}', user '{user_id}' acknowledged/completed. Status: {delete_result.status}")
                return {"success": True, "message": f"Qdrant vector deletion for document '{document_name}' completed. Status: {delete_result.status}."}
            else:
                logger.warning(f"Qdrant delete operation for document '{document_name}', user '{user_id}' returned status: {delete_result.status}")
                return {"success": False, "message": f"Qdrant delete operation status: {delete_result.status}"}

        except Exception as e:
            logger.error(f"Error deleting document vectors from Qdrant for document '{document_name}', user '{user_id}': {e}", exc_info=True)
            # Check for specific Qdrant client errors if possible, e.g., if the collection doesn't exist.
            return {"success": False, "message": f"Failed to delete Qdrant vectors: {str(e)}"}

    def close(self):
        logger.info("VectorDBService close called.")
        # No specific resources like ThreadPoolExecutor to release in this version.
        # QdrantClient does not have an explicit close() method in recent versions.
```

`server/rag_service/__init__.py`

```python

```

`server/routes/adminDocuments.js`

```javascript
// server/routes/adminDocuments.js
const express = require('express');
const multer = require('multer');
const path = require('path');
const fs = require('fs');
const fsPromises = fs.promises;
const AdminDocument = require('../models/AdminDocument');
const { fixedAdminAuthMiddleware } = require('../middleware/fixedAdminAuthMiddleware');
const axios = require('axios');

const router = express.Router();

// --- Constants, Multer Config, Helpers (EXISTING CODE - no changes here for this step) ---
const ADMIN_UPLOAD_DIR_BASE = path.join(__dirname, '..', 'assets', '_admin_uploads_');
const MAX_FILE_SIZE = 20 * 1024 * 1024;
const allowedAdminMimeTypes = {
    'application/pdf': 'docs',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document': 'docs',
    'text/plain': 'docs',
    'text/markdown': 'docs',
};
const allowedAdminExtensions = ['.pdf', '.docx', '.txt', '.md'];

const adminStorage = multer.diskStorage({
    destination: (req, file, cb) => {
        const fileMimeType = file.mimetype.toLowerCase();
        const fileTypeSubfolder = allowedAdminMimeTypes[fileMimeType] || 'others';
        const destinationPath = path.join(ADMIN_UPLOAD_DIR_BASE, fileTypeSubfolder);
        fs.mkdir(destinationPath, { recursive: true }, (err) => {
            if (err) return cb(err);
            cb(null, destinationPath);
        });
    },
    filename: (req, file, cb) => {
        const timestamp = Date.now();
        const fileExt = path.extname(file.originalname).toLowerCase();
        const sanitizedBaseName = path.basename(file.originalname, fileExt)
            .replace(/[^a-zA-Z0-9._-]/g, '_').substring(0, 100);
        cb(null, `${timestamp}-${sanitizedBaseName}${fileExt}`);
    }
});
const adminFileFilter = (req, file, cb) => {
    const fileExt = path.extname(file.originalname).toLowerCase();
    const mimeType = file.mimetype.toLowerCase();
    if (allowedAdminMimeTypes[mimeType] && allowedAdminExtensions.includes(fileExt)) {
        cb(null, true);
    } else {
        const error = new multer.MulterError('LIMIT_UNEXPECTED_FILE_TYPE_ADMIN');
        error.message = `Invalid file type. Allowed: ${allowedAdminExtensions.join(', ')}`;
        cb(error, false);
    }
};
const adminUpload = multer({ storage: adminStorage, fileFilter: adminFileFilter, limits: { fileSize: MAX_FILE_SIZE }});
async function triggerPythonTextExtractionForAdmin(filePath, originalName) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
    if (!pythonServiceUrl) return { success: false, message: "Python service URL not configured.", text: null };
    const addDocumentUrl = `${pythonServiceUrl}/add_document`;
    try {
        const response = await axios.post(addDocumentUrl, {
            user_id: "fixed_admin_text_extraction_user",
            file_path: filePath, original_name: originalName
        }, { timeout: 300000 });
        const text = response.data?.raw_text_for_analysis || null;
        if (text) return { success: true, message: "Text extracted.", text: text };
        return { success: false, message: response.data?.message || "Python extracted no text.", text: null };
    } catch (error) {
        const errorMsg = error.response?.data?.error || error.message || "Unknown error calling Python RAG.";
        return { success: false, message: `Python RAG call failed: ${errorMsg}`, text: null };
    }
}
// --- End Existing Code ---


// @route   POST /api/admin/documents/upload (EXISTING - NO CHANGES FOR THIS STEP)
router.post('/upload', fixedAdminAuthMiddleware, adminUpload.single('file'), async (req, res) => {
    // ... (existing upload logic remains the same)
    if (!req.file) {
        return res.status(400).json({ message: 'No file uploaded or file type rejected.' });
    }
    const { filename: serverFilename, originalname: originalName, path: tempServerPath } = req.file;
    let adminDocRecord;
    try {
        const existingDoc = await AdminDocument.findOne({ originalName: originalName });
        if (existingDoc) {
            await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Error deleting duplicate temp file ${tempServerPath}:`, e));
            return res.status(409).json({ message: `Document with original name '${originalName}' already exists for admin.` });
        }
        const textExtractionResult = await triggerPythonTextExtractionForAdmin(tempServerPath, originalName);
        if (!textExtractionResult.success || !textExtractionResult.text || textExtractionResult.text.trim() === "") {
            await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Error deleting temp file ${tempServerPath} after failed text extraction:`, e));
            return res.status(422).json({
                message: textExtractionResult.message || "Failed to extract usable text from the document.",
                filename: serverFilename, originalname: originalName
            });
        }
        adminDocRecord = new AdminDocument({
            filename: serverFilename, originalName: originalName, text: textExtractionResult.text,
            analysis: { faq: "", topics: "", mindmap: "" }, analysisUpdatedAt: null,
        });
        await adminDocRecord.save();
        await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Non-critical error deleting temp file ${tempServerPath} after DB save:`, e));
        res.status(202).json({
            message: `Admin document '${originalName}' uploaded. Text extracted. Analysis initiated.`,
            filename: serverFilename, originalname: originalName,
        });
        const { Worker } = require('worker_threads');
        const adminAnalysisWorkerPath = path.resolve(__dirname, '..', 'workers', 'adminAnalysisWorker.js');
        if (fs.existsSync(adminAnalysisWorkerPath)) {
            const worker = new Worker(adminAnalysisWorkerPath, {
                workerData: {
                    adminDocumentId: adminDocRecord._id.toString(),
                    originalName: originalName, textForAnalysis: textExtractionResult.text
                }
            });
            worker.on('message', (msg) => console.log(`Admin Analysis Worker [Doc: ${msg.originalName || originalName}]: ${msg.message || JSON.stringify(msg)}`));
            worker.on('error', (err) => console.error(`Admin Analysis Worker Error [Doc: ${originalName}]:`, err));
            worker.on('exit', (code) => console.log(`Admin Analysis Worker [Doc: ${originalName}] exited (code ${code}).`));
        } else {
            console.error(`Admin Upload: adminAnalysisWorker.js not found at ${adminAnalysisWorkerPath}.`);
        }
    } catch (error) {
        console.error(`Admin Upload: Overall error for '${originalName || (req.file && req.file.originalname)}':`, error);
        if (tempServerPath) await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Error cleaning up temp file ${tempServerPath} after overall error:`, e));
        if (!res.headersSent) {
            if (error.code === 11000) res.status(409).json({ message: 'Document processing conflict.' });
            else res.status(500).json({ message: 'Server error during admin document upload.' });
        }
    }
});

// @route   GET /api/admin/documents (EXISTING - NO CHANGES FOR THIS STEP)
router.get('/', fixedAdminAuthMiddleware, async (req, res) => {
    // ... (existing list logic remains the same)
    try {
        const adminDocs = await AdminDocument.find().sort({ uploadedAt: -1 })
            .select('originalName filename uploadedAt analysisUpdatedAt analysis.faq analysis.topics analysis.mindmap');
        const documentsList = adminDocs.map(doc => ({
            originalName: doc.originalName, serverFilename: doc.filename, uploadedAt: doc.uploadedAt,
            analysisUpdatedAt: doc.analysisUpdatedAt,
            hasFaq: !!(doc.analysis && doc.analysis.faq && doc.analysis.faq.trim() !== ""),
            hasTopics: !!(doc.analysis && doc.analysis.topics && doc.analysis.topics.trim() !== ""),
            hasMindmap: !!(doc.analysis && doc.analysis.mindmap && doc.analysis.mindmap.trim() !== ""),
        }));
        res.json({ documents: documentsList });
    } catch (error) {
        res.status(500).json({ message: 'Server error fetching admin documents.' });
    }
});

// @route   DELETE /api/admin/documents/:serverFilename (EXISTING - NO CHANGES FOR THIS STEP)
router.delete('/:serverFilename', fixedAdminAuthMiddleware, async (req, res) => {
    // ... (existing delete logic remains the same)
    const { serverFilename } = req.params;
    if (!serverFilename) return res.status(400).json({ message: 'Server filename parameter is required.' });
    try {
        const docToDelete = await AdminDocument.findOneAndDelete({ filename: serverFilename });
        if (!docToDelete) return res.status(404).json({ message: `Admin document '${serverFilename}' not found.` });
        res.status(200).json({ message: `Admin document '${docToDelete.originalName}' record deleted.` });
    } catch (error) {
        res.status(500).json({ message: 'Server error during admin document deletion.' });
    }
});

// @route   GET /api/admin/documents/:serverFilename/analysis (EXISTING - NO CHANGES FOR THIS STEP)
router.get('/:serverFilename/analysis', fixedAdminAuthMiddleware, async (req, res) => {
    // ... (existing analysis fetch by serverFilename logic remains the same)
    const { serverFilename } = req.params;
    if (!serverFilename) return res.status(400).json({ message: 'Server filename parameter is required.' });
    try {
        const adminDoc = await AdminDocument.findOne({ filename: serverFilename }).select('originalName analysis analysisUpdatedAt');
        if (!adminDoc) return res.status(404).json({ message: `Admin document '${serverFilename}' not found.` });
        if (!adminDoc.analysis || (!adminDoc.analysis.faq && !adminDoc.analysis.topics && !adminDoc.analysis.mindmap)) {
            return res.status(200).json({
                originalName: adminDoc.originalName, message: 'Analysis not generated or empty.',
                analysis: { faq: "", topics: "", mindmap: "" }, analysisUpdatedAt: adminDoc.analysisUpdatedAt
            });
        }
        res.status(200).json({
            originalName: adminDoc.originalName, analysis: adminDoc.analysis,
            analysisUpdatedAt: adminDoc.analysisUpdatedAt
        });
    } catch (error) {
        res.status(500).json({ message: 'Server error retrieving admin document analysis.' });
    }
});

// --- NEW ROUTE FOR STEP 2 ---
// @route   GET /api/admin/documents/by-original-name/:originalName/analysis
// @desc    Get analysis data for a specific admin document by its originalName
// @access  Admin Only (via fixedAdminAuthMiddleware)
router.get('/by-original-name/:originalName/analysis', fixedAdminAuthMiddleware, async (req, res) => {
    const { originalName } = req.params;
    if (!originalName) {
        return res.status(400).json({ message: 'Original name parameter is required.' });
    }

    try {
        const decodedOriginalName = decodeURIComponent(originalName);
        const adminDoc = await AdminDocument.findOne({ originalName: decodedOriginalName })
            .select('originalName filename analysis analysisUpdatedAt'); // Select necessary fields

        if (!adminDoc) {
            return res.status(404).json({ message: `Admin document with original name '${decodedOriginalName}' not found.` });
        }

        // Check if the analysis object or its specific fields are empty/null
        if (!adminDoc.analysis ||
            (!adminDoc.analysis.faq?.trim() && // Check if specific fields are empty strings after trim
             !adminDoc.analysis.topics?.trim() &&
             !adminDoc.analysis.mindmap?.trim())) {
            return res.status(200).json({
                originalName: adminDoc.originalName,
                serverFilename: adminDoc.filename,
                message: 'Analysis has not been generated or is empty for this document.',
                analysis: { // Return a default empty structure
                    faq: adminDoc.analysis?.faq || "",
                    topics: adminDoc.analysis?.topics || "",
                    mindmap: adminDoc.analysis?.mindmap || ""
                },
                analysisUpdatedAt: adminDoc.analysisUpdatedAt
            });
        }

        res.status(200).json({
            originalName: adminDoc.originalName,
            serverFilename: adminDoc.filename, // Include serverFilename for context if frontend needs it
            analysis: adminDoc.analysis,       // This contains { faq, topics, mindmap } strings
            analysisUpdatedAt: adminDoc.analysisUpdatedAt
        });
    } catch (error) {
        console.error(`Error fetching analysis for admin document by original name '${originalName}':`, error);
        res.status(500).json({ message: 'Server error while retrieving admin document analysis by original name.' });
    }
});


module.exports = router;
```

`server/routes/analysis.js`

```javascript
// server/routes/analysis.js
const express = require('express');
const router = express.Router();
const { authMiddleware } = require('../middleware/authMiddleware');
const User = require('../models/User');

// @route   GET /api/analysis/:documentFilename
// @desc    Get analysis data (faq, topics, mindmap) for a specific document
// @access  Private (requires auth)
router.get('/:documentFilename', authMiddleware, async (req, res) => {
    const userId = req.user._id; // From authMiddleware
    const { documentFilename } = req.params;
    
    if (!documentFilename) {
        return res.status(400).json({ message: 'Document filename parameter is required.' });
    }

    try {
        const user = await User.findById(userId).select('uploadedDocuments');
        if (!user) {
            return res.status(404).json({ message: 'User not found.' });
        }

        const document = user.uploadedDocuments.find(doc => doc.filename === documentFilename);

        if (!document) {
            return res.status(404).json({ message: `Document '${documentFilename}' not found for this user.` });
        }

        if (!document.analysis) {
            // This case might happen if the analysis object itself is missing, though schema has defaults.
            console.warn(`Analysis object missing for document '${documentFilename}', user '${userId}'. Sending empty analysis.`);
            return res.status(200).json({
                faq: "",
                topics: "",
                mindmap: ""
            });
        }
        
        // Send the analysis sub-document
        res.status(200).json(document.analysis);

    } catch (error) {
        console.error(`Error fetching analysis for document '${documentFilename}', user '${userId}':`, error);
        res.status(500).json({ message: 'Server error while retrieving document analysis.' });
    }
});

module.exports = router;
```

`server/routes/auth.js`

```javascript
// server/routes/auth.js
const express = require('express');
const jwt = require('jsonwebtoken'); // <-- Import jsonwebtoken
const { v4: uuidv4 } = require('uuid');
const User = require('../models/User');
const { authMiddleware } = require('../middleware/authMiddleware');
require('dotenv').config(); // Ensures process.env has values from .env

const router = express.Router();

const JWT_EXPIRATION = process.env.JWT_EXPIRATION || '1h'; // Default to 1 hour

// --- @route   POST /api/auth/signup ---
// --- @desc    Register a new user ---
// --- @access  Public ---
router.post('/signup', async (req, res) => {
  const { username, password } = req.body;

  if (!username || !password) {
    return res.status(400).json({ message: 'Please provide username and password' });
  }
  if (password.length < 6) {
     return res.status(400).json({ message: 'Password must be at least 6 characters long' });
  }

  try {
    const existingUser = await User.findOne({ username });
    if (existingUser) {
      return res.status(400).json({ message: 'Username already exists' });
    }

    const newUser = new User({ username, password });
    await newUser.save();

    const sessionId = uuidv4(); // Initial session ID

    // Create JWT Payload
    const payload = {
      userId: newUser._id,
      username: newUser.username,
    };

    // Sign the token
    const token = jwt.sign(
      payload,
      process.env.JWT_SECRET, // Make sure JWT_SECRET is in your .env
      { expiresIn: JWT_EXPIRATION }
    );

    res.status(201).json({
      token: token, // <-- Send token
      _id: newUser._id,
      username: newUser.username,
      sessionId: sessionId,
      message: 'User registered successfully',
    });

  } catch (error) {
    console.error('Signup Error:', error);
    if (error.code === 11000) {
        return res.status(400).json({ message: 'Username already exists.' });
    }
    res.status(500).json({ message: 'Server error during signup' });
  }
});

// --- @route   POST /api/auth/signin ---
// --- @desc    Authenticate user & return JWT ---
// --- @access  Public ---
router.post('/signin', async (req, res) => {
  const { username, password } = req.body;

  if (!username || !password) {
    return res.status(400).json({ message: 'Please provide username and password' });
  }

  try {
    const user = await User.findByCredentials(username, password);

    if (!user) {
      return res.status(401).json({ message: 'Invalid credentials' });
    }

    const sessionId = uuidv4(); // New session ID for this login

    // Create JWT Payload
    const payload = {
      userId: user._id,
      username: user.username,
    };

    // Sign the token
    const token = jwt.sign(
      payload,
      process.env.JWT_SECRET,
      { expiresIn: JWT_EXPIRATION }
    );

    res.status(200).json({
      token: token, // <-- Send token
      _id: user._id,
      username: user.username,
      sessionId: sessionId,
      message: 'Login successful',
    });

  } catch (error) {
    console.error('Signin Error:', error);
    res.status(500).json({ message: 'Server error during signin' });
  }
});

// --- @route   GET /api/auth/me ---
// --- @desc    Get current authenticated user's details (requires JWT middleware) ---
// --- @access  Private ---
// We will add the middleware for this route in server.js
router.get('/me',authMiddleware, async (req, res) => {
    // If the JWT middleware (to be created next) runs successfully,
    // req.user will be populated.
    if (!req.user) {
        // This should ideally be caught by the middleware itself,
        // but as a fallback.
        return res.status(401).json({ message: 'Not authorized, user context missing.' });
    }
    try {
        // req.user is already the user document (excluding password typically)
        // thanks to the upcoming authMiddleware.
        res.status(200).json({
            _id: req.user._id,
            username: req.user.username,
            // Add any other fields you want the frontend to know about the user
            // e.g., email, roles, preferences, if stored.
        });
    } catch (error) {
        console.error('Error in /api/auth/me:', error);
        res.status(500).json({ message: 'Server error fetching user details.' });
    }
});


module.exports = router;
```

`server/routes/chat.js`

```javascript
// server/routes/chat.js
const express = require('express');
const { v4: uuidv4 } = require('uuid');
const ChatHistory = require('../models/ChatHistory');
const User = require('../models/User'); // Import User model
const { generateContentWithHistory } = require('../services/geminiService');
const geminiService = require('../services/geminiService');
const ollamaService = require('../services/ollamaService');
const { CHAT_MAIN_SYSTEM_PROMPT, CHAT_USER_PROMPT_TEMPLATES } = require('../config/promptTemplates');
const { createOrUpdateSummary } = require('../services/summarizationService');
const axios = require('axios');

const router = express.Router();

// --- Helper to call Python RAG Query Endpoint ---
async function queryPythonRagService(
    userId, query, criticalThinkingEnabled, documentContextNameToPass, clientFilter = null, k = 5
) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
    if (!pythonServiceUrl) {
        console.error("PYTHON_RAG_SERVICE_URL is not set. RAG features disabled for this request.");
        return [];
    }
    const searchUrl = `${pythonServiceUrl}/query`;
    console.log(`Querying Python RAG: User ${userId}, Query (first 50): "${query.substring(0, 50)}...", k=${k}, CriticalThinking=${criticalThinkingEnabled}, DocContext=${documentContextNameToPass}`);

    const payload = {
        query: query, k: k, user_id: userId,
        use_kg_critical_thinking: !!criticalThinkingEnabled,
        documentContextName: documentContextNameToPass || null
    };
    if (clientFilter && typeof clientFilter === 'object' && Object.keys(clientFilter).length > 0) {
        payload.filter = clientFilter;
    }

    try {
        const response = await axios.post(searchUrl, payload, {
            headers: { 'Content-Type': 'application/json' },
            timeout: process.env.PYTHON_RAG_TIMEOUT || 30000
        });
        if (response.data && Array.isArray(response.data.retrieved_documents_list)) {
            return response.data.retrieved_documents_list.map(doc => ({
                documentName: doc.metadata?.file_name || doc.metadata?.original_name || doc.metadata?.title || 'Unknown Document',
                content: doc.page_content || "", score: doc.metadata?.score,
            }));
        }
        return [];
    } catch (error) {
        let errorMsg = error.message;
        if (error.response?.data?.error) errorMsg = `Python Service Error: ${error.response.data.error}`;
        else if (error.code === 'ECONNABORTED') errorMsg = 'Python RAG service request timed out.';
        console.error(`Error querying Python RAG service at ${searchUrl}:`, errorMsg);
        return [];
    }
}


// --- @route   POST /api/chat/message ---
// --- @desc    Send a message, get AI response, save interaction ---
// --- @access  Private ---
router.post('/message', async (req, res) => {
    const {
        query, sessionId, useRag, llmProvider: clientLlmProvider,
        systemPrompt: clientProvidedSystemInstruction, criticalThinkingEnabled,
        documentContextName, filter
    } = req.body;
    const userId = req.user._id;

    if (!query || typeof query !== 'string' || query.trim() === '') {
        return res.status(400).json({ message: 'Query message text required.' });
    }
    if (!sessionId || typeof sessionId !== 'string') {
        return res.status(400).json({ message: 'Session ID required.' });
    }

    const userMessageForDb = { role: 'user', parts: [{ text: query }], timestamp: new Date() };
    console.log(`>>> POST /api/chat/message: User=${userId}, Session=${sessionId}, RAG=${useRag}, Query: "${query.substring(0, 50)}..."`);

    try {
        // 1. FETCH AUTHORITATIVE STATE FROM DB
        const [chatSession, user] = await Promise.all([
            ChatHistory.findOne({ sessionId: sessionId, userId: userId }),
            User.findById(userId).select('preferredLlmProvider ollamaModel').lean()
        ]);
        const llmProvider = user?.preferredLlmProvider || clientLlmProvider || 'gemini';
        const ollamaModel = user?.ollamaModel || process.env.OLLAMA_DEFAULT_MODEL;

        const historyFromDb = chatSession ? chatSession.messages : [];
        const summaryFromDb = chatSession ? chatSession.summary || "" : "";

        // 2. PREPARE PROMPT FOR LLM (using only DB state)
        let referencesForResponse = [];
        let actualSourcePipeline = `${llmProvider}-direct`;
        let ragContextString = "";
        
        if (useRag) {
            actualSourcePipeline = `${llmProvider}-rag`;
            const relevantDocsFromRag = await queryPythonRagService(
                userId.toString(), query.trim(), criticalThinkingEnabled, documentContextName, filter
            );
            if (relevantDocsFromRag?.length > 0) {
                ragContextString = relevantDocsFromRag.map((doc, index) => {
                    referencesForResponse.push({
                        number: index + 1, source: doc.documentName,
                        content_preview: doc.content.substring(0, 100) + (doc.content.length > 100 ? "..." : "")
                    });
                    return `\n[${index + 1}] Source: ${doc.documentName}\nContent:\n${doc.content}\n---`;
                }).join('');
            }
        }
        
        const historyForLlm = [];
        if (summaryFromDb) {
            historyForLlm.push({ role: 'user', parts: [{ text: `CONTEXT: Here is a summary of our conversation so far. Use it to inform your response but do not mention the summary itself in your answer:\n\n"""\n${summaryFromDb}\n"""` }] });
            historyForLlm.push({ role: 'model', parts: [{ text: "Okay, I have reviewed the summary of our previous conversation. I will use this context for my next response. How can I help you now?" }] });
        }
        
        const formattedDbMessages = historyFromDb.map(msg => ({
            role: msg.role, parts: msg.parts.map(part => ({ text: part.text || '' }))
        }));
        historyForLlm.push(...formattedDbMessages);
        
        const queryForLLM = useRag && ragContextString
            ? CHAT_USER_PROMPT_TEMPLATES.rag(query.trim(), ragContextString, clientProvidedSystemInstruction)
            : CHAT_USER_PROMPT_TEMPLATES.direct(query.trim(), clientProvidedSystemInstruction);
        const fullHistoryForLLM = [...historyForLlm, { role: 'user', parts: [{ text: queryForLLM }] }];
        
        // 3. CALL LLM SERVICE
        console.log(`   Calling ${llmProvider} API. Effective history length for LLM: ${fullHistoryForLLM.length}.`);
        const aiResponseMessageText = llmProvider === 'ollama'
            ? await ollamaService.generateContentWithHistory(fullHistoryForLLM, CHAT_MAIN_SYSTEM_PROMPT(), { model: ollamaModel })
            : await geminiService.generateContentWithHistory(fullHistoryForLLM, CHAT_MAIN_SYSTEM_PROMPT());

        const aiMessageForDbAndClient = {
            sender: 'bot', role: 'model', parts: [{ text: aiResponseMessageText }], text: aiResponseMessageText,
            timestamp: new Date(), thinking: null, references: referencesForResponse, source_pipeline: actualSourcePipeline,
        };

        // 4. PERSIST FINAL STATE TO DB
        await ChatHistory.findOneAndUpdate(
            { sessionId: sessionId, userId: userId },
            { $push: { messages: { $each: [userMessageForDb, aiMessageForDbAndClient] } }, $set: { updatedAt: new Date() } },
            { upsert: true, new: true, setDefaultsOnInsert: true }
        );

        console.log(`<<< POST /api/chat/message successful for Session ${sessionId}. DB state updated.`);
        res.status(200).json({ reply: aiMessageForDbAndClient });

    } catch (error) {
        console.error(`!!! Error processing chat message for Session ${sessionId}:`, error);
        const statusCode = error.status || error.response?.status || 500;
        const clientMessage = error.message || "Failed to get response from AI service.";
        
        const errorMessageForChat = {
            sender: 'bot', role: 'model', parts: [{ text: `Error: ${clientMessage}` }], text: `Error: ${clientMessage}`,
            timestamp: new Date(), thinking: `Error occurred: ${error.message}`, references: [], source_pipeline: 'error-pipeline'
        };
        
        try {
            await ChatHistory.findOneAndUpdate(
                { sessionId: sessionId, userId: userId },
                { $push: { messages: { $each: [userMessageForDb, errorMessageForChat] } }, $set: { updatedAt: new Date() } },
                { upsert: true, new: true, setDefaultsOnInsert: true }
            );
        } catch (dbError) {
            console.error(`!!! CRITICAL: Failed to save error message to chat history for Session ${sessionId}:`, dbError);
        }
        res.status(statusCode).json({ message: clientMessage, reply: errorMessageForChat });
    }
});


// --- @route   POST /api/chat/history ---
// --- @desc    Handles starting a new session, summarizing the old one to carry over context ---
// --- @access  Private ---
router.post('/history', async (req, res) => {
    const { previousSessionId } = req.body;
    const userId = req.user._id;
    const newSessionId = uuidv4();
    let summaryOfOldSession = "";

    console.log(`>>> POST /api/chat/history (New Session): User=${userId}, PrevSID=${previousSessionId}`);

    if (previousSessionId) {
        try {
            const oldSession = await ChatHistory.findOne({ sessionId: previousSessionId, userId: userId });
            const user = await User.findById(userId).select('preferredLlmProvider ollamaModel').lean();
            const llmProvider = user?.preferredLlmProvider || 'gemini';
            const ollamaModel = user?.ollamaModel || process.env.OLLAMA_DEFAULT_MODEL;

            if (oldSession && oldSession.messages?.length > 0) {
                console.log(`   Summarizing previous session ${previousSessionId} to carry over context.`);
                const fullHistoryOfOldSession = oldSession.messages;
                summaryOfOldSession = await createOrUpdateSummary(
                    fullHistoryOfOldSession,
                    oldSession.summary, // Pass existing summary to be cumulative
                    llmProvider,
                    ollamaModel
                );
            }
        } catch (summaryError) {
            console.error(`!!! Could not summarize previous session ${previousSessionId}:`, summaryError);
        }
    }

    try {
        await ChatHistory.create({
            userId: userId,
            sessionId: newSessionId,
            messages: [],
            summary: summaryOfOldSession,
        });
        console.log(`<<< POST /api/chat/history: New session ${newSessionId} created for User=${userId}. Summary length: ${summaryOfOldSession.length}`);
        res.status(200).json({
            message: 'New session started.',
            newSessionId: newSessionId,
        });
    } catch (dbError) {
        console.error(`!!! Failed to create new chat session ${newSessionId} in DB:`, dbError);
        res.status(500).json({ message: 'Failed to create new session due to a server error.' });
    }
});


// --- @route   GET /api/chat/sessions ---
router.get('/sessions', async (req, res) => {
    const userId = req.user._id;
    console.log(`>>> GET /api/chat/sessions: User=${userId}`);
    try {
        const sessions = await ChatHistory.find({ userId: userId })
            .sort({ updatedAt: -1 })
            .select('sessionId createdAt updatedAt messages')
            .lean();

        const sessionSummaries = sessions.map(session => {
            const firstUserMessage = session.messages?.find(m => m.role === 'user');
            let preview = firstUserMessage?.parts?.[0]?.text?.substring(0, 75) || 'Chat Session';
            if (preview.length === 75) preview += '...';
            
            return {
                sessionId: session.sessionId,
                createdAt: session.createdAt,
                updatedAt: session.updatedAt,
                messageCount: session.messages?.length || 0,
                preview: preview
            };
        });
        console.log(`<<< GET /api/chat/sessions: Found ${sessionSummaries.length} sessions for User ${userId}.`);
        res.status(200).json(sessionSummaries);
    } catch (error) {
        console.error(`!!! Error fetching chat sessions for user ${userId}:`, error);
        res.status(500).json({ message: 'Failed to retrieve chat sessions.' });
    }
});


// --- @route   GET /api/chat/session/:sessionId ---
router.get('/session/:sessionId', async (req, res) => {
    const userId = req.user._id;
    const { sessionId } = req.params;
    console.log(`>>> GET /api/chat/session/${sessionId}: User=${userId}`);

    if (!sessionId) {
        return res.status(400).json({ message: 'Session ID parameter is required.' });
    }

    try {
        const session = await ChatHistory.findOne({ sessionId: sessionId, userId: userId }).lean();
        if (!session) {
            console.log(`--- GET /api/chat/session/${sessionId}: Session not found for User ${userId}.`);
            return res.status(404).json({ message: 'Chat session not found or access denied.' });
        }
        
        const messagesForFrontend = (session.messages || []).map(msg => ({
            id: msg._id || uuidv4(),
            sender: msg.role === 'model' ? 'bot' : 'user',
            text: msg.parts?.[0]?.text || '',
            thinking: msg.thinking,
            references: msg.references,
            timestamp: msg.timestamp,
            source_pipeline: msg.source_pipeline
        }));
        
        res.status(200).json({ ...session, messages: messagesForFrontend });
    } catch (error) {
        console.error(`!!! Error fetching chat session ${sessionId} for user ${userId}:`, error);
        res.status(500).json({ message: 'Failed to retrieve chat session details.' });
    }
});

module.exports = router;
```

`server/routes/files.js`

```javascript
// server/routes/files.js
const express = require('express');
const fs = require('fs').promises;
const path = require('path');
const { authMiddleware } = require('../middleware/authMiddleware');
const User = require('../models/User');
const axios = require('axios');
const router = express.Router();

const ASSETS_DIR = path.join(__dirname, '..', 'assets');
const BACKUP_DIR = path.join(__dirname, '..', 'backup_assets');

// --- Helper functions (sanitizeUsernameForDir, parseServerFilename, ensureDirExists are existing) ---
const sanitizeUsernameForDir = (username) => {
    if (!username) return '';
    return username.replace(/[^a-zA-Z0-9_-]/g, '_');
};

const parseServerFilename = (filename) => {
    // Matches "timestamp-originalName.ext"
    // Allows originalName to contain dots now.
    const match = filename.match(/^(\d+)-(.+?)(\.\w+)$/);
    if (match && match.length === 4) {
        return { timestamp: match[1], originalName: `${match[2]}${match[3]}`, extension: match[3] };
    }
    // Fallback for names that might not perfectly fit the new pattern, or originalName without extension before timestamp
    const ext = path.extname(filename);
    const baseWithoutExt = filename.substring(0, filename.length - ext.length);
    const tsMatch = baseWithoutExt.match(/^(\d+)-(.*)$/);
    if (tsMatch) {
        return { timestamp: tsMatch[1], originalName: `${tsMatch[2]}${ext}`, extension: ext };
    }
    // Final fallback if no timestamp prefix is reliably parsed
    return { timestamp: null, originalName: filename, extension: path.extname(filename) };
};

const ensureDirExists = async (dirPath) => {
    try { await fs.mkdir(dirPath, { recursive: true }); }
    catch (error) { if (error.code !== 'EEXIST') { console.error(`Error creating dir ${dirPath}:`, error); throw error; } }
};

async function callPythonDeletionEndpoint(method, endpointPath, userId, originalName, logContext) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL || process.env.DEFAULT_PYTHON_RAG_URL || 'http://localhost:5000'; // Fallback if not set
    if (!pythonServiceUrl) {
        console.error(`Python Service Deletion Error for ${logContext}: PYTHON_RAG_SERVICE_URL not set.`);
        return { success: false, message: "Python service URL not configured." };
    }

    const deleteUrl = `${pythonServiceUrl.replace(/\/$/, '')}${endpointPath}`;

    try {
        console.log(`Calling Python Service (${method.toUpperCase()}) for deletion: ${deleteUrl} (Doc: ${originalName}, User: ${userId})`);
        let response;
        if (method.toUpperCase() === 'DELETE') {
            // For DELETE, data is often in query params or path, but axios allows a 'data' field for body
            response = await axios.delete(deleteUrl, {
                data: { // For Python endpoints that expect a body (like a new Qdrant delete one)
                    user_id: userId,
                    document_name: originalName
                },
                timeout: 30000 // 30s timeout
            });
        } else {
            throw new Error(`Unsupported method for Python deletion: ${method}`);
        }

        if (response.status === 200 || response.status === 204) { // 204 No Content is also success
            return { success: true, message: response.data?.message || `Successfully deleted from ${endpointPath}` };
        } else {
            return { success: false, message: response.data?.message || `Python service returned ${response.status} for ${endpointPath}` };
        }
    } catch (error) {
        const errorMsg = error.response?.data?.error || error.response?.data?.message || error.message || `Unknown error deleting from ${endpointPath}`;
        console.error(`Error calling Python Service for deletion (${deleteUrl}) for ${originalName} (User: ${userId}): ${errorMsg}`, error.response ? { status: error.response.status, data: error.response.data } : error);
        return { success: false, message: `Python service call failed for ${endpointPath}: ${errorMsg}` };
    }
}
// --- End Helper Functions ---


// --- @route   GET /api/files ---
// Use authMiddleware middleware 
// TO GET FILE NAMES
router.get('/', authMiddleware, async (req, res) => {
    
    const userFiles = []
    try {
        const userId = req.user._id.toString();

        // Find user by ID, select only uploadedDocuments to optimize
        const user = await User.findById(userId).select('uploadedDocuments');

        if (!user) return res.status(404).json({ msg: 'User not found' });

        // Extract filenames
        const filenames = user.uploadedDocuments
        .map(doc => doc.filename)
        .filter(Boolean)  // filter out undefined or null filenames just in case
        .reverse();       // reverse the order

        return res.json({ filenames });

    } catch (error) {
        console.log(error.message);
        return res.status(500).json({ msg: 'Server error' });
    }
});


// --- @route   DELETE /api/files/:serverFilename ---
// Use authMiddleware middleware
router.delete('/:serverFilename', authMiddleware, async (req, res) => {
  
    const { serverFilename } = req.params;
    const userId = req.user._id.toString(); // Get userId from authenticated user
    const usernameForLog = req.user.username;

    if (!serverFilename) {
        return res.status(400).json({ message: 'Server filename parameter is required.' });
    }

    const parsedFileDetails = parseServerFilename(serverFilename);
    const originalName = parsedFileDetails.originalName;
    if (!originalName) {
        console.error(`DELETE /api/files: Could not parse originalName from serverFilename: ${serverFilename}`);
        return res.status(400).json({ message: 'Invalid server filename format for deletion.' });
    }
    const logContext = `File: '${originalName}' (server: ${serverFilename}), User: ${usernameForLog} (${userId})`;
    console.log(`Attempting to delete all data for ${logContext}`);

    const results = {
        mongodb: { success: false, message: "Not attempted" },
        qdrant: { success: false, message: "Not attempted" },
        neo4j: { success: false, message: "Not attempted" },
        filesystem: { success: false, message: "Not attempted" },
    };
    let overallSuccess = true; // Assume success, set to false if any critical step fails
    let httpStatus = 200;
    let fileFoundInMongo = false;
    let physicalFileFound = false;

    try {
        // 1. Delete from MongoDB
        try {
            const user = await User.findById(userId);
            if (!user) {
                results.mongodb.message = "User not found.";
                // If user not found, we can't confirm if the file was theirs.
                // Treat as if the file wasn't found for this user.
            } else {
                const docIndex = user.uploadedDocuments.findIndex(doc => doc.filename === originalName);
                if (docIndex > -1) {
                    fileFoundInMongo = true;
                    user.uploadedDocuments.splice(docIndex, 1);
                    await user.save();
                    results.mongodb.success = true;
                    results.mongodb.message = "Successfully removed from user's document list.";
                    console.log(`MongoDB: Document entry '${originalName}' removed for user ${userId}.`);
                } else {
                    results.mongodb.message = "Document not found in user's list.";
                    console.log(`MongoDB: Document entry '${originalName}' not found for user ${userId}.`);
                }
            }
        } catch (mongoError) {
            console.error(`MongoDB Deletion Error for ${logContext}:`, mongoError);
            results.mongodb.message = `MongoDB deletion failed: ${mongoError.message}`;
            overallSuccess = false; // DB error is critical
        }

        // 2. Delete from Qdrant (via Python service)
        // This endpoint will need to be created in Python: e.g., /delete_qdrant_document_data
        // It should expect { user_id: userId, document_name: originalName } in the body
        const qdrantDeleteResult = await callPythonDeletionEndpoint(
            'DELETE',
            `/delete_qdrant_document_data`,
            userId,
            originalName,
            logContext
        );
        results.qdrant = qdrantDeleteResult;
        if (!qdrantDeleteResult.success) {
            console.warn(`Qdrant deletion failed or reported no data for ${logContext}. Message: ${qdrantDeleteResult.message}`);
            // overallSuccess = false; // Non-critical for now, but log
        }

        // 3. Delete from Neo4j (via Python service)
        // This uses the existing Python endpoint: /kg/<user_id>/<document_name>
        const neo4jEndpointPath = `/kg/${userId}/${encodeURIComponent(originalName)}`;
        const neo4jDeleteResult = await callPythonDeletionEndpoint(
            'DELETE',
            neo4jEndpointPath, // userId and originalName are in the path
            userId, // still pass for logging consistency in helper
            originalName, // still pass for logging consistency in helper
            logContext
        );
        results.neo4j = neo4jDeleteResult;
        if (!neo4jDeleteResult.success) {
            console.warn(`Neo4j deletion failed or reported no data for ${logContext}. Message: ${neo4jDeleteResult.message}`);
            // overallSuccess = false; // Non-critical for now, but log
        }

        // 4. Move physical file to backup (filesystem operation)
        let currentPath = null;
        let fileType = '';
        const fileTypesToSearch = ['docs', 'images', 'code', 'others'];
        const sanitizedUsernameForPath = sanitizeUsernameForDir(usernameForLog);

        for (const type of fileTypesToSearch) {
            const potentialPath = path.join(ASSETS_DIR, sanitizedUsernameForPath, type, serverFilename);
            try {
                await fs.access(potentialPath); // Check if file exists
                currentPath = potentialPath;
                fileType = type;
                physicalFileFound = true;
                break;
            } catch (e) {
                if (e.code !== 'ENOENT') {
                    console.warn(`Filesystem: Error accessing ${potentialPath} during delete scan: ${e.message}`);
                }
            }
        }

        if (currentPath) { // If physical file was found
            const backupUserDir = path.join(BACKUP_DIR, sanitizedUsernameForPath, fileType);
            await ensureDirExists(backupUserDir);
            const backupPath = path.join(backupUserDir, serverFilename);
            try {
                await fs.rename(currentPath, backupPath);
                results.filesystem = { success: true, message: "File moved to backup successfully." };
                console.log(`Filesystem: Moved '${currentPath}' to '${backupPath}'.`);
            } catch (fsError) {
                console.error(`Filesystem: Error moving file ${currentPath} to backup for ${logContext}:`, fsError);
                results.filesystem.message = `Filesystem move to backup failed: ${fsError.message}`;
                // overallSuccess = false; // Decide if this is critical enough to mark overall failure
            }
        } else {
            results.filesystem.message = "Physical file not found in assets, or already moved.";
            console.log(`Filesystem: Physical file '${serverFilename}' not found for user ${usernameForLog}.`);
        }

        // Determine final status and message
        const successfulDeletes = [results.mongodb.success, results.qdrant.success, results.neo4j.success, results.filesystem.success].filter(Boolean).length;

        if (!fileFoundInMongo && !physicalFileFound) {
            httpStatus = 404;
            finalMessage = `File '${originalName}' not found for user.`;
        } else if (results.mongodb.success) { // Primary record deleted
            if (successfulDeletes === 4) {
                finalMessage = `Successfully deleted all data associated with '${originalName}'.`;
                httpStatus = 200;
            } else {
                finalMessage = `File '${originalName}' removed from your list. Some backend data cleanup attempts had issues. Check server logs for details.`;
                httpStatus = 207; // Multi-Status
            }
        } else { // MongoDB deletion failed, but file might have existed
            finalMessage = `Failed to remove '${originalName}' from your list. Some backend data cleanup may have also failed. Check server logs.`;
            httpStatus = 500;
        }

        console.log(`Deletion outcome for ${logContext}: HTTP Status=${httpStatus}, Overall Success Flag (was pre-status logic)=${overallSuccess}`);
        return res.status(httpStatus).json({
            message: finalMessage,
            details: results
        });

    } catch (error) {
        console.error(`!!! UNEXPECTED Error in DELETE /api/files/${serverFilename} for user ${usernameForLog}:`, error);
        return res.status(500).json({
            message: 'An unexpected server error occurred during file deletion.',
            details: results // Send partial results if any
        });
    }
});


module.exports = router;

```

`server/routes/mindmap.js`

```javascript
// server/routes/mindmap.js
const express = require('express');
const router = express.Router();
const { authMiddleware } = require('../middleware/authMiddleware');
const User = require('../models/User'); // For a more advanced implementation

// @route   GET /api/mindmap
// @desc    Get Mermaid code for a mind map
// @access  Private (requires auth)
router.get('/', authMiddleware, async (req, res) => {
    const userId = req.user._id; // User is authenticated
    console.log(`>>> GET /api/mindmap: User=${userId}`);

    try {
        const user = await User.findById(userId).select('uploadedDocuments.filename uploadedDocuments.analysis.mindmap'); // Select only necessary fields
        
        let mindmapCode = null;
        let sourceDocumentName = "Unknown Document";

        if (user && user.uploadedDocuments && user.uploadedDocuments.length > 0) {
            // Find the most recent document that has a mindmap analysis.
            // This assumes higher index means more recent, or you'd sort by an explicit timestamp if available.
            for (let i = user.uploadedDocuments.length - 1; i >= 0; i--) {
                const doc = user.uploadedDocuments[i];
                if (doc.analysis && typeof doc.analysis.mindmap === 'string' && doc.analysis.mindmap.trim() !== "") {
                    mindmapCode = doc.analysis.mindmap.trim();
                    sourceDocumentName = doc.filename || "Untitled Document";
                    console.log(`   Found mindmap for document '${sourceDocumentName}' for user ${userId}.`);
                    break;
                }
            }
        }

        if (mindmapCode) {
            // Basic check if the code starts with a known Mermaid diagram type.
            // This is a simple heuristic. Robust validation is complex.
            const trimmedCode = mindmapCode; // Already trimmed
            const validMermaidPrefixes = ['mindmap', 'graph', 'flowchart', 'sequenceDiagram', 'gantt', 'classDiagram', 'stateDiagram', 'pie', 'erDiagram', 'journey', 'requirementDiagram', 'gitGraph'];
            
            const isPotentiallyValidMermaid = validMermaidPrefixes.some(prefix => 
                trimmedCode.toLowerCase().startsWith(prefix)
            );

            if (!isPotentiallyValidMermaid) {
                // If the stored code doesn't look like Mermaid, prepend 'mindmap'
                // This is an assumption that the stored data *should* be a mindmap if it's in this field.
                console.warn(`   Mindmap code for '${sourceDocumentName}' does not start with a recognized Mermaid type. Prefixing with 'mindmap'.`);
                mindmapCode = `mindmap\n${trimmedCode}`; 
            } else if (!trimmedCode.toLowerCase().startsWith('mindmap')) {
                 // If it's valid Mermaid but not explicitly 'mindmap' (e.g. 'graph TD'),
                 // and the user specifically clicked "Mind Map", it's still okay to send.
                 // The Mermaid library on the frontend can render various diagram types.
                console.log(`   Sending stored analysis as Mermaid diagram. Type: ${trimmedCode.split('\n')[0].trim()}`);
            }
            return res.status(200).json({ mermaidCode: mindmapCode, source: sourceDocumentName });
        } else {
            console.log(`   No mindmap analysis found for user ${userId}. Returning default mindmap.`);
            const defaultMermaidCode = `
mindmap
  root((No Mind Map Available))
    (Please upload a document and ensure its analysis includes a mind map.)
    (Or, no documents processed yet.)
`;
            return res.status(200).json({ mermaidCode: defaultMermaidCode, source: "Default" });
        }

    } catch (error) {
        console.error(`!!! Error in GET /api/mindmap for User ${userId}:`, error);
        res.status(500).json({ message: "Failed to retrieve mind map code due to a server error." });
    }
});

module.exports = router;
```

`server/routes/network.js`

```javascript
const express = require('express');
const router = express.Router();
const os = require('os');

function getAllIPs() {
    const interfaces = os.networkInterfaces();
    const ips = new Set(['localhost']); // Include localhost by default

    for (const [name, netInterface] of Object.entries(interfaces)) {
        // Skip loopback and potentially virtual interfaces if desired
        if (name.includes('lo') || name.toLowerCase().includes('virtual') || name.toLowerCase().includes('vmnet')) continue;

        for (const addr of netInterface) {
            // Focus on IPv4, non-internal addresses
            if (addr.family === 'IPv4' && !addr.internal) {
                ips.add(addr.address);
            }
        }
    }
    return Array.from(ips);
}

router.get('/ip', (req, res) => {
    res.json({
        ips: getAllIPs(),
        // req.ip might be less reliable behind proxies, but can be included
        // currentRequestIp: req.ip
    });
});

module.exports = router;

```

`server/routes/subjects.js`

```javascript
// server/routes/subjects.js
const express = require('express');
const router = express.Router();
const AdminDocument = require('../models/AdminDocument'); // Model for admin-uploaded documents

// @route   GET /api/subjects
// @desc    Get a list of available subject names (derived from admin-uploaded document originalNames)
// @access  Private (Regular User Authenticated via JWT)
router.get('/', async (req, res) => {
    // req.user is available here from authMiddleware
    console.log(`User ${req.user.username} is requesting the list of subjects.`);
    try {
        // Fetch distinct originalName values from the AdminDocument collection
        // and sort them alphabetically.
        const subjectObjects = await AdminDocument.find().sort({ originalName: 1 }).select('originalName').lean();
        const subjectNames = subjectObjects.map(doc => doc.originalName);
        
        // Alternative using distinct, but sorting might be different or need post-processing
        // const subjectNames = await AdminDocument.distinct('originalName').exec();
        // subjectNames.sort((a, b) => a.localeCompare(b));


        res.json({ subjects: subjectNames }); // Send as { subjects: ["Subject 1", "Subject 2", ...] }
    } catch (error) {
        console.error("Error fetching subjects for user display:", error);
        res.status(500).json({ message: "Server error while fetching available subjects." });
    }
});

module.exports = router;
```

`server/routes/syllabus.js`

```javascript
// server/routes/syllabus.js
const express = require('express');
const fs = require('fs').promises;
const path = require('path');
const { authMiddleware } = require('../middleware/authMiddleware'); // Protect the route

const router = express.Router();
const SYLLABI_DIR = path.join(__dirname, '..', 'syllabi');

// --- @route   GET /api/syllabus/:subjectId ---
// --- @desc    Get syllabus content for a specific subject ---
// --- @access  Private (requires auth) ---
router.get('/:subjectId', authMiddleware, async (req, res) => {
    const { subjectId } = req.params;

    // Basic sanitization: Allow only alphanumeric and underscores
    // Prevents directory traversal (e.g., ../../etc/passwd)
    const sanitizedSubjectId = subjectId.replace(/[^a-zA-Z0-9_]/g, '');

    if (!sanitizedSubjectId || sanitizedSubjectId !== subjectId) {
        console.warn(`Syllabus request rejected due to invalid characters: ${subjectId}`);
        return res.status(400).json({ message: 'Invalid subject identifier format.' });
    }

    const filePath = path.join(SYLLABI_DIR, `${sanitizedSubjectId}.md`);

    try {
        // Check if file exists first (more specific error)
        await fs.access(filePath);

        // Read the file content
        const content = await fs.readFile(filePath, 'utf-8');

        res.status(200).json({ syllabus: content });

    } catch (error) {
        if (error.code === 'ENOENT') {
            console.warn(`Syllabus file not found: ${filePath}`);
            return res.status(404).json({ message: `Syllabus for '${subjectId}' not found.` });
        } else {
            console.error(`Error reading syllabus file ${filePath}:`, error);
            return res.status(500).json({ message: 'Server error retrieving syllabus.' });
        }
    }
});

module.exports = router;

```

`server/routes/upload.js`

```javascript
// server/routes/upload.js
const express = require('express');
const multer = require('multer');
const path = require('path');
const fs = require('fs');
const axios = require('axios');
const { authMiddleware } = require('../middleware/authMiddleware');
const User = require('../models/User'); // Import the User model
const { Worker } = require('worker_threads');
// const { ANALYSIS_PROMPTS } = require('../config/promptTemplates'); 
// const geminiService = require('../services/geminiService');

const router = express.Router();

// --- Constants ---
const UPLOAD_DIR = path.join(__dirname, '..', 'assets');
const MAX_FILE_SIZE = 20 * 1024 * 1024; // 20 MB

// Define allowed types by mimetype and extension (lowercase)
// Mapping mimetype to subfolder name
const allowedMimeTypes = {
    // Documents -> 'docs'
    'application/pdf': 'docs',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document': 'docs', // .docx
    'application/msword': 'docs', // .doc (Might be less reliable mimetype)
    'application/vnd.openxmlformats-officedocument.presentationml.presentation': 'docs', // .pptx
    'application/vnd.ms-powerpoint': 'docs', // .ppt (Might be less reliable mimetype)
    'text/plain': 'docs', // .txt
    // Code -> 'code'
    'text/x-python': 'code', // .py
    'application/javascript': 'code', // .js
    'text/javascript': 'code', // .js (alternative)
    'text/markdown': 'code', // .md
    'text/html': 'code', // .html
    'application/xml': 'code', // .xml
    'text/xml': 'code', // .xml
    'application/json': 'code', // .json
    'text/csv': 'code', // .csv
    // Images -> 'images'
    'image/jpeg': 'images',
    'image/png': 'images',
    'image/bmp': 'images',
    'image/gif': 'images',
    // Add more specific types if needed, otherwise they fall into 'others'
};
// Define allowed extensions (lowercase) - This is a secondary check
const allowedExtensions = [
    '.pdf', '.docx', '.doc', '.pptx', '.ppt', '.txt',
    '.py', '.js', '.md', '.html', '.xml', '.json', '.csv', '.log', // Added .log
    '.jpg', '.jpeg', '.png', '.bmp', '.gif'
];

// --- Multer Config ---
const storage = multer.diskStorage({
    destination: (req, file, cb) => {
        // authMiddleware middleware ensures req.user exists here
        if (!req.user || !req.user.username) {
            // This should ideally not happen if authMiddleware works correctly
            console.error("Multer Destination Error: User context missing after auth middleware.");
            return cb(new Error("Authentication error: User context not found."));
        }
        const sanitizedUsername = req.user.username.replace(/[^a-zA-Z0-9_-]/g, '_');
        const fileMimeType = file.mimetype.toLowerCase();

        // Determine subfolder based on mimetype, default to 'others'
        const fileTypeSubfolder = allowedMimeTypes[fileMimeType] || 'others';
        const destinationPath = path.join(UPLOAD_DIR, sanitizedUsername, fileTypeSubfolder);

        // Ensure the destination directory exists (use async for safety)
        fs.mkdir(destinationPath, { recursive: true }, (err) => {
             if (err) {
                 console.error(`Error creating destination path ${destinationPath}:`, err);
                 cb(err);
             } else {
                 cb(null, destinationPath);
             }
         });
    },
    filename: (req, file, cb) => {
        const timestamp = Date.now();
        const fileExt = path.extname(file.originalname).toLowerCase();
        // Sanitize base name: remove extension, replace invalid chars, limit length
        const sanitizedBaseName = path.basename(file.originalname, fileExt)
                                      .replace(/[^a-zA-Z0-9._-]/g, '_') // Allow letters, numbers, dot, underscore, hyphen
                                      .substring(0, 100); // Limit base name length
        const uniqueFilename = `${timestamp}-${sanitizedBaseName}${fileExt}`;
        cb(null, uniqueFilename);
    }
});

const fileFilter = (req, file, cb) => {
    // authMiddleware middleware should run before this, ensuring req.user exists
    if (!req.user) {
         console.warn(`Upload Rejected (File Filter): User context missing.`);
         const error = new multer.MulterError('UNAUTHENTICATED'); // Custom code?
         error.message = `User not authenticated.`;
         return cb(error, false);
    }

    const fileExt = path.extname(file.originalname).toLowerCase();
    const mimeType = file.mimetype.toLowerCase();

    // Primary check: Mimetype must be in our known list OR extension must be allowed
    // Secondary check: Extension must be in the allowed list
    const isMimeTypeKnown = !!allowedMimeTypes[mimeType];
    const isExtensionAllowed = allowedExtensions.includes(fileExt);

    // Allow if (MIME type is known OR extension is explicitly allowed) AND extension is in the allowed list
    // This allows known MIME types even if extension isn't listed, and listed extensions even if MIME isn't known (e.g. text/plain for .log)
    // But we always require the extension itself to be in the allowed list for safety.
    // if ((isMimeTypeKnown || isExtensionAllowed) && isExtensionAllowed) {

    // Stricter: Allow only if BOTH mimetype is known AND extension is allowed
    if (isMimeTypeKnown && isExtensionAllowed) {
        cb(null, true); // Accept file
    } else {
        console.warn(`Upload Rejected (File Filter): User='${req.user.username}', File='${file.originalname}', MIME='${mimeType}', Ext='${fileExt}'. MimeKnown=${isMimeTypeKnown}, ExtAllowed=${isExtensionAllowed}`);
        const error = new multer.MulterError('LIMIT_UNEXPECTED_FILE');
        error.message = `Invalid file type or extension. Allowed extensions: ${allowedExtensions.join(', ')}`;
        cb(error, false); // Reject file
    }
};

const upload = multer({
    storage: storage,
    fileFilter: fileFilter,
    limits: { fileSize: MAX_FILE_SIZE }
});
// --- End Multer Config ---


// --- Function to call Python RAG service ---
async function triggerPythonRagProcessing(userId, filePath, originalName) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
    if (!pythonServiceUrl) {
        console.error("PYTHON_RAG_SERVICE_URL is not set in environment. Cannot trigger RAG processing.");
        return {
            success: false,
            message: "RAG service URL not configured.",
            status: 'error', // Indicate a config error
            text: null,
            chunksForKg: []
        };
    }

    const addDocumentUrl = `${pythonServiceUrl}/add_document`;
    console.log(`Calling Python RAG Service: ${addDocumentUrl} for document '${originalName}' (User: ${userId})`);

    try {
        const response = await axios.post(addDocumentUrl, {
            user_id: userId,
            file_path: filePath, // Absolute path to the file on the server
            original_name: originalName
        }); // 5 minute timeout

        const pythonData = response.data;
        // console.log(`Python RAG service response for '${originalName}':`, JSON.stringify(pythonData).substring(0, 500) + "..."); // Log snippet

        // Extract data carefully, providing defaults
        const text = pythonData?.raw_text_for_analysis || null;
        const chunksForKg = pythonData?.chunks_with_metadata || [];
        const pythonStatus = pythonData?.status; // e.g., 'added', 'skipped_no_content', 'processed_qdrant_chunks_not_added', etc.
        let pythonMessage = pythonData?.message || "No specific message from Python RAG service.";

        // Determine overall success for the RAG step based on Python's status
        // 'added' means Qdrant was updated, which is the primary goal for RAG.
        // 'processed_for_analysis_only_no_qdrant' means text was extracted but Qdrant failed/skipped. This might still be a "partial success" if text is valuable.
        // For now, let's consider 'added' as the main success criteria for proceeding with text-dependent tasks.
        const isRagStepSuccessful = pythonStatus === 'added';

        if (!isRagStepSuccessful && !text) {
            // If RAG didn't succeed in adding to Qdrant AND there's no text, it's a more significant failure.
            pythonMessage = `RAG processing critical failure: ${pythonMessage} (Status: ${pythonStatus})`;
        } else if (!isRagStepSuccessful && text) {
            pythonMessage = `RAG processing partial: ${pythonMessage} (Status: ${pythonStatus}). Text was extracted, but Qdrant step may have issues.`;
        }


        return {
            success: isRagStepSuccessful, // True primarily if pythonStatus is 'added'
            status: pythonStatus,         // The actual status string from Python
            message: pythonMessage,
            text: text,                   // Extracted text (can be null)
            chunksForKg: chunksForKg      // Chunks for KG (can be empty)
        };

    } catch (error) {
        const errorMsg = error.response?.data?.error || error.response?.data?.message || error.message || "Unknown error calling Python RAG service";
        console.error(`Error calling Python RAG service for '${originalName}': ${errorMsg}`);
        // Log more details if available from error.response
        if (error.response && error.response.data) {
            // console.error("Python service error details:", error.response.data);
        }
        return {
            success: false,
            message: `Python RAG service call failed: ${errorMsg}`,
            status: 'error_calling_python', // Custom status for this type of failure
            text: null,
            chunksForKg: []
        };
    }
}
// --- End Function ---


// --- Function to call Generate Analysis
async function triggerAnalysisGeneration(userId, originalName, textForAnalysis) {
    console.log(`Starting analysis generation for document '${originalName}', User ID: ${userId}. Text length: ${textForAnalysis.length}`);

    let allAnalysesSuccessful = true; // Assume success initially
    const analysisResults = {
        faq: null,
        topics: null,
        mindmap: null
    };
    const logCtx = { userId, originalName }; // Context for logging within generateSingleAnalysis

    // Inner helper function to generate a single type of analysis
    async function generateSingleAnalysis(type, promptContent, context) {
        try {
            console.log(`Attempting to generate ${type} for '${context.originalName}' (User: ${context.userId}).`);

            // Prepare history for geminiService.generateContentWithHistory
            // The 'promptContent' (which is the system prompt) will be passed as the second argument.
            const historyForGemini = [
                { role: 'user', parts: [{ text: "Please perform the requested analysis based on the system instruction provided." }] }
            ];

            const generatedText = await geminiService.generateContentWithHistory(
                historyForGemini,
                promptContent // This is passed as systemPromptText to generateContentWithHistory
            );

            if (!generatedText || typeof generatedText !== 'string' || generatedText.trim() === "") {
                console.warn(`Gemini returned empty or invalid content for ${type} for '${context.originalName}'.`);
                allAnalysesSuccessful = false; // Update the outer scope variable
                return `Notice: No content was generated by the AI for ${type}. The input text might have been unsuitable or the AI returned an empty response.`;
            }

            console.log(`${type} generation successful for '${context.originalName}'. Length: ${generatedText.length}`);
            return generatedText.trim();

        } catch (error) {
            console.error(`Error during ${type} generation for '${context.originalName}' (User: ${context.userId}): ${error.message}`);
            allAnalysesSuccessful = false; // Update the outer scope variable
            // Return a user-friendly error message, or a snippet of the technical error
            const errorMessage = error.message || "Unknown error during AI generation.";
            return `Error generating ${type}: ${errorMessage.split('\n')[0].substring(0, 250)}`; // First line of error, truncated
        }
    }

    // 1. Generate FAQs
    console.log(`[Analysis Step 1/3] Preparing FAQ generation for '${originalName}'.`);
    const faqPrompt = ANALYSIS_PROMPTS.faq.getPrompt(textForAnalysis);
    analysisResults.faq = await generateSingleAnalysis('FAQ', faqPrompt, logCtx);
    if (!allAnalysesSuccessful) {
        console.warn(`FAQ generation failed or produced no content for '${originalName}'. Continuing to next analysis type.`);
        // We continue even if one fails, allAnalysesSuccessful flag will reflect the overall status.
    }

    // 2. Generate Topics
    console.log(`[Analysis Step 2/3] Preparing Topics generation for '${originalName}'.`);
    const topicsPrompt = ANALYSIS_PROMPTS.topics.getPrompt(textForAnalysis);
    analysisResults.topics = await generateSingleAnalysis('Topics', topicsPrompt, logCtx);
    if (!allAnalysesSuccessful && analysisResults.topics.startsWith("Error generating Topics:")) { // Check if this specific step failed
        console.warn(`Topics generation failed or produced no content for '${originalName}'. Continuing to next analysis type.`);
    }


    // 3. Generate Mindmap
    console.log(`[Analysis Step 3/3] Preparing Mindmap generation for '${originalName}'.`);
    const mindmapPrompt = ANALYSIS_PROMPTS.mindmap.getPrompt(textForAnalysis);
    analysisResults.mindmap = await generateSingleAnalysis('Mindmap', mindmapPrompt, logCtx);
    if (!allAnalysesSuccessful && analysisResults.mindmap.startsWith("Error generating Mindmap:")) { // Check if this specific step failed
        console.warn(`Mindmap generation failed or produced no content for '${originalName}'.`);
    }

    // Log final outcome of the analysis generation process
    if (allAnalysesSuccessful) {
        console.log(`All analyses (FAQ, Topics, Mindmap) appear to have been generated successfully for '${originalName}'.`);
    } else {
        console.warn(`One or more analyses failed or produced no content for '${originalName}'. Review individual results for details.`);
        // Log the specific results for easier debugging
        console.warn(`FAQ Result for '${originalName}': ${analysisResults.faq.substring(0,100)}...`);
        console.warn(`Topics Result for '${originalName}': ${analysisResults.topics.substring(0,100)}...`);
        console.warn(`Mindmap Result for '${originalName}': ${analysisResults.mindmap.substring(0,100)}...`);
    }

    return {
        success: allAnalysesSuccessful,
        results: analysisResults
    };
}
// --- End Analysis Generation Function ---


router.post('/', authMiddleware, (req, res) => {
    const uploader = upload.single('file');

    uploader(req, res, async function (err) {
        if (!req.user) {
            console.error("Upload Route: User context missing after auth middleware.");
            return res.status(401).json({ message: "Authentication error: User context not found." });
        }
        const userId = req.user._id.toString();
        const username = req.user.username;

        let absoluteFilePath = null; // Will be set if file is processed by multer
        let originalName = null;
        let serverFilename = null;

        if (err) {
            console.error(`Upload Route: Multer error for user '${username}': ${err.message}`);
            if (err instanceof multer.MulterError) {
                return res.status(400).json({ message: err.message });
            }
            return res.status(500).json({ message: "Server error during upload preparation." });
        }

        if (!req.file) {
            console.warn(`Upload Route: No file received for user '${username}'.`);
            return res.status(400).json({ message: "No file received or file type rejected by filter." });
        }

        // File successfully received by multer
        absoluteFilePath = path.resolve(req.file.path);
        originalName = req.file.originalname;
        serverFilename = req.file.filename;
        console.log(`Upload Route: File received for user '${username}'. Server Filename: ${serverFilename}, Original: ${originalName}`);

        // Fetch user's LLM preferences for workers
        const userLlmPrefs = await User.findById(userId).select('preferredLlmProvider ollamaModel').lean();
        const llmProviderForWorkers = userLlmPrefs?.preferredLlmProvider || 'gemini'; // Default to gemini if not set
        const ollamaModelForWorkers = userLlmPrefs?.ollamaModel || process.env.OLLAMA_DEFAULT_MODEL;

        try {
            // ----- STAGE 1: MongoDB Pre-check for existing originalName -----
            const userForPreCheck = await User.findById(userId).select('uploadedDocuments.filename'); // Only need filename
            if (!userForPreCheck) {
                console.error(`Upload Route: User ${userId} ('${username}') not found during pre-check. Deleting uploaded file: ${absoluteFilePath}`);
                await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Upload Route Cleanup: Error deleting file (user not found): ${e.message}`));
                return res.status(404).json({ message: "User not found, cannot process upload." });
            }
            const existingDocument = userForPreCheck.uploadedDocuments.find(doc => doc.filename === originalName);
            if (existingDocument) {
                console.log(`Upload Route: File '${originalName}' already exists for user '${username}'. Deleting uploaded file: ${absoluteFilePath}`);
                await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Upload Route Cleanup: Error deleting file (duplicate): ${e.message}`));
                return res.status(409).json({
                    message: `File '${originalName}' already exists. No new processing initiated.`,
                    filename: serverFilename,
                    originalname: originalName,
                });
            }
            console.log(`Upload Route: Pre-check passed for '${originalName}' (User: '${username}'). Proceeding to RAG processing.`);

            // ----- STAGE 2: RAG Processing (Synchronous Call to Python Service) -----
            // This call extracts text, chunks, and gets data ready for Qdrant.
            // It needs to complete before we can save the initial document record and respond to the user.
            const ragResult = await triggerPythonRagProcessing(userId, absoluteFilePath, originalName);
            // Expected ragResult: { success, status ('added' or 'skipped'), text, chunksForKg, message }

            if (!ragResult.success || ragResult.status !== 'added' || !ragResult.text || ragResult.text.trim() === '') {
                const errorMessage = (ragResult && ragResult.message) || "RAG processing failed or returned insufficient data from Python service.";
                console.error(`Upload Route Error: RAG processing failed for '${originalName}' (User: '${username}'): ${errorMessage}. Python Status: ${ragResult.status}. Deleting file.`);
                if (absoluteFilePath) { // Check if path is still valid
                    await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Upload Route Cleanup: Error deleting file (RAG fail): ${e.message}`));
                }
                return res.status(500).json({ // Or 422 if it's a content issue from RAG
                    message: errorMessage,
                    filename: serverFilename, originalname: originalName
                });
            }
            console.log(`Upload Route: RAG processing by Python service completed for '${originalName}'. Text obtained. Python Status: ${ragResult.status}.`);

            // ----- STAGE 2.5: Initial MongoDB Save for the Document Entry -----
            // This creates the document shell with the text from RAG and pending statuses.
            const newDocumentEntryData = {
                filename: originalName,
                text: ragResult.text, // Save the text obtained from RAG
                analysis: { faq: "", topics: "", mindmap: "" }, // Initialize
                uploadedAt: new Date(),
                ragStatus: ragResult.status, // Should be 'added' here
                analysisStatus: "pending",   // Will be updated by analysisWorker
                kgStatus: "pending"          // Will be updated by kgWorker
            };

            try {
                await User.updateOne(
                    { _id: userId },
                    { $push: { uploadedDocuments: newDocumentEntryData } }
                );
                console.log(`Upload Route: Initial document entry for '${originalName}' saved to user '${username}' in MongoDB.`);
            } catch (dbError) {
                console.error(`Upload Route Error: MongoDB error saving initial document entry for '${originalName}': ${dbError.message}. Deleting file.`);
                if (absoluteFilePath) {
                    await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Upload Route Cleanup: Error deleting file (initial DB save fail): ${e.message}`));
                }
                // This is a server error, RAG was successful but we couldn't save.
                return res.status(500).json({ message: `Database error after RAG processing: ${dbError.message}`, filename: serverFilename, originalname: originalName });
            }

            // ----- IMMEDIATE RESPONSE TO CLIENT -----
            // Respond now, indicating acceptance and background processing.
            res.status(202).json({ // HTTP 202 Accepted
                message: `File '${originalName}' uploaded successfully. Processing has started in the background.`,
                filename: serverFilename, // Server-generated filename
                originalname: originalName,   // Original filename from user
                initialStatus: {
                    rag: ragResult.status,
                    analysis: "pending",
                    knowledgeGraph: "pending"
                }
            });
            console.log(`Upload Route: Sent 202 Accepted to client for '${originalName}'. Offloading further tasks.`);


            // ----- BACKGROUND PROCESSING INITIATION (AFTER RESPONSE) -----

            // Offload Analysis Generation to a Worker
            if (ragResult.text && ragResult.text.trim() !== '') {
                console.log(`[Upload Route BG] Initiating Analysis Worker for '${originalName}'`);
                const analysisWorkerPath = path.resolve(__dirname, '../workers/analysisWorker.js');
                try {
                    const analysisWorker = new Worker(analysisWorkerPath, {
                        workerData: {
                            userId: userId,
                            originalName: originalName,
                            textForAnalysis: ragResult.text, // Pass the full text
                            llmProvider: llmProviderForWorkers,
                            ollamaModel: ollamaModelForWorkers
                        }
                    });
                    analysisWorker.on('message', (msg) => console.log(`[Upload Route BG] Analysis Worker [Doc: ${msg.originalName || originalName}]: ${msg.message || JSON.stringify(msg)}`));
                    analysisWorker.on('error', (err) => console.error(`[Upload Route BG] Analysis Worker Error [Doc: ${originalName}]:`, err));
                    analysisWorker.on('exit', (code) => console.log(`[Upload Route BG] Analysis Worker [Doc: ${originalName}] exited (code ${code}).`));
                } catch (workerLaunchError) {
                    console.error(`[Upload Route BG] Failed to launch Analysis Worker for '${originalName}':`, workerLaunchError);
                    // Log this error, perhaps update DB doc analysisStatus to 'launch_failed'
                    User.updateOne(
                        { _id: userId, "uploadedDocuments.filename": originalName },
                        { $set: { "uploadedDocuments.$.analysisStatus": "launch_failed" } }
                    ).catch(e => console.error("DB update error for analysis launch fail (background):", e));
                }
            } else {
                console.warn(`[Upload Route BG] Skipping Analysis Worker for '${originalName}' due to no text from RAG.`);
                User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: { "uploadedDocuments.$.analysisStatus": "skipped_no_text" } }
                ).catch(e => console.error("DB update error for analysis skipped (background):", e));
            }

            // Offload KG Generation to a Worker
            // Ensure ragResult.chunksForKg is correctly populated by triggerPythonRagProcessing
            if (ragResult.status === "added" && ragResult.chunksForKg && ragResult.chunksForKg.length > 0) {
                console.log(`[Upload Route BG] Initiating KG Worker for '${originalName}'. Chunks: ${ragResult.chunksForKg.length}`);
                const kgWorkerScriptPath = path.resolve(__dirname, '../workers/kgWorker.js');
                try {
                    const kgWorker = new Worker(kgWorkerScriptPath, {
                        workerData: {
                            chunksForKg: ragResult.chunksForKg, // This comes from Python
                            userId: userId,
                            originalName: originalName,
                            llmProvider: llmProviderForWorkers,
                            ollamaModel: ollamaModelForWorkers
                        }
                    });
                    kgWorker.on('message', (msg) => console.log(`[Upload Route BG] KG Worker [Doc: ${msg.originalName || originalName}]: ${msg.message || JSON.stringify(msg)}`));
                    kgWorker.on('error', (workerErr) => console.error(`[Upload Route BG] KG Worker Error [Doc: ${originalName}]:`, workerErr));
                    kgWorker.on('exit', (code) => console.log(`[Upload Route BG] KG Worker [Doc: ${originalName}] exited (code ${code}).`));
                } catch (workerLaunchError) {
                    console.error(`[Upload Route BG] Failed to launch KG worker for '${originalName}':`, workerLaunchError);
                    User.updateOne(
                        { _id: userId, "uploadedDocuments.filename": originalName },
                        { $set: { "uploadedDocuments.$.kgStatus": "launch_failed" } }
                    ).catch(e => console.error("DB update error for KG launch fail (background):", e));
                }
            } else {
                let kgSkipReason = "skipped_rag_issue";
                if (ragResult.chunksForKg && ragResult.chunksForKg.length === 0) {
                    kgSkipReason = "skipped_no_chunks";
                }
                console.log(`[Upload Route BG] KG Worker not triggered for '${originalName}'. RAG Status: ${ragResult.status}, Chunks: ${ragResult.chunksForKg ? ragResult.chunksForKg.length : 'N/A'}`);
                User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: { "uploadedDocuments.$.kgStatus": kgSkipReason } }
                ).catch(e => console.error("DB update error for KG skipped (background):", e));
            }

            // Optional: Delete the physical uploaded file from the 'assets' directory
            // Do this only if the text content is reliably stored in MongoDB (ragResult.text)
            // and workers have what they need (text or chunk data).
            if (absoluteFilePath) {
                console.log(`[Upload Route BG] Attempting to delete temporary uploaded file: ${absoluteFilePath} as processing is fully offloaded.`);
                await fs.promises.unlink(absoluteFilePath)
                    .catch(e => console.error(`[Upload Route BG] Non-critical: Failed to delete temp file ${absoluteFilePath} after offloading: ${e.message}`));
                absoluteFilePath = null; // Mark as deleted
            }

        } catch (processError) {
            // This catch block handles errors from STAGE 1, 2, or 2.5, or any unhandled synchronous error
            console.error(`Upload Route: !!! Overall processing error for ${originalName || 'unknown file'} (User: '${username}'):`, processError.message, processError.stack);
            if (absoluteFilePath) { // If file path is known, try to delete it
                await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Upload Route Cleanup: Error deleting file (overall fail): ${e.message}`));
            }
            // If res hasn't been sent (e.g., error before 202 response)
            if (!res.headersSent) {
                return res.status(500).json({
                    message: `Server error during file processing: ${processError.message || 'Unknown error.'}`,
                    filename: serverFilename, // May be null if error was very early
                    originalname: originalName // May be null
                });
            } else {
                // If response was already sent, we can only log the error.
                // A separate mechanism might be needed to update the user/DB about this failure.
                console.error(`Upload Route: Error occurred for ${originalName} after 202 response was sent. This indicates a problem in the background initiation logic itself or unhandled promise rejection before workers fully take over.`);
            }
        }
    }); 
});



module.exports = router;

```

`server/server.js`

```javascript
// server/server.js
const express = require('express');
const dotenv = require('dotenv');
const cors = require('cors');
const path = require('path');
const { getLocalIPs } = require('./utils/networkUtils');
const fs = require('fs'); // Keep fs for existsSync, fs.promises for async operations
const axios = require('axios');
const os = require('os');
const mongoose = require('mongoose');
const readline = require('readline').createInterface({
  input: process.stdin,
  output: process.stdout,
});
const { fixedAdminAuthMiddleware } = require('./middleware/fixedAdminAuthMiddleware'); 

// --- Custom Modules ---
const connectDB = require('./config/db');
const { performAssetCleanup } = require('./utils/assetCleanup');
 // Import new middleware

// --- Configuration Loading ---
dotenv.config(); // Load environment variables

// --- Configuration Defaults & Variables ---
const DEFAULT_PORT = 5001;
const DEFAULT_MONGO_URI = 'mongodb://localhost:27017/chatbotGeminiDB';
const DEFAULT_PYTHON_RAG_URL = 'http://localhost:5000';

let port = process.env.PORT || DEFAULT_PORT;
let mongoUri = process.env.MONGO_URI || '';
let pythonRagUrl = process.env.PYTHON_RAG_SERVICE_URL || '';
let geminiApiKey = process.env.GEMINI_API_KEY || '';

// Ensure JWT_SECRET is loaded and available
if (!process.env.JWT_SECRET) {
    console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
    console.error("!!! FATAL: JWT_SECRET environment variable is not set.       !!!");
    console.error("!!! Please set it in your .env file before running:        !!!");
    console.error("!!! JWT_SECRET='your_super_strong_and_secret_jwt_key'      !!!");
    console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
    process.exit(1);
}

// --- Express Application Setup ---
const app = express();

// --- Core Middleware ---
app.use(cors());
app.use(express.json());

// --- Basic Root Route ---
app.get('/', (req, res) => res.send('Chatbot Backend API is running...'));

// --- API Route Mounting ---
// Public routes (like network info, and the auth routes for signup/signin)
// server/server.js
// ... other imports ...
const { authMiddleware } = require('./middleware/authMiddleware'); // Correct import

// ...
// --- API Route Mounting ---
app.use('/api/network', require('./routes/network'));
app.use('/api/auth', require('./routes/auth'));

// Protected routes
app.use('/api/chat', authMiddleware, require('./routes/chat'));
app.use('/api/upload', authMiddleware, require('./routes/upload'));
app.use('/api/files', authMiddleware, require('./routes/files'));
app.use('/api/syllabus', authMiddleware, require('./routes/syllabus'));
app.use('/api/mindmap', authMiddleware, require('./routes/mindmap'));
app.use('/api/analysis', authMiddleware, require('./routes/analysis')); 
app.use('/api/admin/documents', require('./routes/adminDocuments'));
app.use('/api/subjects', authMiddleware, require('./routes/subjects'));

// app.use('/api/kg', authMiddleware, require('./routes/kg'));


// --- Centralized Error Handling Middleware ---
app.use((err, req, res, next) => {
    console.error("Unhandled Error:", err.stack || err);
    const statusCode = err.status || 500;
    let message = err.message || 'An internal server error occurred.';
    if (process.env.NODE_ENV === 'production' && statusCode === 500) {
        message = 'An internal server error occurred.';
    }
    if (req.originalUrl.startsWith('/api/')) {
         return res.status(statusCode).json({ message: message });
    }
    // Fallback for non-API routes if any
    res.status(statusCode).send(message);
});

// --- Server Instance Variable ---
let server;

// --- Graceful Shutdown Logic ---
const gracefulShutdown = async (signal) => {
    console.log(`\n${signal} received. Shutting down gracefully...`);
    readline.close();
    try {
        if (server) {
            server.close(async () => {
                console.log('HTTP server closed.');
                try {
                    await mongoose.connection.close();
                    console.log('MongoDB connection closed.');
                } catch (dbCloseError) {
                    console.error("Error closing MongoDB connection:", dbCloseError);
                }
                process.exit(0);
            });
        } else {
             try {
                 await mongoose.connection.close();
                 console.log('MongoDB connection closed (no HTTP server instance).');
             } catch (dbCloseError) {
                 console.error("Error closing MongoDB connection:", dbCloseError);
             }
            process.exit(0);
        }

        setTimeout(() => {
            console.error('Graceful shutdown timed out, forcing exit.');
            process.exit(1);
        }, 10000);

    } catch (shutdownError) {
        console.error("Error during graceful shutdown initiation:", shutdownError);
        process.exit(1);
    }
};

process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
process.on('SIGINT', () => gracefulShutdown('SIGINT'));

// --- RAG Service Health Check ---
async function checkRagService(url) {
    console.log(`\nChecking RAG service health at ${url}...`);
    try {
        const response = await axios.get(`${url}/health`, { timeout: 7000 });
        if (response.status === 200 && response.data?.status === 'ok') {
            console.log(' Python RAG service is available and healthy.');
            // Log details from the Python health check
            const services = response.data.services || {};
            const qdrantStatus = services.qdrant?.status || 'unknown';
            const neo4jStatus = services.neo4j?.status || 'unknown';
            const embeddingModel = response.data.embedding_models?.document_embedding_model || 'N/A';
            
            console.log(`  Embedding Model: ${embeddingModel}`);
            console.log(`  Qdrant Status: ${qdrantStatus}`);
            console.log(`  Neo4j Status: ${neo4jStatus}`);

            if (response.data.message && response.data.message.includes("Warning:")) {
                 console.warn(`  RAG Health Warning: ${response.data.message}`);
            }
            return true;
        } else {
             console.warn(`! Python RAG service responded but status is not OK: ${response.status} - ${JSON.stringify(response.data)}`);
             return false;
        }
    } catch (error) {
        console.warn('! Python RAG service is not reachable.');
        if (error.code === 'ECONNREFUSED') {
             console.warn(`  Connection refused at ${url}. Ensure the Python RAG service (e.g., server/rag_service/app.py) is running.`);
        } else if (error.code === 'ECONNABORTED' || error.message.includes('timeout')) {
             console.warn(`  Connection timed out to ${url}. The Python RAG service might be slow to start or unresponsive.`);
        } else {
             console.warn(`  Error connecting to Python RAG Service: ${error.message}`);
        }
        console.warn('  RAG-dependent features (document upload processing, context retrieval) will be unavailable.');
        return false;
    }
}

// --- Directory Structure Check ---
async function ensureServerDirectories() {
    const dirs = [
        path.join(__dirname, 'assets'),
        path.join(__dirname, 'backup_assets'),
        path.join(__dirname, 'syllabi') // Added syllabi directory check
    ];
    console.log("\nEnsuring server directories exist...");
    try {
        for (const dir of dirs) {
            if (!fs.existsSync(dir)) {
                await fs.promises.mkdir(dir, { recursive: true });
                console.log(`  Created directory: ${dir}`);
            }
        }
        console.log(" Server directories checked/created.");
    } catch (error) {
        console.error('!!! Error creating essential server directories:', error);
        throw error;
    }
}

// --- Prompt for Configuration ---
function askQuestion(query) {
    return new Promise(resolve => readline.question(query, resolve));
}

async function configureAndStart() {
    console.log("--- Starting Server Configuration ---");
    
    if (!geminiApiKey) {
        console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
        console.error("!!! FATAL: GEMINI_API_KEY environment variable is not set. !!!");
        console.error("!!! Please set it before running the server:               !!!");
        console.error("!!! export GEMINI_API_KEY='YOUR_API_KEY'                   !!!");
        console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
        process.exit(1);
    } else {
        console.log(" GEMINI_API_KEY found.");
    }
    // JWT_SECRET is checked at the top of the file.

    if (!mongoUri) {
        const answer = await askQuestion(`Enter MongoDB URI or press Enter for default (${DEFAULT_MONGO_URI}): `);
        mongoUri = answer.trim() || DEFAULT_MONGO_URI;
    }
    console.log(`Using MongoDB URI: ${mongoUri}`);

    if (!pythonRagUrl) {
        const answer = await askQuestion(`Enter Python RAG Service URL or press Enter for default (${DEFAULT_PYTHON_RAG_URL}): `);
        pythonRagUrl = answer.trim() || DEFAULT_PYTHON_RAG_URL;
    }
    console.log(`Using Python RAG Service URL: ${pythonRagUrl}`);
    console.log(`Node.js server will listen on port: ${port}`);
    readline.close();

    process.env.MONGO_URI = mongoUri;
    process.env.PYTHON_RAG_SERVICE_URL = pythonRagUrl;

    console.log("--- Configuration Complete ---");
    await startServer();
}

// --- Asynchronous Server Startup Function ---
async function startServer() {
    console.log("\n--- Starting Server Initialization ---");
    try {
        await ensureServerDirectories();
        await connectDB(mongoUri); 
        await performAssetCleanup(); 
        await checkRagService(pythonRagUrl);

        const PORT = port;
        const availableIPs = getLocalIPs();

        server = app.listen(PORT, '0.0.0.0', () => {
            console.log('\n=== Node.js Server Ready ===');
            console.log(` Server listening on port ${PORT}`);
            console.log('   Access the application via these URLs (using common frontend ports):');
            const frontendPorts = [3000, 3001, 8080, 5173]; 
            availableIPs.forEach(ip => {
                 frontendPorts.forEach(fp => {
                    console.log(`   - http://${ip}:${fp} (Frontend) -> Connects to Backend at http://${ip}:${PORT}`);
                 });
            });
            console.log('============================\n');
            console.log(" Hint: Client automatically detects backend IP based on how you access the frontend.");
            console.log(`   Ensure firewalls allow connections on port ${PORT} (Backend) and your frontend port.`);
            console.log("--- Server Initialization Complete ---");
        });

    } catch (error) {
        console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
        console.error("!!! Failed to start Node.js server:", error.message);
        console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
        process.exit(1);
    }
}

// --- Execute Configuration and Server Start ---
configureAndStart();
```

`server/services/adminDocuments.js`

```javascript
// server/routes/adminDocuments.js
const express = require('express');
const multer = require('multer');
const path = require('path');
const fs = require('fs'); // Using Node.js fs for directory creation and file ops
const fsPromises = fs.promises; // For async file operations
const AdminDocument = require('../models/AdminDocument');
const { fixedAdminAuthMiddleware } = require('../middleware/fixedAdminAuthMiddleware');
const axios = require('axios'); // For calling Python RAG service

const router = express.Router();

// --- Constants for Admin Uploads ---
const ADMIN_UPLOAD_DIR_BASE = path.join(__dirname, '..', 'assets', '_admin_uploads_');
const MAX_FILE_SIZE = 20 * 1024 * 1024; // 20 MB

// Allowed types for admin uploads
const allowedAdminMimeTypes = {
    'application/pdf': 'docs',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document': 'docs', // docx
    'text/plain': 'docs', // txt
    'text/markdown': 'docs', // md
    // Add more as needed for admin
};
const allowedAdminExtensions = ['.pdf', '.docx', '.txt', '.md'];

// --- Multer Config for Admin Uploads ---
const adminStorage = multer.diskStorage({
    destination: (req, file, cb) => {
        const fileMimeType = file.mimetype.toLowerCase();
        const fileTypeSubfolder = allowedAdminMimeTypes[fileMimeType] || 'others'; // Default to 'others'
        const destinationPath = path.join(ADMIN_UPLOAD_DIR_BASE, fileTypeSubfolder);

        fs.mkdir(destinationPath, { recursive: true }, (err) => {
            if (err) {
                console.error(`Admin Upload Multer: Error creating destination path ${destinationPath}:`, err);
                return cb(err);
            }
            cb(null, destinationPath);
        });
    },
    filename: (req, file, cb) => {
        const timestamp = Date.now();
        const fileExt = path.extname(file.originalname).toLowerCase();
        const sanitizedBaseName = path.basename(file.originalname, fileExt)
            .replace(/[^a-zA-Z0-9._-]/g, '_')
            .substring(0, 100); // Limit base name length
        const uniqueFilename = `${timestamp}-${sanitizedBaseName}${fileExt}`;
        cb(null, uniqueFilename);
    }
});

const adminFileFilter = (req, file, cb) => {
    const fileExt = path.extname(file.originalname).toLowerCase();
    const mimeType = file.mimetype.toLowerCase();

    const isMimeTypeAllowed = !!allowedAdminMimeTypes[mimeType];
    const isExtensionAllowed = allowedAdminExtensions.includes(fileExt);

    if (isMimeTypeAllowed && isExtensionAllowed) {
        cb(null, true);
    } else {
        console.warn(`Admin Upload Rejected (Filter): File='${file.originalname}', MIME='${mimeType}', Ext='${fileExt}'.`);
        const error = new multer.MulterError('LIMIT_UNEXPECTED_FILE_TYPE_ADMIN');
        error.message = `Invalid file type or extension for admin upload. Allowed: ${allowedAdminExtensions.join(', ')}`;
        cb(error, false);
    }
};

const adminUpload = multer({
    storage: adminStorage,
    fileFilter: adminFileFilter,
    limits: { fileSize: MAX_FILE_SIZE }
});

// --- Helper to call Python RAG service for Admin Docs (Text Extraction Only) ---
async function triggerPythonTextExtractionForAdmin(filePath, originalName) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
    if (!pythonServiceUrl) {
        console.error("ADMIN RAG: PYTHON_RAG_SERVICE_URL not set. Cannot extract text.");
        return { success: false, message: "Python service URL not configured for text extraction.", text: null };
    }
    const addDocumentUrl = `${pythonServiceUrl}/add_document`;
    console.log(`ADMIN RAG: Calling Python Service: ${addDocumentUrl} for text extraction of '${originalName}'`);

    try {
        // For admin docs, we pass a generic user_id or a specific marker.
        // The Python service might try to add to Qdrant/Neo4j with this ID.
        // If admin docs are NOT to be in the main Qdrant/Neo4j, the Python service
        // would ideally have a flag to skip DB insertions for certain user_ids/contexts.
        // For now, Node.js only cares about the returned text.
        const response = await axios.post(addDocumentUrl, {
            user_id: "fixed_admin_text_extraction_user", // A distinct ID for Python's logging/potential filtering
            file_path: filePath,
            original_name: originalName
        }, { timeout: 300000 }); // 5 min timeout

        const pythonData = response.data;
        const text = pythonData?.raw_text_for_analysis || null;

        if (text) {
            console.log(`ADMIN RAG: Text extracted successfully for '${originalName}'. Length: ${text.length}`);
            return { success: true, message: "Text extracted.", text: text };
        } else {
            console.warn(`ADMIN RAG: Python service returned no text for '${originalName}'. Status: ${pythonData?.status}, Message: ${pythonData?.message}`);
            return { success: false, message: pythonData?.message || "Python service extracted no text.", text: null };
        }
    } catch (error) {
        const errorMsg = error.response?.data?.error || error.response?.data?.message || error.message || "Unknown error calling Python RAG for text extraction.";
        console.error(`ADMIN RAG: Error calling Python service for '${originalName}': ${errorMsg}`);
        return { success: false, message: `Python RAG call failed: ${errorMsg}`, text: null };
    }
}


// --- Admin Document Routes ---

// @route   POST /api/admin/documents/upload
// @desc    Upload a document for the admin, extract text, and initiate analysis.
// @access  Admin Only (via fixedAdminAuthMiddleware)
router.post('/upload', fixedAdminAuthMiddleware, adminUpload.single('file'), async (req, res) => {
    if (!req.file) {
        return res.status(400).json({ message: 'No file uploaded or file type rejected.' });
    }

    const { filename: serverFilename, originalname: originalName, path: tempServerPath } = req.file;
    let adminDocRecord;

    try {
        // 1. Check for existing document with the same originalName
        const existingDoc = await AdminDocument.findOne({ originalName: originalName });
        if (existingDoc) {
            await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Error deleting duplicate temp file ${tempServerPath}:`, e));
            return res.status(409).json({ message: `Document with original name '${originalName}' already exists for admin.` });
        }

        // 2. Extract text using Python RAG service
        console.log(`Admin Upload: Attempting text extraction for '${originalName}' from ${tempServerPath}`);
        const textExtractionResult = await triggerPythonTextExtractionForAdmin(tempServerPath, originalName);

        if (!textExtractionResult.success || !textExtractionResult.text || textExtractionResult.text.trim() === "") {
            await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Error deleting temp file ${tempServerPath} after failed text extraction:`, e));
            return res.status(422).json({ // Unprocessable Entity
                message: textExtractionResult.message || "Failed to extract usable text from the document.",
                filename: serverFilename,
                originalname: originalName
            });
        }
        console.log(`Admin Upload: Text extracted for '${originalName}'. Proceeding to save and analyze.`);

        // 3. Save initial AdminDocument record
        adminDocRecord = new AdminDocument({
            filename: serverFilename,
            originalName: originalName,
            text: textExtractionResult.text,
            // serverPath and fileTypeSubfolder are not in the simplified model.
            // If we decide to keep the file, we'd need to move it from tempServerPath
            // to a final location and store that path. For now, assume tempServerPath is cleaned up.
            analysis: { faq: "", topics: "", mindmap: "" }, // Initialize analysis
            analysisUpdatedAt: null,
        });
        await adminDocRecord.save();
        console.log(`Admin Upload: Initial DB record saved for '${originalName}' (Server: ${serverFilename}).`);

        // 4. Delete the temporary file uploaded by multer as text is now in DB
        // If you decide to keep the physical file, this step would be a move operation instead.
        await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Non-critical error deleting temp file ${tempServerPath} after DB save:`, e));


        // 5. Respond to client (202 Accepted) & Trigger Background Analysis
        res.status(202).json({
            message: `Admin document '${originalName}' uploaded. Text extracted. Analysis initiated.`,
            filename: serverFilename,
            originalname: originalName,
        });
        console.log(`Admin Upload: Sent 202 Accepted for '${originalName}'. Offloading analysis.`);

        // --- Trigger Background Analysis Worker ---
        // This requires an 'adminAnalysisWorker.js'
        const { Worker } = require('worker_threads');
        const adminAnalysisWorkerPath = path.resolve(__dirname, '..', 'workers', 'adminAnalysisWorker.js');
        
        try {
            if (fs.existsSync(adminAnalysisWorkerPath)) { // Check if worker file exists
                const worker = new Worker(adminAnalysisWorkerPath, {
                    workerData: {
                        adminDocumentId: adminDocRecord._id.toString(), // Pass ID to update the specific doc
                        originalName: originalName,
                        textForAnalysis: textExtractionResult.text
                    }
                });
                worker.on('message', (msg) => console.log(`Admin Analysis Worker [Doc: ${msg.originalName || originalName}]: ${msg.message || JSON.stringify(msg)}`));
                worker.on('error', (err) => console.error(`Admin Analysis Worker Error [Doc: ${originalName}]:`, err));
                worker.on('exit', (code) => console.log(`Admin Analysis Worker [Doc: ${originalName}] exited (code ${code}).`));
            } else {
                console.error(`Admin Upload: adminAnalysisWorker.js not found at ${adminAnalysisWorkerPath}. Analysis cannot be started.`);
                // Optionally update the AdminDocument status to 'analysis_launch_failed'
            }
        } catch (workerError) {
            console.error(`Admin Upload: Error launching Admin Analysis Worker for '${originalName}':`, workerError);
        }

    } catch (error) {
        console.error(`Admin Upload: Overall error for '${originalName || (req.file && req.file.originalname)}':`, error);
        if (tempServerPath) { // If path is known, try to clean up temp file
            await fsPromises.unlink(tempServerPath).catch(e => console.error(`Admin Upload: Error cleaning up temp file ${tempServerPath} after overall error:`, e));
        }
        if (!res.headersSent) {
            if (error.code === 11000) { // MongoDB duplicate key
                 res.status(409).json({ message: 'Document processing conflict (e.g., duplicate server filename). Please try again.' });
            } else {
                 res.status(500).json({ message: 'Server error during admin document upload processing.' });
            }
        }
    }
});

// @route   GET /api/admin/documents
// @desc    Get list of documents uploaded by the admin
// @access  Admin Only (via fixedAdminAuthMiddleware)
router.get('/', fixedAdminAuthMiddleware, async (req, res) => {
    try {
        // Fetching fields relevant for listing and identifying documents.
        // Exclude 'text' and full 'analysis' objects by default to keep payload small.
        const adminDocs = await AdminDocument.find()
            .sort({ uploadedAt: -1 })
            .select('originalName filename uploadedAt analysisUpdatedAt analysis.faq analysis.topics analysis.mindmap'); // Select specific fields

        const documentsList = adminDocs.map(doc => ({
            originalName: doc.originalName,
            serverFilename: doc.filename, // Useful if frontend needs to make further requests (e.g., delete)
            uploadedAt: doc.uploadedAt,
            analysisUpdatedAt: doc.analysisUpdatedAt,
            hasFaq: !!(doc.analysis && doc.analysis.faq && doc.analysis.faq.trim() !== ""),
            hasTopics: !!(doc.analysis && doc.analysis.topics && doc.analysis.topics.trim() !== ""),
            hasMindmap: !!(doc.analysis && doc.analysis.mindmap && doc.analysis.mindmap.trim() !== ""),
        }));

        // For frontend compatibility with existing DocumentList component,
        // it might expect an array of strings (originalName).
        // If so, change `res.json({ documents: documentsList });` to
        // `res.json({ filenames: documentsList.map(d => d.originalName) });`
        // However, sending more info like `documentsList` is generally more useful.
        res.json({ documents: documentsList });

    } catch (error) {
        console.error('Admin List Documents Error:', error);
        res.status(500).json({ message: 'Server error fetching admin documents.' });
    }
});

// @route   DELETE /api/admin/documents/:serverFilename
// @desc    Delete a document uploaded by the admin (DB record only for simplified model)
// @access  Admin Only (via fixedAdminAuthMiddleware)
router.delete('/:serverFilename', fixedAdminAuthMiddleware, async (req, res) => {
    const { serverFilename } = req.params;

    if (!serverFilename) {
        return res.status(400).json({ message: 'Server filename parameter is required for deletion.' });
    }

    try {
        const docToDelete = await AdminDocument.findOneAndDelete({ filename: serverFilename });

        if (!docToDelete) {
            return res.status(404).json({ message: `Admin document with server name '${serverFilename}' not found.` });
        }

        console.log(`Admin Delete: Document record '${docToDelete.originalName}' (Server: ${serverFilename}) deleted from MongoDB.`);
        
        // Since we are not storing serverPath in the simplified model and deleting temp files after text extraction,
        // there's no physical file to delete from 'assets/_admin_uploads_' based on DB record alone at this stage.
        // If, in the future, you decide to *keep* admin-uploaded files, you'd add file deletion logic here
        // and would need to store `serverPath` in AdminDocument model.

        // TODO (Future): If admin documents were processed by Qdrant/Neo4j,
        // trigger deletion from those services here.

        res.status(200).json({ message: `Admin document '${docToDelete.originalName}' record deleted successfully.` });

    } catch (error) {
        console.error(`Admin Delete Error for serverFilename '${serverFilename}':`, error);
        res.status(500).json({ message: 'Server error during admin document deletion.' });
    }
});


// @route   GET /api/admin/documents/:serverFilename/analysis
// @desc    Get analysis data for a specific admin document
// @access  Admin Only
router.get('/:serverFilename/analysis', fixedAdminAuthMiddleware, async (req, res) => {
    const { serverFilename } = req.params;
    if (!serverFilename) {
        return res.status(400).json({ message: 'Server filename parameter is required.' });
    }

    try {
        const adminDoc = await AdminDocument.findOne({ filename: serverFilename }).select('originalName analysis analysisUpdatedAt');
        if (!adminDoc) {
            return res.status(404).json({ message: `Admin document '${serverFilename}' not found.` });
        }
        if (!adminDoc.analysis || 
            (!adminDoc.analysis.faq && !adminDoc.analysis.topics && !adminDoc.analysis.mindmap)) {
            return res.status(200).json({ 
                originalName: adminDoc.originalName,
                message: 'Analysis has not been generated or is empty for this document.',
                analysis: { faq: "", topics: "", mindmap: "" }, // Return empty structure
                analysisUpdatedAt: adminDoc.analysisUpdatedAt
            });
        }
        res.status(200).json({
            originalName: adminDoc.originalName,
            analysis: adminDoc.analysis, // Contains faq, topics, mindmap strings
            analysisUpdatedAt: adminDoc.analysisUpdatedAt
        });
    } catch (error) {
        console.error(`Error fetching analysis for admin document '${serverFilename}':`, error);
        res.status(500).json({ message: 'Server error while retrieving admin document analysis.' });
    }
});


module.exports = router;
```

`server/services/geminiService.js`

```javascript
// server/services/geminiService.js
const { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } = require('@google/generative-ai');

const API_KEY = process.env.GEMINI_API_KEY;
const MODEL_NAME = "gemini-1.5-flash"; // Or "gemini-1.5-pro" if you switch

if (!API_KEY) {
    console.error("FATAL ERROR: GEMINI_API_KEY is not available in the environment. Server should have exited.");
    throw new Error("GEMINI_API_KEY is missing.");
}

const genAI = new GoogleGenerativeAI(API_KEY);

const DEFAULT_MAX_OUTPUT_TOKENS_CHAT = 8192; // Increased default for potentially longer thinking + answer
const DEFAULT_MAX_OUTPUT_TOKENS_KG = 65536;   // Default specific for KG, might need adjustment

const baseSafetySettings = [
    { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH },
    { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH },
    { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH },
    { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH },
];

// Modified function to accept maxTokens override
const generateContentWithHistory = async (
    chatHistory,
    systemPromptText = null,
    customMaxOutputTokens = null 
) => {
    try {
        if (!Array.isArray(chatHistory) || chatHistory.length === 0) {
             throw new Error("Chat history must be a non-empty array.");
        }
        // It's good practice to ensure history ends with a user role for many models
        // if (chatHistory[chatHistory.length - 1].role !== 'user') {
        //     console.warn("Warning: Chat history for Gemini API call does not end with a 'user' role. This might lead to unexpected behavior. Last role:", chatHistory[chatHistory.length - 1].role);
        // }

        const effectiveMaxOutputTokens = customMaxOutputTokens || DEFAULT_MAX_OUTPUT_TOKENS_CHAT;

        const generationConfig = {
            temperature: 0.7, // Or make this configurable too
            maxOutputTokens: effectiveMaxOutputTokens,
        };

        const modelOptions = {
            model: MODEL_NAME,
            generationConfig: generationConfig,
            safetySettings: baseSafetySettings,
            ...(systemPromptText && typeof systemPromptText === 'string' && systemPromptText.trim() !== '' && {
                systemInstruction: {
                    // Gemini API expects systemInstruction to be an object with a 'parts' array
                    parts: [{ text: systemPromptText.trim() }]
                }
             })
        };
        const model = genAI.getGenerativeModel(modelOptions);

        const historyForStartChat = chatHistory.slice(0, -1) 
            .map(msg => ({
                 role: msg.role, 
                 parts: Array.isArray(msg.parts) ? msg.parts.map(part => ({ text: part.text || '' })) : [{text: ''}] 
            }))
            .filter(msg => msg.role && msg.parts && msg.parts.length > 0 && typeof msg.parts[0].text === 'string');

        const chat = model.startChat({
            history: historyForStartChat,
        });

        let lastUserMessageParts = chatHistory[chatHistory.length - 1]?.parts;
        if (!Array.isArray(lastUserMessageParts) || lastUserMessageParts.length === 0 || typeof lastUserMessageParts[0].text !== 'string') {
            console.error("Invalid last user message structure:", chatHistory[chatHistory.length - 1]);
            throw new Error("Internal error: Last user message for API call is malformed.");
        }
        let lastUserMessageText = lastUserMessageParts[0].text;


        console.log(`Sending message to Gemini. History sent to startChat: ${historyForStartChat.length}. System Prompt: ${!!modelOptions.systemInstruction}. Max Output Tokens: ${effectiveMaxOutputTokens}`);
        // console.log("Last User Message Text Sent to Gemini (first 200 chars):", lastUserMessageText.substring(0, 200) + "...");

        const result = await chat.sendMessage(lastUserMessageText);
        const response = result.response;
        const candidate = response?.candidates?.[0];

        if (candidate && (candidate.finishReason === 'STOP' || candidate.finishReason === 'MAX_TOKENS')) {
            const responseText = candidate?.content?.parts?.[0]?.text;
            if (typeof responseText === 'string') {
                if (candidate.finishReason === 'MAX_TOKENS') {
                    console.warn("Gemini response was truncated due to MAX_TOKENS limit.");
                }
                return responseText;
            } else {
                 console.warn("Gemini response finished normally but text content is missing or invalid.", { finishReason: candidate?.finishReason, content: candidate?.content });
                 throw new Error("Received an empty or invalid response from the AI service.");
            }
        } else {
             const finishReason = candidate?.finishReason || 'Unknown';
             const safetyRatings = candidate?.safetyRatings;
             console.warn("Gemini response was potentially blocked or had issues.", { finishReason, safetyRatings });
             let blockMessage = `AI response generation failed or was blocked.`;
             if (finishReason === 'SAFETY') {
                 blockMessage += ` Reason: SAFETY.`;
                 if (safetyRatings) {
                    const blockedCategories = safetyRatings.filter(r => r.blocked).map(r => r.category).join(', ');
                    if (blockedCategories) blockMessage += ` Blocked Categories: ${blockedCategories}.`;
                 }
             } else if (finishReason) {
                 blockMessage += ` Reason: ${finishReason}.`;
             }
             const error = new Error(blockMessage);
             error.status = 400; 
             throw error;
        }
    } catch (error) {
        console.error("Gemini API Call Error:", error?.message || error);
        let clientMessage = "Failed to get response from AI service.";
        if (error.message?.includes("API key not valid")) clientMessage = "AI Service Error: Invalid API Key.";
        else if (error.message?.includes("blocked due to safety")) clientMessage = "AI response blocked due to safety settings.";
        else if (error.message?.includes("Invalid JSON payload")) clientMessage = "AI Service Error: Invalid request format sent to AI.";
        else if (error.message?.includes("User location is not supported")) clientMessage = "AI Service Error: User location is not supported for this model.";
        else if (error.status === 400) clientMessage = `AI Service Error: ${error.message}`; 
        
        const enhancedError = new Error(clientMessage);
        enhancedError.status = error.status || 500; 
        enhancedError.originalError = error; 
        throw enhancedError;
    }
};

module.exports = {
    generateContentWithHistory,
    DEFAULT_MAX_OUTPUT_TOKENS_KG 
};
```

`server/services/kgService.js`

```javascript
// server/services/kgService.js
const geminiService = require('./geminiService');
const ollamaService = require('./ollamaService'); // Import Ollama service
const { v4: uuidv4 } = require('uuid');
const axios = require('axios');
// --- IMPORT THE PROMPTS ---
const {
    KG_GENERATION_SYSTEM_PROMPT,
    KG_BATCH_USER_PROMPT_TEMPLATE // Import the new template
} = require('../config/promptTemplates');

// --- MODIFIED: Function to construct the user prompt for a BATCH of chunks ---
function constructKgPromptForBatch(chunkTexts) {
    // chunkTexts is an array of strings, where each string is the text_content of a chunk.
    let formattedChunkTexts = "";
    chunkTexts.forEach((chunkText, index) => {
        formattedChunkTexts += `
--- START OF CHUNK ${index + 1} ---
${chunkText}
--- END OF CHUNK ${index + 1} ---
`;
    });

    // Replace the placeholder in the template with the actual formatted chunk texts
    return KG_BATCH_USER_PROMPT_TEMPLATE.replace('{BATCHED_CHUNK_TEXTS_HERE}', formattedChunkTexts);
}

// --- NEW: Internal function to process a single BATCH of chunks ---
// (This function _processBatchOfChunksForKg remains the same as in the previous good answer)
async function _processBatchOfChunksForKg(batchOfChunkObjects, batchIndex, llmProvider, ollamaModel) {
    // batchOfChunkObjects is an array of the original chunk objects
    // e.g., [{ text_content: "...", metadata: {...} }, ...]
    const logPrefix = `[KG Service Batch ${batchIndex}]`;

    const chunkTextsForPrompt = batchOfChunkObjects.map(chunk => chunk.text_content);

    if (chunkTextsForPrompt.length === 0) {
        console.log(`${logPrefix} No text content in this batch. Skipping.`);
        return [];
    }

    const userPromptForBatch = constructKgPromptForBatch(chunkTextsForPrompt); // Uses the new templated function
    const chatHistory = [
        { role: 'user', parts: [{ text: userPromptForBatch }] }
    ];

    try {
        console.log(`${logPrefix} Processing ${chunkTextsForPrompt.length} chunks for KG generation using ${llmProvider}.`);
        let responseText;

        if (llmProvider === 'ollama') {
            responseText = await ollamaService.generateContentWithHistory(
                chatHistory, // This structure is simple for KG (just user prompt)
                KG_GENERATION_SYSTEM_PROMPT,
                { model: ollamaModel, maxOutputTokens: ollamaService.DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_KG }
            );
        } else { // Default to Gemini
            responseText = await geminiService.generateContentWithHistory(
                chatHistory,
                KG_GENERATION_SYSTEM_PROMPT, // System prompt applies to EACH chunk's processing logic
                geminiService.DEFAULT_MAX_OUTPUT_TOKENS_KG
            );
        }

        if (!responseText) {
            console.warn(`${logPrefix} Empty response from Gemini for batch.`);
            return [];
        }

        let cleanedResponseText = responseText.trim();
        // More robust cleaning for ```json ... ``` or ``` ... ``` blocks
        if (cleanedResponseText.startsWith("```json")) {
            cleanedResponseText = cleanedResponseText.substring(7); // Remove ```json
            if (cleanedResponseText.endsWith("```")) {
                cleanedResponseText = cleanedResponseText.slice(0, -3); // Remove ```
            }
        } else if (cleanedResponseText.startsWith("```")) {
            cleanedResponseText = cleanedResponseText.substring(3); // Remove ```
            if (cleanedResponseText.endsWith("```")) {
                cleanedResponseText = cleanedResponseText.slice(0, -3); // Remove ```
            }
        }
        cleanedResponseText = cleanedResponseText.trim();
        console.log("-----------------------------------------------------------------------------------------------------");
        console.log(cleanedResponseText);
        const graphFragmentsArray = JSON.parse(cleanedResponseText);

        if (!Array.isArray(graphFragmentsArray)) {
            console.warn(`${logPrefix} Gemini response was not a JSON array. Response (first 200 chars):`, cleanedResponseText.substring(0, 200));
            return [];
        }

        if (graphFragmentsArray.length !== batchOfChunkObjects.length) {
            console.warn(`${logPrefix} Mismatch: Expected ${batchOfChunkObjects.length} KG fragments, but received ${graphFragmentsArray.length}. Results might be misaligned.`);
        }
        
        const validFragments = [];
        graphFragmentsArray.forEach((fragment, i) => {
            if (fragment && typeof fragment === 'object' && Array.isArray(fragment.nodes) && Array.isArray(fragment.edges)) {
                validFragments.push(fragment);
            } else {
                const chunkRef = batchOfChunkObjects[i]?.metadata?.chunk_reference_name || `chunk index ${i} in batch`;
                console.warn(`${logPrefix} Invalid graph structure from Gemini for ${chunkRef}. Discarding this fragment. Fragment:`, JSON.stringify(fragment).substring(0,100));
            }
        });
        console.log(`${logPrefix} Successfully parsed ${validFragments.length} valid KG fragments from Gemini response.`);
        return validFragments;

    } catch (error) {
        console.error(`${logPrefix} Error processing batch:`, error.message);
        if (error.originalError) console.error(`${logPrefix} Original Gemini error:`, error.originalError);
        if (error.response?.data) console.error(`${logPrefix} Gemini error data:`, error.response.data);
        return [];
    }
}


// --- MERGE FUNCTION (remains the same as your provided version or my previous good one) ---
function _mergeGraphFragments(graphFragments) {
    console.log(`[KG Service] Merging ${graphFragments.length} graph fragments...`);
    const finalNodesMap = new Map();
    const finalEdgesSet = new Set(); // Using a Set to store unique stringified edges

    for (const fragment of graphFragments) {
        if (!fragment || !fragment.nodes || !fragment.edges) {
            console.warn("[KG Service Merge] Skipping invalid or null graph fragment.");
            continue;
        }
        
        // Process Nodes
        for (const node of fragment.nodes) {
            if (!node || typeof node.id !== 'string' || !node.id.trim()) {
                console.warn("[KG Service Merge] Skipping invalid node (missing/empty ID):", node);
                continue;
            }
            const nodeId = node.id.trim();
            if (!finalNodesMap.has(nodeId)) {
                finalNodesMap.set(nodeId, { ...node, id: nodeId });
            } else {
                const existingNode = finalNodesMap.get(nodeId);
                if (node.description && typeof node.description === 'string' &&
                    (!existingNode.description || node.description.length > existingNode.description.length)) {
                    existingNode.description = node.description;
                }
                if (node.type && (!existingNode.type || existingNode.type === "generic" || existingNode.type.toLowerCase() === "unknown")) {
                    existingNode.type = node.type;
                }
                if (node.parent && !existingNode.parent) {
                    existingNode.parent = node.parent;
                }
            }
        }

        // Process Edges
        for (const edge of fragment.edges) {
            if (!edge || typeof edge.from !== 'string' || typeof edge.to !== 'string' || typeof edge.relationship !== 'string' ||
                !edge.from.trim() || !edge.to.trim() || !edge.relationship.trim()) {
                console.warn("[KG Service Merge] Skipping invalid edge (missing from/to/relationship or empty):", edge);
                continue;
            }
            const edgeKey = `${edge.from.trim()}|${edge.to.trim()}|${edge.relationship.trim().toUpperCase()}`;
            finalEdgesSet.add(edgeKey);
        }
    }

    const mergedNodes = Array.from(finalNodesMap.values());
    const mergedEdges = Array.from(finalEdgesSet).map(edgeKey => {
        const [from, to, relationship] = edgeKey.split('|');
        return { from, to, relationship };
    });

    console.log(`[KG Service Merge] Merged into ${mergedNodes.length} nodes and ${mergedEdges.length} edges.`);
    return { nodes: mergedNodes, edges: mergedEdges };
}

// --- MODIFIED: Main function for KG generation and storage ---
// (This function generateAndStoreKg remains the same as in the previous good answer)
async function generateAndStoreKg(chunksForKg, userId, originalName, llmProvider, ollamaModel) {
    const logPrefix = `[KG Service Doc: ${originalName}, User: ${userId}]`;
    console.log(`${logPrefix} Starting KG generation with ${chunksForKg.length} initial chunks.`);

    if (!chunksForKg || chunksForKg.length === 0) {
        console.warn(`${logPrefix} No chunks provided for KG generation.`);
        return { success: true, message: "No chunks to process for KG.", finalKgNodesCount: 0, finalKgEdgesCount: 0 };
    }

    const allGraphFragments = [];
    const BATCH_SIZE = parseInt(process.env.KG_GENERATION_BATCH_SIZE) || 50;
    console.log(`${logPrefix} Using batch size: ${BATCH_SIZE}`);
    let batchIndex = 0;

    for (let i = 0; i < chunksForKg.length; i += BATCH_SIZE) {
        batchIndex++;
        const currentBatchOfChunks = chunksForKg.slice(i, i + BATCH_SIZE);
        
        const validChunksInBatch = currentBatchOfChunks.filter(chunk => chunk && chunk.text_content && chunk.text_content.trim() !== '');
        if (validChunksInBatch.length === 0) {
            console.log(`${logPrefix} Batch ${batchIndex} has no valid chunks with text. Skipping.`);
            continue;
        }
        
        console.log(`${logPrefix} Processing batch ${batchIndex} (chunks ${i} to ${Math.min(i + BATCH_SIZE - 1, chunksForKg.length - 1)}), ${validChunksInBatch.length} valid chunks.`);
        
        const fragmentsFromBatch = await _processBatchOfChunksForKg(validChunksInBatch, batchIndex, llmProvider, ollamaModel); // Pass LLM info
        if (fragmentsFromBatch && fragmentsFromBatch.length > 0) {
            allGraphFragments.push(...fragmentsFromBatch);
        } else {
            console.warn(`${logPrefix} Batch ${batchIndex} yielded no valid graph fragments.`);
        }
    }

    if (allGraphFragments.length === 0) {
        console.warn(`${logPrefix} No valid graph fragments were generated from any batch.`);
        return { success: true, message: "No KG data extracted from any document chunks.", finalKgNodesCount: 0, finalKgEdgesCount: 0 };
    }

    console.log(`${logPrefix} Generated a total of ${allGraphFragments.length} raw graph fragments. Merging...`);
    const finalKg = _mergeGraphFragments(allGraphFragments);
    
    if (!finalKg || finalKg.nodes.length === 0) {
        console.warn(`${logPrefix} Merged KG has no nodes. Nothing to store.`);
         return { success: true, message: "Merged KG was empty after processing all fragments.", finalKgNodesCount: 0, finalKgEdgesCount: 0 };
    }
    console.log(`${logPrefix} Merged KG successfully. Nodes: ${finalKg.nodes.length}, Edges: ${finalKg.edges.length}.`);

    const baseRagUrl = process.env.PYTHON_RAG_SERVICE_URL || process.env.DEFAULT_PYTHON_RAG_URL || 'http://localhost:5000';
    const kgIngestionApiUrl = `${baseRagUrl.replace(/\/$/, '')}/kg`;

    if (!kgIngestionApiUrl.startsWith('http')) {
        console.error(`${logPrefix} KG Ingestion API URL is invalid: ${kgIngestionApiUrl}. Check PYTHON_RAG_SERVICE_URL.`);
        return {
            success: false,
            message: "KG generated, but KG Ingestion API URL is invalid. KG not stored.",
            finalKgNodesCount: finalKg.nodes.length,
            finalKgEdgesCount: finalKg.edges.length
        };
    }

    console.log(`${logPrefix} Sending final merged KG to Ingestion API: ${kgIngestionApiUrl}`);
    try {
        const payload = {
            userId: userId,
            originalName: originalName,
            nodes: finalKg.nodes,
            edges: finalKg.edges
        };

        const serviceResponse = await axios.post(kgIngestionApiUrl, payload, {
            timeout: 300000
        });

        const responseData = serviceResponse.data;
        const API_SUCCESS_STATUS_VALUE = "completed";

        if (serviceResponse.status >= 200 && serviceResponse.status < 300 && responseData && responseData.status === API_SUCCESS_STATUS_VALUE) {
            if (responseData['documentName'] !== originalName || responseData.userId !== userId) {
                console.warn(`${logPrefix} Mismatch in KG API response. Expected doc/user: ${originalName}/${userId}, Got: ${responseData['documentName']}/${responseData.userId}`);
            }
            const successMessage = `KG for '${originalName}' successfully processed by Ingestion API. Status: ${responseData.status}. Nodes: ${finalKg.nodes.length}, Edges: ${finalKg.edges.length}`;
            console.log(`${logPrefix} ${successMessage}`);
            return {
                success: true,
                message: successMessage,
                serviceResponseData: responseData,
                finalKgNodesCount: finalKg.nodes.length,
                finalKgEdgesCount: finalKg.edges.length
            };
        } else {
            const failureMessage = `KG Ingestion API for '${originalName}' indicated failure or unexpected status. HTTP: ${serviceResponse.status}, API Status: '${responseData?.status || "N/A"}'. API Msg: ${responseData?.message || responseData?.error || 'No specific error from API.'}`;
            console.warn(`${logPrefix} ${failureMessage}`);
            return {
                success: false,
                message: failureMessage,
                serviceResponseData: responseData,
                finalKgNodesCount: finalKg.nodes.length,
                finalKgEdgesCount: finalKg.edges.length
            };
        }
    } catch (error) {
        const errorMsg = error.response?.data?.message || error.response?.data?.error || error.message || "Unknown error calling KG Ingestion API";
        console.error(`${logPrefix} Error calling KG Ingestion API:`, errorMsg);
        if (error.response?.data) console.error(`${logPrefix} KG API Error Response Data:`, error.response.data);
        if (error.code === 'ECONNABORTED' || error.message.toLowerCase().includes('timeout')) {
            console.error(`${logPrefix} KG Ingestion API call timed out.`);
        }
        return {
            success: false,
            message: `KG generated, but error calling KG Ingestion API: ${errorMsg}`,
            finalKgNodesCount: finalKg.nodes.length,
            finalKgEdgesCount: finalKg.edges.length
        };
    }
}

module.exports = { generateAndStoreKg };
```

`server/services/ollamaService.js`

```javascript
// server/services/ollamaService.js
const axios = require('axios');

const OLLAMA_BASE_URL = process.env.OLLAMA_API_BASE_URL || 'http://localhost:11434';
const DEFAULT_OLLAMA_MODEL = process.env.OLLAMA_DEFAULT_MODEL || 'llama3'; // Ensure this is set in .env

const DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_CHAT = 4096; // Ollama's equivalent to maxOutputTokens (num_predict)
const DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_KG = 8192;   // Larger for KG tasks

// Helper to format history for Ollama.
// Many models expect a specific format, e.g., Llama 2 chat format.
// This is a generic approach; specific models might need fine-tuning.
function formatHistoryForOllama(chatHistory, systemPromptText) {
    let promptString = "";

    if (systemPromptText && systemPromptText.trim() !== "") {
        // A common way to prepend system prompt for instruct/chat models
        promptString += `System: ${systemPromptText.trim()}\n\n`;
    }

    chatHistory.forEach(msg => {
        const role = msg.role === 'model' ? 'Assistant' : 'User';
        const text = (Array.isArray(msg.parts) && msg.parts[0]?.text) ? msg.parts[0].text : (msg.text || "");
        promptString += `${role}: ${text}\n`;
    });
    // The final prompt to Ollama will append the *current* user message after this history.
    // So, if the last message in chatHistory is the one we want a response to,
    // it should be included as the final "User:" part here.
    // Or, if chatHistory is true history, then the calling function appends the current query.
    return promptString;
}


const generateContentWithHistory = async (
    chatHistory, // Array of { role: 'user'/'model', parts: [{ text: '...' }] }
    systemPromptText = null,
    options = {} // { model, maxOutputTokens }
) => {
    const modelToUse = options.model || DEFAULT_OLLAMA_MODEL;
    const effectiveMaxOutputTokens = options.maxOutputTokens || DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_CHAT;

    if (!Array.isArray(chatHistory) || chatHistory.length === 0) {
        throw new Error("Ollama: Chat history must be a non-empty array.");
    }

    // The `chatHistory` passed here should *not* include the most recent user message if it's a typical chat flow.
    // That message will be the main "prompt" to Ollama.
    // If `chatHistory` *does* include the final user message, then the prompt below is just that message.

    const historyString = formatHistoryForOllama(chatHistory.slice(0, -1), systemPromptText);
    const currentUserMessage = (chatHistory[chatHistory.length - 1]?.parts?.[0]?.text) || "";

    if (!currentUserMessage.trim()) {
        throw new Error("Ollama: The final user message in history is empty or missing.");
    }
    
    // Construct the full prompt for Ollama
    // Ollama's /api/generate expects a single "prompt" field.
    // History is typically prepended to the current user's message.
    const fullPrompt = historyString + `User: ${currentUserMessage}\nAssistant:`; // Prompt for assistant's turn


    const requestPayload = {
        model: modelToUse,
        prompt: fullPrompt,
        stream: false, // We want the full response
        options: {
            temperature: options.temperature || 0.7,
            num_predict: effectiveMaxOutputTokens, // num_predict is Ollama's way of limiting output length
            // Add other Ollama options here if needed (e.g., top_k, top_p, seed)
        }
    };
    
    // If a system prompt was provided, and the model supports a dedicated 'system' field, use it.
    // Otherwise, it's already prepended in formatHistoryForOllama.
    // For /api/generate, it's usually part of the main prompt.
    // Some models might allow a `system` field in the payload for /api/generate. Check Ollama docs for specific model.
    // if (systemPromptText && systemPromptText.trim() !== "" && modelSupportsSystemField(modelToUse)) {
    //    requestPayload.system = systemPromptText.trim();
    // }


    const endpoint = `${OLLAMA_BASE_URL}/api/generate`;
    console.log(`Ollama Service: Sending request to ${endpoint} for model ${modelToUse}. Prompt (first 100): "${fullPrompt.substring(0, 100)}..."`);

    try {
        const response = await axios.post(endpoint, requestPayload, { timeout: 120000 }); // 2 min timeout

        if (response.data && response.data.response) {
            if (response.data.done === false || response.data.truncated) { // `truncated` might be a custom field or implied by `done: false` if `num_predict` is hit
                 console.warn(`Ollama response for model ${modelToUse} may have been truncated. Done: ${response.data.done}. Context length: ${response.data.context?.length}`);
            }
            return response.data.response.trim();
        } else {
            console.error("Ollama API Error: Invalid response structure.", response.data);
            throw new Error("Ollama service returned an invalid response structure.");
        }
    } catch (error) {
        console.error("Ollama API Call Error:", error.message);
        let clientMessage = "Failed to get response from Ollama AI service.";
        if (error.response) {
            console.error("Ollama Error Response Data:", error.response.data);
            clientMessage = `Ollama Service Error: ${error.response.data.error || error.message}`;
        } else if (error.request) {
            clientMessage = "No response received from Ollama service. Check if it's running and accessible.";
        }
        const enhancedError = new Error(clientMessage);
        enhancedError.status = error.response?.status || 503; // Service Unavailable or other
        enhancedError.originalError = error;
        throw enhancedError;
    }
};

module.exports = {
    generateContentWithHistory,
    DEFAULT_OLLAMA_MODEL, 
    DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_CHAT,
    DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_KG,
};
```

`server/services/summarizationService.js`

```javascript
// server/services/summarizationService.js
const geminiService = require('./geminiService');
const ollamaService = require('./ollamaService');

// This prompt is key. It instructs the LLM on how to create a good, cumulative summary.
const SUMMARIZATION_SYSTEM_PROMPT = `You are an expert conversation summarizer. Your task is to create a concise, yet comprehensive summary of the provided chat history between a User and an AI Assistant.

If an "Existing Summary" is provided, you MUST integrate the "New Messages" into it to create a single, updated, and coherent summary. Do not just append the new information; seamlessly weave it into the existing narrative.

The final summary MUST be in the third person.
Focus on capturing:
- The user's primary goals or questions.
- Key facts, concepts, or entities discussed.
- Important conclusions or resolutions reached.
- Any unresolved questions or next steps mentioned by the user.

Do NOT include conversational filler (e.g., "The user said hello"). The output should be a dense, information-rich paragraph.

Example of a good updated summary:
"Previously, the user, a PhD student, asked about 'Separation of Concerns'. In the latest exchange, they pivoted to inquiring about the specifics of Ohm's Law, and the AI provided the formula V=IR based on a document the user supplied. The user's current goal appears to be understanding foundational engineering concepts, moving from software to electrical principles."
`;

/**
 * Creates or updates a conversation summary.
 * @param {Array<Object>} messagesToSummarize - The array of new message objects to add to the summary.
 * @param {string} existingSummary - The existing summary from the database.
 * @param {string} llmProvider - The LLM provider to use ('gemini' or 'ollama').
 * @param {string} ollamaModel - The specific Ollama model if the provider is 'ollama'.
 * @returns {Promise<string>} The generated summary text.
 */
async function createOrUpdateSummary(messagesToSummarize, existingSummary, llmProvider, ollamaModel) {
    if (!messagesToSummarize || messagesToSummarize.length === 0) {
        return existingSummary || ""; // Return old summary or empty string if nothing to summarize
    }

    // Format the history for the summarization prompt
    const newMessagesText = messagesToSummarize.map(msg => {
        const role = msg.role === 'model' ? 'Assistant' : 'User';
        const text = msg.parts?.[0]?.text || '';
        return `${role}: ${text}`;
    }).join('\n\n');

    let userPrompt = "";
    if (existingSummary && existingSummary.trim() !== "") {
        userPrompt = `Existing Summary:\n"""\n${existingSummary}\n"""\n\nNew Messages to integrate:\n"""\n${newMessagesText}\n"""\n\nPlease provide the new, updated summary.`;
    } else {
        userPrompt = `New Messages to summarize:\n"""\n${newMessagesText}\n"""\n\nPlease provide the summary.`;
    }

    const historyForLlm = [{ role: 'user', parts: [{ text: userPrompt }] }];

    console.log(`[SummarizationService] Requesting summary using ${llmProvider}. Existing summary length: ${existingSummary ? existingSummary.length : 0}, New messages length: ${newMessagesText.length}`);

    try {
        let summary;
        if (llmProvider === 'ollama') {
            summary = await ollamaService.generateContentWithHistory(
                historyForLlm,
                SUMMARIZATION_SYSTEM_PROMPT,
                { model: ollamaModel, maxOutputTokens: 2048 } // Use a reasonable token limit for summaries
            );
        } else { // Default to Gemini
            summary = await geminiService.generateContentWithHistory(
                historyForLlm,
                SUMMARIZATION_SYSTEM_PROMPT
            );
        }

        console.log(`[SummarizationService] Summary generated successfully.`);
        return summary.trim();
    } catch (error) {
        console.error(`[SummarizationService] Error generating summary: ${error.message}`);
        // Return the old summary on failure to avoid losing context.
        return existingSummary || "";
    }
}

module.exports = { createOrUpdateSummary };
```

`server/utils/assetCleanup.js`

```javascript
const fs = require('fs').promises; // Use fs.promises for async operations
const path = require('path');

// Define constants relative to this file's location (server/utils)
const ASSETS_DIR = path.join(__dirname, '..', 'assets'); // Go up one level to server/assets
const BACKUP_DIR = path.join(__dirname, '..', 'backup_assets'); // Go up one level to server/backup_assets
const FOLDER_TYPES = ['docs', 'images', 'code', 'others']; // Folders within each user's asset dir

/**
 * Moves existing user asset folders (docs, images, code, others) to a timestamped
 * backup location and recreates empty asset folders for each user on server startup.
 */
async function performAssetCleanup() {
    console.log("\n--- Starting Asset Cleanup ---");
    try {
        // Ensure backup base directory exists
        await fs.mkdir(BACKUP_DIR, { recursive: true });

        // List potential user directories in assets
        let userDirs = [];
        try {
            userDirs = await fs.readdir(ASSETS_DIR);
        } catch (err) {
            if (err.code === 'ENOENT') {
                console.log("Assets directory doesn't exist yet, creating it and skipping cleanup.");
                await fs.mkdir(ASSETS_DIR, { recursive: true }); // Ensure assets dir exists
                console.log("--- Finished Asset Cleanup (No existing assets found) ---");
                return; // Nothing to clean up
            }
            throw err; // Re-throw other errors accessing assets dir
        }

        if (userDirs.length === 0) {
             console.log("Assets directory is empty. Skipping backup/move operations.");
             console.log("--- Finished Asset Cleanup (No user assets found) ---");
             return;
        }

        const timestamp = new Date().toISOString().replace(/[:.]/g, '-'); // Create a safe timestamp string

        for (const userName of userDirs) {
            const userAssetPath = path.join(ASSETS_DIR, userName);
            const userBackupPathBase = path.join(BACKUP_DIR, userName);
            const userTimestampBackupPath = path.join(userBackupPathBase, `backup_${timestamp}`);

            try {
                // Check if the item in assets is actually a directory
                const stats = await fs.stat(userAssetPath);
                if (!stats.isDirectory()) {
                    console.log(`  Skipping non-directory item in assets: ${userName}`);
                    continue;
                }

                console.log(`  Processing assets for user: [${userName}]`);
                let backupDirCreated = false; // Track if backup dir was created for this user/run
                let movedSomething = false; // Track if anything was actually moved

                // Process each defined folder type (docs, images, etc.)
                for (const type of FOLDER_TYPES) {
                    const sourceTypePath = path.join(userAssetPath, type);
                    try {
                        // Check if the source type directory exists before trying to move
                        await fs.access(sourceTypePath);

                        // If source exists, ensure the timestamped backup directory is ready
                        if (!backupDirCreated) {
                            await fs.mkdir(userTimestampBackupPath, { recursive: true });
                            backupDirCreated = true;
                            // console.log(`    Created backup directory: ${userTimestampBackupPath}`);
                        }

                        // Define the destination path in the backup folder
                        const backupTypePath = path.join(userTimestampBackupPath, type);
                        // console.log(`    Moving ${sourceTypePath} to ${backupTypePath}`);
                        // Move the existing type folder to the backup location
                        await fs.rename(sourceTypePath, backupTypePath);
                        movedSomething = true;

                    } catch (accessErr) {
                        // Ignore error if the source directory doesn't exist (ENOENT)
                        if (accessErr.code !== 'ENOENT') {
                            console.error(`    Error accessing source folder ${sourceTypePath}:`, accessErr.message);
                        }
                        // If ENOENT, the folder doesn't exist, nothing to move.
                    }

                    // Always ensure the empty type directory exists in the main assets folder
                    try {
                        // console.log(`    Ensuring empty directory: ${sourceTypePath}`);
                        await fs.mkdir(sourceTypePath, { recursive: true });
                    } catch (mkdirErr) {
                         console.error(`    Failed to recreate directory ${sourceTypePath}:`, mkdirErr.message);
                    }
                } // End loop through FOLDER_TYPES

                 if (movedSomething) {
                     console.log(`  Finished backup for user [${userName}] to backup_${timestamp}`);
                 } else {
                     console.log(`  No existing asset types found to backup for user [${userName}]`);
                 }


            } catch (userDirStatErr) {
                 // Error checking if the item in assets is a directory
                 console.error(`Error processing potential user asset directory ${userAssetPath}:`, userDirStatErr.message);
            }
        } // End loop through userDirs

        console.log("--- Finished Asset Cleanup ---");

    } catch (error) {
        // Catch errors related to backup dir creation or reading the main assets dir
        console.error("!!! Critical Error during Asset Cleanup process:", error);
    }
}

// Export the function to be used elsewhere
module.exports = { performAssetCleanup };

```

`server/utils/networkUtils.js`

```javascript
const os = require('os');

function getLocalIPs() {
    const interfaces = os.networkInterfaces();
    const ips = new Set(['localhost']); // Include localhost

    for (const iface of Object.values(interfaces)) {
        for (const addr of iface) {
            // Include IPv4 non-internal addresses
            if (addr.family === 'IPv4' && !addr.internal) {
                ips.add(addr.address);
            }
        }
    }
    return Array.from(ips);
}

function getPreferredLocalIP() {
    const ips = getLocalIPs();
    // Prioritize non-localhost, non-link-local (169.254) IPs
    // Often 192.168.* or 10.* or 172.16-31.* are common private ranges
    return ips.find(ip => !ip.startsWith('169.254.') && ip !== 'localhost' && (ip.startsWith('192.168.') || ip.startsWith('10.') || ip.match(/^172\.(1[6-9]|2[0-9]|3[0-1])\./))) ||
           ips.find(ip => !ip.startsWith('169.254.') && ip !== 'localhost') || // Any other non-link-local
           'localhost'; // Fallback
}

module.exports = { getLocalIPs, getPreferredLocalIP };

```

`server/workers/adminAnalysisWorker.js`

```javascript
// server/workers/adminAnalysisWorker.js
const { workerData, parentPort } = require('worker_threads');
const mongoose = require('mongoose');
const path = require('path'); // For resolving .env path

// Adjust paths if your project structure is different
const AdminDocument = require('../models/AdminDocument'); // Specific model for admin docs
const connectDB = require('../config/db');
const geminiService = require('../services/geminiService');
const { ANALYSIS_PROMPTS } = require('../config/promptTemplates');

// Load .env variables from the server directory for the worker
require('dotenv').config({ path: path.resolve(__dirname, '..', '.env') });


async function performAdminDocAnalysis(adminDocumentId, originalName, textForAnalysis) {
    const logPrefix = `[AdminAnalysisWorker ${process.pid}, Doc: ${originalName}, ID: ${adminDocumentId}]`;
    console.log(`${logPrefix} Starting analysis. Text length: ${textForAnalysis ? textForAnalysis.length : 0}`);

    const analysisResults = { faq: "", topics: "", mindmap: "" };
    let allIndividualAnalysesSuccessful = true;

    async function generateSingleAnalysis(type, promptContentForLLM) {
        try {
            console.log(`${logPrefix} Generating ${type}...`);
            // For admin docs, we don't have a "user" in the same sense for history.
            // We send a simple instruction to perform the task.
            const historyForGemini = [{ role: 'user', parts: [{ text: "Perform the requested analysis based on the system instruction and provided document text." }] }];
            
            const generatedText = await geminiService.generateContentWithHistory(
                historyForGemini,
                promptContentForLLM // This is the full prompt from ANALYSIS_PROMPTS including the document text
            );

            if (!generatedText || typeof generatedText !== 'string' || generatedText.trim() === "") {
                console.warn(`${logPrefix} Gemini returned empty content for ${type}.`);
                return { success: false, content: `Notice: No content generated by the AI for ${type}.` };
            }
            console.log(`${logPrefix} ${type} generation successful.`);
            return { success: true, content: generatedText.trim() };
        } catch (error) {
            console.error(`${logPrefix} Error during ${type} generation: ${error.message}`);
            allIndividualAnalysesSuccessful = false;
            return { success: false, content: `Error generating ${type}: ${error.message.split('\n')[0].substring(0, 250)}` };
        }
    }

    if (!textForAnalysis || textForAnalysis.trim() === "") {
        console.warn(`${logPrefix} No text provided for analysis. Skipping generation.`);
        allIndividualAnalysesSuccessful = true; // Not a failure, just nothing to do.
        analysisResults.faq = "Skipped: No text content provided.";
        analysisResults.topics = "Skipped: No text content provided.";
        analysisResults.mindmap = "Skipped: No text content provided.";
    } else {
        // --- Generate FAQ, Topics, and Mindmap IN PARALLEL ---
        const analysisPromises = [
            generateSingleAnalysis('FAQ', ANALYSIS_PROMPTS.faq.getPrompt(textForAnalysis)),
            generateSingleAnalysis('Topics', ANALYSIS_PROMPTS.topics.getPrompt(textForAnalysis)),
            generateSingleAnalysis('Mindmap', ANALYSIS_PROMPTS.mindmap.getPrompt(textForAnalysis))
        ];

        const [faqOutcome, topicsOutcome, mindmapOutcome] = await Promise.allSettled(analysisPromises);

        if (faqOutcome.status === 'fulfilled') {
            analysisResults.faq = faqOutcome.value.content;
            if (!faqOutcome.value.success) allIndividualAnalysesSuccessful = false;
        } else {
            analysisResults.faq = `Error generating FAQ: ${faqOutcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
            allIndividualAnalysesSuccessful = false;
            console.error(`${logPrefix} FAQ generation promise rejected:`, faqOutcome.reason);
        }

        if (topicsOutcome.status === 'fulfilled') {
            analysisResults.topics = topicsOutcome.value.content;
            if (!topicsOutcome.value.success) allIndividualAnalysesSuccessful = false;
        } else {
            analysisResults.topics = `Error generating Topics: ${topicsOutcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
            allIndividualAnalysesSuccessful = false;
            console.error(`${logPrefix} Topics generation promise rejected:`, topicsOutcome.reason);
        }

        if (mindmapOutcome.status === 'fulfilled') {
            analysisResults.mindmap = mindmapOutcome.value.content;
            if (!mindmapOutcome.value.success) allIndividualAnalysesSuccessful = false;
        } else {
            analysisResults.mindmap = `Error generating Mindmap: ${mindmapOutcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
            allIndividualAnalysesSuccessful = false;
            console.error(`${logPrefix} Mindmap generation promise rejected:`, mindmapOutcome.reason);
        }
    }
    
    // Update MongoDB with all results
    // Note: This worker doesn't set 'analysisStatus' as it's not in the simplified AdminDocument model.
    // It directly updates the analysis fields.
    try {
        const updateResult = await AdminDocument.updateOne(
            { _id: adminDocumentId }, // Find by the document's MongoDB _id
            {
                $set: {
                    "analysis.faq": analysisResults.faq,
                    "analysis.topics": analysisResults.topics,
                    "analysis.mindmap": analysisResults.mindmap,
                    "analysisUpdatedAt": new Date()
                }
            }
        );

        if (updateResult.matchedCount === 0) {
            console.error(`${logPrefix} DB Error: AdminDocument with ID ${adminDocumentId} not found for update.`);
            return { success: false, message: `AdminDocument not found in DB (ID: ${adminDocumentId}).`, results: analysisResults };
        }
        if (updateResult.modifiedCount === 0 && updateResult.matchedCount === 1) {
            console.warn(`${logPrefix} Analysis results for already matched existing content in DB (ID: ${adminDocumentId}). No change made or content was identical.`);
        } else {
             console.log(`${logPrefix} Analysis results stored in DB.`);
        }
        return { success: allIndividualAnalysesSuccessful, message: `Analysis ${allIndividualAnalysesSuccessful ? 'completed' : 'completed with some failures'}.`, results: analysisResults };
    } catch (dbError) {
        console.error(`${logPrefix} DB Error storing analysis results:`, dbError);
        return { success: false, message: `DB Error storing analysis: ${dbError.message}`, results: analysisResults };
    }
}

async function run() {
    const { adminDocumentId, originalName, textForAnalysis } = workerData;
    let dbConnected = false;
    let overallTaskSuccess = false;
    let finalMessageToParent = "Admin analysis worker encountered an issue.";
    const logPrefix = `[AdminAnalysisWorker ${process.pid}, Doc: ${originalName}, ID: ${adminDocumentId}]`;

    try {
        console.log(`${logPrefix} Worker received task.`);
        if (!process.env.MONGO_URI) throw new Error("MONGO_URI not set in AdminAnalysisWorker environment.");
        if (!adminDocumentId || !originalName) throw new Error("Missing adminDocumentId or originalName in workerData.");
        
        await connectDB(process.env.MONGO_URI);
        dbConnected = true;
        console.log(`${logPrefix} DB Connected.`);

        const analysisServiceResult = await performAdminDocAnalysis(adminDocumentId, originalName, textForAnalysis);
        overallTaskSuccess = analysisServiceResult.success;
        finalMessageToParent = analysisServiceResult.message;

        if (parentPort) {
            parentPort.postMessage({
                success: overallTaskSuccess,
                originalName: originalName, // For logging on main thread
                adminDocumentId: adminDocumentId,
                message: finalMessageToParent
            });
        }

    } catch (error) {
        console.error(`${logPrefix} Critical error in worker:`, error.message, error.stack);
        finalMessageToParent = error.message || "Unknown critical error in AdminAnalysisWorker.";
        overallTaskSuccess = false;
        // Note: We don't update a status field here as the simplified model doesn't have one.
        // The main thread (adminDocuments.js) might log this worker failure.
        if (parentPort) {
            parentPort.postMessage({ success: false, originalName, adminDocumentId, error: finalMessageToParent });
        }
    } finally {
        if (dbConnected) {
            await mongoose.disconnect().catch(e => console.error(`${logPrefix} Error disconnecting DB:`, e));
            console.log(`${logPrefix} DB Disconnected.`);
        }
        console.log(`${logPrefix} Finished task. Overall Success: ${overallTaskSuccess}`);
        // Worker exits automatically if parentPort exists and main thread doesn't keep it alive,
        // or if it's the end of the run() promise.
    }
}

run();
```

`server/workers/analysisWorker.js`

```javascript
// server/workers/analysisWorker.js
const { workerData, parentPort } = require('worker_threads');
const mongoose = require('mongoose');
// const path = require('path'); // Not strictly needed if paths below are correct

// Assuming worker is in server/workers/ and services/models are in server/services/, server/models/
const User = require('../models/User');
const connectDB = require('../config/db');
const geminiService = require('../services/geminiService'); // For actual LLM calls
const ollamaService = require('../services/ollamaService'); // Import Ollama service
const { ANALYSIS_PROMPTS } = require('../config/promptTemplates'); // For prompts

// This function will now contain the actual analysis generation logic
async function performFullAnalysis(userId, originalName, textForAnalysis, llmProvider, ollamaModel) {
    console.log(`[Analysis Worker ${process.pid}] Starting actual analysis generation for '${originalName}'. Text length: ${textForAnalysis.length}`);

    const analysisResults = { faq: "", topics: "", mindmap: "" };
    let allIndividualAnalysesSuccessful = true; // Tracks if each specific analysis type was successful

    // Helper for a single analysis type, similar to what was in upload.js
    async function generateSingleAnalysis(type, promptContentForLLM, context) {
        try {
            console.log(`[Analysis Worker] Generating ${type} for '${context.originalName}' (User: ${context.userId}).`);
            const historyForGemini = [{ role: 'user', parts: [{ text: "Please perform the requested analysis based on the system instruction provided." }] }];
            
            let generatedText;
            if (llmProvider === 'ollama') {
                generatedText = await ollamaService.generateContentWithHistory(
                    historyForGemini, // This structure might need adjustment for ollamaService's prompt formatter
                    promptContentForLLM, // This is the system prompt + document text
                    { model: ollamaModel, maxOutputTokens: ollamaService.DEFAULT_MAX_OUTPUT_TOKENS_OLLAMA_CHAT } // Pass model and token options
                );
            } else { // Default to Gemini
                generatedText = await geminiService.generateContentWithHistory(
                    historyForGemini,
                    promptContentForLLM // This is the full prompt including the document text
                );
            }

            if (!generatedText || typeof generatedText !== 'string' || generatedText.trim() === "") {
                console.warn(`[Analysis Worker] Gemini returned empty content for ${type} for '${context.originalName}'.`);
                return { success: false, content: `Notice: No content generated by the AI for ${type}.` };
            }
            console.log(`[Analysis Worker] ${type} generation successful for '${context.originalName}'.`);
            return { success: true, content: generatedText.trim() };
        } catch (error) {
            console.error(`[Analysis Worker] Error during ${type} generation for '${context.originalName}': ${error.message}`);
            allIndividualAnalysesSuccessful = false; // Mark that at least one analysis type failed
            return { success: false, content: `Error generating ${type}: ${error.message.split('\n')[0].substring(0, 250)}` };
        }
    }

    const logCtx = { userId, originalName };

    // --- Generate FAQ, Topics, and Mindmap IN PARALLEL within this worker ---
    // This makes the worker itself more efficient if the LLM calls are independent.
    const analysisPromises = [
        generateSingleAnalysis('FAQ', ANALYSIS_PROMPTS.faq.getPrompt(textForAnalysis), logCtx),
        generateSingleAnalysis('Topics', ANALYSIS_PROMPTS.topics.getPrompt(textForAnalysis), logCtx),
        generateSingleAnalysis('Mindmap', ANALYSIS_PROMPTS.mindmap.getPrompt(textForAnalysis), logCtx)
    ];

    const [faqOutcome, topicsOutcome, mindmapOutcome] = await Promise.allSettled(analysisPromises);

    // Process outcomes from Promise.allSettled
    if (faqOutcome.status === 'fulfilled') {
        analysisResults.faq = faqOutcome.value.content;
        if (!faqOutcome.value.success) allIndividualAnalysesSuccessful = false;
    } else { // rejected
        analysisResults.faq = `Error generating FAQ: ${faqOutcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
        allIndividualAnalysesSuccessful = false;
        console.error(`[Analysis Worker] FAQ generation promise rejected for ${originalName}:`, faqOutcome.reason);
    }

    if (topicsOutcome.status === 'fulfilled') {
        analysisResults.topics = topicsOutcome.value.content;
        if (!topicsOutcome.value.success) allIndividualAnalysesSuccessful = false;
    } else { // rejected
        analysisResults.topics = `Error generating Topics: ${topicsOutcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
        allIndividualAnalysesSuccessful = false;
        console.error(`[Analysis Worker] Topics generation promise rejected for ${originalName}:`, topicsOutcome.reason);
    }

    if (mindmapOutcome.status === 'fulfilled') {
        analysisResults.mindmap = mindmapOutcome.value.content;
        if (!mindmapOutcome.value.success) allIndividualAnalysesSuccessful = false;
    } else { // rejected
        analysisResults.mindmap = `Error generating Mindmap: ${mindmapOutcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
        allIndividualAnalysesSuccessful = false;
        console.error(`[Analysis Worker] Mindmap generation promise rejected for ${originalName}:`, mindmapOutcome.reason);
    }
    
    // Update MongoDB with all results (even if some failed, we store what we have or the error messages)
    const finalAnalysisStatus = allIndividualAnalysesSuccessful ? "completed" : "failed_partial";
    try {
        await User.updateOne(
            { _id: userId, "uploadedDocuments.filename": originalName },
            {
                $set: {
                    "uploadedDocuments.$.analysis.faq": analysisResults.faq,
                    "uploadedDocuments.$.analysis.topics": analysisResults.topics,
                    "uploadedDocuments.$.analysis.mindmap": analysisResults.mindmap,
                    "uploadedDocuments.$.analysisStatus": finalAnalysisStatus,
                    "uploadedDocuments.$.analysisTimestamp": new Date()
                }
            }
        );
        console.log(`[Analysis Worker ${process.pid}] Analysis results for '${originalName}' (Status: ${finalAnalysisStatus}) stored in DB.`);
        return { success: allIndividualAnalysesSuccessful, message: `Analysis ${allIndividualAnalysesSuccessful ? 'completed successfully' : 'completed with some failures'}.`, results: analysisResults };
    } catch (dbError) {
        console.error(`[Analysis Worker ${process.pid}] DB Error storing analysis results for '${originalName}':`, dbError);
        // This is a critical error for the worker's task.
        // The 'analysisStatus' might remain 'processing' or be whatever it was before this attempt.
        return { success: false, message: `DB Error storing analysis: ${dbError.message}`, results: analysisResults };
    }
}

async function run() {
    const { userId, originalName, textForAnalysis, llmProvider, ollamaModel } = workerData;
    let dbConnected = false;
    let overallTaskSuccess = false; // Renamed for clarity for the worker's overall task
    let finalMessageToParent = "Analysis worker encountered an issue.";

    try {
        console.log(`[Analysis Worker ${process.pid}] Received task for: ${originalName}, User: ${userId}`);
        if (!process.env.MONGO_URI) {
            throw new Error("MONGO_URI not set in Analysis worker environment.");
        }
        if (!userId || !originalName) {
            throw new Error("Missing userId or originalName in workerData.");
        }
        
        await connectDB(process.env.MONGO_URI);
        dbConnected = true;
        console.log(`[Analysis Worker ${process.pid}] DB Connected for ${originalName}.`);

        // Update status to 'processing_analysis'
        await User.updateOne(
            { _id: userId, "uploadedDocuments.filename": originalName },
            { $set: { "uploadedDocuments.$.analysisStatus": "processing" } }
        );
        console.log(`[Analysis Worker ${process.pid}] Set analysisStatus to 'processing' for ${originalName}.`);


        if (!textForAnalysis || textForAnalysis.trim() === '') {
            console.warn(`[Analysis Worker ${process.pid}] No text provided for analysis for ${originalName}. Marking as skipped.`);
            await User.updateOne(
                { _id: userId, "uploadedDocuments.filename": originalName },
                { $set: { "uploadedDocuments.$.analysisStatus": "skipped_no_text", "uploadedDocuments.$.analysisTimestamp": new Date() } }
            );
            overallTaskSuccess = true; // Not a failure of the worker, just nothing to do.
            finalMessageToParent = "Analysis skipped: No text provided.";
            // Fall through to postMessage and finally block.
        } else {
            const analysisServiceResult = await performFullAnalysis(userId, originalName, textForAnalysis, llmProvider, ollamaModel);
            overallTaskSuccess = analysisServiceResult.success;
            finalMessageToParent = analysisServiceResult.message;
        }

        if (parentPort) {
            parentPort.postMessage({
                success: overallTaskSuccess,
                originalName: originalName,
                message: finalMessageToParent
                // Optionally send back analysisServiceResult.results if the main thread needs them
            });
        }

    } catch (error) {
        console.error(`[Analysis Worker ${process.pid}] Critical error processing '${originalName}':`, error.message, error.stack);
        finalMessageToParent = error.message || "Unknown critical error in Analysis worker.";
        overallTaskSuccess = false; // Ensure this is false on critical error
        if (dbConnected && userId && originalName) { // Check if userId & originalName are defined
            try {
                await User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: { "uploadedDocuments.$.analysisStatus": "failed_critical" } }
                );
            } catch (dbUpdateError) {
                console.error(`[Analysis Worker ${process.pid}] Failed to update status to 'failed_critical' for ${originalName} after error:`, dbUpdateError);
            }
        }
        if (parentPort) {
            parentPort.postMessage({ success: false, originalName, error: finalMessageToParent });
        }
    } finally {
        if (dbConnected) {
            await mongoose.disconnect().catch(e => console.error("[Analysis Worker] Error disconnecting DB:", e));
            console.log(`[Analysis Worker ${process.pid}] DB Disconnected for ${originalName}.`);
        }
        // The worker will exit automatically after the run() promise fulfills or rejects.
        // If parentPort exists, Node.js waits for messages or explicit exit.
        // If no parentPort (e.g. direct execution), we might need process.exit.
        // Since we expect parentPort, this is okay.
        console.log(`[Analysis Worker ${process.pid}] Finished task for ${originalName}. Overall Success: ${overallTaskSuccess}`);
    }
}

run();
```

`server/workers/kgWorker.js`

```javascript
// server/workers/kgWorker.js
const { workerData, parentPort } = require('worker_threads');
const mongoose = require('mongoose');

const User = require('../models/User');
const connectDB = require('../config/db');
const kgService = require('../services/kgService');

async function runKgGeneration() {
    const { chunksForKg: allInitialChunks, userId, originalName, llmProvider, ollamaModel } = workerData;
    let dbConnected = false;
    let overallSuccess = false;
    let finalMessage = "KG processing encountered an issue.";
    const logPrefix = `[KG Worker ${process.pid}, Doc: ${originalName}]`;

    try {
        console.log(`${logPrefix} Received task. User: ${userId}, Initial Chunks: ${allInitialChunks ? allInitialChunks.length : 0}`);
        if (!process.env.MONGO_URI) throw new Error("MONGO_URI not set in KG worker environment.");
        if (!userId || !originalName) throw new Error("Missing userId or originalName in KG workerData.");

        await connectDB(process.env.MONGO_URI);
        dbConnected = true;
        console.log(`${logPrefix} DB Connected.`);

        await User.updateOne(
            { _id: userId, "uploadedDocuments.filename": originalName },
            { $set: { "uploadedDocuments.$.kgStatus": "processing" } }
        );
        console.log(`${logPrefix} Status set to 'processing'.`);

        if (!allInitialChunks || allInitialChunks.length === 0) {
            console.log(`${logPrefix} No chunks provided for KG generation. Marking as skipped.`);
            await User.updateOne(
                { _id: userId, "uploadedDocuments.filename": originalName },
                { $set: { "uploadedDocuments.$.kgStatus": "skipped_no_chunks", "uploadedDocuments.$.kgTimestamp": new Date() } }
            );
            finalMessage = "No chunks provided for KG generation.";
            overallSuccess = true; // Not a failure of this worker's process
        } else {
            const kgExtractionResult = await kgService.generateAndStoreKg(allInitialChunks, userId, originalName, llmProvider, ollamaModel);

            if (kgExtractionResult && kgExtractionResult.success) {
                await User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: {
                        "uploadedDocuments.$.kgStatus": "completed",
                        "uploadedDocuments.$.kgNodesCount": kgExtractionResult.finalKgNodesCount,
                        "uploadedDocuments.$.kgEdgesCount": kgExtractionResult.finalKgEdgesCount,
                        "uploadedDocuments.$.kgTimestamp": new Date()
                        }
                    }
                );
                overallSuccess = true;
                finalMessage = kgExtractionResult.message || "KG generation and storage completed successfully.";
                console.log(`${logPrefix} SUCCESS: ${finalMessage}`);
            } else {
                await User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: { "uploadedDocuments.$.kgStatus": "failed_extraction" } }
                );
                finalMessage = (kgExtractionResult && kgExtractionResult.message) ? kgExtractionResult.message : "KG detailed extraction or storage failed.";
                console.error(`${logPrefix} FAILED (Extraction/Store): ${finalMessage}`);
                overallSuccess = false;
            }
        }

        if (parentPort) {
            parentPort.postMessage({ success: overallSuccess, originalName, message: finalMessage });
        }

    } catch (error) {
        console.error(`${logPrefix} CRITICAL error:`, error.message, error.stack);
        finalMessage = error.message || "Unknown critical error in KG worker.";
        overallSuccess = false;
        if (dbConnected && userId && originalName) {
            try {
                await User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: { "uploadedDocuments.$.kgStatus": "failed_critical" } }
                );
            } catch (dbUpdateError) {
                console.error(`${logPrefix} DB update error on critical fail:`, dbUpdateError);
            }
        }
        if (parentPort) {
            parentPort.postMessage({ success: false, originalName, error: finalMessage });
        }
    } finally {
        if (dbConnected) {
            await mongoose.disconnect().catch(e => console.error(`${logPrefix} Error disconnecting DB:`, e));
            console.log(`${logPrefix} DB Disconnected.`);
        }
        console.log(`${logPrefix} Finished task. Overall Success: ${overallSuccess}`);
    }
}

runKgGeneration();
```

`testing/abhishek_story.txt`

```
The Rising Star: The Story of Abhishek Sharma

In the bustling city of Amritsar, Punjab, where cricket isn't just a sport but a way of life, a young boy named Abhishek Sharma would spend hours under the sweltering sun, perfecting his cover drives on cracked concrete pitches. From the very beginning, there was something different about him. With a bat in hand, he moved with the calm confidence of someone who belonged to the game.

Abhishek was born on September 4, 2000, into a middle-class family that recognized his potential early. His father, a school principal and former cricketer himself, ensured that education and discipline walked hand-in-hand with cricket practice. By the age of 15, Abhishek had already made headlines in junior cricket circles, known for his aggressive batting and handy left-arm orthodox spin.

His big breakthrough came during the 2018 ICC Under-19 World Cup, where he played a crucial role in Indias victorious campaign under Prithvi Shaw's captaincy. The cricketing world saw a glimpse of his potentiala fearless middle-order batter who could swing the momentum of a game in just a few overs.

Soon after, he was picked up by the Delhi Daredevils (now Delhi Capitals) in the IPL auction. On his debut in 2018, he smashed a blistering 46 off just 19 balls, immediately making the cricketing fraternity sit up and take notice. That innings wasnt just about runsit was a statement: Abhishek Sharma had arrived.

But like many young prodigies, the journey wasn't without its share of challenges. Competition in Indian cricket is fierce. Inconsistent form and a lack of opportunities meant that he had to wait, watch, and work harder than ever. He spent the next few years honing his craftsharpening his power-hitting, building patience, and refining his bowling.

In 2022, playing for Sunrisers Hyderabad, Abhishek finally found his rhythm. Promoted to open the batting, he blossomed. He became known for his elegant yet explosive stroke playespecially his fearless lofted shots over cover. That year, he scored over 400 runs in the IPL, becoming one of the team's most reliable performers.

What made Abhishek special wasnt just his talent, but his temperament. He never let success get to his head or failures drag him down. Off the field, he remained grounded, often visiting his childhood coach in Amritsar and inspiring young kids from his city to believe in their dreams.

By 2025, Abhishek Sharma had transformed from a promising youngster into a dependable performer in both IPL and domestic cricket. Whispers of an India call-up grew louder. And when it finally camea T20 debut against South Africa in front of a packed crowd in MumbaiAbhishek walked in with his usual calm demeanor. He struck a fluent half-century, mixing finesse with fire, and earned the "Player of the Match" on debut.

As the Indian flag fluttered behind him during the national anthem that evening, Abhishek knew his journey had just begun. From the narrow gullies of Amritsar to international stadiums filled with roaring fans, he had carved his pathnot just with talent, but with relentless hard work, humility, and heart.

And as fans across the country began chanting his name, a new cricketing chapter was being writtenone led by Abhishek Sharma, the boy who dared to dream.









```

