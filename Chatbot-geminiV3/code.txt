`code.txt`

```

```

`frontend/.env`

```
#REACT_APP_API_BASE_URL=http://localhost:5001/api
# OR for Vite:
VITE_API_BASE_URL=http://localhost:5001/api






```

`frontend/eslint.config.js`

```javascript
import js from '@eslint/js'
import globals from 'globals'
import reactHooks from 'eslint-plugin-react-hooks'
import reactRefresh from 'eslint-plugin-react-refresh'

export default [
  { ignores: ['dist'] },
  {
    files: ['**/*.{js,jsx}'],
    languageOptions: {
      ecmaVersion: 2020,
      globals: globals.browser,
      parserOptions: {
        ecmaVersion: 'latest',
        ecmaFeatures: { jsx: true },
        sourceType: 'module',
      },
    },
    plugins: {
      'react-hooks': reactHooks,
      'react-refresh': reactRefresh,
    },
    rules: {
      ...js.configs.recommended.rules,
      ...reactHooks.configs.recommended.rules,
      'no-unused-vars': ['error', { varsIgnorePattern: '^[A-Z_]' }],
      'react-refresh/only-export-components': [
        'warn',
        { allowConstantExport: true },
      ],
    },
  },
]

```

`frontend/index.html`

```html
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>AI TUTOR</title>

    <script src="https://cdn.jsdelivr.net/npm/d3@6"></script>
    <script src="https://cdn.jsdelivr.net/npm/markmap-lib@latest"></script>
    <script src="https://cdn.jsdelivr.net/npm/markmap-view@latest"></script>
    <script src="https://cdn.jsdelivr.net/npm/markmap-toolbar@latest"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/markmap-toolbar@latest/dist/style.css">
    <script src="https://cdn.jsdelivr.net/npm/mermaid@latest/dist/mermaid.min.js"></script>
    
    <script>
      document.addEventListener('DOMContentLoaded', () => {
        if (typeof mermaid !== 'undefined') {
          mermaid.initialize({ startOnLoad: false, theme: 'neutral' }); 
          console.log("Mermaid.js initialized globally with 'neutral' theme via index.html.");
        } else {
          console.error("Mermaid.js not found on window after script load. Mermaid diagrams may not render.");
        }
      });
    </script>

  </head>
  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.jsx"></script>
  </body>
</html>
```

`frontend/postcss.config.js`

```javascript
export default {
  plugins: {
    'postcss-nesting': {},
    tailwindcss: {},
    autoprefixer: {},
  },
}
```

`frontend/src/App.css`

```css
/* #root {
  max-width: 1280px;
  margin: 0 auto;
  padding: 2rem;
  text-align: center;
}

.logo {
  height: 6em;
  padding: 1.5em;
  will-change: filter;
  transition: filter 300ms;
}
.logo:hover {
  filter: drop-shadow(0 0 2em #646cffaa);
}
.logo.react:hover {
  filter: drop-shadow(0 0 2em #61dafbaa);
}

@keyframes logo-spin {
  from {
    transform: rotate(0deg);
  }
  to {
    transform: rotate(360deg);
  }
}

@media (prefers-reduced-motion: no-preference) {
  a:nth-of-type(2) .logo {
    animation: logo-spin infinite 20s linear;
  }
}

.card {
  padding: 2em;
}

.read-the-docs {
  color: #888;
} */

```

`frontend/src/App.jsx`

```javascript
import React, { useState, useEffect, useCallback } from 'react';
import { useAuth } from './hooks/useAuth.jsx';
import { useAppState } from './contexts/AppStateContext.jsx';
import AuthModal from './components/auth/AuthModal.jsx';
import TopNav from './components/layout/TopNav.jsx';
import LeftPanel from './components/layout/LeftPanel.jsx';
import CenterPanel from './components/layout/CenterPanel.jsx';
import RightPanel from './components/layout/RightPanel.jsx';
import LeftCollapsedNav from './components/layout/LeftCollapsedNav.jsx';
import RightCollapsedNav from './components/layout/RightCollapsedNav.jsx';
import ChatHistoryModal from './components/chat/ChatHistoryModal.jsx';
import api from './services/api.js'; // This will use MOCKED API if api.js is set to DEV_MODE_MOCK_API = true
import toast from 'react-hot-toast';
import { motion, AnimatePresence } from 'framer-motion';

function App() {
    const { 
        token, 
        user, 
        loading: authLoadingFromContext, // Renamed to avoid conflict with appInitializing
        logout, 
        setUser: setAuthUser, // From AuthContext, to update user details if login response has more
    } = useAuth();

    const { 
        theme, 
        isLeftPanelOpen, 
        isRightPanelOpen, 
        currentSessionId, 
        setSessionId: setGlobalSessionId 
    } = useAppState();
    
    // Local state for App.jsx's own initialization step AFTER AuthContext is ready
    const [appInitializing, setAppInitializing] = useState(true); 
    const [showAuthModal, setShowAuthModal] = useState(false); // Controls AuthModal visibility
    const [messages, setMessages] = useState([]);
    const [chatStatus, setChatStatus] = useState('Ready. Send a message to start!');
    const [orchestratorStatus, setOrchestratorStatus] = useState({ status: "loading", message: "Connecting..." });
    const [isHistoryModalOpen, setIsHistoryModalOpen] = useState(false);

    // Effect to apply Tailwind dark/light mode class to HTML element
    useEffect(() => {
        const rootHtmlElement = document.documentElement;
        rootHtmlElement.classList.remove('light', 'dark'); // Clear previous
        rootHtmlElement.classList.add(theme); // Add current
        // Optional: If you have body-specific theme styles for elements not covered by Tailwind's dark: prefix
        document.body.className = ''; 
        document.body.classList.add(theme === 'dark' ? 'bg-background-dark' : 'bg-background-light');
        console.log("App.jsx: Theme effect, theme is:", theme);
    }, [theme]);

    // Effect to handle initial authentication status and session setup
    useEffect(() => {
        console.log("App.jsx: Auth/Session useEffect. authLoading:", authLoadingFromContext, "Token:", token, "User:", user, "SessionId:", currentSessionId);
        if (authLoadingFromContext) {
            console.log("App.jsx: AuthContext is loading. App initializing...");
            setAppInitializing(true); // Show app loader while AuthContext determines auth state
            return;
        }

        // AuthContext has finished its loading
        console.log("App.jsx: AuthContext finished loading. Token:", token);
        if (!token) { // No token means user is not logged in
            console.log("App.jsx: No token. Showing AuthModal.");
            setShowAuthModal(true);
            setAppInitializing(false); // Done with this phase of init, modal will show
        } else { // Token exists, user is considered logged in
            console.log("App.jsx: Token exists. Hiding AuthModal. User:", user);
            setShowAuthModal(false); 
            // If user is logged in (token exists, user object should be set by AuthContext soon if not already)
            // AND there's no currentSessionId in AppStateContext, try to get/start one.
            if (user && !currentSessionId) { 
                console.log("App.jsx: User authenticated, but no currentSessionId. Starting new session via API.");
                api.startNewSession() // This will be a MOCKED call in V1
                    .then(data => {
                        if (data && data.sessionId) {
                            setGlobalSessionId(data.sessionId);
                            console.log("App.jsx: New session started/set from API:", data.sessionId);
                        } else {
                            console.error("App.jsx: Mock api.startNewSession did not return sessionId.");
                            toast.error("Could not initialize session (mock error).");
                        }
                    })
                    .catch(err => {
                        toast.error("Failed to start new session (mock error).");
                        console.error("App.jsx: Error starting new session (mock):", err);
                    });
            } else if (!user && token) {
                // This is an edge case: token present, but user object from AuthContext not yet propagated.
                // AuthContext's useEffect should set the user. We can wait or re-check.
                console.warn("App.jsx: Token exists, but user object is pending. Waiting for AuthContext to update user.");
                setAppInitializing(true); // Remain in initializing state until user object is available
                return; // Skip setting appInitializing to false yet
            }
            setAppInitializing(false); // Done with app-level init for authenticated user
        }
    }, [token, user, authLoadingFromContext, currentSessionId, setGlobalSessionId]);


    // Effect to fetch orchestrator status (uses mocked API in V1)
    useEffect(() => {
        api.getOrchestratorStatus().then(statusData => {
            setOrchestratorStatus(statusData);
            console.log("App.jsx: Orchestrator status fetched (mocked):", statusData);
        });
        // Interval for status check can be added later for V2
    }, []);

    // Effect to fetch chat history when session ID or token changes
    const fetchChatHistory = useCallback(async (sid) => {
        if (!sid || !token) {
            setMessages([]);
            setChatStatus(token ? "Start or select a chat." : "Please login.");
            return;
        }
        setChatStatus("Loading chat history (mocked)...");
        try {
            const historyData = await api.getChatHistory(sid); // Mocked call
            const formattedMessages = (Array.isArray(historyData) ? historyData : []).map(msg => ({
                id: msg.id || msg._id || String(Math.random() + Date.now()),
                sender: msg.sender || (msg.role === 'model' ? 'bot' : 'user'),
                text: msg.parts?.[0]?.text || msg.text || '',
                thinking: msg.thinking, references: msg.references || [],
                timestamp: msg.timestamp || new Date().toISOString(),
                source_pipeline: msg.source_pipeline
            }));
            setMessages(formattedMessages);
            setChatStatus(formattedMessages.length > 0 ? "Mock history loaded." : "Chat is empty (mock).");
        } catch (error) {
            toast.error(`Mock history load failed: ${error.message}`);
            setChatStatus("Error loading mock history.");
        }
    }, [token]); 

    useEffect(() => {
        if (currentSessionId && token) {
            fetchChatHistory(currentSessionId);
        } else if (!token) { // If token becomes null (e.g., after logout)
            setMessages([]);
            setChatStatus("Please login.");
        }
    }, [currentSessionId, token, fetchChatHistory]);

    // Callback for AuthModal upon successful login/signup (or dev login)
    const handleAuthSuccess = (authData) => {
        console.log("App.jsx: handleAuthSuccess called with data:", authData);
        setShowAuthModal(false); // Close the modal
        // AuthContext should have already set the token and user.
        // App.jsx primarily needs to ensure the session ID is handled.
        if (authData && authData.sessionId) {
            setGlobalSessionId(authData.sessionId);
        } else if (token && !currentSessionId) { // Fallback: if logged in but no session came from authData
            api.startNewSession().then(data => setGlobalSessionId(data.sessionId));
        }
        // If authData (from backend login/signup) has more complete user info than what jwtDecode provided
        if(authData && authData.username && authData._id){
            setAuthUser({username: authData.username, id: authData._id}); 
        }
    };
    
    // Handler for logout action
    const handleLogoutAndShowModal = () => {
        logout(); // From AuthContext - clears token, user in context and localStorage
        setGlobalSessionId(null); // Clear session in AppStateContext
        localStorage.removeItem('aiTutorSessionId'); // Also clear from localStorage directly
        setMessages([]);
        setChatStatus("Logged out. Please login.");
        setShowAuthModal(true); // Show AuthModal after logout
        toast.success("Logged out successfully.");
    };

    // Handler for "New Chat" button
    const handleNewChat = async () => {
        try {
            const data = await api.startNewSession(); // Mocked API call
            setGlobalSessionId(data.sessionId);
            setMessages([]); 
            setChatStatus("New chat started (mock).");
            toast.success("New mock chat started!");
        } catch (error) {
            toast.error("Failed to start new mock chat.");
        }
    };

    // Handler for when a session is selected from ChatHistoryModal
    const handleSelectSessionFromHistory = (sessionId) => {
        if (sessionId && sessionId !== currentSessionId) {
            setGlobalSessionId(sessionId); 
            // fetchChatHistory will be called by its useEffect
            toast.success(`Loading mock session...`);
        } else if (sessionId === currentSessionId) {
            toast.info("This session is already loaded.");
        }
        setIsHistoryModalOpen(false); 
    };

    // Render initial loading spinner if app or auth context is still initializing
    if (appInitializing || authLoadingFromContext) { 
        return (
            <div className="fixed inset-0 flex flex-col items-center justify-center bg-background-light dark:bg-background-dark text-text-light dark:text-text-dark">
                <div className="animate-spin rounded-full h-12 w-12 border-t-4 border-b-4 border-primary mb-4"></div>
                <p className="text-xl">Initializing AI Tutor...</p>
            </div>
        );
    }

    return (
        <div className={`flex flex-col h-screen overflow-hidden font-sans ${theme}`}>
            <AnimatePresence>
                {showAuthModal && !token && ( // Show AuthModal if flag is true AND user is not authenticated
                    <AuthModal 
                        isOpen={showAuthModal} 
                        onClose={handleAuthSuccess} 
                    />
                )}
            </AnimatePresence>

            {/* Render main application UI if user is authenticated (token and user exist) */}
            {(token && user) && (
                <>
                    <TopNav
                        user={user}
                        onLogout={handleLogoutAndShowModal}
                        onNewChat={handleNewChat}
                        onHistoryClick={() => setIsHistoryModalOpen(true)}
                        orchestratorStatus={orchestratorStatus}
                    />
                    <div className="flex flex-1 overflow-hidden pt-16 bg-background-light dark:bg-background-dark">
                        {/* Left Panel Area */}
                        <AnimatePresence mode="wait">
                            {isLeftPanelOpen ? (
                                <motion.aside 
                                    key="left-panel-main"
                                    initial={{ x: '-100%', opacity: 0 }}
                                    animate={{ x: '0%', opacity: 1 }}
                                    exit={{ x: '-100%', opacity: 0 }}
                                    transition={{ type: 'spring', stiffness: 300, damping: 30 }}
                                    className="w-full md:w-72 lg:w-80 xl:w-96 bg-surface-light dark:bg-surface-dark border-r border-border-light dark:border-border-dark overflow-y-auto p-3 sm:p-4 shadow-lg flex-shrink-0 custom-scrollbar"
                                >
                                    <LeftPanel /> 
                                </motion.aside>
                            ) : (
                                <LeftCollapsedNav /> // Shows icons and open button
                            )}
                        </AnimatePresence>
                        
                        {/* Center Panel */}
                        <main className={`flex-1 flex flex-col overflow-hidden p-1 sm:p-2 md:p-4 
                                         transition-all duration-300 ease-in-out
                                         ${isLeftPanelOpen ? 'lg:ml-0' : 'lg:ml-16 md:ml-14'} 
                                         ${isRightPanelOpen ? 'lg:mr-0' : 'lg:mr-16 md:mr-14'}`}>
                           <CenterPanel 
                                messages={messages} 
                                setMessages={setMessages} 
                                currentSessionId={currentSessionId}
                                chatStatus={chatStatus}
                                setChatStatus={setChatStatus}
                            />
                        </main>

                        {/* Right Panel Area */}
                        <AnimatePresence mode="wait">
                            {isRightPanelOpen ? (
                                <motion.aside 
                                    key="right-panel-main"
                                    initial={{ x: '100%', opacity: 0 }}
                                    animate={{ x: '0%', opacity: 1 }}
                                    exit={{ x: '100%', opacity: 0 }}
                                    transition={{ type: 'spring', stiffness: 300, damping: 30 }}
                                    className="hidden md:flex md:flex-col md:w-72 lg:w-80 xl:w-96 bg-surface-light dark:bg-surface-dark border-l border-border-light dark:border-border-dark overflow-y-auto p-3 sm:p-4 shadow-lg flex-shrink-0 custom-scrollbar"
                                >
                                    <RightPanel />
                                </motion.aside>
                            ) : (
                                <RightCollapsedNav /> // Shows icons and open button
                            )}
                        </AnimatePresence>
                    </div>
                    
                    {/* Chat History Modal */}
                    <ChatHistoryModal
                        isOpen={isHistoryModalOpen}
                        onClose={() => setIsHistoryModalOpen(false)}
                        onSelectSession={handleSelectSessionFromHistory}
                    />
                </>
            )}
            
            {/* Fallback UI if not initializing, not authenticated, and AuthModal isn't showing (should be rare) */}
            { !appInitializing && !token && !showAuthModal && (
                 <div className="fixed inset-0 flex flex-col items-center justify-center bg-background-light dark:bg-background-dark text-text-light dark:text-text-dark">
                     <p className="text-xl">Please <button 
                        onClick={()=> { setShowAuthModal(true); }} 
                        className="text-primary hover:underline font-semibold"
                        >log in</button> to continue.</p>
                 </div>
            )}
        </div>
    );
}

export default App;
```

`frontend/src/components/analysis/AnalysisTool.jsx`

```javascript
// frontend/src/components/analysis/AnalysisTool.jsx
import React, { useState } from 'react';
import api from '../../services/api.js'; // Assuming .js for services
import toast from 'react-hot-toast';
import MindmapViewer from './MindmapViewer.jsx';
import { ChevronDown, ChevronUp, Loader2, AlertTriangle } from 'lucide-react'; // Loader2 is imported once here
import * as LucideIcons from 'lucide-react'; // For dynamic icon selection by name
import { marked } from 'marked';
import Button from '../core/Button.jsx';
import IconButton from '../core/IconButton.jsx'; // Import IconButton
import { motion } from 'framer-motion'; // Import motion
import DOMPurify from 'dompurify';

marked.setOptions({
  breaks: true,
  gfm: true,
});

const createMarkup = (markdownText) => {
    if (!markdownText) return { __html: '' };
    const rawHtml = marked.parse(markdownText);
    const cleanHtml = DOMPurify.sanitize(rawHtml);
    return { __html: cleanHtml };
};

const escapeHtml = (unsafe) => { // Helper for <pre> tags if thinking content isn't markdown
    if (typeof unsafe !== 'string') return '';
    return unsafe
         .replace(/&/g, "&")
         .replace(/</g, "<")
         .replace(/>/g, ">")
         .replace(/"/g, '"')
         .replace(/'/g, "'");
};

function AnalysisTool({ toolType, title, iconName, selectedDocumentFilename }) {
    const [isOpen, setIsOpen] = useState(false);
    const [result, setResult] = useState(null);
    const [thinking, setThinking] = useState(null);
    const [isLoading, setIsLoading] = useState(false);
    const [error, setError] = useState('');
    const [isFetchingStored, setIsFetchingStored] = useState(false); // For fetching stored data


    // Dynamically select icon component based on iconName prop
    const IconComponent = LucideIcons[iconName] || LucideIcons.HelpCircle; // Default to HelpCircle if not found
    console.log('selectedDocumentFilename :::: ', selectedDocumentFilename);
    

    


    const handleRunAnalysis = async () => {
        if (!selectedDocumentFilename) {
            toast.error("Please select a document from the left panel first.");
            return;
        }
        setIsLoading(true);
        setError('');
        setResult(null);
        setThinking(null);
        const toastId = toast.loading(`Generating ${title} for ${selectedDocumentFilename}...`);

        try {
            
            const payload = { filename: selectedDocumentFilename, analysis_type: toolType };
            const response = await api.requestAnalysis(payload); // Mocked in V1
            setResult(response.content);
            setThinking(response.thinking);
            setIsOpen(true); 
            toast.success(`${title} generated (mock data)!`, { id: toastId });
        } catch (err) {
            const errorMessage = err.response?.data?.message || err.message || `Failed to generate ${title}.`;
            setError(errorMessage);
            toast.error(errorMessage, { id: toastId });
            console.error("AnalysisTool Error:", err);
        } finally {
            setIsLoading(false);
        }
    };

    return (
        <div className="card-base p-3"> {/* Use themed card style from index.css */}
            <div className="flex items-center justify-between">
                <button 
                    onClick={() => setIsOpen(!isOpen)}
                    className="flex items-center gap-2 text-sm font-medium text-text-light dark:text-text-dark focus:outline-none w-full text-left hover:text-primary dark:hover:text-primary-light transition-colors"
                    aria-expanded={isOpen}
                >
                    <IconComponent size={16} className="text-primary dark:text-primary-light flex-shrink-0" />
                    <span className="flex-grow">{title}</span>
                </button>
                <div className="flex items-center gap-1 flex-shrink-0">
                    <Button
                        onClick={handleRunAnalysis}
                        variant="primary" 
                        size="sm"
                        className="!px-3 !py-1 text-xs" // Override Button padding for smaller size
                        isLoading={isLoading} // Button component handles its own loader icon
                        disabled={isLoading || !selectedDocumentFilename}
                        title={!selectedDocumentFilename ? "Select a document first" : `Run ${title} Analysis`}
                    >
                       Run
                    </Button>
                    <IconButton 
                        icon={isOpen ? ChevronUp : ChevronDown} 
                        onClick={() => setIsOpen(!isOpen)} 
                        size="sm" 
                        variant="ghost"
                        className="p-1" // Ensure IconButton has padding if its default is too large
                        aria-label={isOpen ? "Collapse section" : "Expand section"}
                    />
                </div>
            </div>

            {isOpen && (
                <motion.div 
                    initial={{ height: 0, opacity: 0 }} 
                    animate={{ height: 'auto', opacity: 1 }} 
                    exit={{ height: 0, opacity: 0 }}
                    transition={{ duration: 0.2, ease: "easeInOut" }}
                    className="mt-2 pt-2 border-t border-border-light dark:border-border-dark overflow-hidden" 
                >
                    <div className="space-y-2"> {/* Added wrapper for consistent spacing */}
                        {isLoading && (
                            <p className="text-xs text-text-muted-light dark:text-text-muted-dark p-2 flex items-center gap-2">
                                <Loader2 size={14} className="animate-spin"/>Generating...
                            </p>
                        )}
                        {error && (
                            <div className="p-2 bg-red-500/10 border border-red-500/30 text-red-600 dark:text-red-300 rounded-md text-xs flex items-center gap-1">
                                <AlertTriangle size={14} /> {error}
                            </div>
                        )}
                        {thinking && !error && (
                            <details className="text-xs" open={!!result}> {/* Open if result is also present */}
                                <summary className="cursor-pointer text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light font-medium">
                                    AI Reasoning
                                </summary>
                                <pre className="mt-1 p-1.5 bg-gray-100 dark:bg-gray-900 rounded text-[0.7rem] max-h-28 overflow-y-auto custom-scrollbar whitespace-pre-wrap break-words">
                                    <code>{escapeHtml(thinking)}</code>
                                </pre>
                            </details>
                        )}
                        {result && !error && (
                            toolType === 'mindmap' ? (
                                <MindmapViewer markdownContent={result} />
                            ) : (
                                <div 
                                    className="prose prose-xs dark:prose-invert max-w-none text-text-light dark:text-text-dark p-1 max-h-60 overflow-y-auto custom-scrollbar text-[0.75rem] leading-relaxed"
                                    dangerouslySetInnerHTML={createMarkup(result)}
                                />
                            )
                        )}
                        {!isLoading && !result && !error && !selectedDocumentFilename && (
                             <p className="text-xs text-text-muted-light dark:text-text-muted-dark p-2">Select a document to run analysis.</p>
                        )}
                         {!isLoading && !result && !error && selectedDocumentFilename && (
                             <p className="text-xs text-text-muted-light dark:text-text-muted-dark p-2">Click "Run" to generate analysis.</p>
                        )}
                    </div>
                </motion.div>
            )}
        </div>
    );
}
export default AnalysisTool;
```

`frontend/src/components/analysis/AnalysisToolRunner.jsx`

```javascript
// src/components/analysis/AnalysisToolRunner.jsx
import React, { useState, useEffect, useCallback, useRef } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import api from '../../services/api.js';
import toast from 'react-hot-toast';
import { ChevronDown, ChevronUp, Loader2, Eye, AlertTriangle, Sparkles, HelpCircle as DefaultIcon, Download } from 'lucide-react';
import * as LucideIcons from 'lucide-react';
import Button from '../core/Button.jsx';
import IconButton from '../core/IconButton.jsx';
import Modal from '../core/Modal.jsx';
import { marked } from 'marked';
import MindmapViewer from './MindmapViewer.jsx'; 
import DOMPurify from 'dompurify';
import Prism from 'prismjs'; 
import { renderMathInHtml } from '../../utils/markdownUtils';
import { useAppState } from '../../contexts/AppStateContext.jsx'; 

marked.setOptions({
  breaks: true,
  gfm: true,
});

const createMarkup = (markdownText) => {
    if (!markdownText) return { __html: '' };
    let html = marked.parse(markdownText);
    html = renderMathInHtml(html); 
    const cleanHtml = DOMPurify.sanitize(html, {
        USE_PROFILES: { html: true, mathMl: true, svg: true }, 
        ADD_TAGS: ['iframe'], 
        ADD_ATTR: ['allow', 'allowfullscreen', 'frameborder', 'scrolling'],
    });
    return { __html: cleanHtml };
};

const escapeHtml = (unsafe) => {
    if (typeof unsafe !== 'string') return '';
    return unsafe.replace(/&/g, "&").replace(/</g, "<").replace(/>/g, ">").replace(/"/g, '"').replace(/'/g, "'");
};

const ENGAGEMENT_TEXTS = {
    faq: ["Analyzing FAQs...", "Identifying questions...", "Compiling answers..."],
    topics: ["Extracting topics...", "Identifying themes...", "Summarizing points..."],
    mindmap: ["Generating mind map...", "Structuring concepts...", "Visualizing..."],
    default: ["Processing...", "Thinking...", "Working on it..."]
};

// Placeholder messages to check against for AI Reasoning section
const placeholderReasoningMessages = [
    "Retrieved stored analysis. No detailed AI reasoning provided.",
    "AI reasoning not available.",
    "Mock generation for",
    "Retrieved stored mindmap data. No specific thinking process recorded in content."
];

function AnalysisToolRunner({ toolType, title, iconName, selectedDocumentFilename }) {
    const [isSectionOpen, setIsSectionOpen] = useState(true);
    const [isDropdownOpen, setIsDropdownOpen] = useState(false);
    const [isLoading, setIsLoading] = useState(false);
    const [error, setError] = useState('');
    const [analysisContent, setAnalysisContent] = useState(null);
    const [aiReasoning, setAiReasoning] = useState(null);
    const [isModalOpen, setIsModalOpen] = useState(false);
    const [currentEngagementText, setCurrentEngagementText] = useState('');

    const IconComponent = LucideIcons[iconName] || DefaultIcon;
    const modalAnalysisContentRef = useRef(null);
    const aiReasoningContentRef = useRef(null);
    const mindmapViewerRef = useRef(null); 
    const { theme: appTheme } = useAppState(); 

    useEffect(() => {
        let intervalId;
        if (isLoading) {
            const texts = ENGAGEMENT_TEXTS[toolType] || ENGAGEMENT_TEXTS.default;
            let textIndex = 0;
            setCurrentEngagementText(texts[0]);
            intervalId = setInterval(() => {
                textIndex = (textIndex + 1) % texts.length;
                setCurrentEngagementText(texts[textIndex]);
            }, 1800);
        } else {
            setCurrentEngagementText('');
        }
        return () => clearInterval(intervalId);
    }, [isLoading, toolType]);

    useEffect(() => {
        if (!selectedDocumentFilename) {
            setIsLoading(false);
            setError('');
            setAnalysisContent(null);
            setAiReasoning(null);
            setIsDropdownOpen(false);
        } else {
            // When a new document is selected, optionally reset previous results
            // to avoid showing old data before a new "Run"
             setAnalysisContent(null);
             setAiReasoning(null);
             setIsDropdownOpen(false);
             setError('');
             setIsLoading(false); // Ensure loading state is reset
        }
    }, [selectedDocumentFilename]);

    useEffect(() => {
        if (isModalOpen && analysisContent && toolType !== 'mindmap' && modalAnalysisContentRef.current) {
            const timer = setTimeout(() => {
                if (modalAnalysisContentRef.current) Prism.highlightAllUnder(modalAnalysisContentRef.current);
            }, 50);
            return () => clearTimeout(timer);
        }
    }, [isModalOpen, analysisContent, toolType]);

    useEffect(() => {
        if (aiReasoningContentRef.current && aiReasoning && isDropdownOpen) {
            const timer = setTimeout(() => {
                if (aiReasoningContentRef.current) Prism.highlightAllUnder(aiReasoningContentRef.current);
            }, 0);
            return () => clearTimeout(timer);
        }
    }, [aiReasoning, isDropdownOpen]);

    const handleRunAnalysis = async () => {
        if (!selectedDocumentFilename) {
            toast.error("Please select a document first.");
            return;
        }
        setIsLoading(true);
        setError('');
        setAnalysisContent(null);
        setAiReasoning(null);
        setIsDropdownOpen(false);

        const payload = { filename: selectedDocumentFilename, analysis_type: toolType };
        const toastId = toast.loading(`Generating ${title} for "${selectedDocumentFilename}"...`);

        try {
            const response = await api.requestAnalysis(payload);
            toast.dismiss(toastId);

            if (response) {
                if (response.content && response.content.trim() !== "" && !response.content.startsWith("Error:")) {
                    setAnalysisContent(response.content);
                    toast.success(`${title} analysis complete! Click 'View Full ${title}' to see details.`);
                } else if (response.content && response.content.startsWith("Error:")) {
                    setError(response.content);
                    toast.error(`Error in ${title}: ${response.content.substring(0, 100)}...`);
                } else {
                    setError(`No content returned for ${title}.`);
                    toast.warn(`No content was generated for ${title}.`);
                }

                if (response.thinking && response.thinking.trim() !== "") {
                    setAiReasoning(response.thinking);
                } else {
                    setAiReasoning(response.content ? "Retrieved stored analysis. No detailed AI reasoning provided." : "AI reasoning not available.");
                }
                setIsDropdownOpen(true);
            } else {
                throw new Error("Empty response from analysis service.");
            }
        } catch (err) {
            toast.dismiss(toastId);
            const errorMessage = err.message || `Failed to generate or fetch ${title}.`;
            setError(errorMessage);
            toast.error(errorMessage);
            console.error(`Run ${title} Analysis Error:`, err);
            setIsDropdownOpen(false);
        } finally {
            setIsLoading(false);
        }
    };

    const handleDownloadMindmap = async (format = 'svg') => {
        if (mindmapViewerRef.current && mindmapViewerRef.current.getSvgElement) {
            const svgElement = mindmapViewerRef.current.getSvgElement();
            if (!svgElement) {
                toast.error("Mindmap SVG element not found or not rendered yet.");
                return;
            }

            const filenameBase = selectedDocumentFilename ? selectedDocumentFilename.split('.')[0] : 'mindmap';
            const filename = `${filenameBase}_${toolType}.${format}`;

            if (format === 'svg') {
                const serializer = new XMLSerializer();
                let svgString = serializer.serializeToString(svgElement);
                svgString = '<?xml version="1.0" standalone="no"?>\r\n' + svgString;
                const blob = new Blob([svgString], { type: 'image/svg+xml;charset=utf-8' });
                const url = URL.createObjectURL(blob);
                const link = document.createElement('a');
                link.href = url;
                link.download = filename;
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);
                URL.revokeObjectURL(url);
                toast.success("SVG downloaded!");
            } else if (format === 'png') {
                const pngToastId = toast.loading("Preparing PNG download...");
                try {
                    // Ensure save-svg-as-png is available (e.g., npm install save-svg-as-png)
                    // If it's not working, common issues include:
                    // 1. Library not installed/imported correctly.
                    // 2. Complex SVG features (e.g., foreignObject, certain CSS filters) that the library doesn't support.
                    // 3. Browser security restrictions if the SVG contains external resources (unlikely for Mermaid).
                    // 4. Very large SVGs causing memory issues.
                    const { saveSvgAsPng } = await import('save-svg-as-png');
                    if (saveSvgAsPng) {
                        saveSvgAsPng(svgElement, filename, { 
                            scale: 2, 
                            backgroundColor: appTheme === 'dark' ? '#1E293B' : '#FFFFFF' 
                        });
                        toast.success("PNG download started!", { id: pngToastId });
                    } else {
                        throw new Error("saveSvgAsPng function not found after import.");
                    }
                } catch (e) {
                    console.error("Error loading/using save-svg-as-png:", e);
                    toast.error(`Failed to export PNG: ${e.message}. SVG export is available. Consider checking console for details if library is missing.`, { id: pngToastId });
                }
            }
        } else {
            toast.error("Mindmap viewer component not ready or SVG not available.");
        }
    };
    
    const renderModalContent = () => {
        if (isLoading && !analysisContent) {
            return (
                <div className="flex items-center justify-center h-48">
                    <Loader2 size={32} className="animate-spin text-primary" />
                    <p className="ml-2 text-text-muted-light dark:text-text-muted-dark">Loading analysis...</p>
                </div>
            );
        }
        if (error && !analysisContent) {
             return <p className="p-4 text-center text-red-500 dark:text-red-400">{error}</p>;
        }
        if (!analysisContent) {
            return <p className="p-4 text-center text-text-muted-light dark:text-text-muted-dark">No analysis content available to display.</p>;
        }

        if (toolType === 'mindmap') {
            return (
                <div className="mindmap-modal-content-wrapper min-h-[60vh] h-[calc(70vh-80px)] flex justify-center items-center">
                     <MindmapViewer mermaidCode={analysisContent} ref={mindmapViewerRef} />
                </div>
            );
        }
        return (
            <div
                ref={modalAnalysisContentRef}
                className="prose prose-sm dark:prose-invert max-w-none text-text-light dark:text-text-dark p-1 custom-scrollbar text-[0.8rem] leading-relaxed"
                dangerouslySetInnerHTML={createMarkup(analysisContent)}
            />
        );
    };

    // Determine if AI reasoning is substantial or just a placeholder
    const showReasoning = aiReasoning && !placeholderReasoningMessages.some(msg => aiReasoning.includes(msg));

    return (
        <div className="card-base p-3">
            <div className="flex items-center justify-between">
                <div
                    className="flex items-center gap-2 text-sm font-medium text-text-light dark:text-text-dark focus:outline-none w-full text-left cursor-pointer hover:text-primary dark:hover:text-primary-light transition-colors"
                    onClick={() => setIsSectionOpen(!isSectionOpen)}
                    aria-expanded={isSectionOpen}
                >
                    <IconComponent size={16} className="text-primary dark:text-primary-light flex-shrink-0" />
                    <span className="flex-grow">{title}</span>
                </div>
                <div className="flex items-center gap-1 flex-shrink-0">
                    <Button
                        onClick={handleRunAnalysis}
                        variant="primary"
                        size="sm"
                        className="!px-3 !py-1 text-xs"
                        isLoading={isLoading}
                        disabled={!selectedDocumentFilename || isLoading}
                        title={!selectedDocumentFilename ? "Select a document first" : `Run ${title} Analysis`}
                    >
                       {isLoading ? (currentEngagementText.split(' ')[0] || "...") : "Run"}
                    </Button>
                    <IconButton
                        icon={isSectionOpen ? ChevronUp : ChevronDown}
                        onClick={() => setIsSectionOpen(!isSectionOpen)}
                        size="sm"
                        variant="ghost"
                        className="p-1"
                        aria-label={isSectionOpen ? "Collapse section" : "Expand section"}
                        disabled={isLoading && isSectionOpen}
                    />
                </div>
            </div>

            <AnimatePresence>
                {isSectionOpen && (
                    <motion.div
                        key="tool-section-content"
                        initial={{ height: 0, opacity: 0 }}
                        animate={{ height: 'auto', opacity: 1 }}
                        exit={{ height: 0, opacity: 0 }}
                        transition={{ duration: 0.25, ease: "easeInOut" }}
                        className="mt-2 pt-2 border-t border-border-light dark:border-border-dark overflow-hidden"
                    >
                        {isLoading && (
                            <div className="text-xs text-text-muted-light dark:text-text-muted-dark p-2 flex items-center justify-center gap-2 animate-fadeIn">
                                <Loader2 size={14} className="animate-spin"/> {currentEngagementText}
                            </div>
                        )}

                        {error && !isLoading && (
                            <div className="my-2 p-2 bg-red-500/10 border border-red-500/30 text-red-600 dark:text-red-300 rounded-md text-xs flex items-center gap-1">
                                <AlertTriangle size={14} /> {error.length > 150 ? error.substring(0,147) + "..." : error}
                            </div>
                        )}

                        {!isLoading && !error && (analysisContent || aiReasoning) && isDropdownOpen && (
                            <motion.div
                                key="analysis-dropdown"
                                initial={{ opacity: 0, y: -10 }}
                                animate={{ opacity: 1, y: 0 }}
                                exit={{ opacity: 0, y: -10 }}
                                transition={{ duration: 0.2 }}
                                className="mt-2 space-y-2"
                            >
                                {showReasoning && aiReasoning && ( // Conditionally render based on showReasoning
                                    <details className="group text-xs rounded-md border border-border-light dark:border-border-dark bg-surface-light dark:bg-gray-800 shadow-sm">
                                        <summary className="flex items-center justify-between gap-1 p-2 cursor-pointer text-text-muted-light dark:text-text-muted-dark hover:bg-gray-50 dark:hover:bg-gray-700 transition-colors rounded-t-md">
                                            <span className="flex items-center gap-1.5 font-medium">
                                                <Sparkles size={14} className="text-accent" /> AI Reasoning
                                            </span>
                                            <ChevronDown size={16} className="group-open:rotate-180 transition-transform" />
                                        </summary>
                                        <div
                                            ref={aiReasoningContentRef}
                                            className="p-2.5 prose prose-xs dark:prose-invert max-w-none text-text-light dark:text-text-dark max-h-60 overflow-y-auto custom-scrollbar text-[0.75rem] leading-relaxed bg-gray-50 dark:bg-gray-900/50 rounded-b-md"
                                            dangerouslySetInnerHTML={createMarkup(aiReasoning)}
                                        />
                                    </details>
                                )}

                                {analysisContent && ( 
                                     <Button
                                        onClick={() => setIsModalOpen(true)}
                                        variant="outline" 
                                        size="sm"
                                        fullWidth
                                        leftIcon={<Eye size={14}/>}
                                        className="!py-1.5 text-xs border-primary/70 text-primary hover:bg-primary/10 dark:border-primary-light/70 dark:text-primary-light dark:hover:bg-primary-light/10"
                                    >
                                       View Full {title}
                                    </Button>
                                )}
                            </motion.div>
                        )}
                        
                        {!isLoading && !isDropdownOpen && !error && (
                            <p className="text-xs text-text-muted-light dark:text-text-muted-dark p-2 text-center">
                                {selectedDocumentFilename ? `Click "Run" to generate ${title} for "${selectedDocumentFilename}".` : "Select a document to enable analysis."}
                            </p>
                        )}
                    </motion.div>
                )}
            </AnimatePresence>

            <Modal
                isOpen={isModalOpen}
                onClose={() => setIsModalOpen(false)}
                title={`${title} for "${selectedDocumentFilename || 'document'}"`}
                size={toolType === 'mindmap' ? "3xl" : "xl"}
                footerContent={
                    <>
                        {toolType === 'mindmap' && analysisContent && (
                            <>
                                <Button onClick={() => handleDownloadMindmap('svg')} variant="outline" size="sm" className="text-xs" leftIcon={<Download size={14}/>}>SVG</Button>
                                {/* <Button onClick={() => handleDownloadMindmap('png')} variant="outline" size="sm" className="text-xs" leftIcon={<Download size={14}/>}>PNG</Button> */}
                                <div className="flex-grow"></div> {/* Spacer */}
                            </>
                        )}
                        <Button onClick={() => setIsModalOpen(false)} variant="secondary" size="sm" className="text-xs">Close</Button>
                    </>
                }
            >
                <div className={`max-h-[70vh] overflow-y-auto custom-scrollbar p-1 pr-2 rounded-md shadow-inner ${toolType === 'mindmap' ? 'bg-transparent dark:bg-transparent' : 'bg-gray-50 dark:bg-gray-800'}`}>
                    {selectedDocumentFilename && (
                        <p className="text-xs text-text-muted-light dark:text-text-muted-dark mb-2 border-b border-border-light dark:border-border-dark pb-1.5">
                            Source Document: <strong>{selectedDocumentFilename}</strong>
                        </p>
                    )}
                    {renderModalContent()}
                </div>
            </Modal>
        </div>
    );
}
export default AnalysisToolRunner;
```

`frontend/src/components/analysis/MindmapViewer.jsx`

```javascript
// frontend/src/components/analysis/MindmapViewer.jsx
import React, { useEffect, useRef, useState, useImperativeHandle, forwardRef } from 'react';
import toast from 'react-hot-toast';
import { escapeHtml } from '../../utils/helpers.js'; // Import escapeHtml helper

const MindmapViewer = forwardRef(({ mermaidCode }, ref) => {
    const svgContainerRef = useRef(null);
    const [error, setError] = useState(null);
    const [isMermaidReady, setIsMermaidReady] = useState(false);
    const [isLoading, setIsLoading] = useState(false);
    const [uniqueId] = useState(() => `mermaid-graph-${Math.random().toString(36).substr(2, 9)}`);

    useImperativeHandle(ref, () => ({
        getSvgElement: () => {
            return svgContainerRef.current?.querySelector('svg');
        }
    }));

    useEffect(() => {
        if (typeof window.mermaid !== 'undefined') {
            setIsMermaidReady(true);
        } else {
            const intervalId = setInterval(() => {
                if (typeof window.mermaid !== 'undefined') {
                    setIsMermaidReady(true);
                    clearInterval(intervalId);
                }
            }, 100);
            return () => clearInterval(intervalId);
        }
    }, []);

    useEffect(() => {
        if (!isMermaidReady || !mermaidCode || !svgContainerRef.current) {
            if (svgContainerRef.current) svgContainerRef.current.innerHTML = '';
            setError(null);
            setIsLoading(false);
            return;
        }

        const renderMermaidDiagram = async () => {
            setIsLoading(true);
            setError(null);
            if (!svgContainerRef.current) {
                setIsLoading(false);
                return;
            }
            svgContainerRef.current.innerHTML = '<div class="flex justify-center items-center h-full w-full text-sm text-text-muted-light dark:text-text-muted-dark"><div class="animate-spin rounded-full h-6 w-6 border-t-2 border-b-2 border-primary mr-2"></div>Rendering diagram...</div>';
            
            let codeToRender = mermaidCode.trim();
            // Remove Markdown code fences: ```mermaid ... ``` or ``` ... ```
            // Regex explanation:
            // ^```         - Matches starting triple backticks
            // (?:mermaid\b)? - Optionally matches "mermaid" followed by a word boundary (case-insensitive due to i flag)
            // \s*          - Matches any whitespace (including newlines) after "mermaid" or ```
            // ([\s\S]*?)  - Captures the actual Mermaid code (non-greedy)
            // \s*          - Matches any whitespace before closing backticks
            // ```$         - Matches closing triple backticks at the end of the string
            // i            - Case-insensitive flag (for "mermaid" keyword)
            const fenceRegex = /^```(?:mermaid\b)?\s*([\s\S]*?)\s*```$/i;
            const match = codeToRender.match(fenceRegex);
            if (match && match[1]) {
                codeToRender = match[1].trim(); // Use the captured group
            }
            
            try {
                if (typeof window.mermaid === 'undefined') {
                    throw new Error("Mermaid library failed to load or initialize properly.");
                }

                const { svg, bindFunctions } = await window.mermaid.render(uniqueId, codeToRender);
                
                if (svgContainerRef.current) {
                    svgContainerRef.current.innerHTML = svg;
                    if (bindFunctions) {
                        bindFunctions(svgContainerRef.current);
                    }
                    const svgElement = svgContainerRef.current.querySelector('svg');
                    if (svgElement) {
                        svgElement.style.width = '100%';
                        svgElement.style.height = 'auto'; 
                        svgElement.style.maxWidth = '100%'; 
                        svgElement.style.display = 'block';
                    }
                }
            } catch (e) {
                console.error("Error rendering Mermaid diagram with input:", codeToRender, e);
                const errorMsg = e.message || "Failed to render mind map. Invalid Mermaid syntax?";
                setError(errorMsg);
                if (svgContainerRef.current) {
                    const codeSnippet = escapeHtml(codeToRender.substring(0, 200) + (codeToRender.length > 200 ? "..." : ""));
                    svgContainerRef.current.innerHTML = `<div class="p-4 text-center text-red-500 dark:text-red-400 text-xs break-all"><strong>Error rendering:</strong> ${escapeHtml(errorMsg)}<br><strong class='mt-2 block'>Input Code (first 200 chars):</strong><pre class='text-left text-xs bg-gray-100 dark:bg-gray-700 p-2 rounded mt-1 whitespace-pre-wrap'>${codeSnippet}</pre></div>`;
                }
            } finally {
                setIsLoading(false);
            }
        };

        const timer = setTimeout(renderMermaidDiagram, 100); 
        return () => clearTimeout(timer);
        
    }, [mermaidCode, uniqueId, isMermaidReady]);

    if (!isMermaidReady && !error) {
      return <div className="p-4 text-center text-text-muted-light dark:text-text-muted-dark text-xs">Waiting for Mermaid.js library...</div>;
    }
    if (error && (!isLoading || (svgContainerRef.current && svgContainerRef.current.innerHTML.includes('Error rendering')))) {
        return <div ref={svgContainerRef} className="mermaid-diagram-render-area w-full h-full flex justify-center items-center bg-gray-50 dark:bg-gray-800/50 p-2 rounded-md">
                {/* Error message will be injected by useEffect's catch block */}
               </div>;
    }
    
    if (isLoading) { 
         return <div ref={svgContainerRef} className="mermaid-diagram-render-area w-full h-full flex justify-center items-center bg-gray-50 dark:bg-gray-800/50 p-2 rounded-md">
            {/* Loading message is set by renderMermaidDiagram's initial innerHTML write */}
         </div>;
    }

    if (!mermaidCode && !error && isMermaidReady) { 
        return <p className="text-xs text-center text-text-muted-light dark:text-text-muted-dark p-4">No mind map data to display.</p>;
    }
    
    return (
        <div 
            ref={svgContainerRef} 
            className="mermaid-diagram-render-area w-full h-full flex justify-center items-center bg-gray-50 dark:bg-gray-800/50 p-2 rounded-md"
        >

        </div>
    );
});

export default MindmapViewer;
```

`frontend/src/components/analysis/RightPanel.jsx`

```javascript
// frontend/src/components/layout/RightPanel.jsx
import React, { useState } from 'react';
import { useAppState } from '../../contexts/AppStateContext';
import AnalysisTool from '../analysis/AnalysisTool.jsx'; // Added .jsx
import { PanelRightClose, ChevronDown, ChevronUp, Telescope } from 'lucide-react';
import IconButton from '../core/IconButton.jsx'; // Added .jsx
import { motion } from 'framer-motion';

function RightPanel() {
    const { setIsRightPanelOpen, selectedDocumentForAnalysis } = useAppState();
    const [isAnalyzerOpen, setIsAnalyzerOpen] = useState(true);

    const currentSelectedDocFilename = selectedDocumentForAnalysis?.originalName || null;

    return (
        <div className="flex flex-col h-full p-3 sm:p-4 bg-surface-light dark:bg-surface-dark text-text-light dark:text-text-dark custom-scrollbar">
            <div className="flex items-center justify-between mb-4 pb-2 border-b border-border-light dark:border-border-dark">
                <h2 className="text-base font-semibold">Advanced Analyzer</h2>
                <IconButton 
                    icon={PanelRightClose} 
                    onClick={() => setIsRightPanelOpen(false)} 
                    title="Close Analyzer Panel"
                    variant="ghost"
                    size="sm"
                    className="text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
                />
            </div>
            
            <button 
                onClick={() => setIsAnalyzerOpen(!isAnalyzerOpen)}
                className="w-full flex items-center justify-between px-3 py-2.5 text-sm font-medium text-left bg-gray-50 dark:bg-gray-800 hover:bg-gray-100 dark:hover:bg-gray-700 rounded-md focus:outline-none shadow-sm border border-border-light dark:border-border-dark mb-3"
            >
                <span className="flex items-center gap-2"><Telescope size={16} /> Analysis Tools</span>
                {isAnalyzerOpen ? <ChevronUp size={18} /> : <ChevronDown size={18} />}
            </button>

            {isAnalyzerOpen && (
                <motion.div 
                    initial={{ height: 0, opacity: 0 }} 
                    animate={{ height: 'auto', opacity: 1 }} 
                    exit={{ height: 0, opacity: 0 }}
                    transition={{ duration: 0.2, ease: "easeInOut" }}
                    className="flex-grow space-y-3 overflow-y-auto custom-scrollbar pr-1"
                >
                    {!currentSelectedDocFilename && (
                        <div className="p-4 text-xs text-center text-text-muted-light dark:text-text-muted-dark bg-gray-50 dark:bg-gray-800 rounded-md border border-dashed border-border-light dark:border-border-dark">
                            <p>Select a document from the left panel to enable analysis tools.</p>
                        </div>
                    )}
                    <AnalysisTool toolType="faq" title="FAQ Generator" iconName="HelpCircle" selectedDocumentFilename={currentSelectedDocFilename} />
                    <AnalysisTool toolType="topics" title="Key Topics Extractor" iconName="Tags" selectedDocumentFilename={currentSelectedDocFilename} />
                    <AnalysisTool toolType="mindmap" title="Mind Map Creator" iconName="GitFork" selectedDocumentFilename={currentSelectedDocFilename} />
                </motion.div>
            )}
        </div>
    );
}
export default RightPanel;
```

`frontend/src/components/auth/AuthModal.jsx`

```javascript
// frontend/src/components/auth/AuthModal.jsx
import React, { useState, useEffect } from 'react';
import { useAuth } from '../../hooks/useAuth.jsx';
import { useAppState } from '../../contexts/AppStateContext.jsx';
import LLMSelection from './LLMSelection.jsx';
import api from '../../services/api.js'; 
import toast from 'react-hot-toast';
import { LogIn, UserPlus, X, Terminal, KeyRound, Link2, User as UserIcon, AlertCircle } from 'lucide-react';
import Button from '../core/Button.jsx';
import IconButton from '../core/IconButton.jsx';
import { motion } from 'framer-motion';

function AuthModal({ isOpen, onClose }) { // onClose will be called with authData from AuthContext
    const { 
        login, signup, devLogin, 
        DEV_MODE_ALLOW_DEV_LOGIN, 
        MOCK_DEV_USERNAME, MOCK_DEV_PASSWORD
    } = useAuth(); 
    const { selectedLLM: globalSelectedLLM, switchLLM: setGlobalLLM } = useAppState();
    
    const [isLoginView, setIsLoginView] = useState(true);
    const [username, setUsername] = useState(DEV_MODE_ALLOW_DEV_LOGIN ? (MOCK_DEV_USERNAME || '') : '');
    const [password, setPassword] = useState(DEV_MODE_ALLOW_DEV_LOGIN ? (MOCK_DEV_PASSWORD || '') : '');
    const [localSelectedLLM, setLocalSelectedLLM] = useState(globalSelectedLLM || 'ollama');
    const [geminiApiKey, setGeminiApiKey] = useState('');
    const [ollamaApiUrl, setOllamaApiUrl] = useState('');
    
    const [error, setError] = useState('');
    const [loading, setLoading] = useState(false);
    const [devLoginLoading, setDevLoginLoading] = useState(false); 

    useEffect(() => {
        if (isOpen) {
            setError(''); 
            if (isLoginView && DEV_MODE_ALLOW_DEV_LOGIN) {
                setUsername(MOCK_DEV_USERNAME || '');
                setPassword(MOCK_DEV_PASSWORD || '');
            } else if (!isLoginView) { 
                setUsername('');
                setPassword('');
            }
            setLocalSelectedLLM(globalSelectedLLM || 'ollama');
            setGeminiApiKey('');
            setOllamaApiUrl('');
        }
    }, [isOpen, isLoginView, DEV_MODE_ALLOW_DEV_LOGIN, MOCK_DEV_USERNAME, MOCK_DEV_PASSWORD, globalSelectedLLM]);

    const handleLlmChange = (llm) => setLocalSelectedLLM(llm);

    const handleSubmit = async (e) => {
        e.preventDefault();
        if (!username.trim() || !password.trim()) {
            setError("Username and password are required.");
            toast.error("Username and password are required.");
            return;
        }

        setError(''); setLoading(true);
        const toastId = toast.loading(isLoginView ? 'Logging in...' : 'Signing up...');
        
        try {
            let authDataResponse; // This will contain { token, _id, username, sessionId, message }
            const apiPayload = { username, password };
            if (isLoginView) {
                authDataResponse = await login(apiPayload); // From AuthContext
            } else { 
                authDataResponse = await signup(apiPayload); // From AuthContext
                
                setGlobalLLM(localSelectedLLM); // Update AppStateContext
                
                // Attempt to save LLM config (api.js will handle mock/real)
                if (localSelectedLLM === 'gemini' && geminiApiKey.trim()) {
                    try {
                        await api.updateUserLLMConfig({ llmProvider: 'gemini', apiKey: geminiApiKey.trim() });
                        // No separate toast here, AuthContext's response is primary
                    } catch (configErr) { toast.error(`Note: Could not save Gemini config to backend: ${configErr.message}`);}
                }
                if (localSelectedLLM === 'ollama' && ollamaApiUrl.trim()) {
                    try {
                         await api.updateUserLLMConfig({ llmProvider: 'ollama', ollamaUrl: ollamaApiUrl.trim() });
                    } catch (configErr) { toast.error(`Note: Could not save Ollama config to backend: ${configErr.message}`);}
                }
            }
            toast.dismiss(toastId);
            toast.success(authDataResponse.message || (isLoginView ? 'Login Successful!' : 'Signup Successful!'));
            onClose(authDataResponse); // Pass the full authData from AuthContext to App.jsx
        } catch (err) {
            toast.dismiss(toastId);
            const errorMessage = err.response?.data?.message || err.message || `Failed: ${isLoginView ? 'login' : 'signup'}`;
            setError(errorMessage);
            toast.error(errorMessage);
        } finally { setLoading(false); }
    };

    const handleDevLogin = async () => {
        if (!devLogin) {
            toast.error("Dev Quick Login is not available in current setup.");
            return;
        }
        setDevLoginLoading(true); setError('');
        const toastId = toast.loading("Attempting Dev Quick Login...");
        try {
            const devAuthData = await devLogin(); // From AuthContext
            toast.dismiss(toastId);
            toast.success(devAuthData.message || "Dev Quick Login Successful!");
            onClose(devAuthData); // Pass full authData
        } catch(err) {
            toast.dismiss(toastId);
            const errorMessage = err.response?.data?.message || err.message || "Dev Quick Login encountered an error.";
            setError(errorMessage);
            toast.error(errorMessage);
        } finally {
            setDevLoginLoading(false);
        }
    };

    if (!isOpen) return null;

    const inputWrapperClass = "relative";
    const inputIconClass = "absolute left-3 top-1/2 -translate-y-1/2 h-5 w-5 text-text-muted-light dark:text-text-muted-dark pointer-events-none";
    const inputFieldStyledClass = "input-field pl-10 py-2.5 text-sm";

    return (
        <div className="fixed inset-0 bg-black/70 backdrop-blur-sm flex items-center justify-center z-50 p-4 animate-fadeIn">
            <motion.div 
                key="auth-modal-content"
                initial={{ opacity: 0, scale: 0.95, y: -10 }}
                animate={{ opacity: 1, scale: 1, y: 0 }}
                exit={{ opacity: 0, scale: 0.95, y: 10 }}
                transition={{ type: "spring", stiffness: 400, damping: 25 }}
                className="card-base p-6 sm:p-8 w-full max-w-md glass-effect"
            >
                <div className="flex justify-between items-center mb-6">
                    <h2 className="text-xl sm:text-2xl font-bold text-text-light dark:text-text-dark">
                        {isLoginView ? 'Welcome Back' : 'Create Your Account'}
                    </h2>
                    <IconButton 
                        icon={X} 
                        onClick={() => onClose(null)} // Pass null if modal closed manually without auth
                        variant="ghost" 
                        size="sm" 
                        title="Close" 
                        className="text-text-muted-light dark:text-text-muted-dark hover:text-red-500 dark:hover:text-red-400"
                    />
                </div>

                {error && <div className="mb-4 p-3 bg-red-500/10 border border-red-500/30 text-red-600 dark:text-red-300 rounded-md text-sm animate-fadeIn flex items-center gap-2"><AlertCircle size={16}/>{error}</div>}

                <form onSubmit={handleSubmit} className="space-y-5">
                    <div className={inputWrapperClass}>
                        <UserIcon className={inputIconClass} />
                        <input type="text" id="username" className={inputFieldStyledClass} placeholder="Username" value={username} onChange={(e) => setUsername(e.target.value)} required disabled={loading || devLoginLoading}/>
                    </div>
                    <div className={inputWrapperClass}>
                        <KeyRound className={inputIconClass} />
                        <input type="password" id="password" className={inputFieldStyledClass} placeholder="Password (min. 6 characters)" value={password} onChange={(e) => setPassword(e.target.value)} required minLength="6" disabled={loading || devLoginLoading}/>
                    </div>

                    {!isLoginView && (
                        <div className="space-y-4 pt-2 animate-fadeIn">
                            <LLMSelection selectedLLM={localSelectedLLM} onLlmChange={handleLlmChange} disabled={loading || devLoginLoading}/>
                            {localSelectedLLM === 'gemini' && (
                                <div className="mt-3 space-y-1">
                                    <label htmlFor="geminiApiKeyModal" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark">Gemini API Key (Optional)</label>
                                    <div className={inputWrapperClass}>
                                        <KeyRound className={inputIconClass} />
                                        <input type="password" id="geminiApiKeyModal" className={inputFieldStyledClass} placeholder="Enter your Gemini API Key" value={geminiApiKey} onChange={(e) => setGeminiApiKey(e.target.value)} disabled={loading || devLoginLoading}/>
                                    </div>
                                </div>
                            )}
                            {localSelectedLLM === 'ollama' && (
                                <div className="mt-3 space-y-1">
                                    <label htmlFor="ollamaApiUrlModal" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark">Ollama API URL (Optional)</label>
                                     <div className={inputWrapperClass}>
                                        <Link2 className={inputIconClass} />
                                        <input type="text" id="ollamaApiUrlModal" className={inputFieldStyledClass} placeholder="Default: http://localhost:11434" value={ollamaApiUrl} onChange={(e) => setOllamaApiUrl(e.target.value)} disabled={loading || devLoginLoading}/>
                                    </div>
                                </div>
                            )}
                        </div>
                    )}

                    <Button type="submit" fullWidth isLoading={loading} disabled={devLoginLoading} leftIcon={isLoginView ? <LogIn size={18}/> : <UserPlus size={18}/>} className="py-2.5 !text-base">
                        {isLoginView ? 'Login' : 'Sign Up'}
                    </Button>
                </form>

                <p className="mt-6 text-center text-sm">
                    <button 
                        onClick={() => { setIsLoginView(!isLoginView); setError(''); }}
                        className="font-medium text-primary hover:text-primary-dark dark:text-primary-light dark:hover:text-primary-darker transition-colors"
                        disabled={loading || devLoginLoading}
                    >
                        {isLoginView ? "Don't have an account? Sign Up" : "Already have an account? Login"}
                    </button>
                </p>

                {DEV_MODE_ALLOW_DEV_LOGIN && devLogin && (
                    <div className="mt-4 pt-4 border-t border-border-light dark:border-border-dark">
                        <Button
                            type="button" onClick={handleDevLogin} fullWidth 
                            className="bg-yellow-500 hover:bg-yellow-600 dark:bg-yellow-600 dark:hover:bg-yellow-700 !text-white dark:!text-gray-900 font-semibold py-2.5 !text-base"
                            leftIcon={<Terminal size={18} />}
                            isLoading={devLoginLoading} 
                            disabled={loading} 
                        >
                            Dev Quick Login
                        </Button>
                    </div>
                )}
            </motion.div>
        </div>
    );
}
export default AuthModal;
```

`frontend/src/components/auth/LLMSelection.jsx`

```javascript
// frontend/src/components/auth/LLMSelection.jsx
import React from 'react';
import { HardDrive, Cloud } from 'lucide-react';

function LLMSelection({ selectedLLM, onLlmChange, disabled = false }) {
    const llms = [
        { id: 'ollama', name: 'Ollama LLM', description: 'Local & Private. Requires Ollama running.', Icon: HardDrive },
        { id: 'gemini', name: 'Gemini LLM', description: 'Cloud-based by Google. API Key may be required.', Icon: Cloud },
    ];

    return (
        <div>
            <label className="block text-sm font-medium text-text-light dark:text-text-dark mb-2">
                Choose Your LLM Provider
            </label>
            <div className="grid grid-cols-1 sm:grid-cols-2 gap-3">
                {llms.map((llm) => {
                    const isSelected = selectedLLM === llm.id;
                    return (
                        <button
                            key={llm.id}
                            type="button"
                            onClick={() => onLlmChange(llm.id)}
                            disabled={disabled}
                            className={`p-4 border rounded-lg text-left transition-all duration-150 focus:outline-none group focus:ring-2 focus:ring-offset-2 dark:focus:ring-offset-surface-dark focus:ring-primary
                                ${isSelected 
                                    ? 'bg-primary dark:bg-primary border-primary dark:border-primary-dark ring-2 ring-primary dark:ring-primary-dark shadow-lg' 
                                    : 'bg-surface-light dark:bg-surface-dark border-border-light dark:border-border-dark hover:border-primary-light dark:hover:border-primary-dark hover:shadow-md'
                                }
                                ${disabled ? 'opacity-70 cursor-not-allowed' : ''}
                            `}
                        >
                            <div className="flex items-center mb-1">
                                <llm.Icon size={20} className={`mr-2 transition-colors 
                                    ${isSelected 
                                        ? 'text-white dark:text-blue-100' // High contrast for selected
                                        : 'text-text-muted-light dark:text-text-muted-dark group-hover:text-primary dark:group-hover:text-primary-light'}`} />
                                <span className={`font-semibold transition-colors 
                                    ${isSelected 
                                        ? 'text-white dark:text-white' // High contrast for selected
                                        : 'text-text-light dark:text-text-dark group-hover:text-primary dark:group-hover:text-primary-light'}`}>
                                    {llm.name}
                                </span>
                            </div>
                            <p className={`text-xs transition-colors 
                                ${isSelected 
                                    ? 'text-blue-100 dark:text-blue-200' // High contrast for selected
                                    : 'text-text-muted-light dark:text-text-muted-dark'}`}>
                                {llm.description}
                            </p>
                        </button>
                    );
                })}
            </div>
        </div>
    );
}

export default LLMSelection;
```

`frontend/src/components/chat/ChatHistory.jsx`

```javascript
// src/components/chat/ChatHistory.jsx
import React, { useRef, useEffect } from 'react';
import MessageBubble from './MessageBubble';
import { motion, AnimatePresence } from 'framer-motion';

function ChatHistory({ messages, isLoading }) {
    const chatHistoryRef = useRef(null);

    useEffect(() => {
        if (chatHistoryRef.current) {
            // Smart scroll: only scroll if user is already near the bottom
            const { scrollHeight, clientHeight, scrollTop } = chatHistoryRef.current;
            const isScrolledToBottom = scrollHeight - clientHeight <= scrollTop + 100; // 100px tolerance
            if (isScrolledToBottom) {
                chatHistoryRef.current.scrollTop = chatHistoryRef.current.scrollHeight;
            }
        }
    }, [messages]);

    return (
        <div ref={chatHistoryRef} className="flex-1 overflow-y-auto p-4 space-y-4 custom-scrollbar">
            <AnimatePresence initial={false}>
                {messages.map((msg, index) => ( // Ensure msg.id is unique and stable
                    <motion.div
                        key={msg.id || `msg-${index}-${msg.timestamp}`} // Fallback key if id is missing
                        layout
                        initial={{ opacity: 0, y: 20 }}
                        animate={{ opacity: 1, y: 0 }}
                        exit={{ opacity: 0, y: -10, transition: { duration: 0.15 } }}
                        transition={{ duration: 0.3, ease: "easeOut" }}
                    >
                        <MessageBubble
                            sender={msg.sender} // 'user' or 'bot'
                            text={msg.text}
                            thinking={msg.thinking}
                            references={msg.references}
                            timestamp={msg.timestamp}
                            sourcePipeline={msg.source_pipeline}
                        />
                    </motion.div>
                ))}
            </AnimatePresence>
            {isLoading && ( // Show typing indicator, even if no prior messages for immediate feedback
                 <motion.div 
                    layout
                    initial={{ opacity: 0, y: 10 }}
                    animate={{ opacity: 1, y: 0 }}
                    className="flex justify-start pl-2 mt-2"
                 >
                    <div className="message-bubble bot-message bg-surface-light dark:bg-surface-dark p-2 inline-flex items-center gap-1 rounded-lg shadow">
                        <span className="animate-pulseDot1 text-text-muted-light dark:text-text-muted-dark text-xs">●</span>
                        <span className="animate-pulseDot2 text-text-muted-light dark:text-text-muted-dark text-xs">●</span>
                        <span className="animate-pulseDot3 text-text-muted-light dark:text-text-muted-dark text-xs">●</span>
                    </div>
                </motion.div>
            )}
        </div>
    );
}
export default ChatHistory;
```

`frontend/src/components/chat/ChatHistoryModal.jsx`

```javascript
// src/components/chat/ChatHistoryModal.jsx
import React, { useState, useEffect, useCallback } from 'react';
import api from '../../services/api';
import toast from 'react-hot-toast';
import { X, MessageSquareText, Loader2, AlertTriangle, Trash2 } from 'lucide-react'; // Added Trash2
import Modal from '../core/Modal.jsx';
import IconButton from '../core/IconButton.jsx'; // Import IconButton

const formatDate = (dateString) => {
    if (!dateString) return 'N/A';
    try {
        return new Date(dateString).toLocaleString(undefined, { 
            month: 'short', day: 'numeric', year: 'numeric', hour: '2-digit', minute: '2-digit' 
        });
    } catch (e) {
        return 'Invalid Date';
    }
};

function ChatHistoryModal({ isOpen, onClose, onSelectSession }) {
    const [sessions, setSessions] = useState([]);
    const [selectedSessionId, setSelectedSessionId] = useState(null);
    const [sessionMessages, setSessionMessages] = useState([]);
    const [loadingSessions, setLoadingSessions] = useState(false);
    const [loadingMessages, setLoadingMessages] = useState(false);
    const [error, setError] = useState('');

    const fetchSessions = useCallback(async () => {
        if (!isOpen) return; 
        setLoadingSessions(true);
        setError('');
        try {
            const data = await api.getChatSessions(); // Fetches { sessionId, preview, updatedAt, ... }
            setSessions(Array.isArray(data) ? data : []);
            if (data.length === 0) {
                toast.info("No past chat sessions found.");
            }
        } catch (err) {
            toast.error("Failed to load chat sessions.");
            setError(err.message || "Could not fetch sessions.");
        } finally {
            setLoadingSessions(false);
        }
    }, [isOpen]);

    useEffect(() => {
        if (isOpen) {
            fetchSessions();
            setSelectedSessionId(null); 
            setSessionMessages([]);
        }
    }, [isOpen, fetchSessions]); 

    const handleSessionSelectForPreview = async (sessionId) => {
        if (selectedSessionId === sessionId && sessionMessages.length > 0) return; 

        setSelectedSessionId(sessionId);
        setLoadingMessages(true);
        setSessionMessages([]); // Clear previous preview
        setError(''); 
        try {
            // api.getChatHistory returns the array of messages directly
            const messagesArray = await api.getChatHistory(sessionId); 
            // Map to the structure expected by the modal's display loop
            setSessionMessages(messagesArray.map(msg => ({
                id: msg.id || msg._id || `hist-${Date.now()}-${Math.random()}`,
                sender: msg.sender, // 'user' or 'bot'
                text: msg.text, // Main text content
                timestamp: msg.timestamp
                // No need for thinking/references in this preview
            })));
        } catch (err) {
            toast.error("Failed to load messages for this session.");
            setError(`Error loading messages: ${err.message}`);
        } finally {
            setLoadingMessages(false);
        }
    };

    const handleLoadSessionAndClose = () => {
        if (selectedSessionId) {
            onSelectSession(selectedSessionId); 
            onClose();
        } else {
            toast.error("Please select a session to load.");
        }
    };
    
    // Placeholder for delete functionality (implement with backend support later)
    const handleDeleteSession = async (sessionIdToDelete, e) => {
        e.stopPropagation(); // Prevent selecting the session
        if (!window.confirm(`Are you sure you want to delete session ${sessionIdToDelete.substring(0,8)}...? This action cannot be undone.`)) return;
        
        const toastId = toast.loading(`Deleting session ${sessionIdToDelete.substring(0,8)}... (mock)`);
        // try {
        //     await api.deleteChatSession(sessionIdToDelete); // You'll need to create this API endpoint
        //     toast.success("Session deleted.", { id: toastId });
        //     fetchSessions(); // Refresh list
        //     if (selectedSessionId === sessionIdToDelete) {
        //         setSelectedSessionId(null);
        //         setSessionMessages([]);
        //     }
        // } catch (err) {
        //     toast.error(`Failed to delete session: ${err.message}`, { id: toastId });
        // }
        setTimeout(() => { // Simulate API call
            toast.success(`Mock: Session ${sessionIdToDelete.substring(0,8)} would be deleted.`, { id: toastId });
            // setSessions(prev => prev.filter(s => s.sessionId !== sessionIdToDelete)); // Optimistic UI update
        }, 1000);

    };

    return (
        <Modal isOpen={isOpen} onClose={onClose} title="Chat History" size="2xl">
            <div className="flex flex-col md:flex-row gap-4 max-h-[70vh] h-[70vh]">
                <div className="w-full md:w-1/3 border-r border-border-light dark:border-border-dark pr-0 md:pr-2 overflow-y-auto custom-scrollbar">
                    <h3 className="text-sm font-semibold mb-2 text-text-light dark:text-text-dark px-1">Your Sessions</h3>
                    {loadingSessions && <div className="flex justify-center p-4"><Loader2 className="animate-spin text-primary" size={24}/></div>}
                    {!loadingSessions && error && !sessions.length && <div className="text-red-500 text-xs p-2">{error}</div>}
                    {!loadingSessions && !error && sessions.length === 0 && <p className="text-xs text-text-muted-light dark:text-text-muted-dark p-2">No past sessions found.</p>}
                    
                    <ul className="space-y-1">
                        {sessions.map(session => (
                            <li key={session.sessionId}
                                onClick={() => handleSessionSelectForPreview(session.sessionId)}
                                className={`p-2.5 rounded-md cursor-pointer text-xs transition-colors group relative hover:shadow-md
                                            ${selectedSessionId === session.sessionId 
                                                ? 'bg-primary text-white dark:bg-primary-dark shadow-lg ring-2 ring-primary-dark' 
                                                : 'bg-surface-light dark:bg-gray-800 hover:bg-gray-100 dark:hover:bg-gray-700 border border-transparent hover:border-primary-light'}`}
                            >
                                <div className="font-medium truncate" title={session.preview}>{session.preview || `Session ${session.sessionId.substring(0,8)}`}</div>
                                <div className={`text-[0.7rem] ${selectedSessionId === session.sessionId ? 'text-blue-100 dark:text-blue-200' : 'text-text-muted-light dark:text-text-muted-dark'}`}>
                                    {formatDate(session.updatedAt)} - {session.messageCount} msgs
                                </div>
                                <IconButton
                                    icon={Trash2}
                                    size="sm"
                                    variant="ghost"
                                    title="Delete session (Mock)"
                                    className="absolute top-1 right-1 p-1 text-red-400 hover:text-red-600 opacity-0 group-hover:opacity-100 transition-opacity !rounded-full hover:bg-red-500/10"
                                    onClick={(e) => handleDeleteSession(session.sessionId, e)}
                                />
                            </li>
                        ))}
                    </ul>
                </div>

                <div className="w-full md:w-2/3 flex flex-col overflow-hidden mt-4 md:mt-0">
                    <h3 className="text-sm font-semibold mb-2 text-text-light dark:text-text-dark">
                        {selectedSessionId ? `Preview: ${selectedSessionId.substring(0,8)}...` : "Session Preview"}
                    </h3>
                    <div className="flex-grow bg-gray-50 dark:bg-gray-800/50 p-3 rounded-md overflow-y-auto custom-scrollbar border border-border-light dark:border-border-dark">
                        {loadingMessages && <div className="flex justify-center p-4"><Loader2 className="animate-spin text-primary" size={24} /></div>}
                        {!selectedSessionId && !loadingMessages && (
                            <div className="flex flex-col items-center justify-center h-full text-text-muted-light dark:text-text-muted-dark text-sm">
                                <MessageSquareText size={40} className="mb-3 opacity-50" />
                                <p>Select a session from the left to view its messages.</p>
                            </div>
                        )}
                        {selectedSessionId && !loadingMessages && !error && sessionMessages.length === 0 && 
                            <p className="text-center text-sm text-text-muted-light dark:text-text-muted-dark p-4">No messages in this session.</p>
                        }
                        {selectedSessionId && !loadingMessages && error && 
                             <div className="flex flex-col items-center justify-center h-full text-red-500 dark:text-red-400 text-sm p-2">
                                <AlertTriangle size={30} className="mb-2"/> {error}
                            </div>
                        }
                        <div className="space-y-3">
                            {sessionMessages.map(msg => (
                                <div key={msg.id} 
                                     className={`p-2.5 rounded-lg shadow-sm w-fit max-w-[90%] text-xs
                                                ${msg.sender === 'user' 
                                                    ? 'bg-blue-500 text-white ml-auto' 
                                                    : 'bg-gray-200 text-gray-800 dark:bg-gray-700 dark:text-gray-100'}`}>
                                    <p className="font-semibold text-[0.7rem] mb-0.5">{msg.sender === 'user' ? 'You' : 'AI Tutor'}</p>
                                    <p className="whitespace-pre-wrap break-words">{msg.text}</p>
                                    <p className="text-[0.65rem] opacity-70 mt-1 text-right">{formatDate(msg.timestamp)}</p>
                                </div>
                            ))}
                        </div>
                    </div>
                </div>
            </div>
            <div className="mt-6 pt-4 border-t border-border-light dark:border-border-dark flex justify-end gap-3">
                <button 
                    onClick={onClose} 
                    className="btn-secondary !text-xs !py-1.5 !px-3" // Use your button classes
                >
                    Close
                </button>
                <button 
                    onClick={handleLoadSessionAndClose} 
                    className="btn-primary !text-xs !py-1.5 !px-3" // Use your button classes
                    disabled={!selectedSessionId || loadingMessages || loadingSessions}
                >
                    Load Selected Session
                </button>
            </div>
        </Modal>
    );
}
export default ChatHistoryModal;
```

`frontend/src/components/chat/ChatInput.jsx`

```javascript
// src/components/chat/ChatInput.jsx
import React, { useState, useEffect, useRef } from 'react';
import { Send, Mic, PlusCircle, Loader2, SearchCheck, SearchSlash, Brain } from 'lucide-react'; // Added Brain  
import { useWebSpeech } from '../../hooks/useWebSpeech';
import Button from '../core/Button.jsx'; 
import IconButton from '../core/IconButton.jsx';
import toast from 'react-hot-toast'; // Added toast import
import blueBrain from "./../../assets/blueBrain.svg"

function ChatInput({ 
    onSendMessage, 
    isLoading, 
    currentStatus, 
    useRag, 
    setUseRag,
    criticalThinkingEnabled, // New prop
    setCriticalThinkingEnabled // New prop
}) {
    const [inputValue, setInputValue] = useState('');
    const { transcript, listening, isSpeechSupported, startListening, stopListening, resetTranscript } = useWebSpeech();
    const textareaRef = useRef(null);

    useEffect(() => {
        if (transcript) {
            setInputValue(prev => prev + (prev ? " " : "") + transcript);
            resetTranscript(); 
        }
    }, [transcript, resetTranscript]);
    
    useEffect(() => {
        if (textareaRef.current) {
            textareaRef.current.style.height = 'auto';
            textareaRef.current.style.height = `${Math.min(textareaRef.current.scrollHeight, 128)}px`; // Max height 128px (max-h-32)
        }
    }, [inputValue]);

    const handleSubmit = (e) => {
        e.preventDefault();
        if (inputValue.trim() && !isLoading) {
            // MODIFIED: Explicitly pass criticalThinkingEnabled
            // The onSendMessage function (defined in parent) will need to handle this additional argument.
            onSendMessage(inputValue.trim(), criticalThinkingEnabled); 
            setInputValue('');
        }
    };

    const handleKeyDown = (e) => {
        if (e.key === 'Enter' && !e.shiftKey && !isLoading) {
            e.preventDefault(); // Prevent newline in textarea
            handleSubmit(e);
        }
    };

    const icon = criticalThinkingEnabled
    ? () => <img src={blueBrain} alt="Blue Brain" className="w-5 h-5" />
    : Brain;


    return (
        <div className="p-2 sm:p-3 border-t border-border-light dark:border-border-dark bg-surface-light dark:bg-surface-dark">
            <div className="text-xs text-text-muted-light dark:text-text-muted-dark mb-1.5 h-4 transition-opacity duration-300">
                {isLoading ? (
                    <span className="flex items-center gap-1"> 
                        <Loader2 size={12} className="animate-spin" /> {currentStatus || "Processing..."}
                    </span>
                ) : (
                    currentStatus || "Ready"
                )}
            </div>

            <form onSubmit={handleSubmit} className="flex items-end gap-2">
                <IconButton
                    icon={PlusCircle}
                    title="Attach file (Coming Soon)"
                    onClick={() => toast.info("Attachment feature coming soon!")}
                    variant="ghost"
                    size="md" 
                    className="p-2 text-text-muted-light dark:text-text-muted-dark hover:text-primary"
                    disabled={isLoading}
                />

                <textarea
                    ref={textareaRef}
                    value={inputValue}
                    onChange={(e) => setInputValue(e.target.value)}
                    onKeyDown={handleKeyDown}
                    placeholder="Type your message or ask a question..."
                    className="input-field flex-1 p-2.5 resize-none min-h-[44px] max-h-32 custom-scrollbar text-sm" 
                    rows="1"
                    disabled={isLoading}
                />

                {isSpeechSupported && (
                    <IconButton
                        icon={Mic}
                        onClick={() => listening ? stopListening() : startListening()}
                        title={listening ? "Stop listening" : "Start voice input"}
                        variant={listening ? "danger" : "ghost"} 
                        size="md"
                        className={`p-2 ${listening ? 'text-red-500 dark:text-red-400 animate-pulse' : 'text-text-muted-light dark:text-text-muted-dark hover:text-primary'}`}
                        disabled={isLoading}
                    />
                )}
                
                <IconButton
                    icon={useRag ? SearchCheck : SearchSlash}
                    onClick={() => setUseRag(!useRag)}
                    title={useRag ? "Disable RAG (Chat with LLM directly)" : "Enable RAG (Use your documents)"}
                    variant="ghost"
                    size="md"
                    className={`p-2 ${useRag ? 'text-green-500 dark:text-green-400' : 'text-text-muted-light dark:text-text-muted-dark hover:text-primary'}`}
                    disabled={isLoading}
                />

                {/* New Critical Thinking Toggle */}
               <IconButton
                    icon={icon}
                    onClick={() => setCriticalThinkingEnabled(!criticalThinkingEnabled)}
                    title={criticalThinkingEnabled ? "Disable Critical Thinking (KG)" : "Enable Critical Thinking (KG)"}
                    variant="ghost"
                    size="md"
                    className={`p-2 ${criticalThinkingEnabled ? 'text-purple-500 dark:text-purple-400' : 'text-text-muted-light dark:text-text-muted-dark hover:text-primary'}`}
                    disabled={isLoading}
                />


                <Button 
                    type="submit"
                    variant="primary"
                    size="md" 
                    className="!p-2.5" 
                    disabled={isLoading || !inputValue.trim()}
                    isLoading={isLoading && inputValue.trim()} 
                    title="Send message"
                >
                    {!isLoading || !inputValue.trim() ? <Send size={20} /> : null}
                </Button>
            </form>
        </div>
    );
}
export default ChatInput;
```

`frontend/src/components/chat/MessageBubble.jsx`

```javascript
// src/components/chat/MessageBubble.jsx
import React, { useEffect, useRef } from 'react'; // useEffect and useRef are already here
import { marked } from 'marked';
import DOMPurify from 'dompurify';
import Prism from 'prismjs'; 
import { renderMathInHtml } from '../../utils/markdownUtils';
import { ChevronDown, Brain, Link as LinkIcon, Zap, Server, ServerCrash } from 'lucide-react'; // Added ServerCrash just in case

marked.setOptions({
  breaks: true,
  gfm: true,
});

const createMarkup = (markdownText) => {
  if (!markdownText) return { __html: '' };
  console.log("[Math Test] createMarkup: Original Markdown:", markdownText);

  let html = marked.parse(markdownText);
  console.log("[Math Test] createMarkup: HTML after marked.parse():", html);

  html = renderMathInHtml(html); // <<<< RE-ENABLE THIS
  console.log("[Math Test] createMarkup: HTML after renderMathInHtml():", html);

  // Use a VERY PERMISSIVE DOMPurify config for this test, or even bypass temporarily
  // This is to see if KaTeX output itself is okay before complex sanitization.
  const cleanHtml = DOMPurify.sanitize(html, {
      // Option A: Try with USE_PROFILES first if your DOMPurify supports it
      USE_PROFILES: { html: true, mathMl: true, svg: true },
      // Option B: If USE_PROFILES is not enough or not available,
      // start with a broader allowance for tags and attributes known to be used by KaTeX.
      // This is less secure for general HTML but helps debug KaTeX rendering.
      // ADD_TAGS: ['math', 'mrow', 'mi', 'mo', 'mn', 'msup', 'msub', 'mfrac', 'msqrt', 'mtable', 'mtr', 'mtd', 'mstyle', 'semantics', 'annotation', 'span'],
      // ADD_ATTR: ['class', 'style', 'xmlns', 'display', 'mathvariant', 'mathsize', 'fontstyle', 'fontweight', 'color', 'background', 'href', 'encoding', 'role', 'aria-hidden', /* add more as needed from KaTeX output */],
      // FOR_THIS_TEST_ONLY_IF_STILL_ISSUES (VERY INSECURE - REMOVE FOR PRODUCTION):
      // RETURN_TRUSTED_TYPE: true, // Might be needed for some modern browser contexts if issues persist with types
      // ALLOW_UNKNOWN_PROTOCOLS: true, // If KaTeX uses any odd hrefs (unlikely)
      // ALLOW_DATA_ATTR: true, // KaTeX might use data-* attributes
  });
  console.log("[Math Test] createMarkup: HTML after DOMPurify.sanitize():", cleanHtml);

  return { __html: cleanHtml };
};


const escapeHtml = (unsafe) => {
    if (typeof unsafe !== 'string') return '';
    return unsafe
         .replace(/&/g, "&")
         .replace(/</g, "<")
         .replace(/>/g, ">")
         .replace(/"/g, `"`)
         .replace(/'/g, "'");
};

function MessageBubble({ sender, text, thinking, references, timestamp, sourcePipeline }) {
    const isUser = sender === 'user';
    const messageContentRef = useRef(null); // Ref for the main message content div
    const thinkingContentRef = useRef(null); // Ref for the thinking content pre/code block if it contains Markdown

    const formatTimestamp = (ts) => {
        if (!ts) return '';
        try {
            return new Date(ts).toLocaleTimeString([], { hour: '2-digit', minute: '2-digit' });
        } catch (e) { return 'Invalid Time'; }
    };

    const getPipelineIcon = () => {
        if (!sourcePipeline) return null;
        const lowerPipeline = sourcePipeline.toLowerCase();
        if (lowerPipeline.includes('ollama')) return <Zap size={12} className="text-green-400" title="Ollama Powered" />;
        if (lowerPipeline.includes('gemini')) return <Server size={12} className="text-blue-400" title="Gemini Powered" />;
        if (lowerPipeline.includes('rag')) return <Zap size={12} className="text-purple-400" title="RAG Enhanced" />;
        if (lowerPipeline.includes('error')) return <ServerCrash size={12} className="text-red-400" title="Error" />;
        return null;
    };

    useEffect(() => {
        if (messageContentRef.current) {
            Prism.highlightAllUnder(messageContentRef.current);
        }
    }, [text]);

    useEffect(() => {
        if (thinkingContentRef.current && thinking && typeof thinking === 'string') {
            const isThinkingMarkdown = thinkingContentRef.current.querySelector('.prose'); // A simple check
            if (isThinkingMarkdown) {
                Prism.highlightAllUnder(thinkingContentRef.current);
            }
        }
    }, [thinking]); // Re-run when the 'thinking' prop changes

    return (
        <div className={`flex flex-col ${isUser ? 'items-end' : 'items-start'} w-full group`}>
            <div
                className={`message-bubble max-w-[85%] md:max-w-[75%] p-3 rounded-2xl shadow-md break-words ${
                    isUser
                    ? 'bg-primary dark:bg-primary-dark text-white rounded-br-lg'
                    : 'bg-surface-light dark:bg-surface-dark text-text-light dark:text-text-dark rounded-bl-lg border border-border-light dark:border-border-dark'
                }`}
            >
                {/* Main message content */}
                <div
                    ref={messageContentRef} // Assign ref to the div that will contain the HTML from Markdown
                    className="prose prose-sm dark:prose-invert max-w-none message-content leading-relaxed"
                    dangerouslySetInnerHTML={createMarkup(text || '')}
                />

                {/* Timestamp and Pipeline Icon */}
                <div className="flex items-center justify-end mt-1.5 text-xs opacity-70">
                    {!isUser && getPipelineIcon() && <span className="mr-1.5">{getPipelineIcon()}</span>}
                    {formatTimestamp(timestamp)}
                </div>
            </div>

            {/* Metadata: Thinking and References for Bot Messages */}
            {!isUser && (thinking || (references && references.length > 0)) && (
                <div className="message-metadata-container max-w-[85%] md:max-w-[75%] mt-1.5 pl-2 space-y-1 opacity-0 group-hover:opacity-100 transition-opacity duration-200">
                    {thinking && thinking.trim() && (
                        <details className="group/details text-xs">
                            <summary className="flex items-center gap-1 cursor-pointer text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light transition-colors">
                                <Brain size={14} /> AI Reasoning
                                <ChevronDown size={14} className="group-open/details:rotate-180 transition-transform" />
                            </summary>
                            {/*
                                If 'thinking' is just plain text to be displayed in a <pre><code> block,
                                then Prism.highlightAllUnder won't naturally pick it up unless you
                                manually add a language class to the <code> tag AND 'thinking' contains
                                code in that language.

                                If 'thinking' can itself be Markdown (and thus contain fenced code blocks),
                                you would use dangerouslySetInnerHTML here as well and apply Prism to it.
                                For now, assuming 'thinking' is primarily plain text.
                            */}
                            <pre
                                ref={thinkingContentRef} // Add ref here if 'thinking' can be Markdown with code blocks
                                className="mt-1 p-2 bg-gray-100 dark:bg-gray-800 rounded-md text-text-light dark:text-text-dark whitespace-pre-wrap break-all text-[0.7rem] max-h-32 overflow-y-auto custom-scrollbar"
                                // If 'thinking' is Markdown:
                                // dangerouslySetInnerHTML={createMarkup(thinking)}
                            >
                                {/* If 'thinking' is plain text: */}
                                <code className="language-text">{escapeHtml(thinking)}</code>
                                {/* Added language-text to allow Prism to at least touch it, though it won't do much for plain text.
                                    If 'thinking' was Python code for example, you'd use 'language-python'.
                                    This part is tricky if 'thinking' isn't structured Markdown itself.
                                */}
                            </pre>
                        </details>
                    )}
                    {references && references.length > 0 && (
                        <details className="group/details text-xs" open>
                            <summary className="flex items-center gap-1 cursor-pointer text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light transition-colors">
                                <LinkIcon size={14} /> References
                                <ChevronDown size={14} className="group-open/details:rotate-180 transition-transform" />
                            </summary>
                            <ul className="mt-1 pl-1 space-y-0.5 text-[0.7rem]">
                                {references.map((ref, index) => (
                                    <li
                                        key={index}
                                        className="text-text-muted-light dark:text-text-muted-dark hover:text-text-light dark:hover:text-text-dark transition-colors truncate"
                                        title={`Preview: ${escapeHtml(ref.content_preview || '')}\nSource: ${escapeHtml(ref.source || '')}`}
                                    >
                                        <span className="font-semibold text-accent">[{ref.number}]</span> {escapeHtml(ref.source)}
                                    </li>
                                ))}
                            </ul>
                        </details>
                    )}
                </div>
            )}
        </div>
    );
}
export default MessageBubble;
```

`frontend/src/components/common/ThemeToggle.jsx`

```javascript
import React from 'react';
import { Sun, Moon } from 'lucide-react';
import { useTheme } from '../../hooks/useTheme';

function ThemeToggle() {
    const { theme, toggleTheme } = useTheme();

    return (
        <button
            onClick={toggleTheme}
            className="p-2 rounded-full text-text-muted-light dark:text-text-muted-dark hover:bg-gray-200 dark:hover:bg-gray-700 transition-colors focus:outline-none focus:ring-2 focus:ring-primary"
            aria-label={theme === 'light' ? 'Switch to dark theme' : 'Switch to light theme'}
        >
            {theme === 'light' ? <Moon size={20} /> : <Sun size={20} />}
        </button>
    );
}

export default ThemeToggle;
```

`frontend/src/components/core/Button.jsx`

```javascript
// src/components/core/Button.jsx
import React from 'react';
import { Loader2 } from 'lucide-react'; // For loading spinner

const Button = ({
    children,
    onClick,
    type = 'button',
    variant = 'primary', // 'primary', 'secondary', 'danger', 'outline', 'ghost'
    size = 'md', // 'sm', 'md', 'lg'
    leftIcon,
    rightIcon,
    isLoading = false,
    disabled = false,
    fullWidth = false,
    className = '',
    ...props
}) => {
    const baseStyles = "font-semibold rounded-lg focus:outline-none focus:ring-2 focus:ring-opacity-75 transition-all duration-150 ease-in-out flex items-center justify-center gap-2";

    const variantStyles = {
        primary: "bg-primary hover:bg-primary-dark text-white focus:ring-primary",
        secondary: "bg-secondary hover:bg-secondary-dark text-white focus:ring-secondary",
        danger: "bg-red-500 hover:bg-red-600 text-white focus:ring-red-500",
        outline: "border border-primary text-primary hover:bg-primary-light dark:hover:bg-opacity-10 focus:ring-primary",
        ghost: "text-primary hover:bg-primary-light dark:hover:bg-opacity-10 focus:ring-primary",
    };

    const sizeStyles = {
        sm: "px-3 py-1.5 text-xs",
        md: "px-4 py-2 text-sm",
        lg: "px-6 py-3 text-base",
    };

    const widthStyle = fullWidth ? "w-full" : "";
    const isDisabled = disabled || isLoading;
    const finalDisabledStyle = isDisabled ? "opacity-60 cursor-not-allowed" : "cursor-pointer";

    const spinnerSize = size === 'sm' ? 14 : (size === 'lg' ? 20 : 16);
    
    return (
        <button
            type={type}
            onClick={onClick}
            disabled={isDisabled} // Use the corrected variable
            className={`${baseStyles} ${variantStyles[variant]} ${sizeStyles[size]} ${widthStyle} ${finalDisabledStyle} ${className}`}
            {...props}
        >
            {isLoading && (
                <Loader2 size={spinnerSize} className="animate-spin" />
            )}
            {!isLoading && leftIcon && <span className="icon-left">{leftIcon}</span>}

            <span className={isLoading ? 'ml-2' : ''}>{children}</span>

            {!isLoading && rightIcon && <span className="icon-right">{rightIcon}</span>}
        </button>
    );
};

export default Button;
```

`frontend/src/components/core/IconButton.jsx`

```javascript
import React from 'react';
import { Loader2 } from 'lucide-react';

const IconButton = ({
    icon: Icon, // Pass the Lucide icon component directly
    onClick,
    variant = 'ghost', // 'ghost', 'outline', 'subtle'
    size = 'md', // 'sm', 'md', 'lg'
    isLoading = false,
    disabled = false,
    className = '',
    title, // For accessibility and tooltips
    ariaLabel,
    ...props
}) => {
    const baseStyles = "rounded-md focus:outline-none focus:ring-2 focus:ring-opacity-75 transition-colors duration-150 flex items-center justify-center";

    const variantStyles = {
        ghost: "text-text-muted-light dark:text-text-muted-dark hover:bg-gray-200 dark:hover:bg-gray-700 focus:ring-primary",
        outline: "border border-gray-300 dark:border-gray-600 text-text-muted-light dark:text-text-muted-dark hover:border-primary hover:text-primary focus:ring-primary",
        subtle: "bg-gray-100 dark:bg-gray-700 text-text-light dark:text-text-dark hover:bg-gray-200 dark:hover:bg-gray-600 focus:ring-primary",
        danger: "text-red-500 hover:bg-red-100 dark:hover:bg-red-900 focus:ring-red-500"
    };

    const sizeStyles = {
        sm: "p-1.5", // Icon size typically 14-16px
        md: "p-2",   // Icon size typically 18-20px
        lg: "p-2.5", // Icon size typically 22-24px
    };
    
    const iconSizeMap = {
        sm: 16,
        md: 20,
        lg: 24,
    };

    const disabledStyle = (disabled || isLoading) ? "opacity-50 cursor-not-allowed" : "cursor-pointer";

    return (
        <button
            type="button"
            onClick={onClick}
            disabled={disabled || isLoading}
            className={`${baseStyles} ${variantStyles[variant]} ${sizeStyles[size]} ${disabledStyle} ${className}`}
            title={title}
            aria-label={ariaLabel || title}
            {...props}
        >
            {isLoading ? (
                <Loader2 size={iconSizeMap[size]} className="animate-spin" />
            ) : (
                Icon && <Icon size={iconSizeMap[size]} />
            )}
        </button>
    );
};

export default IconButton;
```

`frontend/src/components/core/Modal.jsx`

```javascript
// src/components/core/Modal.jsx
import React, { useEffect, useRef } from 'react';
import { X } from 'lucide-react';
import { motion, AnimatePresence } from 'framer-motion';

const Modal = ({
    isOpen,
    onClose,
    title,
    children,
    footerContent,
    size = 'md', // 'sm', 'md', 'lg', 'xl', '2xl', '3xl', '4xl', '5xl', 'full'
    closeOnOverlayClick = true,
    initialFocusRef, // Optional ref for focusing an element inside the modal on open
}) => {
    const modalRef = useRef(null);

    // Handle Escape key for closing
    useEffect(() => {
        const handleEscapeKey = (event) => {
            if (event.key === 'Escape' && isOpen) {
                onClose();
            }
        };
        if (isOpen) {
            document.addEventListener('keydown', handleEscapeKey);
        }
        return () => {
            document.removeEventListener('keydown', handleEscapeKey);
        };
    }, [isOpen, onClose]);

    // Handle focus trapping and initial focus
    useEffect(() => {
        if (isOpen) {
            // Set focus to the initialFocusRef or the modal itself
            if (initialFocusRef && initialFocusRef.current) {
                initialFocusRef.current.focus();
            } else if (modalRef.current) {
                modalRef.current.focus(); // Fallback to modal itself
            }

            // Basic focus trapping (can be made more robust with a library)
            const focusableElements = modalRef.current?.querySelectorAll(
                'button, [href], input, select, textarea, [tabindex]:not([tabindex="-1"])'
            );
            if (focusableElements && focusableElements.length > 0) {
                const firstElement = focusableElements[0];
                const lastElement = focusableElements[focusableElements.length - 1];

                const onKeyDown = (e) => {
                    if (e.key === 'Tab') {
                        if (e.shiftKey) { // Shift + Tab
                            if (document.activeElement === firstElement) {
                                lastElement.focus();
                                e.preventDefault();
                            }
                        } else { // Tab
                            if (document.activeElement === lastElement) {
                                firstElement.focus();
                                e.preventDefault();
                            }
                        }
                    }
                };
                modalRef.current?.addEventListener('keydown', onKeyDown);
                return () => modalRef.current?.removeEventListener('keydown', onKeyDown);
            }
        }
    }, [isOpen, initialFocusRef]);


    const sizeClasses = {
        sm: 'max-w-sm',
        md: 'max-w-md',
        lg: 'max-w-lg',
        xl: 'max-w-xl',
        '2xl': 'max-w-2xl',
        '3xl': 'max-w-3xl',
        '4xl': 'max-w-4xl',
        '5xl': 'max-w-5xl',
        full: 'max-w-full h-full rounded-none sm:rounded-lg sm:max-h-[95vh]', // Special case for full screen like
    };

    const backdropVariants = {
        visible: { opacity: 1, transition: { duration: 0.2, ease: "easeOut" } },
        hidden: { opacity: 0, transition: { duration: 0.15, ease: "easeIn" } },
    };

    const modalVariants = {
        hidden: { y: "-30px", opacity: 0, scale: 0.98, transition: { duration: 0.15, ease: "easeIn" } },
        visible: { y: "0", opacity: 1, scale: 1, transition: { type: "spring", stiffness: 400, damping: 30, duration: 0.3 } },
        exit: { y: "30px", opacity: 0, scale: 0.98, transition: { duration: 0.2, ease: "easeIn" } }
    };

    if (!isOpen) return null;

    return (
        <AnimatePresence mode="wait">
            {isOpen && (
                <motion.div
                    key="modal-backdrop"
                    className="fixed inset-0 z-50 flex items-center justify-center p-4 bg-black/70 dark:bg-black/80 backdrop-blur-sm"
                    initial="hidden"
                    animate="visible"
                    exit="hidden"
                    variants={backdropVariants}
                    onClick={closeOnOverlayClick ? onClose : undefined}
                    aria-labelledby="modal-title" // For screen readers
                    role="dialog" // Role for the backdrop itself, more specific roles on content
                    aria-modal="true" // Indicate it's a modal overlaying other content
                >
                    <motion.div
                        key="modal-content-wrapper" // Changed key for potential AnimatePresence behavior
                        ref={modalRef}
                        tabIndex={-1} // Make the modal itself focusable for fallback
                        className={`bg-surface-light dark:bg-surface-dark rounded-lg shadow-xl w-full ${sizeClasses[size]} flex flex-col overflow-hidden
                                    ${size === 'full' ? '' : 'max-h-[90vh] sm:max-h-[85vh]'}`} 
                                    // Apply max-h unless it's 'full' size
                        role="document" // The actual dialog content
                        aria-modal="true"
                        aria-labelledby={title ? "modal-title-text" : undefined} // Point to title if exists
                        initial="hidden"
                        animate="visible"
                        exit="exit"
                        variants={modalVariants}
                        onClick={(e) => e.stopPropagation()} // Prevent closing when clicking inside modal
                    >
                        {/* Modal Header */}
                        <div className="flex items-center justify-between px-5 py-3.5 border-b border-border-light dark:border-border-dark sticky top-0 bg-surface-light dark:bg-surface-dark z-10 flex-shrink-0">
                            {title && (
                                <h2 id="modal-title-text" className="text-lg font-semibold text-text-light dark:text-text-dark truncate pr-4">
                                    {title}
                                </h2>
                            )}
                            <button
                                onClick={onClose}
                                className="p-1.5 rounded-full text-text-muted-light dark:text-text-muted-dark 
                                           hover:bg-gray-200/80 dark:hover:bg-gray-700/80 
                                           hover:text-red-500 dark:hover:text-red-400 
                                           focus:outline-none focus:ring-2 focus:ring-primary dark:focus:ring-primary-light focus:ring-offset-1 dark:focus:ring-offset-surface-dark"
                                aria-label="Close modal"
                            >
                                <X size={20} />
                            </button>
                        </div>

                        {/* Modal Body */}
                        <div className="px-5 py-4 overflow-y-auto flex-grow custom-scrollbar">
                            {children}
                        </div>

                        {/* Modal Footer */}
                        {footerContent && (
                            <div className="px-5 py-3.5 border-t border-border-light dark:border-border-dark flex justify-end gap-3 sticky bottom-0 bg-surface-light dark:bg-surface-dark z-10 flex-shrink-0">
                                {footerContent}
                            </div>
                        )}
                    </motion.div>
                </motion.div>
            )}
        </AnimatePresence>
    );
};

export default Modal;
```

`frontend/src/components/documents/DocumentList.jsx`

```javascript


// frontend/src/components/documents/DocumentList.jsx
import React, { useState, useEffect, useCallback } from 'react';
import api from '../../services/api.js'; // Mocked for V1
import toast from 'react-hot-toast';
import { FileText, Edit3, Trash2, Loader2, AlertTriangle, CheckCircle } from 'lucide-react';
import IconButton from '../core/IconButton.jsx'; // Make sure IconButton is imported
import { useAuth } from '../../hooks/useAuth.jsx';

// Props from LeftPanel: onSelectDocument is selectDocumentForAnalysis from AppStateContext
// selectedDocument is selectedDocumentForAnalysis from AppStateContext
function DocumentList({ onSelectDocument, selectedDocument }) {
  const [files, setFiles] = useState([]);
  const [loading, setLoading] = useState(true);
  const [error, setError] = useState('');

  const fetchFiles = useCallback(async () => {
    setLoading(true);
    setError('');
    try {
      
      const response = await api.getFiles(); // Returns { filenames: ["A.txt", "B.pdf"] }
      const filenames = Array.isArray(response.filenames) ? response.filenames : [];
      setFiles(filenames);
      
    } catch (err) {
      console.error("Failed to fetch files:", err);
      setError(err.message || "Failed to fetch files.");
      toast.error("Could not load documents.");
    } finally {
      setLoading(false);
    }
  }, []);



  useEffect(() => {
    fetchFiles();
  }, [fetchFiles]);

  const handleDelete = async (filename) => {
    if (!window.confirm(`Are you sure you want to delete "${filename}"?`)) return;
    const toastId = toast.loading(`Deleting ${filename}...`);
    try {
      await api.deleteFile(filename); // Assumes this works with filename
      toast.success(`${filename} deleted.`, { id: toastId });
      fetchFiles();
      if (selectedDocument === filename) {
        onSelectDocument(null);
      }
    } catch (err) {
      toast.error(`Delete failed: ${err.message}`, { id: toastId });
    }
  };

  if (loading) {
    return (
      <div className="flex items-center justify-center p-4 text-text-muted-light dark:text-text-muted-dark">
        <Loader2 size={20} className="animate-spin mr-2" /> Loading documents...
      </div>
    );
  }

  if (error) {
    return (
      <div className="p-3 bg-red-500/10 border border-red-500/30 text-red-600 dark:text-red-300 rounded-md text-sm flex items-center gap-2">
        <AlertTriangle size={18} /> {error}
        <button onClick={fetchFiles} className="ml-auto text-xs underline hover:text-red-400">Retry</button>
      </div>
    );
  }

  if (files.length === 0) {
    return <p className="text-center text-xs text-text-muted-light dark:text-text-muted-dark p-4">No documents uploaded.</p>;
  }

  return (
    <div className="space-y-1.5 text-xs custom-scrollbar pr-1">
      {files.map(filename => {
        const isSelected = selectedDocument === filename;

        return (
          <div
            key={filename}
            onClick={() => onSelectDocument(isSelected ? null : filename)}
            className={`p-2.5 bg-surface-light dark:bg-gray-800 border rounded-md flex items-center justify-between hover:shadow-md transition-all duration-150 cursor-pointer
                        ${isSelected
                          ? 'ring-2 ring-primary dark:ring-primary-light shadow-lg border-primary dark:border-primary-light'
                          : 'border-border-light dark:border-border-dark hover:border-gray-400 dark:hover:border-gray-500'}`}
            title={`Select ${filename}`}
          >
            <div className="flex items-center gap-2 truncate">
              {isSelected ? (
                <CheckCircle size={16} className="text-green-500 flex-shrink-0" />
              ) : (
                <FileText size={16} className="text-primary dark:text-primary-light flex-shrink-0" />
              )}
              <span className={`truncate ${isSelected ? 'font-semibold text-primary dark:text-primary-light' : 'text-text-light dark:text-text-dark'}`}>
                {filename}
              </span>
            </div>
            <div className="flex-shrink-0 flex items-center gap-0.5">
              <IconButton
                icon={Trash2}
                size="sm"
                variant="ghost"
                title="Delete"
                onClick={(e) => {
                  e.stopPropagation();
                  handleDelete(filename);
                }}
                className="text-red-500 hover:text-red-700 dark:text-red-400 dark:hover:text-red-300 p-1"
              />
            </div>
          </div>
        );
      })}
    </div>
  );
}


export default DocumentList;
```

`frontend/src/components/documents/DocumentUpload.jsx`

```javascript
// frontend/src/components/documents/DocumentUpload.jsx
import React, { useState, useRef, useEffect } from 'react';
import api from '../../services/api.js';
import toast from 'react-hot-toast';
import { UploadCloud, FileText, XCircle, Loader2, CheckCircle, AlertTriangle, Paperclip } from 'lucide-react';
import Button from '../core/Button.jsx'; // Your custom Button

// Define the states and corresponding button texts
const BUTTON_TEXT_STATES = {
    IDLE_NO_FILE: "Select a File",
    IDLE_FILE_SELECTED: "Upload Document",
    UPLOADING_BYTES: "Uploading file...", // Static text during byte transfer phase
    // Cycling messages after byte upload, while Node.js waits for Python
    EXTRACTING_CONTENT: "Extracting content...",
    CLEANING_TEXT: "Cleaning text...",
    ANALYZING_DOCUMENT: "Analyzing document...",
    // After Node.js 202 response (Python call finished from Node's perspective)
    FINALIZING_SUBMISSION: "Finalizing...",
    ERROR: "Upload Failed - Retry?", // Or simply "Upload Failed"
};

// Order for the first cycle of detailed processing messages on the button
const firstCycleButtonMessages = [
    BUTTON_TEXT_STATES.EXTRACTING_CONTENT,
    BUTTON_TEXT_STATES.CLEANING_TEXT,
    BUTTON_TEXT_STATES.ANALYZING_DOCUMENT,
];

// Order for subsequent looping cycles on the button
const loopCycleButtonMessages = [
    BUTTON_TEXT_STATES.CLEANING_TEXT, // Loop starts from "Cleaning..."
    BUTTON_TEXT_STATES.ANALYZING_DOCUMENT,
];

const MESSAGE_BUTTON_DISPLAY_DURATION_MS = 3000; // 3 seconds per message

function DocumentUpload({ onUploadSuccess }) {
    const [selectedFile, setSelectedFile] = useState(null);
    const [isProcessing, setIsProcessing] = useState(false);
    const [buttonText, setButtonText] = useState(BUTTON_TEXT_STATES.IDLE_NO_FILE);
    const [errorMessage, setErrorMessage] = useState('');
    const [dragActive, setDragActive] = useState(false); // For dropzone visual feedback

    const fileInputRef = useRef(null);
    const intervalRef = useRef(null);       // Stores the setInterval ID
    const messageIndexRef = useRef(0);    // Current index in the message array
    const currentMessageArrayRef = useRef(firstCycleButtonMessages); // Which array to use (first or loop)
    const isMountedRef = useRef(true);      // Track if component is mounted

    console.log(`[UploadFinalUX] Component Render/Re-render. isProcessing: ${isProcessing}, buttonText: "${buttonText}"`);

    // Effect for component mount and unmount
    useEffect(() => {
        isMountedRef.current = true;
        console.log("[UploadFinalUX] Component Mounted.");
        return () => {
            isMountedRef.current = false;
            if (intervalRef.current) {
                clearInterval(intervalRef.current);
                console.log("[UploadFinalUX] Component Unmounting - Cleared interval:", intervalRef.current);
            }
            console.log("[UploadFinalUX] Component Unmounted.");
        };
    }, []);

    // Effect to manage the cycling of button text messages
    useEffect(() => {
        const clearLocalInterval = (reason = "unspecified") => {
            if (intervalRef.current) {
                console.log(`[UploadFinalUX CycleEffect] Clearing interval (Reason: ${reason}). ID: ${intervalRef.current}`);
                clearInterval(intervalRef.current);
                intervalRef.current = null;
            }
        };

        console.log(`[UploadFinalUX CycleEffect] Evaluating. isProcessing: ${isProcessing}, buttonText: "${buttonText}"`);

        const isCurrentlyInCyclingState =
            buttonText === BUTTON_TEXT_STATES.EXTRACTING_CONTENT ||
            buttonText === BUTTON_TEXT_STATES.CLEANING_TEXT ||
            buttonText === BUTTON_TEXT_STATES.ANALYZING_DOCUMENT;

        if (isProcessing && isCurrentlyInCyclingState) {
            if (!intervalRef.current) { // Only start a new interval if one isn't already running
                console.log(`[UploadFinalUX CycleEffect] Starting new interval. Initial buttonText for cycle: "${buttonText}"`);

                // Determine which array and index to start/resume from
                if (buttonText === BUTTON_TEXT_STATES.EXTRACTING_CONTENT) {
                    currentMessageArrayRef.current = firstCycleButtonMessages;
                    messageIndexRef.current = 0; // Start from the beginning of the first cycle
                } else { // Resuming or starting mid-loop (e.g., if state was restored)
                    const loopIdx = loopCycleButtonMessages.indexOf(buttonText);
                    currentMessageArrayRef.current = loopCycleButtonMessages;
                    messageIndexRef.current = (loopIdx !== -1) ? loopIdx : 0;
                }
                // No need to setButtonText here, as it's already in a cycling state which triggered this.

                intervalRef.current = setInterval(() => {
                    if (!isMountedRef.current || !isProcessing) {
                        clearLocalInterval("component unmounted or no longer processing in interval");
                        return;
                    }

                    messageIndexRef.current++; // Advance to the next message in the current array
                    if (messageIndexRef.current >= currentMessageArrayRef.current.length) {
                        // Reached the end of the current message array, switch to loopCycleMessages
                        currentMessageArrayRef.current = loopCycleButtonMessages;
                        messageIndexRef.current = 0; // Reset index for the loop array
                        console.log("[UploadFinalUX Interval] Switched/Reset to loopCycleMessages. Next message index: 0");
                    }
                    
                    const nextButtonText = currentMessageArrayRef.current[messageIndexRef.current];
                    console.log(`[UploadFinalUX Interval] Setting buttonText to: "${nextButtonText}" (Index: ${messageIndexRef.current} in [${currentMessageArrayRef.current.join(', ')}])`);
                    if (isMountedRef.current) setButtonText(nextButtonText);

                }, MESSAGE_BUTTON_DISPLAY_DURATION_MS);
                console.log(`[UploadFinalUX CycleEffect] Interval started. ID: ${intervalRef.current}. Initial array: [${currentMessageArrayRef.current.join(', ')}]`);
            } else {
                console.log(`[UploadFinalUX CycleEffect] Interval already running for a cycling state. ID: ${intervalRef.current}`);
            }
        } else {
            // If not processing, or if buttonText is not one of the cycling states, clear any existing interval.
            if (intervalRef.current) {
                clearLocalInterval(`not processing or not in cycling state (Text: ${buttonText})`);
            } else {
                // console.log(`[UploadFinalUX CycleEffect] Conditions for cycling NOT met, and no active interval to clear.`);
            }
        }

        return () => { // Cleanup function for this useEffect
            // console.log(`[UploadFinalUX CycleEffect] Cleanup on dep change (isProcessing/buttonText). Current interval ID: ${intervalRef.current}`);
            clearLocalInterval("effect dependency change cleanup");
        };
    }, [isProcessing, buttonText]); // Key dependencies for managing the interval


    const handleFileChange = (e) => {
        console.log("[UploadFinalUX] handleFileChange triggered.");
        if (isProcessing) {
            console.log("[UploadFinalUX] handleFileChange: Currently processing, ignoring file change.");
            return;
        }
        const file = e.target.files && e.target.files[0];
        if (file) {
            setSelectedFile(file);
            setButtonText(BUTTON_TEXT_STATES.IDLE_FILE_SELECTED);
            setErrorMessage('');
            console.log("[UploadFinalUX] handleFileChange: File selected:", file.name);
        } else {
            console.log("[UploadFinalUX] handleFileChange: No file selected or selection cancelled.");
            resetState(); // Resets to IDLE_NO_FILE
        }
    };

    const handleDrag = (e) => { e.preventDefault(); e.stopPropagation(); if (isProcessing) return; if (e.type === "dragenter" || e.type === "dragover") setDragActive(true); else if (e.type === "dragleave") setDragActive(false); };
    const handleDrop = (e) => { e.preventDefault(); e.stopPropagation(); if (isProcessing) return; setDragActive(false); const file = e.dataTransfer.files && e.dataTransfer.files[0]; if (file) { setSelectedFile(file); setButtonText(BUTTON_TEXT_STATES.IDLE_FILE_SELECTED); setErrorMessage(''); console.log("[UploadFinalUX] handleDrop: File dropped:", file.name); } };

    const handleUpload = async () => {
    if (!selectedFile) {
        toast.error("Please select a file first.");
        return;
    }

    console.log("[UploadFinalUX] handleUpload: Starting upload for", selectedFile.name);
    setIsProcessing(true);
    setButtonText(BUTTON_TEXT_STATES.UPLOADING_BYTES);
    setErrorMessage("");

    // Reset cycling refs
    messageIndexRef.current = 0;
    currentMessageArrayRef.current = firstCycleButtonMessages;

    const formData = new FormData();
    formData.append("file", selectedFile);

    // ─── Fallback: if onUploadProgress never reaches 100%, force EXTRACTING_CONTENT after 500ms ───
    const fallbackTimer = setTimeout(() => {
        if (
        isMountedRef.current &&
        isProcessing &&
        buttonText === BUTTON_TEXT_STATES.UPLOADING_BYTES
        ) {
        console.log(
            "[UploadFinalUX] handleUpload: Forcing EXTRACTING_CONTENT (fallback)."
        );
        setButtonText(BUTTON_TEXT_STATES.EXTRACTING_CONTENT);
        }
    }, 500);
    // ───────────────────────────────────────────────────────────────────────────────────────────

    try {
        console.log("[UploadFinalUX] handleUpload: Calling api.uploadFile");
        await api.uploadFile(formData, (event) => {
        if (isMountedRef.current && isProcessing) {
            if (event.lengthComputable) {
            if (event.loaded === event.total) {
                if (buttonText !== BUTTON_TEXT_STATES.EXTRACTING_CONTENT) {
                console.log(
                    "[UploadFinalUX] onUploadProgress: 100% bytes sent. Setting EXTRACTING_CONTENT."
                );
                setButtonText(BUTTON_TEXT_STATES.EXTRACTING_CONTENT);
                }
                clearTimeout(fallbackTimer);
            }
            } else if (buttonText === BUTTON_TEXT_STATES.UPLOADING_BYTES) {
            console.log(
                "[UploadFinalUX] onUploadProgress: Not computable & still UPLOADING_BYTES. Setting EXTRACTING_CONTENT."
            );
            setButtonText(BUTTON_TEXT_STATES.EXTRACTING_CONTENT);
            clearTimeout(fallbackTimer);
            }
        }
        });

        console.log(
        "[UploadFinalUX] handleUpload: api.uploadFile resolved (Node.js 202 received)."
        );
        clearTimeout(fallbackTimer);

        if (isMountedRef.current && isProcessing) {
        console.log(
            "[UploadFinalUX] handleUpload: Setting buttonText to FINALIZING_SUBMISSION."
        );
        setButtonText(BUTTON_TEXT_STATES.FINALIZING_SUBMISSION);
        }

        if (onUploadSuccess) {
        onUploadSuccess({ originalname: selectedFile.name });
        }
        toast.success(`"${selectedFile.name}" submitted. Background tasks initiated.`);

        setTimeout(() => {
        if (isMountedRef.current) {
            console.log(
            "[UploadFinalUX] handleUpload: Timeout for resetState after FINALIZING_SUBMISSION."
            );
            resetState();
        }
        }, 1500);
    } catch (error) {
        clearTimeout(fallbackTimer);
        console.error("[UploadFinalUX] Upload failed in catch:", error);
        if (isMountedRef.current) {
        const msg =
            error.response?.data?.message || error.message || "Upload processing failed.";
        setErrorMessage(msg);
        setButtonText(BUTTON_TEXT_STATES.ERROR);
        setIsProcessing(false);
        toast.error(`Upload of "${selectedFile.name}" failed.`);
        }
    }
    };



    const resetState = () => {
        console.log("[UploadFinalUX] resetState called.");
        setSelectedFile(null);
        setButtonText(BUTTON_TEXT_STATES.IDLE_NO_FILE);
        setErrorMessage('');
        setIsProcessing(false); // This will trigger CycleEffect to clear interval
        if (fileInputRef.current) {
            fileInputRef.current.value = null;
        }
        setDragActive(false);
        messageIndexRef.current = 0;
        currentMessageArrayRef.current = firstCycleButtonMessages; // Reset for next cycle
        console.log("[UploadFinalUX] resetState: State reset complete.");
    };

    const isButtonUploadActuallyDisabled = !selectedFile || isProcessing;
    const UploadAreaIcon = Paperclip;

    return (
        <div className="mb-4 p-1">
            <label
                htmlFor="file-upload-input"
                onDragEnter={handleDrag}
                onDragLeave={handleDrag}
                onDragOver={handleDrag}
                onDrop={handleDrop}
                className={`flex flex-col items-center justify-center w-full h-36 px-4 transition-colors duration-200 ease-in-out
                            bg-surface-light dark:bg-gray-800
                            border-2 border-dashed rounded-lg cursor-pointer
                            border-border-light dark:border-border-dark
                            hover:border-primary dark:hover:border-primary-light
                            ${isProcessing ? "opacity-60 cursor-not-allowed" : ""}
                            ${dragActive ? "border-primary dark:border-primary-light ring-2 ring-primary dark:ring-primary-light bg-primary/10 dark:bg-primary-dark/20" : ""}`}
            >
                <div className="flex flex-col items-center justify-center text-center">
                    <UploadAreaIcon size={36} className={`mb-2 transition-colors ${dragActive ? 'text-primary dark:text-primary-light' : 'text-text-muted-light dark:text-text-muted-dark'}`} />
                    <p className="mb-1 text-xs sm:text-sm text-text-muted-light dark:text-text-muted-dark">
                        <span className="font-semibold text-primary dark:text-primary-light">Click to upload</span> or drag and drop
                    </p>
                    <p className="text-[0.7rem] sm:text-xs text-text-muted-light dark:text-text-muted-dark">PDF, DOCX, TXT, PPTX, code files</p>
                </div>
                <input ref={fileInputRef} id="file-upload-input" type="file" className="hidden" onChange={handleFileChange}
                       disabled={isProcessing}
                       accept=".pdf,.doc,.docx,.ppt,.pptx,.txt,.py,.js,.md,.html,.xml,.json,.csv,.log,.c,.cpp,.java" />
            </label>

            {selectedFile && (
                <div className="mt-2 p-2 bg-gray-100 dark:bg-gray-700 rounded-md flex items-center justify-between text-sm animate-fadeIn">
                    <div className="flex items-center gap-2 truncate">
                        {buttonText === BUTTON_TEXT_STATES.ERROR && errorMessage ?
                            <AlertTriangle size={18} className="text-red-500 flex-shrink-0" /> :
                            <FileText size={18} className="text-primary flex-shrink-0" />
                        }
                        <span className="truncate text-text-light dark:text-text-dark" title={selectedFile.name}>{selectedFile.name}</span>
                        <span className="text-text-muted-light dark:text-text-muted-dark text-xs whitespace-nowrap">
                            ({(selectedFile.size / 1024).toFixed(1)} KB)
                        </span>
                    </div>
                    {!isProcessing && buttonText !== BUTTON_TEXT_STATES.ERROR && (
                        <button onClick={resetState} className="text-red-500 hover:text-red-700 dark:hover:text-red-400 transition-colors p-1 rounded-full hover:bg-red-500/10">
                            <XCircle size={18} />
                        </button>
                    )}
                </div>
            )}

            {/* Error message display area (if any) */}
            {errorMessage && buttonText === BUTTON_TEXT_STATES.ERROR && (
                 <div className="mt-2 text-xs text-red-600 dark:text-red-400 p-2 bg-red-500/10 rounded-md flex justify-center items-center h-auto">
                    <AlertTriangle size={14} className="mr-1.5 flex-shrink-0" />
                    <span className="flex-grow text-center">{errorMessage.substring(0,100)}</span>
                 </div>
            )}

            <Button
                onClick={handleUpload}
                fullWidth
                className="mt-3 text-sm min-h-[38px]" // min-height to prevent button size jumping due to text length
                variant="primary"
                isLoading={isProcessing} // Button component shows its spinner when true
                disabled={isButtonUploadActuallyDisabled}
                leftIcon={!isProcessing && buttonText !== BUTTON_TEXT_STATES.ERROR ? <UploadCloud size={16} /> : null}
            >
                {/* The button's text is now directly from the buttonText state */}
                {buttonText}
            </Button>
        </div>
    );
}
export default DocumentUpload;
```

`frontend/src/components/layout/CenterPanel.jsx`

```javascript
// src/components/layout/CenterPanel.jsx
import React, { useState, useEffect } from 'react';
import ChatHistory from '../chat/ChatHistory';
import ChatInput from '../chat/ChatInput';
import api from '../../services/api';
import { useAuth } from '../../hooks/useAuth';
import { useAppState } from '../../contexts/AppStateContext';
import toast from 'react-hot-toast';

function CenterPanel({ messages, setMessages, currentSessionId, chatStatus, setChatStatus }) {
    const { token, user } = useAuth();
    const { selectedLLM, systemPrompt, selectedDocumentForAnalysis } = useAppState(); 
    const [useRag, setUseRag] = useState(false); 
    const [isSending, setIsSending] = useState(false);
    const [criticalThinkingEnabled, setCriticalThinkingEnabled] = useState(false); // State for CT

    // MODIFIED: Accept isCtEnabledFromInput as the second argument
    const handleSendMessage = async (inputText, isCtEnabledFromInput) => { 
        if (!inputText.trim() || !token || !currentSessionId || isSending) {
            if (!currentSessionId) toast.error("No active session. Try 'New Chat'.");
            return;
        }

        const clientSideId = `user-${Date.now()}-${Math.random().toString(16).slice(2)}`;
        const userMessage = {
            id: clientSideId, 
            sender: 'user',
            role: 'user', 
            text: inputText.trim(),
            parts: [{ text: inputText.trim() }], 
            timestamp: new Date().toISOString()
        };
        
        setMessages(prev => [...prev, userMessage]);
        
        setIsSending(true);
        let currentThinkingStatus = "Connecting to AI...";
        // MODIFIED: Use isCtEnabledFromInput for status message
        if (useRag && isCtEnabledFromInput) {
            currentThinkingStatus = `Searching docs, retrieving KG & Contacting ${selectedLLM.toUpperCase()} (RAG + CT)...`;
        } else if (useRag) {
            currentThinkingStatus = `Searching documents & Contacting ${selectedLLM.toUpperCase()} (RAG)...`;
        } else if (isCtEnabledFromInput) {
            currentThinkingStatus = `Retrieving KG & Contacting ${selectedLLM.toUpperCase()} (CT)...`;
        } else {
            currentThinkingStatus = `Contacting ${selectedLLM.toUpperCase()}...`;
        }
        setChatStatus(currentThinkingStatus);

        const historyForBackend = messages.map(m => ({
            role: m.sender === 'bot' ? 'model' : 'user',
            parts: m.parts || [{ text: m.text }], 
            timestamp: m.timestamp,
            ...(m.sender === 'bot' && { 
                thinking: m.thinking,
                references: m.references,
                source_pipeline: m.source_pipeline
            })
        }));
        
        const payload = {
            query: inputText.trim(), 
            history: historyForBackend,
            sessionId: currentSessionId,
            useRag: useRag,
            llmProvider: selectedLLM, 
            systemPrompt: systemPrompt,
            // MODIFIED: Use the parameter and match backend key
            criticalThinkingEnabled: isCtEnabledFromInput, 
            documentContextName: selectedDocumentForAnalysis || null, 
        };
            
        try {
            console.log("CenterPanel: Sending payload to /api/chat/message:", payload);
            const response = await api.sendMessage(payload); 
            
            if (response && response.reply) {
                const aiReply = {
                    ...response.reply, 
                    id: `bot-${Date.now()}-${Math.random().toString(16).slice(2)}` 
                };
                setMessages(prev => [...prev, aiReply]);
                setChatStatus(`Responded via ${aiReply.source_pipeline || selectedLLM.toUpperCase()}.`);
            } else {
                throw new Error("Invalid or empty response structure from AI service.");
            }

        } catch (error) {
            console.error("Error sending message:", error);
            const errorText = error.response?.data?.message || error.message || 'Failed to get response from AI.';
            
            let errorReplyMessage;
            if (error.response?.data?.reply) {
                errorReplyMessage = {
                    ...error.response.data.reply,
                    id: `error-${Date.now()}-${Math.random().toString(16).slice(2)}`
                };
            } else {
                errorReplyMessage = { 
                    id: `error-${Date.now()}-${Math.random().toString(16).slice(2)}`, 
                    sender: 'bot', 
                    text: `Error: ${errorText}`,
                    parts: [{ text: `Error: ${errorText}` }],
                    timestamp: new Date().toISOString(),
                    thinking: "Error processing request.",
                    source_pipeline: "error"
                };
            }
            setMessages(prev => [...prev, errorReplyMessage]);
            setChatStatus(`Error: ${errorText.substring(0,70)}...`);
            toast.error(errorText);
        } finally {
            setIsSending(false);
        }
    };
    
    useEffect(() => {
        if (!currentSessionId) {
            setChatStatus("Please login or start a new chat.");
        } else if (messages.length === 0 && !isSending) {
            setChatStatus("Ready. Send a message to start!");
        }
    }, [currentSessionId, messages, isSending, setChatStatus]); // Added setChatStatus to dependency array


    return (
        <div className="flex flex-col h-full bg-background-light dark:bg-background-dark rounded-lg shadow-inner">
            {messages.length === 0 && !isSending && currentSessionId && (
                 <div className="p-6 sm:p-8 text-center text-text-muted-light dark:text-text-muted-dark animate-fadeIn">
                    <h2 className="text-xl sm:text-2xl font-semibold mb-2 text-text-light dark:text-text-dark">
                        AI Engineering Tutor
                    </h2>
                    <p className="text-base sm:text-lg mb-3">Session ID: {currentSessionId.substring(0,8)}...</p>
                    <div className="text-xs sm:text-sm space-y-1">
                        <p>Current LLM: <span className="font-semibold text-accent">{selectedLLM.toUpperCase()}</span>.</p>
                        <p className="max-w-md mx-auto">
                            Assistant Mode: <span className="italic">"{systemPrompt.length > 60 ? systemPrompt.substring(0,60)+'...' : systemPrompt}"</span>
                        </p>
                        {selectedDocumentForAnalysis && (
                            <p className="mt-1">
                                Analysis Target: <span className="font-medium text-primary dark:text-primary-light">{selectedDocumentForAnalysis}</span>
                            </p>
                        )}
                        <p className="mt-1">
                            {useRag ? <span>RAG is <span className="text-green-500 font-semibold">ON</span>. Using document context.</span> 
                                  : <span>RAG is <span className="text-red-500 font-semibold">OFF</span>. Chatting directly.</span>}
                        </p>
                        <p> {/* New status for Critical Thinking (uses the component's state for display) */}
                            {criticalThinkingEnabled ? <span>Critical Thinking (KG) is <span className="text-purple-500 font-semibold">ON</span>.</span> 
                                  : <span>Critical Thinking (KG) is <span className="text-gray-500 font-semibold">OFF</span>.</span>}
                        </p>
                    </div>
                </div>
            )}

            <ChatHistory messages={messages} isLoading={isSending} />
            <ChatInput 
                onSendMessage={handleSendMessage} 
                isLoading={isSending} 
                currentStatus={chatStatus}
                useRag={useRag}
                setUseRag={setUseRag}
                criticalThinkingEnabled={criticalThinkingEnabled} // Pass state
                setCriticalThinkingEnabled={setCriticalThinkingEnabled} // Pass setter
            />
        </div>
    );
}
export default CenterPanel;
```

`frontend/src/components/layout/LeftCollapsedNav.jsx`

```javascript
// frontend/src/components/layout/LeftCollapsedNav.jsx
import React from 'react';
import { useAppState } from '../../contexts/AppStateContext.jsx';
import { Edit3, UploadCloud, FileText, ChevronRight, Settings2 } from 'lucide-react'; // Settings2 for fallback
import IconButton from '../core/IconButton.jsx'; 
import { motion } from 'framer-motion';

// Mapping icon names (or IDs) to Lucide components
const iconMap = {
    prompt: Edit3,       // Icon for "Custom Prompt"
    upload: UploadCloud, // Icon for "Upload Document"
    docs: FileText,      // Icon for "Document List"
};

function LeftCollapsedNav() {
    const { setIsLeftPanelOpen } = useAppState();

    // Define the items for the collapsed navigation bar
    const navItems = [
        { 
            id: 'prompt', 
            label: 'Custom Prompt', 
            iconName: 'prompt', // Matches key in iconMap
            action: () => { 
                setIsLeftPanelOpen(true); 
                // TODO: Optionally, also scroll to/focus the prompt section in LeftPanel
            } 
        },
        { 
            id: 'upload', 
            label: 'Upload Document', 
            iconName: 'upload', 
            action: () => { 
                setIsLeftPanelOpen(true);
                // TODO: Optionally, open LeftPanel and focus/highlight upload area
            } 
        },
        { 
            id: 'docs', 
            label: 'Document List', 
            iconName: 'docs', 
            action: () => { 
                setIsLeftPanelOpen(true); 
                // TODO: Optionally, open LeftPanel scrolled to document list
            } 
        },
    ];

    return (
        <motion.aside
            key="left-collapsed-nav" // Unique key for AnimatePresence
            initial={{ x: '-100%', opacity: 0 }}
            animate={{ x: '0%', opacity: 1 }}
            exit={{ x: '-100%', opacity: 0 }}
            transition={{ type: 'spring', stiffness: 300, damping: 30 }}
            // Styling for the thin vertical bar
            className="fixed left-0 top-16 bottom-0 z-30 w-14 sm:w-16 
                       bg-surface-light dark:bg-surface-dark 
                       border-r border-border-light dark:border-border-dark 
                       shadow-lg flex flex-col items-center py-3 space-y-2 custom-scrollbar"
        >
            {/* Button to open the full LeftPanel - Placed at the top */}
            <IconButton 
                icon={ChevronRight} 
                onClick={() => setIsLeftPanelOpen(true)} 
                title="Open Assistant Panel"
                ariaLabel="Open Assistant Panel"
                variant="ghost" 
                size="lg" // Make it prominent
                className="mb-2 text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
            />

            {/* Icons for different sections of LeftPanel */}
            {navItems.map(item => {
                const IconComponent = iconMap[item.iconName] || Settings2; // Fallback icon
                return (
                    <IconButton 
                        key={item.id}
                        icon={IconComponent}
                        onClick={item.action} // Action currently just opens the panel
                        title={item.label}
                        ariaLabel={item.label}
                        variant="ghost"
                        size="md" 
                        className="text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
                    />
                );
            })}
            {/* Add a flexible spacer if you want the open button pushed further down from items */}
            {/* <div className="flex-grow"></div> */}
        </motion.aside>
    );
}
export default LeftCollapsedNav;
```

`frontend/src/components/layout/LeftPanel.jsx`

```javascript
// frontend/src/components/layout/LeftPanel.jsx
import React, { useState, useEffect } from 'react';
import { useAppState } from '../../contexts/AppStateContext.jsx';
import DocumentUpload from '../documents/DocumentUpload.jsx';
import DocumentList from '../documents/DocumentList.jsx';   
import { PanelLeftClose, ChevronDown, ChevronUp, FilePlus, Settings2, Bot, BookOpen, Lightbulb } from 'lucide-react';
import IconButton from '../core/IconButton.jsx';
import { motion, AnimatePresence } from 'framer-motion'; // Added AnimatePresence here
import toast from 'react-hot-toast'; // For toast notifications

const PROMPT_PRESETS = [
    { id: 'friendly_tutor', name: 'Friendly Tutor', icon: Bot, text: "You are a friendly, patient, and encouraging tutor specializing in engineering and scientific topics for PhD students. Explain concepts clearly, break down complex ideas, use analogies, and offer positive reinforcement. Ask follow-up questions to ensure understanding." },
    { id: 'concept_explorer', name: 'Concept Explorer', icon: BookOpen, text: "You are an expert academic lecturer introducing a new, complex engineering or scientific concept. Your goal is to provide a deep, structured explanation. Define terms rigorously, outline the theory, provide relevant mathematical formulations (using Markdown), illustrative examples, and discuss applications or limitations pertinent to PhD-level research." },
    { id: 'knowledge_check', name: 'Knowledge Check', icon: Lightbulb, text: "You are assessing understanding of engineering/scientific topics. Ask targeted questions to test knowledge, identify misconceptions, and provide feedback on the answers. Start by asking the user what topic they want to be quizzed on." },
    { id: 'custom', name: 'Custom Prompt', icon: Settings2, text: "You are a helpful AI engineering tutor." }
];

function LeftPanel() {
    const { 
        setIsLeftPanelOpen, 
        systemPrompt, setSystemPrompt, 
        selectDocumentForAnalysis, selectedDocumentForAnalysis // Get these from AppStateContext
    } = useAppState();
    
    const [isPromptSectionOpen, setIsPromptSectionOpen] = useState(true);
    const [isDocManagementOpen, setIsDocManagementOpen] = useState(true);
    const [selectedPresetId, setSelectedPresetId] = useState('custom');

    useEffect(() => {
        const matchedPreset = PROMPT_PRESETS.find(p => p.text === systemPrompt);
        setSelectedPresetId(matchedPreset ? matchedPreset.id : 'custom');
    }, [systemPrompt]);

    const handlePresetChange = (event) => {
        const presetId = event.target.value;
        setSelectedPresetId(presetId);
        const selectedPreset = PROMPT_PRESETS.find(p => p.id === presetId);
        if (selectedPreset) {
            setSystemPrompt(selectedPreset.text);
        }
    };
    
    const [docListKey, setDocListKey] = useState(Date.now()); 
    const handleUploadSuccess = () => { 
        setDocListKey(Date.now()); 
        toast.success("Document list refreshed after upload.");
    };
    

    const SelectedPresetIcon = PROMPT_PRESETS.find(p => p.id === selectedPresetId)?.icon || Settings2;

    return (
        <div className="flex flex-col h-full">
            <div className="flex items-center justify-between mb-3 px-1 pt-1">
                <h2 className="text-sm font-semibold text-text-light dark:text-text-dark">Assistant Controls</h2>
                <IconButton 
                    icon={PanelLeftClose} 
                    onClick={() => setIsLeftPanelOpen(false)} 
                    title="Close Assistant Panel"
                    variant="ghost"
                    size="sm"
                    className="text-text-muted-light dark:text-text-muted-dark hover:text-primary"
                />
            </div>

            {/* Custom Prompt Section */}
            <div className="mb-4">
                <button 
                    onClick={() => setIsPromptSectionOpen(!isPromptSectionOpen)}
                    className="w-full flex items-center justify-between px-3 py-2.5 text-sm font-medium text-left text-text-light dark:text-text-dark bg-gray-50 dark:bg-gray-800 hover:bg-gray-100 dark:hover:bg-gray-700 rounded-md focus:outline-none shadow-sm border border-border-light dark:border-border-dark"
                    aria-expanded={isPromptSectionOpen}
                >
                    <span className="flex items-center gap-2">
                        <SelectedPresetIcon size={16} className="text-primary dark:text-primary-light" />
                        Custom Prompt
                    </span>
                    {isPromptSectionOpen ? <ChevronUp size={18} /> : <ChevronDown size={18} />}
                </button>
                <AnimatePresence>
                    {isPromptSectionOpen && (
                        <motion.div 
                            key="prompt-section-content"
                            initial={{ height: 0, opacity: 0 }} 
                            animate={{ height: 'auto', opacity: 1 }} 
                            exit={{ height: 0, opacity: 0 }}
                            transition={{ duration: 0.2, ease: "easeInOut" }}
                            className="mt-2 p-3 bg-surface-light dark:bg-surface-dark border border-border-light dark:border-border-dark rounded-md shadow-inner overflow-hidden"
                        >
                            <label htmlFor="prompt-preset-select" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark mb-1">
                                Prompt Mode:
                            </label>
                            <select
                                id="prompt-preset-select"
                                value={selectedPresetId}
                                onChange={handlePresetChange}
                                className="input-field mb-2 text-xs py-1.5"
                            >
                                {PROMPT_PRESETS.map(preset => (
                                    <option key={preset.id} value={preset.id}>{preset.name}</option>
                                ))}
                            </select>
                            
                            <label htmlFor="system-prompt-area" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark mb-1">
                                System Prompt (Editable):
                            </label>
                            <textarea
                                id="system-prompt-area"
                                value={systemPrompt}
                                onChange={(e) => {
                                    setSystemPrompt(e.target.value);
                                    setSelectedPresetId('custom');
                                }}
                                rows="5"
                                className="input-field text-xs custom-scrollbar"
                                placeholder="Enter system prompt..."
                            />
                        </motion.div>
                    )}
                </AnimatePresence>
            </div>

            {/* Document Management Section */}
            <div className="flex-grow flex flex-col overflow-hidden">
                 <button 
                    onClick={() => setIsDocManagementOpen(!isDocManagementOpen)}
                    className="w-full flex items-center justify-between px-3 py-2.5 text-sm font-medium text-left text-text-light dark:text-text-dark bg-gray-50 dark:bg-gray-800 hover:bg-gray-100 dark:hover:bg-gray-700 rounded-md focus:outline-none shadow-sm border border-border-light dark:border-border-dark mb-2"
                    aria-expanded={isDocManagementOpen}
                >
                    <span className="flex items-center gap-2"><FilePlus size={16} className="text-primary dark:text-primary-light" /> Document Management</span>
                    {isDocManagementOpen ? <ChevronUp size={18} /> : <ChevronDown size={18} />}
                </button>
                <AnimatePresence>
                    {isDocManagementOpen && (
                        <motion.div 
                            key="doc-management-content"
                            initial={{ height: 0, opacity: 0 }} 
                            animate={{ height: 'auto', opacity: 1 }} 
                            exit={{ height: 0, opacity: 0 }}
                            transition={{ duration: 0.2, ease: "easeInOut" }}
                            className="flex-grow flex flex-col overflow-hidden p-3 bg-surface-light dark:bg-surface-dark border border-border-light dark:border-border-dark rounded-md shadow-inner"
                        >
                            <DocumentUpload onUploadSuccess={handleUploadSuccess} />
                            <div className="mt-3 flex-grow overflow-y-auto custom-scrollbar">
                                <label htmlFor="doc-filter" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark mb-1">Filter documents:</label>
                                 <select id="doc-filter" className="input-field text-xs mt-1 mb-2 py-1.5">
                                    <option value="all">All Documents</option>
                                    <option value="pdf">PDFs</option>
                                    {/* More filter options */}
                                </select>
                                <DocumentList 
                                    key={docListKey} // To re-fetch files on upload
                                    onSelectDocument={selectDocumentForAnalysis} // Pass setter from context
                                    selectedDocument={selectedDocumentForAnalysis} // Pass current selection from context
                                />
                            </div>
                        </motion.div>
                    )}
                </AnimatePresence>
            </div>
        </div>
    );
}
export default LeftPanel;
```

`frontend/src/components/layout/LLMSelectionModal.jsx`

```javascript
// frontend/src/components/layout/LLMSelectionModal.jsx
import React, { useState, useEffect } from 'react';
import { useAppState } from '../../contexts/AppStateContext.jsx';
import api from '../../services/api.js'; // For V1, this is mocked
import toast from 'react-hot-toast';
import { X, Save, KeyRound, Link2, AlertCircle } from 'lucide-react';
import Modal from '../core/Modal.jsx'; // Using the generic Modal component
import Button from '../core/Button.jsx';
import LLMSelection from '../auth/LLMSelection.jsx';
import { motion } from 'framer-motion';

function LLMSelectionModal({ isOpen, onClose, currentLLM, onSelectLLM }) {
    // This component now acts as the content provider for the generic Modal
    const { switchLLM: setGlobalLLMPreference } = useAppState();
    
    const [locallySelectedLLM, setLocallySelectedLLM] = useState(currentLLM);
    const [geminiApiKeyInput, setGeminiApiKeyInput] = useState('');
    const [ollamaApiUrlInput, setOllamaApiUrlInput] = useState('');
    
    const [loading, setLoading] = useState(false);
    const [error, setError] = useState('');

    useEffect(() => {
        if (isOpen) {
            setLocallySelectedLLM(currentLLM); // Sync with global when modal opens
            setGeminiApiKeyInput(''); 
            setOllamaApiUrlInput(''); 
            setError('');
        }
    }, [isOpen, currentLLM]);

    const handleSavePreference = async () => {
        setLoading(true); 
        setError('');
        const toastId = toast.loading('Saving LLM preference...');
        try {
            const configData = { llmProvider: locallySelectedLLM };
            if (locallySelectedLLM === 'gemini' && geminiApiKeyInput.trim()) {
                configData.apiKey = geminiApiKeyInput.trim();
            }
            if (locallySelectedLLM === 'ollama' && ollamaApiUrlInput.trim()) {
                configData.ollamaUrl = ollamaApiUrlInput.trim();
            }
            
            await api.updateUserLLMConfig(configData); // Mocked in V1
            
            setGlobalLLMPreference(locallySelectedLLM); // Update global AppStateContext
            if(onSelectLLM) onSelectLLM(locallySelectedLLM); // Inform parent (TopNav) if needed

            toast.dismiss(toastId);
            toast.success(`LLM preference updated to ${locallySelectedLLM.toUpperCase()} (mocked).`);
            onClose(); // Close the modal
        } catch (err) {
            toast.dismiss(toastId);
            const errorMessage = err.response?.data?.message || err.message || 'Failed to update LLM preference.';
            setError(errorMessage);
            toast.error(errorMessage);
        } finally {
            setLoading(false);
        }
    };
    
    const inputWrapperClass = "relative";
    const inputIconClass = "absolute left-3 top-1/2 -translate-y-1/2 h-5 w-5 text-text-muted-light dark:text-text-muted-dark pointer-events-none";
    const inputFieldStyledClass = "input-field pl-10 py-2 text-sm";

    return (
         <Modal 
            isOpen={isOpen} 
            onClose={onClose} 
            title="Switch LLM Provider" 
            size="lg"
            footerContent={ // Pass footer buttons to the generic Modal
                <>
                    <Button variant="ghost" onClick={onClose} disabled={loading} className="text-sm">Cancel</Button>
                    <Button onClick={handleSavePreference} isLoading={loading} className="text-sm" leftIcon={<Save size={16}/>}>
                        Save Preference
                    </Button>
                </>
            }
        >
            {/* This is the children prop for the generic Modal */}
            <div className="space-y-5"> 
                <p className="text-sm text-text-muted-light dark:text-text-muted-dark">
                    Select your preferred Large Language Model. Your choice will be saved for future sessions. (V1 uses mock data regardless).
                </p>
                <LLMSelection 
                    selectedLLM={locallySelectedLLM} 
                    onLlmChange={setLocallySelectedLLM}
                    disabled={loading}
                />
                {locallySelectedLLM === 'gemini' && (
                    <motion.div 
                        key="gemini-config-modal" 
                        initial={{ opacity: 0, height: 0 }} animate={{ opacity: 1, height: 'auto' }} exit={{ opacity: 0, height: 0 }}
                        className="mt-4 space-y-1 overflow-hidden"
                    >
                        <label htmlFor="modalGeminiApiKey" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark mb-1">
                            Gemini API Key (Optional - Enter to update)
                        </label>
                        <div className={inputWrapperClass}>
                            <KeyRound className={inputIconClass} />
                            <input
                                type="password"
                                id="modalGeminiApiKey"
                                className={inputFieldStyledClass}
                                placeholder="Leave blank to use existing/default"
                                value={geminiApiKeyInput}
                                onChange={(e) => setGeminiApiKeyInput(e.target.value)}
                                disabled={loading}
                            />
                        </div>
                    </motion.div>
                )}
                {locallySelectedLLM === 'ollama' && (
                    <motion.div 
                        key="ollama-config-modal" 
                        initial={{ opacity: 0, height: 0 }} animate={{ opacity: 1, height: 'auto' }} exit={{ opacity: 0, height: 0 }}
                        className="mt-4 space-y-1 overflow-hidden"
                    >
                        <label htmlFor="modalOllamaUrl" className="block text-xs font-medium text-text-muted-light dark:text-text-muted-dark mb-1">
                            Ollama API URL (Optional - Enter to update)
                        </label>
                         <div className={inputWrapperClass}>
                            <Link2 className={inputIconClass} />
                            <input
                                type="text"
                                id="modalOllamaUrl"
                                className={inputFieldStyledClass}
                                placeholder="Default (usually http://localhost:11434)"
                                value={ollamaApiUrlInput}
                                onChange={(e) => setOllamaApiUrlInput(e.target.value)}
                                disabled={loading}
                            />
                        </div>
                    </motion.div>
                )}
                {/* Corrected error display */}
                {error && (
                    <div className="p-3 mt-3 bg-red-500/10 border border-red-500/30 text-red-600 dark:text-red-300 rounded-md text-sm flex items-center gap-2 animate-fadeIn">
                        <AlertCircle size={18}/> {error}
                    </div>
                )}
            </div>
        </Modal>
    );
}

export default LLMSelectionModal;
```

`frontend/src/components/layout/RightCollapsedNav.jsx`

```javascript
// frontend/src/components/layout/RightCollapsedNav.jsx
import React from 'react';
import { useAppState } from '../../contexts/AppStateContext.jsx';
import { HelpCircle, GitFork, Tags, ChevronLeft } from 'lucide-react';
import IconButton from '../core/IconButton.jsx';
import { motion } from 'framer-motion';

const iconMap = {
    HelpCircle: HelpCircle,
    Tags: Tags,
    GitFork: GitFork,
};

function RightCollapsedNav() {
    const { setIsRightPanelOpen } = useAppState();

    const navItems = [
        { id: 'faq', label: 'FAQ Generator', iconName: 'HelpCircle', action: () => { setIsRightPanelOpen(true); /* TODO: set analysis type contextually */ } },
        { id: 'topics', label: 'Key Topics Extractor', iconName: 'Tags', action: () => { setIsRightPanelOpen(true); } },
        { id: 'mindmap', label: 'Mind Map Creator', iconName: 'GitFork', action: () => { setIsRightPanelOpen(true); } },
    ];

    return (
        <motion.aside
            key="right-collapsed-nav"
            initial={{ x: '100%', opacity: 0 }}
            animate={{ x: '0%', opacity: 1 }}
            exit={{ x: '100%', opacity: 0 }}
            transition={{ type: 'spring', stiffness: 300, damping: 30 }}
            className="fixed right-0 top-16 bottom-0 z-30 w-14 sm:w-16 bg-surface-light dark:bg-surface-dark border-l border-border-light dark:border-border-dark shadow-lg flex-col items-center py-3 space-y-2 hidden md:flex"
        >
            {/* Open Panel Button AT THE TOP */}
            <IconButton 
                icon={ChevronLeft} 
                onClick={() => setIsRightPanelOpen(true)} 
                title="Open Analyzer Panel"
                ariaLabel="Open Analyzer Panel"
                variant="ghost" 
                size="lg"
                className="mb-2 text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
            />
            {navItems.map(item => {
                 const Icon = iconMap[item.iconName] || HelpCircle;
                return (
                    <IconButton 
                        key={item.id}
                        icon={Icon}
                        onClick={item.action}
                        title={item.label}
                        ariaLabel={item.label}
                        variant="ghost"
                        size="md"
                        className="text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
                    />
                );
            })}
        </motion.aside>
    );
}
export default RightCollapsedNav;
```

`frontend/src/components/layout/RightPanel.jsx`

```javascript
// src/components/layout/RightPanel.jsx
import React, { useState } from 'react'; // Removed useEffect if not used
import { useAppState } from '../../contexts/AppStateContext';
// import AnalysisTool from '../analysis/AnalysisTool.jsx'; // Comment out or remove old import
import AnalysisToolRunner from '../analysis/AnalysisToolRunner.jsx'; // <-- NEW IMPORT
import { PanelRightClose, ChevronDown, ChevronUp, Telescope } from 'lucide-react';
import IconButton from '../core/IconButton.jsx';
import { motion } from 'framer-motion';

function RightPanel() {
    const { setIsRightPanelOpen, selectedDocumentForAnalysis } = useAppState();
    const [isAnalyzerOpen, setIsAnalyzerOpen] = useState(true);

    const currentSelectedDocFilename = selectedDocumentForAnalysis || null;

    return (
        <div className="flex flex-col h-full p-3 sm:p-4 bg-surface-light dark:bg-surface-dark text-text-light dark:text-text-dark custom-scrollbar">
            <div className="flex items-center justify-between mb-4 pb-2 border-b border-border-light dark:border-border-dark">
                <h2 className="text-base font-semibold">Advanced Analyzer</h2>
                <IconButton 
                    icon={PanelRightClose} 
                    onClick={() => setIsRightPanelOpen(false)} 
                    title="Close Analyzer Panel"
                    variant="ghost"
                    size="sm"
                    className="text-text-muted-light dark:text-text-muted-dark hover:text-primary dark:hover:text-primary-light"
                />
            </div>
            
            <button 
                onClick={() => setIsAnalyzerOpen(!isAnalyzerOpen)}
                className="w-full flex items-center justify-between px-3 py-2.5 text-sm font-medium text-left bg-gray-50 dark:bg-gray-800 hover:bg-gray-100 dark:hover:bg-gray-700 rounded-md focus:outline-none shadow-sm border border-border-light dark:border-border-dark mb-3"
            >
                <span className="flex items-center gap-2"><Telescope size={16} /> Analysis Tools</span>
                {isAnalyzerOpen ? <ChevronUp size={18} /> : <ChevronDown size={18} />}
            </button>

            {isAnalyzerOpen && (
                <motion.div 
                    initial={{ height: 0, opacity: 0 }} 
                    animate={{ height: 'auto', opacity: 1 }} 
                    exit={{ height: 0, opacity: 0 }}
                    transition={{ duration: 0.2, ease: "easeInOut" }}
                    className="flex-grow space-y-3 overflow-y-auto custom-scrollbar pr-1"
                >
                    {!currentSelectedDocFilename && (
                        <div className="p-4 text-xs text-center text-text-muted-light dark:text-text-muted-dark bg-gray-50 dark:bg-gray-800 rounded-md border border-dashed border-border-light dark:border-border-dark">
                            <p>Select a document from the left panel to enable analysis tools.</p>
                        </div>
                    )}
                    {/* Replace AnalysisTool with AnalysisToolRunner */}
                    <AnalysisToolRunner toolType="faq" title="FAQ Generator" iconName="HelpCircle" selectedDocumentFilename={currentSelectedDocFilename} />
                    <AnalysisToolRunner toolType="topics" title="Key Topics Extractor" iconName="Tags" selectedDocumentFilename={currentSelectedDocFilename} />
                    <AnalysisToolRunner toolType="mindmap" title="Mind Map Creator" iconName="GitFork" selectedDocumentFilename={currentSelectedDocFilename} />
                </motion.div>
            )}
        </div>
    );
}
export default RightPanel;
```

`frontend/src/components/layout/TopNav.jsx`

```javascript
// frontend/src/components/layout/TopNav.jsx
import React, { useState } from 'react';
import { useAuth } from '../../hooks/useAuth';
import { useAppState } from '../../contexts/AppStateContext';
import ThemeToggle from '../common/ThemeToggle.jsx';
import LLMSelectionModal from './LLMSelectionModal.jsx';
import { 
    LogOut, User, MessageSquare, History as HistoryIcon, Settings, Cpu, Zap, ServerCrash, Server 
} from 'lucide-react';
import toast from 'react-hot-toast';

function TopNav({ user: authUser, onLogout, onNewChat, onHistoryClick, orchestratorStatus }) { // Renamed user to authUser to avoid conflict
    const { selectedLLM, switchLLM } = useAppState();
    const [isLLMModalOpen, setIsLLMModalOpen] = useState(false);
    
    const getStatusIndicator = () => {
        if (!orchestratorStatus) return <div title="Status unavailable" className="w-4 h-4 bg-gray-400 rounded-full"></div>;
        if (orchestratorStatus.status === "ok") {
            return <Zap size={18} className="text-green-400 animate-pulse" title={`Backend Online: ${orchestratorStatus.message}`} />;
        } else if (orchestratorStatus.status === "loading") {
            return <div className="animate-spin rounded-full h-4 w-4 border-t-2 border-b-2 border-yellow-400" title="Connecting..."></div>;
        } else {
            return <ServerCrash size={18} className="text-red-400" title={`Backend Offline: ${orchestratorStatus.message}`} />;
        }
    };
    
    return (
        <>
            <nav className="fixed top-0 left-0 right-0 z-40 bg-surface-light dark:bg-surface-dark border-b border-border-light dark:border-border-dark shadow-sm h-16 flex items-center justify-between px-2 sm:px-4">
                <div className="flex items-center gap-2">
                    <a href="/" className="flex items-center gap-1.5 sm:gap-2 text-lg sm:text-xl font-semibold text-text-light dark:text-text-dark">
                        <Server size={24} className="text-primary dark:text-primary-light" />
                        <span className="hidden sm:inline">AI Tutor</span>
                    </a>
                </div>

                <div className="flex-1 flex justify-center px-2">
                    <div className="flex items-center gap-1 sm:gap-2">
                         <button
                            onClick={onNewChat} // Connected to App.jsx handleNewChat
                            className="flex items-center gap-1 px-2 py-1.5 text-xs sm:text-sm font-medium rounded-md text-text-light dark:text-text-dark bg-gray-100 dark:bg-gray-700 hover:bg-gray-200 dark:hover:bg-gray-600 transition-colors"
                            title="Start a new chat session"
                        >
                            <MessageSquare size={14} /> <span className="hidden sm:inline">New Chat</span>
                        </button>
                        <button
                            onClick={onHistoryClick} // Connected to App.jsx setIsHistoryModalOpen(true)
                            className="flex items-center gap-1 px-2 py-1.5 text-xs sm:text-sm font-medium rounded-md text-text-light dark:text-text-dark bg-gray-100 dark:bg-gray-700 hover:bg-gray-200 dark:hover:bg-gray-600 transition-colors"
                            title="View chat history"
                        >
                            <HistoryIcon size={14} /> <span className="hidden sm:inline">History</span>
                        </button>
                        <button
                            onClick={() => setIsLLMModalOpen(true)}
                            className="flex items-center gap-1 px-2 py-1.5 text-xs sm:text-sm font-medium rounded-md text-text-light dark:text-text-dark bg-gray-100 dark:bg-gray-700 hover:bg-gray-200 dark:hover:bg-gray-600 transition-colors"
                            title={`Switch LLM (Current: ${selectedLLM.toUpperCase()})`}
                        >
                            <Cpu size={14} /> <span className="hidden xs:inline">{selectedLLM.toUpperCase()}</span>
                        </button>
                    </div>
                </div>

                <div className="flex items-center gap-1.5 sm:gap-2">
                    {getStatusIndicator()}
                    <ThemeToggle />
                    <div className="relative group">
                        <button className="p-1.5 bg-primary-light dark:bg-primary-dark text-white rounded-full focus:outline-none focus:ring-2 focus:ring-offset-2 focus:ring-offset-surface-light dark:focus:ring-offset-surface-dark focus:ring-primary">
                            <User size={18} />
                        </button>
                        <div className="absolute right-0 mt-2 w-48 bg-surface-light dark:bg-surface-dark rounded-md shadow-lg py-1 opacity-0 group-hover:opacity-100 focus-within:opacity-100 transition-opacity duration-150 ease-in-out transform scale-95 group-hover:scale-100 focus-within:scale-100 origin-top-right invisible group-hover:visible focus-within:visible z-50">
                            <div className="px-4 py-2 text-sm text-text-light dark:text-text-dark border-b border-border-light dark:border-border-dark">
                                Signed in as <br/><strong>{authUser?.username || 'User'}</strong>
                            </div>
                            <button
                                onClick={() => toast.info("Profile settings coming soon!")}
                                className="w-full text-left px-4 py-2 text-sm text-text-light dark:text-text-dark hover:bg-gray-100 dark:hover:bg-gray-700 flex items-center gap-2"
                            >
                                <Settings size={16} /> Profile
                            </button>
                            <button
                                onClick={onLogout} // Connected to App.jsx handleLogoutAndShowModal
                                className="w-full text-left px-4 py-2 text-sm text-red-600 dark:text-red-400 hover:bg-red-50 dark:hover:bg-red-900 flex items-center gap-2"
                            >
                                <LogOut size={16} /> Logout
                            </button>
                        </div>
                    </div>
                </div>
            </nav>
            <LLMSelectionModal 
                isOpen={isLLMModalOpen} 
                onClose={() => setIsLLMModalOpen(false)} 
                currentLLM={selectedLLM}
                onSelectLLM={(llm) => {
                    switchLLM(llm); // From AppStateContext
                    setIsLLMModalOpen(false);
                }}
            />
        </>
    );
}
export default TopNav;
```

`frontend/src/contexts/AppStateContext.jsx`

```javascript
// frontend/src/contexts/AppStateContext.jsx
import React, { createContext, useState, useContext, useEffect } from 'react';

export const AppStateContext = createContext(null);

export const useAppState = () => {
    const context = useContext(AppStateContext);
    if (!context) throw new Error('useAppState must be used within an AppStateProvider');
    return context;
};

const defaultSystemPromptText = "You are a helpful AI engineering tutor.";

export const AppStateProvider = ({ children }) => {
    const [theme, setThemeState] = useState(() => {
        const storedTheme = localStorage.getItem('theme') || 'dark';
        if (typeof window !== 'undefined') {
            document.documentElement.classList.remove('light', 'dark');
            document.documentElement.classList.add(storedTheme);
        }
        return storedTheme;
    });

    const [selectedLLM, setSelectedLLM] = useState(localStorage.getItem('selectedLLM') || 'gemini'); // Default to gemini
    const [isLeftPanelOpen, setIsLeftPanelOpen] = useState(true);
    const [isRightPanelOpen, setIsRightPanelOpen] = useState(true); 
    
    const [currentSessionId, setCurrentSessionIdState] = useState(() => {
        return localStorage.getItem('aiTutorSessionId') || null;
    });
    
    const [systemPrompt, setSystemPromptState] = useState(localStorage.getItem('aiTutorSystemPrompt') || defaultSystemPromptText);
    const [selectedDocumentForAnalysis, setSelectedDocumentForAnalysisState] = useState(null);

    const toggleTheme = () => {
        setThemeState(prevTheme => {
            const newTheme = prevTheme === 'light' ? 'dark' : 'light';
            localStorage.setItem('theme', newTheme);
            return newTheme;
        });
    };
    
    const switchLLM = (llm) => {
         setSelectedLLM(llm); 
         localStorage.setItem('selectedLLM', llm);
         console.log("AppStateContext: Switched LLM to:", llm);
    };
    
    const setSessionId = (sessionId) => { // This is setGlobalSessionId in App.jsx
        if (sessionId) {
            localStorage.setItem('aiTutorSessionId', sessionId);
        } else {
            localStorage.removeItem('aiTutorSessionId');
        }
        setCurrentSessionIdState(sessionId); 
        console.log("AppStateContext: Global session ID updated to:", sessionId);
    };

    const setSystemPrompt = (promptText) => {
        setSystemPromptState(promptText);
        localStorage.setItem('aiTutorSystemPrompt', promptText);
    };

    const selectDocumentForAnalysis = (documentFile) => {
        setSelectedDocumentForAnalysisState(documentFile); // Stores filename string
        console.log("AppStateContext: Document selected for analysis:", documentFile || null);
    };

    useEffect(() => {
        const rootHtmlElement = document.documentElement;
        rootHtmlElement.classList.remove('light', 'dark');
        rootHtmlElement.classList.add(theme);
        document.body.className = ''; 
        document.body.classList.add(theme === 'dark' ? 'bg-background-dark' : 'bg-background-light');
    }, [theme]);

    return (
        <AppStateContext.Provider value={{
            theme, toggleTheme,
            selectedLLM, switchLLM,
            isLeftPanelOpen, setIsLeftPanelOpen,
            isRightPanelOpen, setIsRightPanelOpen,
            currentSessionId, setSessionId, 
            systemPrompt, setSystemPrompt,
            selectedDocumentForAnalysis, selectDocumentForAnalysis
        }}>
            {children}
        </AppStateContext.Provider>
    );
};
```

`frontend/src/contexts/AuthContext.jsx`

```javascript
// frontend/src/contexts/AuthContext.jsx
import React, { createContext, useState, useEffect, useCallback } from 'react';
import api from '../services/api.js'; 
import toast from 'react-hot-toast';
// No need for jwt-decode here if backend sends user details or /me provides them.

export const AuthContext = createContext(null);

// --- DEVELOPMENT FLAGS ---
export const DEV_MODE_ALLOW_DEV_LOGIN = false; // <-- SET TO false
const MOCK_DEV_USERNAME = 'DevUser'; 
const MOCK_DEV_PASSWORD = 'devpassword';   
// --- END DEVELOPMENT FLAGS ---

export const AuthProvider = ({ children }) => {
    const [token, setTokenState] = useState(localStorage.getItem('authToken'));
    const [user, setUserState] = useState(null);
    const [loading, setLoading] = useState(true);

    const setToken = (newToken) => {
        if (newToken) {
            localStorage.setItem('authToken', newToken);
        } else {
            localStorage.removeItem('authToken');
        }
        setTokenState(newToken);
    };

    const setUser = (newUser) => {
        setUserState(newUser);
    };
    
    const processAuthData = useCallback((authApiResponse) => {
        // Expects authApiResponse to be: { token, _id, username, sessionId?, message? }
        if (authApiResponse && authApiResponse.token && authApiResponse._id && authApiResponse.username) {
            setToken(authApiResponse.token);
            setUser({ id: authApiResponse._id, username: authApiResponse.username });
            console.log("AuthContext: User and Token set.", { username: authApiResponse.username });
            // Session ID from authApiResponse (like authApiResponse.sessionId)
            // will be passed to App.jsx through the onClose callback of AuthModal
            return authApiResponse; 
        } else {
            console.error("AuthContext: processAuthData received incomplete data from API", authApiResponse);
            // Clear any partial auth state
            setToken(null);
            setUser(null);
            throw new Error("Authentication response from server was incomplete.");
        }
    }, []); // No dependencies needed as setToken and setUser are stable

    useEffect(() => {
        const verifyTokenAndLoadUser = async () => {
            const storedToken = localStorage.getItem('authToken');
            if (storedToken) {
                setTokenState(storedToken); // Set token for api.getMe() to use Authorization header
                try {
                    console.log("AuthContext: Found stored token. Verifying with /me...");
                    const userDataFromMe = await api.getMe(); // api.js will include the token
                    if (userDataFromMe && userDataFromMe._id && userDataFromMe.username) {
                        setUser({ id: userDataFromMe._id, username: userDataFromMe.username });
                        // Token is already set from localStorage and has been confirmed valid by /me
                        console.log("AuthContext: Token verified, user loaded via /me.", userDataFromMe);
                    } else {
                        console.warn("AuthContext: /me endpoint did not return valid user data.", userDataFromMe);
                        setToken(null); // Clear invalid token from state and localStorage
                        setUser(null);
                    }
                } catch (error) {
                    console.warn("AuthContext: Auto-login via /me failed. Token might be invalid or expired.", error.message);
                    setToken(null); // Clear invalid token
                    setUser(null);
                }
            } else {
                console.log("AuthContext: No stored token found.");
            }
            setLoading(false);
        };
        verifyTokenAndLoadUser();
    }, []);

    const login = async (credentials) => {
        setLoading(true);
        try {
            const data = await api.login(credentials); // data = { token, _id, username, sessionId, message }
            return processAuthData(data);
        } catch (error) {
            setToken(null); 
            setUser(null);
            console.error("AuthContext login error:", error.response?.data?.message || error.message);
            throw error; 
        } finally {
            setLoading(false);
        }
    };
    
    const signup = async (signupData) => {
        setLoading(true);
        try {
            const data = await api.signup(signupData); // data = { token, _id, username, sessionId, message }
            return processAuthData(data);
        } catch (error) {
            setToken(null);
            setUser(null);
            console.error("AuthContext signup error:", error.response?.data?.message || error.message);
            throw error;
        } finally {
            setLoading(false);
        }
    };

    const logout = () => {
        console.log("AuthContext: Logging out user.");
        setToken(null); 
        setUser(null);
        // Other contexts (like AppStateContext for sessionId) should react to token/user becoming null.
        toast.success("You have been logged out.");
    };

    // Dev login will attempt to use MOCK_DEV_USERNAME/PASSWORD against the REAL backend if DEV_MODE_MOCK_API in api.js is false.
    // This will likely fail unless that user exists on the backend.
    const devLogin = async () => {
        if (!DEV_MODE_ALLOW_DEV_LOGIN) {
            const msg = "Dev Quick Login is disabled in AuthContext.";
            toast.error(msg);
            return Promise.reject(new Error(msg));
        }
        console.warn("AuthContext: devLogin initiated. This attempts to log in with MOCK credentials against the configured API endpoint.");
        setLoading(true);
        try {
            const data = await api.login({ username: MOCK_DEV_USERNAME, password: MOCK_DEV_PASSWORD });
            return processAuthData(data);
        } catch (error) {
            setToken(null);
            setUser(null);
            const errorMsg = error.response?.data?.message || error.message || "Dev login attempt failed.";
            console.error("AuthContext: Dev Quick Login via API failed:", errorMsg);
            toast.error(`Dev Login Error: ${errorMsg}`);
            throw error; 
        } finally {
            setLoading(false);
        }
    };

    return (
        <AuthContext.Provider value={{ 
            token, 
            user, 
            loading, 
            login, 
            signup, 
            logout, 
            devLogin: DEV_MODE_ALLOW_DEV_LOGIN ? devLogin : undefined,
            setUser, // Allow App.jsx or other components to potentially set user details if needed
            // setToken, // Exposing setToken directly is usually not needed by consumers
            DEV_MODE_ALLOW_DEV_LOGIN,
            MOCK_DEV_USERNAME,
            MOCK_DEV_PASSWORD
        }}>
            {children}
        </AuthContext.Provider>
    );
};
```

`frontend/src/hooks/useAuth.jsx`

```javascript
import { useContext } from 'react';
import { AuthContext } from '../contexts/AuthContext';

export const useAuth = () => {
    const context = useContext(AuthContext);
    if (!context) {
        throw new Error('useAuth must be used within an AuthProvider');
    }
    return context;
};
```

`frontend/src/hooks/useTheme.js`

```javascript
// import { useContext } from 'react';
// import { AppStateContext } from '../contexts/AppStateContext'; // Assuming theme is in AppStateContext

// export const useTheme = () => {
//     const context = useContext(AppStateContext);
//     if (!context) {
//         throw new Error('useTheme must be used within an AppStateProvider');
//     }
//     return { theme: context.theme, toggleTheme: context.toggleTheme };
// };


import { useContext } from 'react';
import { AppStateContext } from '../contexts/AppStateContext.jsx'; // Correct named import for the context object

export const useTheme = () => {
    const context = useContext(AppStateContext); // Use the imported context object
    if (!context) {
        throw new Error('useTheme must be used within an AppStateProvider');
    }
    return { theme: context.theme, toggleTheme: context.toggleTheme };
};
```

`frontend/src/hooks/useWebSpeech.js`

```javascript
import { useState, useEffect, useCallback } from 'react';

const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;

export const useWebSpeech = () => {
    const [transcript, setTranscript] = useState('');
    const [listening, setListening] = useState(false);
    const [recognitionInstance, setRecognitionInstance] = useState(null);
    const isSpeechSupported = !!SpeechRecognition;

    useEffect(() => {
        if (!isSpeechSupported) {
            console.warn("Web Speech API is not supported by this browser.");
            return;
        }

        const recognition = new SpeechRecognition();
        recognition.continuous = false; // Set to true if you want it to keep listening
        recognition.interimResults = false; // Set to true for live results
        recognition.lang = 'en-US';

        recognition.onresult = (event) => {
            const currentTranscript = Array.from(event.results)
                .map(result => result[0])
                .map(result => result.transcript)
                .join('');
            setTranscript(currentTranscript);
            // console.log("Voice input result:", currentTranscript);
        };

        recognition.onerror = (event) => {
            console.error("Speech recognition error:", event.error);
            // Handle common errors like 'no-speech', 'audio-capture', 'not-allowed'
            if (event.error === 'not-allowed') {
                alert("Microphone permission denied. Please allow microphone access in your browser settings.");
            }
            setListening(false);
        };

        recognition.onend = () => {
            setListening(false);
            // console.log("Speech recognition ended.");
        };
        
        setRecognitionInstance(recognition);

        // Cleanup
        return () => {
            if (recognition) {
                recognition.stop();
            }
        };
    }, [isSpeechSupported]);

    const startListening = useCallback(() => {
        if (recognitionInstance && !listening) {
            try {
                setTranscript(''); // Clear previous transcript
                recognitionInstance.start();
                setListening(true);
                // console.log("Speech recognition started.");
            } catch (e) {
                console.error("Error starting speech recognition:", e);
                setListening(false); // Ensure listening state is correct
            }
        }
    }, [recognitionInstance, listening]);

    const stopListening = useCallback(() => {
        if (recognitionInstance && listening) {
            recognitionInstance.stop();
            setListening(false); // Manually set as onend might be delayed
            // console.log("Speech recognition stopped manually.");
        }
    }, [recognitionInstance, listening]);

    const resetTranscript = useCallback(() => {
        setTranscript('');
    }, []);


    return {
        transcript,
        listening,
        isSpeechSupported,
        startListening,
        stopListening,
        resetTranscript
    };
};
```

`frontend/src/index.css`

```css
/* src/index.css */
@tailwind base;
@tailwind components;
@tailwind utilities;

@layer base {
  html, body, #root { /* Apply to html, body, AND your React root div */
    @apply h-full overflow-hidden; /* Force full height and no scroll on these */
  }

  html {
    -webkit-font-smoothing: antialiased;
    -moz-osx-font-smoothing: grayscale;
    scroll-behavior: smooth; /* This is fine, affects internal scrolls */
  }

  body {
    @apply bg-background-light text-text-light transition-colors duration-300;
    font-family: theme('fontFamily.sans');
    /* overflow-hidden is now applied via the html, body, #root rule above */
  }

  html.dark body {
    @apply bg-background-dark text-text-dark;
  }
  html.light body {
    @apply bg-background-light text-text-light;
  }

  .custom-scrollbar {
     @apply scrollbar-thin scrollbar-thumb-secondary dark:scrollbar-thumb-secondary-dark scrollbar-track-surface-light dark:scrollbar-track-gray-800 scrollbar-thumb-rounded-full scrollbar-track-rounded-full;
  }

  /* --- Enhanced Prose Styles --- */
  .prose {
    @apply max-w-none text-text-light dark:text-text-dark;
  }
  .prose, .prose-sm {
    /* Headings */
    h1 { @apply text-2xl sm:text-3xl font-extrabold mb-6 mt-2 text-text-light dark:text-text-dark; }
    h2 { @apply text-xl sm:text-2xl font-bold mb-4 mt-8 border-b border-border-light dark:border-border-dark pb-2; }
    h3 { @apply text-lg sm:text-xl font-semibold mb-3 mt-6; }
    h4 { @apply text-base sm:text-lg font-semibold mb-2 mt-4; }

    /* Paragraphs */
    p { @apply mb-4 leading-relaxed; }

    /* Links */
    a { @apply text-primary dark:text-primary-light hover:underline font-medium; }
    pre a, pre code a { @apply text-inherit no-underline hover:text-inherit; }

    /* Lists */
    ul, ol { @apply pl-5 mb-4 space-y-1; }
    ul { @apply list-disc; }
    ol { @apply list-decimal; }
    li { @apply mb-1; }
    ul ul, ol ol, ul ol, ol ul { @apply pl-5 mt-1 mb-1; }
    li::marker { @apply text-text-muted-light dark:text-text-muted-dark; }

    /* --- GFM Task List Checkboxes - Custom GREEN Styling --- */
    li:has(> input[type="checkbox"]) {
      @apply flex items-center;
      list-style-type: none;
      margin-left: -1.25rem; /* Adjust as needed for alignment */
      padding-left: 0;
    }

    li > input[type="checkbox"] {
      @apply opacity-0 w-0 h-0 absolute;
    }

    li:has(> input[type="checkbox"])::before {
      content: "";
      @apply inline-block w-4 h-4 border-2 rounded-sm mr-2 align-middle flex-shrink-0;
      @apply bg-surface-light dark:bg-gray-700;
      @apply border-border-light dark:border-border-dark;
      transition: all 0.15s ease-in-out;
    }

    li:has(> input[type="checkbox"]:checked)::before {
      @apply bg-green-500 dark:bg-green-600 border-green-500 dark:border-green-600;
      background-image: url("data:image/svg+xml,%3csvg viewBox='0 0 16 16' fill='white' xmlns='http://www.w3.org/2000/svg'%3e%3cpath d='M12.207 4.793a1 1 0 010 1.414l-5 5a1 1 0 01-1.414 0l-2-2a1 1 0 011.414-1.414L6.5 9.086l4.293-4.293a1 1 0 011.414 0z'/%3e%3c/svg%3e");
      background-size: 70% 70%;
      background-position: center;
      background-repeat: no-repeat;
    }

    li:has(> input[type="checkbox"]:disabled:not(:checked))::before {
      @apply opacity-60 cursor-not-allowed;
      @apply bg-gray-100 dark:bg-gray-600 border-gray-300 dark:border-gray-500;
    }

    li:has(> input[type="checkbox"]:checked:disabled)::before {
      @apply bg-green-500/70 dark:bg-green-600/70 border-green-500/70 dark:border-green-600/70;
      opacity: 0.75;
      cursor: not-allowed;
    }


    /* Blockquotes */
    blockquote {
      @apply border-l-4 border-primary dark:border-primary-light pl-4 py-2 my-4 italic text-text-muted-light dark:text-text-muted-dark bg-surface-light dark:bg-gray-800/30 rounded-r-md;
    }
    blockquote p { @apply mb-0; }

    /* Horizontal Rules */
    hr { @apply my-8 border-t border-border-light dark:border-border-dark; }

    /* Tables */
    table { @apply w-full my-6 text-sm border-collapse; }
    thead { @apply border-b-2 border-border-light dark:border-border-dark; }
    th {
      @apply px-4 py-2.5 text-left font-semibold text-text-light dark:text-text-dark bg-gray-100 dark:bg-gray-700/50;
      @apply border border-border-light dark:border-border-dark;
    }
    tbody tr { @apply border-b border-border-light dark:border-border-dark; }
    tbody tr:last-child { @apply border-b-0; }
    tbody tr:nth-child(even) { @apply bg-gray-50 dark:bg-gray-800/20; }
    td { @apply px-4 py-2.5 text-left border-x border-border-light dark:border-border-dark; }
    td code { @apply text-xs; }
    td strong { @apply font-semibold; }

    /* --- Code Styling --- */
    code:not(pre code) {
      @apply px-1.5 py-0.5 bg-primary/10 dark:bg-primary-dark/20 text-primary dark:text-primary-light rounded-md text-xs font-mono break-words;
    }
    code:not(pre code)::before, code:not(pre code)::after { content: ''; }

    pre {
      @apply bg-[#282c34] dark:bg-[#21252b] p-4 rounded-lg shadow-md overflow-x-auto custom-scrollbar my-5;
    }
    pre code {
      @apply bg-transparent p-0 font-mono text-sm leading-relaxed;
      color: #abb2bf;
      white-space: pre-wrap;
      word-break: break-all;
    }

    strong { @apply font-semibold text-text-light dark:text-text-dark; }
  }
}

@layer components {
  /* ... your existing btn, input-field, form-checkbox, card styles ... */
  /* The li:has(> input[type="checkbox"]) from your paste was misplaced, it should be within .prose */

  /* I will keep your existing .form-checkbox rules here as they might be used by other non-prose forms */
  .btn {
    @apply font-semibold py-2 px-4 rounded-lg shadow-sm focus:outline-none focus:ring-2 focus:ring-offset-1 focus:ring-opacity-75 transition-all duration-150 ease-in-out flex items-center justify-center gap-2 disabled:opacity-60 disabled:cursor-not-allowed;
  }
  html.dark .btn { @apply focus:ring-offset-background-dark; }
  html:not(.dark) .btn { @apply focus:ring-offset-background-light; }

  .btn-primary { @apply btn bg-primary text-white hover:bg-primary-dark focus:ring-primary; }
  .btn-secondary { @apply btn bg-secondary text-white hover:bg-secondary-dark focus:ring-secondary; }
  .btn-ghost { @apply btn text-text-muted-light dark:text-text-muted-dark hover:bg-gray-500 hover:bg-opacity-10 focus:ring-primary; }

  .input-field {
    @apply block w-full px-3 py-2 bg-surface-light dark:bg-gray-700 border border-border-light dark:border-border-dark rounded-md text-sm shadow-sm placeholder-text-muted-light dark:placeholder-text-muted-dark
           focus:outline-none focus:border-primary dark:focus:border-primary-light focus:ring-1 focus:ring-primary dark:focus:ring-primary-light;
  }
  .form-input, .form-textarea, .form-select, .form-multiselect { @apply input-field; }

  .form-checkbox, .form-radio {
    @apply rounded shadow-sm border-border-light dark:border-border-dark text-primary focus:ring-primary dark:focus:ring-primary-light;
    @apply bg-surface-light dark:bg-gray-600;
  }
  .form-checkbox:disabled, .form-radio:disabled {
    @apply opacity-70 bg-gray-200 dark:bg-gray-700 border-gray-300 dark:border-gray-600;
  }

  .card-base {
    @apply border rounded-panel shadow-panel;
    @apply bg-surface-light dark:bg-surface-dark border-border-light dark:border-border-dark;
  }
  .card-header-base {
    @apply px-4 py-3 text-sm font-semibold border-b;
    @apply text-text-light dark:text-text-dark border-border-light dark:border-border-dark;
  }
}
```

`frontend/src/main.jsx`

```javascript
import React from 'react';
import ReactDOM from 'react-dom/client';
import App from './App.jsx';
import { AuthProvider } from './contexts/AuthContext.jsx';
import { AppStateProvider } from './contexts/AppStateContext.jsx';
import { Toaster } from 'react-hot-toast';
import './index.css'; 


import 'prismjs/themes/prism-okaidia.css'; 
import 'katex/dist/katex.min.css';
import Prism from 'prismjs'; 
import 'prismjs/components/prism-python';
import 'prismjs/components/prism-javascript';
import 'prismjs/components/prism-jsx';
import 'prismjs/components/prism-css';
import 'prismjs/components/prism-markup'; 
import 'prismjs/components/prism-json';
import 'prismjs/components/prism-bash';
import 'prismjs/components/prism-csharp';
import 'prismjs/components/prism-java';


ReactDOM.createRoot(document.getElementById('root')).render(
  <React.StrictMode>
    <AuthProvider>
      <AppStateProvider>
        <App />
        <Toaster position="top-right" reverseOrder={false} />
      </AppStateProvider>
    </AuthProvider>
  </React.StrictMode>,
);
```

`frontend/src/services/api.js`

```javascript
// frontend/src/services/api.js
import axios from "axios";
import toast from "react-hot-toast";

// --- CENTRAL CONTROL FLAG FOR MOCKING ---
const DEV_MODE_MOCK_API = false; // <--- SET THIS TO false

// --- Axios API Client (for real backend calls) ---
const apiClient = axios.create({
  baseURL: import.meta.env.VITE_API_BASE_URL || "http://localhost:5001/api",
});





// Axios Request Interceptor to add JWT token
apiClient.interceptors.request.use( 
  (config) => {
    const token = localStorage.getItem("authToken");
    if (token) {
      config.headers.Authorization = `Bearer ${token}`;
    }
    return config;
  },
  (error) => {
    return Promise.reject(error);
  }
);

// Axios Response Interceptor to handle common errors (e.g., 401)
apiClient.interceptors.response.use(
  (response) => response,
  (error) => {
    if (error.response && error.response.status === 401) {
      console.error("API Interceptor: Received 401 Unauthorized. Token might be invalid or expired.");
      // The AuthContext will handle the actual logout logic and UI update.
      // We can dispatch a custom event that AuthContext can listen for,
      // or AuthContext can catch the error from the API call directly.
      // For simplicity, AuthContext will catch the error from the API call.
      // localStorage.removeItem('authToken'); // AuthContext will handle this.
    }
    return Promise.reject(error);
  }
);


  // Helper function to parse thinking tags from content
function parseAnalysisOutput(rawOutput) {
    if (!rawOutput || typeof rawOutput !== 'string') {
        return { content: '', thinking: '' };
    }
    const thinkingMatch = rawOutput.match(/<thinking>([\s\S]*?)<\/thinking>/i);
    let thinkingText = '';
    let mainContent = rawOutput;

    if (thinkingMatch && thinkingMatch[1]) {
        thinkingText = thinkingMatch[1].trim();
        // Remove the thinking block (and any leading/trailing newlines around it) from the main content
        mainContent = rawOutput.replace(/<thinking>[\s\S]*?<\/thinking>\s*/i, '').trim();
    }
    return { content: mainContent, thinking: thinkingText };
}

// --- API Definition Object ---
const api = {

  // --- Helper to fetch stored analysis (can be internal to this module) ---
  _getStoredDocumentAnalysis: async (documentFilename) => {
    try {
      // This GET request fetches the whole analysis object { faq, topics, mindmap }
      const response = await apiClient.get(`/analysis/${encodeURIComponent(documentFilename)}`);
      return response.data;
    } catch (error) {
      if (error.response && error.response.status === 404) {
        console.info(`No stored analysis found for document: ${documentFilename}`);
        return null; // Return null if no analysis record exists for the document
      }
      console.error(`Error fetching stored analysis for ${documentFilename}:`, error);
      throw error; // Re-throw other errors to be handled by the caller
    }
  },

  // --- Unified and Intelligent requestAnalysis function ---
  // This function is called by AnalysisTool.jsx's "Run" button.
  requestAnalysis: async (payload) => {
    const { filename, analysis_type } = payload;

    if (!filename || !analysis_type) {
      toast.error("Filename and analysis type are required.");
      throw new Error("Filename and analysis_type are required for requestAnalysis.");
    }

    const toastId = toast.loading(`Checking for stored ${analysis_type} for "${filename}"...`);

    try {
      const storedAnalysisData = await api._getStoredDocumentAnalysis(filename);

      if (storedAnalysisData &&
          storedAnalysisData[analysis_type] &&
          typeof storedAnalysisData[analysis_type] === 'string' &&
          storedAnalysisData[analysis_type].trim() !== "") {
        
        const { content: parsedContent, thinking: parsedThinking } = parseAnalysisOutput(storedAnalysisData[analysis_type]);
        
        toast.success(`Displaying stored ${analysis_type} for "${filename}".`, { id: toastId });
        return {
          content: parsedContent,
          thinking: parsedThinking || `Retrieved stored ${analysis_type} data. No specific thinking process recorded in content.`
        };
      } else {
        toast.dismiss(toastId);
        const generationToastId = toast.loading(`No stored ${analysis_type}. Generating new analysis for "${filename}"... (Mock V1)`);
        console.warn(`No valid stored ${analysis_type} found for "${filename}". Falling back to mock generation.`);

        // --- MOCK GENERATION LOGIC ---
        await new Promise(resolve => setTimeout(resolve, 1000 + Math.random() * 1000));

        let fullMockOutput = ""; // This will be the string as if LLM returned it, including <thinking> tags

        switch (analysis_type) {
          case 'faq':
            fullMockOutput = `<thinking>I will identify key details from the provided text about ${filename} to formulate 5-7 FAQs with concise answers directly from the text. My plan is to scan for questions, key statements, and rephrase them appropriately.</thinking>\n\nQ: What is this document about?\nA: This is mock FAQ content for ${filename}.\n\nQ: How is this generated?\nA: Through a mock API call when no stored data is found.`;
            break;
          case 'topics':
            fullMockOutput = `<thinking>I will identify the key topics in the provided biography of ${filename}. I will focus on the major events and themes highlighted in the narrative, ensuring each topic is explained concisely using only information from the text. I'll then list them with brief explanations.</thinking>\n\n### Mock Key Topics for ${filename}\n\n- Topic A: Mock Data Integration\n- Topic B: Placeholder Information\n- Topic C: ${analysis_type.toUpperCase()} specific to ${filename}`;
            break;
          case 'mindmap':
            fullMockOutput = `<thinking>Planning to generate a mind map structure for ${filename}. Will use Markdown list format focusing on hierarchical relationships found in the text.</thinking>\n\nmindmap\n  root((${filename} - Mock Mindmap))\n    Overview\n      Key Point 1\n      Key Point 2\n    Details\n      Specific Detail A\n      Specific Detail B`;
            break;
          default:
            fullMockOutput = `<thinking>No specific thinking process for unknown analysis type '${analysis_type}'.</thinking>\n\nMock content for an unknown analysis type '${analysis_type}' on ${filename}.`;
        }

        const { content: parsedMockContent, thinking: parsedMockThinking } = parseAnalysisOutput(fullMockOutput);

        toast.success(`${analysis_type} generated (mock data) for "${filename}".`, { id: generationToastId });
        return {
          content: parsedMockContent,
          thinking: parsedMockThinking || `Mock generation for ${analysis_type} on "${filename}".`
        };
        // --- END MOCK GENERATION LOGIC ---
      }
    } catch (error) {
      toast.error(`Error processing ${analysis_type} for "${filename}": ${error.message || 'Unknown error'}`, { id: toastId });
      console.error(`Error in requestAnalysis for ${filename} (${analysis_type}):`, error);
      return {
        content: `Error: Could not retrieve or generate ${analysis_type} for "${filename}".\n${error.message}`,
        thinking: "An error occurred during the analysis process."
      };
    }
  },

  
  // ------------------------------------------------- Auth --------------------------------------------------
 
  // Completed✅
  login: async (credentials) => {
    const response = await apiClient.post("/auth/signin", credentials);
    return response.data; // Expects { token, _id, username, sessionId, message }
  },

  // Completed✅
  signup: async (userData) => {
    const response = await apiClient.post("/auth/signup", userData);
    return response.data; // Expects { token, _id, username, sessionId, message }
  },

  // Completed✅
  getMe: async () => {
    const response = await apiClient.get("/auth/me");
    return response.data; // Expects { _id, username, ... }
  },

  // ------------------------------------------------ Chat -----------------------------------------------
  
  // Not completed yet❌
  sendMessage: async (payload) => {
    const response = await apiClient.post("/chat/message", payload);
    return response.data; // Expects { reply: { role, parts, timestamp, ... } }
  },

  // Not completed yet❌
  getChatHistory: async (sessionId) => {
    const response = await apiClient.get(`/chat/session/${sessionId}`);
    // Backend returns the full session object which includes { messages: [...] }
    return response.data.messages || []; 
  },

  // Not completed yet❌
  getChatSessions: async () => {
    const response = await apiClient.get("/chat/sessions");
    return response.data; // Expects array of session summaries
  },

  // Not completed yet❌
  startNewSession: async () => {
    // This call is to the backend's /api/chat/history to get a new session ID
    // when the user explicitly clicks "New Chat" and is already logged in.
    // The backend creates a new session placeholder if needed and returns a new UUID.
    const response = await apiClient.post("/chat/history", { 
        sessionId: `client-initiate-${Date.now()}`, // Temporary ID, backend replaces it
        messages: [] 
    });
    // Expects { message, savedSessionId (can be null), newSessionId }
    return { sessionId: response.data.newSessionId };
  },

  // Not completed yet❌
  saveChatHistory: async (sessionId, messages) => {
    const response = await apiClient.post("/chat/history", { sessionId, messages });
    return response.data; // Expects { message, savedSessionId, newSessionId }
  },

 
  // -------------------------------------------------- Files ------------------------------------------------------
  
  // Completed✅
  uploadFile: async (formData, onUploadProgress) => {
    const response = await apiClient.post("/upload", formData, {
      headers: { "Content-Type": "multipart/form-data" },
      onUploadProgress,
    });
    return response.data; // Expects { message, filename (serverFilename), originalname }
  },
  
  // Completed✅
  getFiles: async () => {
     
    const response = await apiClient.get("/files");
    console.log("Response from /files ; ", response.data);
    
    return response.data; // Expects array of file objects
  },

  // Completed✅
  deleteFile: async (serverFilename) => {
    const response = await apiClient.delete(`/files/${serverFilename}`);
    return response.data;
  },
  
  // -------------------------------------------- User LLM Config ---------------------------------------------------
  
  // Not completed yet❌-
  updateUserLLMConfig: async (configData) => {
    // For V2, if backend stores user LLM preferences:
    // const response = await apiClient.post('/user/config/llm', configData);
    // return response.data;
    console.warn("api.updateUserLLMConfig (frontend): Node.js backend doesn't have a dedicated user config endpoint yet. This is a local mock via api.js.");
    return new Promise(resolve => setTimeout(() => {
        localStorage.setItem("selectedLLM", configData.llmProvider); // Still update local for UI
        if (configData.apiKey) localStorage.setItem("mockGeminiApiKeyStatus", "set");
        if (configData.ollamaUrl) localStorage.setItem("mockOllamaUrl", configData.ollamaUrl);
        resolve({ message: `LLM preference for ${configData.llmProvider} noted (local mock via API layer).` });
    }, 100));
  },

  // Not completed yet❌
  getUserLLMConfig: async () => {
    // For V2, if backend stores user LLM preferences:
    // const response = await apiClient.get('/user/config/llm');
    // return response.data; // expects { llmProvider }
    console.warn("api.getUserLLMConfig (frontend): Node.js backend doesn't have a dedicated user config endpoint yet. Returning local default via api.js.");
    return new Promise(resolve => setTimeout(() => {
        resolve({ llmProvider: localStorage.getItem("selectedLLM") || "ollama" });
    }, 50));
  },


  // ----------------------------------------------- Status & Syllabus -------------------------------------------
  
  // Not completed yet❌
  getOrchestratorStatus: async () => {
    // For V2, Node.js backend could have its own /api/status endpoint.
    // For now, this simulates a status.
    console.warn("api.getOrchestratorStatus (frontend): Using a local mock via API layer for backend status.");
    return new Promise(resolve => setTimeout(() => {
        resolve({
            status: "ok",
            message: "Backend (Node.js - Mocked Status via Frontend API)",
            database_status: "Connected (Mock)",
        });
    }, 50));
    // Example real call:
    // const response = await apiClient.get('/status'); // Assuming /api/status on Node.js backend
    // return response.data;
  },

  // Not completed yet❌
  getSyllabus: async (subjectId) => {
    const response = await apiClient.get(`/syllabus/${subjectId}`);
    return response.data.syllabus; // Backend returns { syllabus: "markdown_content" }
  },

  // Not completed yet❌
  getMindmap: async () => {
    const response = await apiClient.get('/mindmap'); // Assumes /api/mindmap on backend
    return response.data; // Expects { mermaidCode: "...", source: "..." }
  }
};

export default api;


```

`frontend/src/utils/helpers.js`

```javascript
// Debounce function: Limits the rate at which a function can fire.

export const debounce = (func, delay) => {
    let timeoutId;
    return function(...args) {
        const context = this;
        clearTimeout(timeoutId);
        timeoutId = setTimeout(() => func.apply(context, args), delay);
    };
};

// Throttle function: Ensures a function is called at most once in a specified time period.
export const throttle = (func, limit) => {
    let inThrottle;
    let lastFunc;
    let lastRan;
    return function(...args) {
        const context = this;
        if (!inThrottle) {
            func.apply(context, args);
            lastRan = Date.now();
            inThrottle = true;
            setTimeout(() => {
                inThrottle = false;
                if (lastFunc) {
                    lastFunc.apply(context, args); // Call with latest args if throttled
                    lastRan = Date.now();
                }
            }, limit);
        } else {
            lastFunc = func; // Store the latest call
        }
    };
};

// Simple function to format file size
export const formatFileSize = (bytes, decimals = 2) => {
    if (bytes === 0) return '0 Bytes';
    const k = 1024;
    const dm = decimals < 0 ? 0 : decimals;
    const sizes = ['Bytes', 'KB', 'MB', 'GB', 'TB', 'PB', 'EB', 'ZB', 'YB'];
    const i = Math.floor(Math.log(bytes) / Math.log(k));
    return parseFloat((bytes / Math.pow(k, i)).toFixed(dm)) + ' ' + sizes[i];
};

// Function to generate a simple unique ID (for client-side list keys, etc.)
export const generateUniqueId = (prefix = 'id') => {
    return `${prefix}-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
};

// Function to safely get nested property
export const getNestedValue = (obj, path, defaultValue = undefined) => {
    const value = path.split('.').reduce((acc, part) => acc && acc[part], obj);
    return value === undefined ? defaultValue : value;
};

// Basic HTML escape (can be more comprehensive)
export const escapeHtml = (unsafe) => {
    if (typeof unsafe !== 'string') return '';
    return unsafe
         .replace(/&/g, "&")
         .replace(/</g, "<")
         .replace(/>/g, ">")
         .replace(/"/g, '"')
         .replace(/'/g, "'");
};

// You can add more utility functions here as your project grows.
// For example, date formatting, string manipulation, etc.

// Example: Truncate text
export const truncateText = (text, maxLength = 100) => {
    if (!text || text.length <= maxLength) return text;
    return text.substring(0, maxLength) + '...';
};
```

`frontend/src/utils/markdownUtils.jsx`

```javascript
// src/utils/markdownUtils.jsx
import katex from 'katex';
import DOMPurify from 'dompurify';

const decodeHtmlEntities = (encodedString) => {
  if (typeof encodedString !== 'string') return encodedString;

  const textarea = document.createElement('textarea');
  textarea.innerHTML = encodedString;
  return textarea.value;
};

export const renderMathInHtml = (htmlString) => {
  if (!htmlString || typeof htmlString !== 'string') return htmlString;

  let processedString = htmlString;
  processedString = processedString.replace(/(?<!\\)\$\$([\s\S]+?)(?<!\\)\$\$/g, (match, rawExpression) => {
    const expression = decodeHtmlEntities(rawExpression.trim());
    try {
      const rendered = katex.renderToString(expression, { 
        displayMode: true, 
        throwOnError: false,
        macros: {"\\RR": "\\mathbb{R}"} 
      });
      return DOMPurify.sanitize(rendered, { USE_PROFILES: { mathMl: true, svg: true, html: true } });
    } catch (e) { 
      console.warn(`KaTeX (display) error: ${e.message} for expression: ${expression}`); 
      return match; 
    }
  });

  processedString = processedString.replace(/(^|[^$\\])\$(?![\s$])([^$\n]+?)(?<![\s\\])\$([^\$]|$)/g, (fullMatch, prefix, rawExpression, suffix) => {
    const expression = decodeHtmlEntities(rawExpression.trim());
    if (!expression) return fullMatch; 
    try {
      const rendered = katex.renderToString(expression, { 
        displayMode: false, 
        throwOnError: false,
        macros: {"\\RR": "\\mathbb{R}"}
      });
      return prefix + DOMPurify.sanitize(rendered, { USE_PROFILES: { mathMl: true, svg: true, html: true } }) + suffix;
    } catch (e) { 
      console.warn(`KaTeX (inline) error: ${e.message} for expression: ${expression}`);
      return fullMatch; 
    }
  });
  
  return processedString;
};
```

`frontend/tailwind.config.js`

```javascript
// tailwind.config.js
/** @type {import('tailwindcss').Config} */
export default {
  content: [
    "./index.html",
    "./src/**/*.{js,ts,jsx,tsx}",
  ],
  darkMode: 'class',
  theme: {
    extend: {
      colors: {
        'primary': { light: '#60a5fa', DEFAULT: '#3b82f6', dark: '#2563eb' },
        'secondary': { light: '#9ca3af', DEFAULT: '#6b7280', dark: '#4b5563' },
        'accent': '#2dd4bf',
        'background-dark': '#0F172A', 'surface-dark': '#1E293B', 'border-dark': '#334155', 'text-dark': '#E2E8F0', 'text-muted-dark': '#94A3B8',
        'background-light': '#F8FAFC', 'surface-light': '#FFFFFF', 'border-light': '#E2E8F0', 'text-light': '#0F172A', 'text-muted-light': '#64748B',
      },
      fontFamily: {
        sans: ['"Inter var"', 'Inter', 'system-ui', 'sans-serif'],
      },
      boxShadow: {
        'main': '0 4px 15px -5px rgba(0,0,0,0.07), 0 2px 8px -6px rgba(0,0,0,0.07)',
        'panel': '0 8px 20px -5px rgba(0,0,0,0.1), 0 4px 10px -6px rgba(0,0,0,0.08)',
        'card-hover': '0 6px 18px -4px rgba(0,0,0,0.1), 0 3px 10px -5px rgba(0,0,0,0.1)',
      },
      borderRadius: { 'xl': '0.75rem', '2xl': '1rem', 'panel': '0.75rem' },
      keyframes: {
        fadeIn: { '0%': { opacity: '0', transform: 'translateY(5px)' }, '100%': { opacity: '1', transform: 'translateY(0px)' } },
        slideUp: { '0%': { transform: 'translateY(10px)', opacity: '0' }, '100%': { transform: 'translateY(0)', opacity: '1' } },
        pulseDots: {
          '0%, 100%': { opacity: '0.3', transform: 'scale(0.8)' },
          '50%': { opacity: '1', transform: 'scale(1)' },
        }
      },
      animation: {
        fadeIn: 'fadeIn 0.3s ease-out forwards',
        slideUp: 'slideUp 0.4s ease-out forwards',
        pulseDot1: 'pulseDots 1.4s infinite 0s ease-in-out',
        pulseDot2: 'pulseDots 1.4s infinite 0.2s ease-in-out',
        pulseDot3: 'pulseDots 1.4s infinite 0.4s ease-in-out',
      }
    },
  },
  plugins: [
    require('@tailwindcss/forms')({ strategy: 'class' }),
    require('tailwind-scrollbar')({ nocompatible: true }),
    require('@tailwindcss/typography'),
  ],
}
```

`frontend/vite.config.js`

```javascript
// vite.config.js
import { defineConfig } from 'vite'
import react from '@vitejs/plugin-react'

// https://vite.dev/config/
export default defineConfig({
  plugins: [react()],
})

```

`server/.env`

```
PORT=5001 # Port for the backend (make sure it's free)
MONGO_URI = "mongodb://localhost:27017/chatbot_gemini" # Your MongoDB connection string
JWT_SECRET = "your_super_strong_and_secret_jwt_key_12345" # A strong, random secret key for JWT
GEMINI_API_KEY = "AIzaSyDlY5AEMPkwcIDxIcT5d2kYf8_reuJbFVc" # Your actual Gemini API Key
PYTHON_RAG_SERVICE_URL = "http://127.0.0.1:5000"
KG_GENERATION_BATCH_SIZE=25

```

`server/config/db.js`

```javascript
const mongoose = require('mongoose');
// const dotenv = require('dotenv'); // Removed dotenv

// dotenv.config(); // Removed dotenv

// Modified connectDB to accept the URI as an argument
const connectDB = async (mongoUri) => {
  if (!mongoUri) {
      console.error('MongoDB Connection Error: URI is missing.');
      process.exit(1);
  }
  try {
    // console.log(`Attempting MongoDB connection to: ${mongoUri}`); // Debug: Careful logging URI
    const conn = await mongoose.connect(mongoUri, {
      // Mongoose 6+ uses these defaults, so they are not needed
      // useNewUrlParser: true,
      // useUnifiedTopology: true,
      // serverSelectionTimeoutMS: 5000 // Example: Optional: Timeout faster
    });

    console.log(`✓ MongoDB Connected Successfully`); // Simpler success message
    return conn; // Return connection object if needed elsewhere
  } catch (error) {
    console.error('MongoDB Connection Error:', error.message);
    // Exit process with failure
    process.exit(1);
  }
};

module.exports = connectDB;

```

`server/config/promptTemplates.js`

```javascript
// server/config/promptTemplates.js

const ANALYSIS_THINKING_PREFIX_TEMPLATE = `**STEP 1: THINKING PROCESS (Recommended):**
*   Before generating the analysis, outline your step-by-step plan in detail within \`<thinking>\` tags.
*   Use Markdown for formatting within your thinking process (e.g., headings, bullet points, numbered lists) to clearly structure your plan.
*   Example of detailed thinking:
    \`\`\`
    <thinking>
    ## FAQ Generation Plan
    1.  **Understand Goal:** Generate 5-7 FAQs based *only* on the provided text.
    2.  **Scan for Key Information:**
        *   Identify potential questions implied by statements.
        *   Look for definitions, explanations, or problem/solution pairings.
    3.  **Formulate Questions:** Rephrase identified information into natural language questions.
    4.  **Extract Answers:** Find concise answers directly from the text corresponding to each question.
    5.  **Format Output:** Ensure each Q/A pair follows the 'Q: ... A: ...' format.
    6.  **Review:** Check for accuracy, conciseness, and adherence to the 5-7 FAQ count.
    </thinking>
    \`\`\`
*   If you include thinking, place the final analysis *after* the \`</thinking>\` tag.

**STEP 2: ANALYSIS OUTPUT:**
*   Generate the requested analysis based **strictly** on the text provided below.
*   Follow the specific OUTPUT FORMAT instructions carefully.

--- START DOCUMENT TEXT ---
{doc_text_for_llm}
--- END DOCUMENT TEXT ---
`;

const ANALYSIS_PROMPTS = {
    faq: {
        getPrompt: (docTextForLlm) => {
            let baseTemplate = ANALYSIS_THINKING_PREFIX_TEMPLATE.replace('{doc_text_for_llm}', docTextForLlm);
            baseTemplate += `
**TASK:** Generate 5-7 Frequently Asked Questions (FAQs) with concise answers based ONLY on the provided text.

**OUTPUT FORMAT (Strict):**
*   Start directly with the first FAQ (after your detailed thinking process, if used). Do **NOT** include any preamble before the first 'Q:'.
*   Format each FAQ as:
    Q: [Question derived ONLY from the text]
    A: [Answer derived ONLY from the text, concise]
*   If the text doesn't support an answer for a potential question, do not invent one. Stick to what's explicitly stated or directly implied.
*   Use Markdown for formatting within answers if appropriate (e.g., lists).

**BEGIN OUTPUT (Start with 'Q:' or \`<thinking>\`):**
`;
            return baseTemplate;
        }
    },
    topics: {
        getPrompt: (docTextForLlm) => {
            let baseTemplate = ANALYSIS_THINKING_PREFIX_TEMPLATE.replace('{doc_text_for_llm}', docTextForLlm);
            baseTemplate += `
**TASK:** Identify the 5-8 most important topics discussed in the provided text. For each topic, provide a 1-2 sentence explanation based ONLY on the text.

**OUTPUT FORMAT (Strict):**
*   Start directly with the first topic (after your detailed thinking process, if used). Do **NOT** include any preamble before the first bullet point.
*   Format as a Markdown bulleted list:
    *   **Topic Name:** Brief explanation derived ONLY from the text content (1-2 sentences max).

**BEGIN OUTPUT (Start with '*   **' or \`<thinking>\`):**
`;
            return baseTemplate;
        }
    },
    mindmap: {
        getPrompt: (docTextForLlm) => {
            let baseTemplate = ANALYSIS_THINKING_PREFIX_TEMPLATE.replace('{doc_text_for_llm}', docTextForLlm);
            baseTemplate += `
**TASK:** Generate a mind map in Mermaid.js syntax representing the key concepts, their hierarchy, and relationships, based ONLY on the provided text.

**CORE REQUIREMENTS FOR MERMAID SYNTAX:**
1.  **Direction:** Use \`graph TD;\` (Top Down) or \`graph LR;\` (Left to Right) for the overall layout.
2.  **Nodes:**
    *   Define unique IDs for each node (e.g., \`A\`, \`B\`, \`C1\`, \`ConceptNameID\`). IDs should be short and alphanumeric.
    *   Node labels should be concise and derived from the text (e.g., \`A["Main Idea from Text"]\`, \`B("Key Concept 1")\`, \`C{"Another Concept"}\`).
3.  **Edges (Connections):** Show relationships using \`-->\` (e.g., \`A --> B\`).
4.  **Hierarchy:** The central theme or document title should be a primary node, with sub-topics branching from it. Deeper sub-topics should branch further.
5.  **Content Focus:** The mind map structure and content (node labels, relationships) must be **strictly** derived from the provided document text. Do not invent concepts or relationships not present in the text.
6.  **Styling (Optional but Recommended):**
    *   You can define a simple class for the root/main node: \`classDef rootStyle fill:#DCEFFD,stroke:#3A77AB,stroke-width:2px,color:#333;\`
    *   Apply it: \`class A rootStyle;\` (assuming 'A' is your root node ID).
    *   Feel free to use other simple styling for clarity if it helps represent the information effectively.

**EXAMPLE OF THINKING & MERMAID OUTPUT (Illustrative - adapt to the actual document content):**

*Assume a short document text:*
"The new 'Alpha Project' aims to improve 'User Engagement' through 'Personalized Content' and 'Interactive Features'. Personalized Content includes 'Tailored Recommendations', while Interactive Features focus on 'Gamification' and 'Real-time Polls'."

*Expected Thinking and Output:*
\`\`\`
<thinking>
## Mermaid Mindmap Generation Plan

1.  **Identify Central Theme:** The core subject is the "Alpha Project". This will be the root node.
2.  **Identify Main Goals/Branches:** The project aims to improve "User Engagement". This is a primary branch.
3.  **Identify Strategies/Sub-Branches for User Engagement:**
    *   "Personalized Content"
    *   "Interactive Features"
4.  **Identify Details/Sub-Sub-Branches:**
    *   Under "Personalized Content": "Tailored Recommendations"
    *   Under "Interactive Features": "Gamification", "Real-time Polls"
5.  **Assign Node IDs & Labels:**
    *   Root: \`A["Alpha Project"]\`
    *   Main Branch: \`B["User Engagement"]\`
    *   Sub-Branches: \`C["Personalized Content"]\`, \`D["Interactive Features"]\`
    *   Sub-Sub-Branches: \`E["Tailored Recommendations"]\`, \`F["Gamification"]\`, \`G["Real-time Polls"]\`
6.  **Define Connections:**
    *   A --> B
    *   B --> C
    *   B --> D
    *   C --> E
    *   D --> F
    *   D --> G
7.  **Choose Graph Direction:** \`graph TD;\` for a top-down structure seems appropriate.
8.  **Add Basic Styling:** Style the root node.
9.  **Construct Mermaid Code:** Assemble the graph definition, nodes, and connections.
</thinking>

graph TD;
    A["Alpha Project"]:::rootStyle;
    B["User Engagement"];
    C["Personalized Content"];
    D["Interactive Features"];
    E["Tailored Recommendations"];
    F["Gamification"];
    G["Real-time Polls"];

    A --> B;
    B --> C;
    B --> D;
    C --> E;
    D --> F;
    D --> G;

    classDef rootStyle fill:#DCEFFD,stroke:#3A77AB,stroke-width:2px,color:#333;
    class A rootStyle;
\`\`\`

**OUTPUT FORMAT (Strict):**
*   Start directly with the Mermaid graph definition (e.g., \`graph TD;\` or \`graph LR;\`) (after your detailed thinking process, if used).
*   Do **NOT** include any preamble or explanation before the Mermaid code block (e.g., do not write "Here is the Mermaid code:").
*   The entire output after the thinking block (if any) must be valid Mermaid.js syntax.

**BEGIN OUTPUT (Start with e.g., \`graph TD;\` or \`<thinking>\`):**
`;
            return baseTemplate;
        }
    }
};

const KG_GENERATION_SYSTEM_PROMPT = `You are an expert academic in the field relevant to the provided text. Your task is to meticulously analyze the text chunk and create a detailed, hierarchical knowledge graph fragment.
The output MUST be a valid JSON object with "nodes" and "edges" sections.

Instructions for Node Creation:
1.  Identify CORE CONCEPTS or main topics discussed in the chunk. These should be 'major' nodes (parent: null).
2.  Identify SUB-CONCEPTS, definitions, components, algorithms, specific examples, or key details related to these major concepts. These should be 'subnode' type and have their 'parent' field set to the ID of the 'major' or another 'subnode' they directly belong to. Aim for a granular breakdown.
3.  Node 'id': Use a concise, descriptive, and specific term for the concept (e.g., "Linear Regression", "LMS Update Rule", "Feature Selection"). Capitalize appropriately.
4.  Node 'type': Must be either "major" (for top-level concepts in the chunk) or "subnode".
5.  Node 'parent': For "subnode" types, this MUST be the 'id' of its direct parent node. For "major" nodes, this MUST be null.
6.  Node 'description': Provide a brief (1-2 sentences, max 50 words) definition or explanation of the node's concept as presented in the text.

Instructions for Edge Creation:
1.  Edges represent relationships BETWEEN the nodes you've identified.
2.  The 'from' field should be the 'id' of the child/more specific node.
3.  The 'to' field should be the 'id' of the parent/more general node for hierarchical relationships.
4.  Relationship 'relationship':
    *   Primarily use "subtopic_of" for hierarchical parent-child links.
    *   Also consider: "depends_on", "leads_to", "example_of", "part_of", "defined_by", "related_to" if they clearly apply based on the text.
5.  Ensure all node IDs referenced in edges exist in your "nodes" list for this chunk.

Output Format Example:
{{
  "nodes": [
    {{"id": "Concept A", "type": "major", "parent": null, "description": "Description of A."}},
    {{"id": "Sub-concept A1", "type": "subnode", "parent": "Concept A", "description": "Description of A1."}},
    {{"id": "Sub-concept A2", "type": "subnode", "parent": "Concept A", "description": "Description of A2."}},
    {{"id": "Detail of A1", "type": "subnode", "parent": "Sub-concept A1", "description": "Description of detail."}}
  ],
  "edges": [
    {{"from": "Sub-concept A1", "to": "Concept A", "relationship": "subtopic_of"}},
    {{"from": "Sub-concept A2", "to": "Concept A", "relationship": "subtopic_of"}},
    {{"from": "Detail of A1", "to": "Sub-concept A1", "relationship": "subtopic_of"}},
    {{"from": "Sub-concept A1", "to": "Sub-concept A2", "relationship": "related_to"}} // Example of a non-hierarchical link
  ]
}}

Analyze the provided text chunk carefully and generate the JSON. Be thorough in identifying distinct concepts and their relationships to create a rich graph.
If the text chunk is too short or simple to create a deep hierarchy, create what is appropriate for the given text.
`;
// --- END OF KG GENERATION SYSTEM PROMPT ---

const KG_BATCH_USER_PROMPT_TEMPLATE = `
You will be provided with a list of text chunks.
For EACH text chunk, you MUST perform the following:
1. Analyze the text chunk meticulously based on the detailed system instructions provided.
2. Create a detailed, hierarchical knowledge graph fragment.
3. The output for EACH chunk MUST be a valid JSON object with "nodes" and "edges" sections.

Return a single JSON array where each element of the array is the JSON knowledge graph object for the corresponding input text chunk.
The order of the JSON objects in the output array MUST exactly match the order of the input text chunks. Do not add any other text before or after the JSON array.

Here are the text chunks:
{BATCHED_CHUNK_TEXTS_HERE}

Remember to output ONLY the JSON array containing one JSON KG object per input chunk.
`;
// --- END OF KG BATCH USER PROMPT TEMPLATE ---

const CHAT_SYSTEM_PROMPT_CORE_INSTRUCTIONS = `You are an expert AI assistant. Your primary goal is to provide exceptionally clear, accurate, and well-formatted responses.

**Core Principles for Your Response:**
1.  **Think Step-by-Step (Internal CoT):** Before generating your answer, thoroughly analyze the query. Break down complex questions. Outline the logical steps and information needed. This is your internal process to ensure a high-quality response. *Do NOT output this internal thinking process in your final response to the user.*
2.  **Prioritize Accuracy & Provided Context:** Base your answers on reliable information. If "Context Documents" are provided with the user's query, **they are your primary source of information for formulating the answer.** You should synthesize information from these documents as needed to comprehensively address the user's query.
3.  **Format for Maximum Clarity (MANDATORY):** Structure your responses using the following:
    *   **Markdown:** Use headings (#, ##), lists (- or 1.), bold (**text**), italics (*text*), and blockquotes (>) effectively.
    *   **KaTeX for Math:**
        *   Block Math: ALWAYS use \`<p>$$[expression]$$</p>\`. Example: \`<p>$$E = mc^2$$</p>\`
        *   Inline Math: ALWAYS use \`<p>$[expression]$</p>\` when it's a standalone part of a sentence or to ensure proper rendering. Example: \`An example is <p>$x_i$</p>.\` or \`If <p>$a=b$</p> and <p>$b=c$</p>, then <p>$a=c$</p>.\` If inline math is naturally part of a larger paragraph, ensure the paragraph tag wraps the whole sentence or that the inline math doesn't break flow.
    *   **Code Blocks:** Use \`\`\`language ... \`\`\` for code. Specify the language if known.
    *   **Tables:** Use Markdown tables for structured data.
    *   **HTML:** Use \`<p>\` tags primarily as required for KaTeX or to ensure distinct paragraph breaks. Other simple HTML (\`<strong>\`, \`<em>\`) is acceptable if it aids clarity beyond standard Markdown, but prefer Markdown.
4.  **Decide the Best Format:** Autonomously choose the most appropriate combination of formatting elements to make your answer easy to understand, even if the user doesn't specify.

**Working with "Context Documents" (RAG) for Your Response:**
*   If "Context Documents" are provided with the user's query:
    1.  **Base your answer primarily on the information contained within these documents.**
    2.  **Synthesize:** Combine information from multiple documents if needed. Explain in your own words, drawing from the provided text.
    3.  **Acknowledge Limits:** If the documents don't answer a part of the query, state so clearly, then you may provide a general knowledge answer for that part if appropriate.
    4.  **DO NOT INCLUDE CITATION MARKERS like [1], [2] in your textual response.** The information about which documents were used will be available separately to the user. Your answer should read naturally as if drawing from this knowledge.

**Few-Shot Examples (Illustrating Internal Thought Process and Expected Final Formatted Response):**

---
**Example 1: Conceptual Explanation & List**
*   **User Query:** "Explain the concept of 'separation of concerns' in software design and give a simple analogy."
*   **(Simulated Internal Thought Process by LLM):**
    *   Define SoC.
    *   Identify key benefits (modularity, reusability, reduced complexity).
    *   Develop analogy (kitchen with distinct work areas).
    *   Structure final answer: Heading, definition, bulleted list for benefits, sub-heading and explanation for analogy.
    *   Formatting: Use Markdown headings, bold, lists.
*   **Expected Formatted Response (Directly to User):**
    \`\`\`
    ## Separation of Concerns

    <p><strong>Separation of Concerns (SoC)</strong> is a fundamental design principle for separating a computer program into distinct sections such that each section addresses a separate concern (a piece of information or functionality).</p>

    <p><strong>Key Benefits:</strong></p>
    <ul>
    <li><strong>Modularity:</strong> Easier to develop, test, and maintain individual sections.</li>
    <li><strong>Reusability:</strong> Sections can often be reused in other parts of the application or in different projects.</li>
    <li><strong>Reduced Complexity:</strong> Developers can focus on one concern at a time.</li>
    </ul>

    <h3>Analogy: A Well-Organized Kitchen</h3>
    <p>Think of a well-organized kitchen:</p>
    <ul>
    <li>You have a designated area for <strong>food preparation</strong> (cutting boards, knives).</li>
    <li>Another for <strong>cooking</strong> (stove, oven).</li>
    <li>And another for <strong>cleaning</strong> (sink, dishwasher).</li>
    </ul>
    <p>Each area (concern) has its own tools and purpose. If you want to change how you wash dishes (e.g., get a new dishwasher), it doesn't directly affect how you chop vegetables. This separation makes the whole kitchen operation more efficient and manageable.</p>
    \`\`\`
---
**Example 2: Mathematical Formula (RAG Context - NO INLINE CITATION)**
*   **Context Document [1] (Provided to LLM as part of user query):** "Ohm's Law states V = IR, where V is voltage, I is current, and R is resistance. This was discovered by Georg Ohm."
*   **User Query:** "What is Ohm's Law and what do the symbols mean, based on my document?"
*   **(Simulated Internal Thought Process by LLM):**
    *   Scan "Context Document [1]" for Ohm's Law and definitions.
    *   Extract formula V = IR and variable meanings.
    *   Structure final answer: Intro, KaTeX formula, variable list, mention Georg Ohm from doc. No "[1]" in output.
    *   Formatting: KaTeX \`<p>$$...$$</p>\`, Markdown bold, paragraph tags.
*   **Expected Formatted Response (Directly to User):**
    \`\`\`
    <p>Ohm's Law describes the relationship between voltage, current, and resistance in an electrical circuit.</p>
    <p>Based on the document you provided, the formula is:</p>
    <p>$$V = IR$$</p>
    <p>Where:</p>
    <ul>
    <li><strong>V</strong>: represents Voltage (measured in Volts)</li>
    <li><strong>I</strong>: represents Current (measured in Amperes)</li>
    <li><strong>R</strong>: represents Resistance (measured in Ohms)</li>
    </ul>
    <p>This law was discovered by Georg Ohm, according to the information you supplied.</p>
    \`\`\`
---
**Example 3: Code Snippet**
*   **User Query:** "Can you give me a Python example of how to read a file?"
*   **(Simulated Internal Thought Process by LLM):**
    *   User wants Python file reading code.
    *   Use \`with open(...)\` for best practice.
    *   Include basic error handling (\`try-except\`).
    *   Explain the code.
    *   Structure: Intro, code block, explanation.
    *   Formatting: Markdown, Python code block.
*   **Expected Formatted Response (Directly to User):**
    \`\`\`
    <p>Certainly! Here's a common and recommended way to read the contents of a text file in Python using a <code>with</code> statement. This ensures the file is properly closed even if errors occur:</p>

    \`\`\`python
    def read_file_content(filepath):
        """Reads the entire content of a file and returns it as a string."""
        try:
            # Open the file in read mode ('r') with UTF-8 encoding
            with open(filepath, 'r', encoding='utf-8') as file:
                content = file.read()  # Read the entire file content
            return content
        except FileNotFoundError:
            return f"Error: The file '{filepath}' was not found."
        except Exception as e:
            return f"An error occurred: {e}"

    # Example usage:
    # file_path = 'my_document.txt' 
    # content = read_file_content(file_path)
    # 
    # if not content.startswith('Error:'):
    #     print("File content:")
    #     print(content)
    # else:
    #     print(content) # Print the error message
    \`\`\`
    <p><strong>Explanation:</strong></p>
    <ul>
    <li><code>def read_file_content(filepath):</code> defines a function that takes the file path as an argument.</li>
    <li><code>with open(filepath, 'r', encoding='utf-8') as file:</code> opens the file. 
        <ul>
        <li><code>'r'</code> means read mode.</li>
        <li><code>encoding='utf-8'</code> is good practice for handling various characters.</li>
        <li>The <code>with</code> statement ensures <code>file.close()</code> is called automatically.</li>
        </ul>
    </li>
    <li><code>content = file.read()</code> reads the entire file into the <code>content</code> variable.</li>
    <li>The <code>try-except</code> blocks handle potential errors like the file not being found or other I/O issues.</li>
    </ul>
    <p>Replace <code>'my_document.txt'</code> with the actual path to your file when you use the example.</p>
    \`\`\`
---
`; // End of CHAT_SYSTEM_PROMPT_CORE_INSTRUCTIONS

const CHAT_MAIN_SYSTEM_PROMPT = () => {
    return CHAT_SYSTEM_PROMPT_CORE_INSTRUCTIONS;
};

// This is the thinking instruction block, kept separate for potential future use or different contexts.
// IT IS NOT CURRENTLY USED by CHAT_MAIN_SYSTEM_PROMPT.
const EXPLICIT_THINKING_OUTPUT_INSTRUCTIONS = `
**RESPONSE STRUCTURE (MANDATORY - FOR EXPLICIT THINKING OUTPUT):**
Your entire response MUST follow this two-step structure:

**STEP 1: MANDATORY THINKING PROCESS (OUTPUT FIRST):**
*   Before generating your final answer, you MUST outline your step-by-step plan and reasoning process in detail.
*   Place this entire thinking process within \`<thinking>\` and \`</thinking>\` tags.
*   This \`<thinking>...\</thinking>\` block MUST be the very first thing in your output. No preambles or any other text before it.
*   Use Markdown for formatting within your thinking process (e.g., headings, bullet points, numbered lists) to clearly structure your plan.
*   Example of detailed thinking structure:
    \`\`\`
    <thinking>
    ## Plan to Answer User Query: "[User's Query Example]"

    1.  **Understand Core Request:** [Briefly restate the user's main goal].
    2.  **Identify Key Information Needed/Sub-tasks:**
        *   [Sub-task or piece of information 1]
        *   [Sub-task or piece of information 2]
    3.  **Information Sources (if RAG is used):**
        *   Scan provided "Context Documents" for relevant information related to sub-tasks.
        *   Note key phrases or sections from documents.
    4.  **Structure Final Answer:**
        *   [Outline how the final answer will be structured, e.g., introduction, main points, conclusion].
    5.  **Formatting Considerations for Final Answer:**
        *   [Note any specific formatting required, e.g., KaTeX for equations, Markdown list for steps, code block for code].
    </thinking>
    \`\`\`

**STEP 2: FINAL ANSWER (AFTER \`</thinking>\`):**
*   After the closing \`</thinking>\` tag, generate your comprehensive and well-formatted answer based on your thinking process and the user's query.
*   Follow all formatting guidelines (Markdown, KaTeX, etc.) as instructed for this final answer part.
`;


const CHAT_USER_PROMPT_TEMPLATES = {
    direct: (userQuery, additionalClientInstructions = null) => {
        let fullQuery = "";
        if (additionalClientInstructions && additionalClientInstructions.trim() !== "") {
            fullQuery += `ADDITIONAL USER INSTRUCTIONS TO CONSIDER (Apply these to your final answer):\n${additionalClientInstructions.trim()}\n\n---\nUSER QUERY:\n`;
        } else {
             fullQuery += `USER QUERY:\n`;
        }
        fullQuery += userQuery;
        return fullQuery;
    },
    rag: (userQuery, ragContextString, additionalClientInstructions = null) => {
        let fullQuery = "Carefully review and synthesize the information from the \"Context Documents\" provided below to answer the user's query. Your answer should be primarily based on these documents. Do NOT include any citation markers like [1], [2] etc. in your response text.\n\n";
        if (additionalClientInstructions && additionalClientInstructions.trim() !== "") {
            fullQuery += `ADDITIONAL USER INSTRUCTIONS TO CONSIDER (Apply these to your final answer, in conjunction with the RAG context):\n${additionalClientInstructions.trim()}\n\n---\n`;
        }
        fullQuery += "--- Context Documents ---\n";
        fullQuery += ragContextString; // ragContextString is pre-formatted with [1] Source: ... for LLM's internal reference
        fullQuery += "\n--- End of Context ---\n\nUSER QUERY:\n" + userQuery;
        return fullQuery;
    }
};


module.exports = {
    ANALYSIS_PROMPTS,
    KG_GENERATION_SYSTEM_PROMPT,
    KG_BATCH_USER_PROMPT_TEMPLATE,
    CHAT_MAIN_SYSTEM_PROMPT,
    CHAT_USER_PROMPT_TEMPLATES,
    EXPLICIT_THINKING_OUTPUT_INSTRUCTIONS, // Exporting this for your potential future use
};
```

`server/middleware/authMiddleware.js`

```javascript
// server/middleware/authMiddleware.js
const jwt = require('jsonwebtoken');
const User = require('../models/User');
require('dotenv').config();

const authMiddleware = async (req, res, next) => {
    const authHeader = req.header('Authorization');

    if (!authHeader) {
        console.warn("Auth Middleware: No Authorization header found.");
        return res.status(401).json({ message: 'Not authorized, no token' });
    }

    const parts = authHeader.split(' ');

    if (parts.length !== 2 || parts[0] !== 'Bearer') {
        console.warn("Auth Middleware: Token format is 'Bearer <token>', received:", authHeader);
        return res.status(401).json({ message: 'Token format is invalid' });
    }

    const token = parts[1];

    try {
        const decoded = jwt.verify(token, process.env.JWT_SECRET);
        const user = await User.findById(decoded.userId).select('-password');

        if (!user) {
            console.warn(`Auth Middleware: User not found for ID: ${decoded.userId} from token.`);
            return res.status(401).json({ message: 'User not found, token invalid' });
        }

        req.user = user;
        next();
    } catch (error) {
        console.warn("Auth Middleware: Token verification failed:", error.message);
        if (error.name === 'TokenExpiredError') {
            return res.status(401).json({ message: 'Token expired' });
        }
        if (error.name === 'JsonWebTokenError') {
            return res.status(401).json({ message: 'Token is not valid' });
        }
        res.status(401).json({ message: 'Not authorized, token verification failed' });
    }
};

module.exports = { authMiddleware }; // ONLY export this
```

`server/models/ChatHistory.js`

```javascript
const mongoose = require('mongoose');
const { v4: uuidv4 } = require('uuid'); // For default message ID if needed

const MessageSchema = new mongoose.Schema({
    // id: { type: String, default: uuidv4 }, // Client usually generates this for optimistic updates
    role: { // 'user' or 'model' (for Gemini compatibility)
        type: String,
        enum: ['user', 'model'],
        required: true
    },
    parts: [{ // Gemini structure
        text: {
            type: String,
            required: true
        },
        // _id: false // Mongoose adds _id by default, can disable if truly not needed per part
    }],
    timestamp: {
        type: Date,
        default: Date.now
    },
    // Optional fields from AI response
    thinking: {
        type: String,
        default: ''
    },
    references: {
        type: Array, // Array of objects like { number, source, content_preview }
        default: []
    },
    source_pipeline: { // e.g., "gemini-direct", "gemini-rag"
        type: String,
        default: ''
    }
}, { _id: false }); // Don't create separate _id for each message object in the array

const ChatHistorySchema = new mongoose.Schema({
    userId: {
        type: mongoose.Schema.Types.ObjectId,
        ref: 'User',
        required: true,
        index: true,
    },
    sessionId: {
        type: String,
        required: true,
        unique: true,
        index: true,
    },
    messages: [MessageSchema],
    createdAt: {
        type: Date,
        default: Date.now,
    },
    updatedAt: {
        type: Date,
        default: Date.now,
    }
});

ChatHistorySchema.pre('save', function (next) {
    if (this.isModified()) {
      this.updatedAt = Date.now();
    }
    next();
});

ChatHistorySchema.pre('findOneAndUpdate', function(next) {
  this.set({ updatedAt: new Date() });
  next();
});

const ChatHistory = mongoose.model('ChatHistory', ChatHistorySchema);
module.exports = ChatHistory;
```

`server/models/User.js`

```javascript
const mongoose = require('mongoose');
const bcrypt = require('bcryptjs');

const UserSchema = new mongoose.Schema({
  username: {
    type: String,
    required: [true, 'Please provide a username'],
    unique: true,
    trim: true,
  },
  password: {
    type: String,
    required: [true, 'Please provide a password'],
    minlength: 6,
    select: false, // Explicitly prevent password from being returned by default
  },
  uploadedDocuments: [
    {
      filename: {
        type: String,
      },
      text: {
        type: String,
        default: "",
      },
      analysis: {
        faq: {
          type: String,
          default: "",
        },
        topics: {
          type: String,
          default: "",
        },
        mindmap: {
          type: String,
          default: "",
        },
      },
    },
  ],
  createdAt: {
    type: Date,
    default: Date.now,
  },
});

// Password hashing middleware before saving
UserSchema.pre('save', async function (next) {
  // Only hash the password if it has been modified (or is new)
  if (!this.isModified('password')) {
    return next();
  }
  try {
    const salt = await bcrypt.genSalt(10);
    this.password = await bcrypt.hash(this.password, salt);
    next();
  } catch (err) {
    next(err);
  }
});

// Method to compare entered password with hashed password
// Ensure we fetch the password field when needed for comparison
UserSchema.methods.comparePassword = async function (candidatePassword) {
  // 'this.password' might be undefined due to 'select: false'
  // Fetch the user again including the password if needed, or ensure the calling context selects it
  // However, bcrypt.compare handles the comparison securely.
  // We assume 'this.password' is available in the context where comparePassword is called.
  if (!this.password) {
      // This scenario should be handled by the calling code (e.g., findOne().select('+password'))
      // Or by using a static method like findByCredentials
      console.error("Attempted to compare password, but password field was not loaded on the User object."); // Added more specific log
      throw new Error("Password field not available for comparison.");
  }
  // Use bcryptjs's compare function
  return await bcrypt.compare(candidatePassword, this.password);
};

// Ensure password is selected when finding user for login comparison
UserSchema.statics.findByCredentials = async function(username, password) {
    // Find user by username AND explicitly select the password field
    const user = await this.findOne({ username }).select('+password');
    if (!user) {
        console.log(`findByCredentials: User not found for username: ${username}`); // Debug log
        return null; // User not found
    }
    // Now 'user' object has the password field, safe to call comparePassword
    const isMatch = await user.comparePassword(password);
    if (!isMatch) {
        console.log(`findByCredentials: Password mismatch for username: ${username}`); // Debug log
        return null; // Password doesn't match
    }
    console.log(`findByCredentials: Credentials match for username: ${username}`); // Debug log
    // Return user object (password will still be selected here, but won't be sent in JSON response usually)
    return user;
};


const User = mongoose.model('User', UserSchema);

module.exports = User;

```

`server/rag_service/ai_core.py`

```python
# ./ai_core.py

# Standard Library Imports
import logging
import os
import io
import re
import copy
import uuid
from typing import Any, Callable, Dict, List, Optional, Union
from datetime import datetime # For improved date parsing in metadata

# --- Global Initializations ---
logger = logging.getLogger(__name__)

# --- Configuration Import ---
try:
    import config # This should import server/config.py
except ImportError as e:
    logger.critical(f"CRITICAL: Failed to import 'config' (expected server/config.py): {e}. ")
    # Depending on how critical config is, you might want to sys.exit(1)
    # For now, we'll let it proceed and other parts will fail if config isn't loaded.


# Local aliases for config flags, models, constants, and classes from config.py
# Ensure all these are actually defined in your config.py
PYPDF_AVAILABLE = getattr(config, 'PYPDF_AVAILABLE', False)
PDFPLUMBER_AVAILABLE = getattr(config, 'PDFPLUMBER_AVAILABLE', False)
PANDAS_AVAILABLE = getattr(config, 'PANDAS_AVAILABLE', False)
DOCX_AVAILABLE = getattr(config, 'DOCX_AVAILABLE', False)
PPTX_AVAILABLE = getattr(config, 'PPTX_AVAILABLE', False)
PIL_AVAILABLE = getattr(config, 'PIL_AVAILABLE', False)
FITZ_AVAILABLE = getattr(config, 'FITZ_AVAILABLE', False)
PYTESSERACT_AVAILABLE = getattr(config, 'PYTESSERACT_AVAILABLE', False)
SPACY_MODEL_LOADED = getattr(config, 'SPACY_MODEL_LOADED', False)
PYPDF2_AVAILABLE = getattr(config, 'PYPDF2_AVAILABLE', False)
EMBEDDING_MODEL_LOADED = getattr(config, 'EMBEDDING_MODEL_LOADED', False)
MAX_TEXT_LENGTH_FOR_NER  = getattr(config, 'MAX_TEXT_LENGTH_FOR_NER', 500000)
LANGCHAIN_SPLITTER_AVAILABLE = getattr(config, 'LANGCHAIN_SPLITTER_AVAILABLE', False)

PYPDF_PDFREADERROR = getattr(config, 'PYPDF_PDFREADERROR', Exception)
TESSERACT_ERROR = getattr(config, 'TESSERACT_ERROR', Exception)

# Libraries and Models (ensure these are None if not available to prevent AttributeError)
pypdf = getattr(config, 'pypdf', None)
PyPDF2 = getattr(config, 'PyPDF2', None)
pdfplumber = getattr(config, 'pdfplumber', None)
pd = getattr(config, 'pd', None)
DocxDocument = getattr(config, 'DocxDocument', None)
Presentation = getattr(config, 'Presentation', None)
Image = getattr(config, 'Image', None)
fitz = getattr(config, 'fitz', None)
pytesseract = getattr(config, 'pytesseract', None)
nlp_spacy_core = getattr(config, 'nlp_spacy_core', None)
document_embedding_model = getattr(config, 'document_embedding_model', None)
RecursiveCharacterTextSplitter = getattr(config, 'RecursiveCharacterTextSplitter', None)

# Constants
AI_CORE_CHUNK_SIZE = getattr(config, 'AI_CORE_CHUNK_SIZE', 1024) # Default if not in config
AI_CORE_CHUNK_OVERLAP = getattr(config, 'AI_CORE_CHUNK_OVERLAP', 200) # Default if not in config
DOCUMENT_EMBEDDING_MODEL_NAME = getattr(config, 'DOCUMENT_EMBEDDING_MODEL_NAME', "unknown_model")


# ==============================================================================
# Phase 2: Unified Rich Element Extraction Layer
# ==============================================================================

# Standard Output Structure for Element Extractors
# {
#     'text_content': Optional[str],
#     'tables': List[Union[pd.DataFrame, List[List[str]]]],
#     'images': List[Image.Image],
#     'parser_metadata': Dict[str, Any],
#     'is_scanned_heuristic': bool
# }

def _make_empty_extraction_result() -> Dict[str, Any]:
    """Helper to create a default empty result structure."""
    return {
        'text_content': None,
        'tables': [],
        'images': [],
        'parser_metadata': {},
        'is_scanned_heuristic': False
    }

def _extract_pdf_elements(file_path: str) -> Dict[str, Any]:
    if not os.path.exists(file_path):
        logger.error(f"PDF file not found: {file_path}")
        return _make_empty_extraction_result()

    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    extracted_text_parts = []

    # 1. Text and Table Extraction with pdfplumber (if available)
    if PDFPLUMBER_AVAILABLE and pdfplumber:
        try:
            with pdfplumber.open(file_path) as pdf:
                num_pages_plumber = len(pdf.pages)
                for i, page in enumerate(pdf.pages):
                    page_text = page.extract_text(x_tolerance=1, y_tolerance=1.5, layout=False) # layout=False for more raw text
                    if page_text and page_text.strip():
                        extracted_text_parts.append(page_text.strip())

                    # Extract tables
                    page_tables_data = page.extract_tables()
                    if page_tables_data:
                        for table_data_list in page_tables_data:
                            if not table_data_list: continue
                            if PANDAS_AVAILABLE and pd:
                                try:
                                    # Attempt to use first row as header if meaningful
                                    if len(table_data_list) > 1 and all(c is not None and isinstance(c, str) for c in table_data_list[0]):
                                        df = pd.DataFrame(table_data_list[1:], columns=table_data_list[0])
                                    else:
                                        df = pd.DataFrame(table_data_list)
                                    result['tables'].append(df)
                                except Exception as df_err:
                                    logger.warning(f"pdfplumber: DataFrame conversion error for table on page {i+1} of {file_base_name}: {df_err}. Storing as list.")
                                    result['tables'].append(table_data_list)
                            else:
                                result['tables'].append(table_data_list)
                
                result['text_content'] = "\n\n".join(extracted_text_parts).strip() or None
                if result['tables']: logger.info(f"pdfplumber: Extracted {len(result['tables'])} tables from {file_base_name}.")

                # Scanned PDF Heuristic (based on pdfplumber text)
                if num_pages_plumber > 0:
                    total_chars = sum(len(pt.replace(" ", "")) for pt in extracted_text_parts)
                    avg_chars_per_page = total_chars / num_pages_plumber
                    # Heuristic: low average characters per page suggests scanned
                    if avg_chars_per_page < 20 and total_chars < (num_pages_plumber * 50): # Tunable thresholds
                        result['is_scanned_heuristic'] = True
                        logger.info(f"PDF {file_base_name} potentially scanned (low avg text [{avg_chars_per_page:.1f} chars/page] from pdfplumber).")

        except Exception as e_plumber:
            logger.warning(f"pdfplumber: Error processing PDF {file_base_name}: {e_plumber}", exc_info=True)
            # If pdfplumber fails, pypdf (now pypdf) can be a fallback for basic text
            if PYPDF_AVAILABLE and pypdf and not result['text_content']:
                logger.info(f"Attempting pypdf fallback for text extraction from {file_base_name}")
                try:
                    reader = pypdf.PdfReader(file_path)
                    pypdf_text_parts = []
                    for page in reader.pages:
                        page_text = page.extract_text()
                        if page_text and page_text.strip():
                            pypdf_text_parts.append(page_text.strip())
                    result['text_content'] = "\n\n".join(pypdf_text_parts).strip() or None
                except Exception as e_pypdf:
                    logger.warning(f"pypdf fallback also failed for {file_base_name}: {e_pypdf}")


    # 2. Image Extraction with Fitz (PyMuPDF)
    if FITZ_AVAILABLE and fitz and PIL_AVAILABLE and Image:
        try:
            doc_fitz = fitz.open(file_path)
            if not result['is_scanned_heuristic'] and not result['text_content'] and len(doc_fitz) > 0:
                # If no text from plumber/pypdf, but fitz finds pages, highly likely scanned.
                result['is_scanned_heuristic'] = True
                logger.info(f"PDF {file_base_name} likely scanned (no text extracted, but pages found by fitz).")

            for page_idx in range(len(doc_fitz)):
                for img_info_tuple in doc_fitz.get_page_images(page_idx):
                    xref = img_info_tuple[0]
                    try:
                        img_bytes_dict = doc_fitz.extract_image(xref)
                        if img_bytes_dict and "image" in img_bytes_dict:
                             result['images'].append(Image.open(io.BytesIO(img_bytes_dict["image"])))
                    except Exception as img_err:
                        logger.warning(f"fitz: Could not extract/open image xref {xref} from page {page_idx} of {file_base_name}: {img_err}")
            if result['images']: logger.info(f"fitz: Extracted {len(result['images'])} images from {file_base_name}.")
            doc_fitz.close()
        except Exception as e_fitz:
            logger.warning(f"fitz: Error processing PDF {file_base_name} for images: {e_fitz}", exc_info=True)

    # 3. Metadata with PyPDF2 (or pypdf if PyPDF2 not available/fails)
    metadata_extractor = None
    if PYPDF2_AVAILABLE and PyPDF2:
        metadata_extractor = PyPDF2.PdfReader
        extractor_name = "PyPDF2"
    elif PYPDF_AVAILABLE and pypdf: # Fallback to pypdf for metadata
        metadata_extractor = pypdf.PdfReader
        extractor_name = "pypdf"

    if metadata_extractor:
        try:
            with open(file_path, 'rb') as f:
                reader = metadata_extractor(f)
                info = reader.metadata
                if info:
                    if hasattr(info, 'title') and info.title: result['parser_metadata']['title'] = str(info.title).strip()
                    if hasattr(info, 'author') and info.author: result['parser_metadata']['author'] = str(info.author).strip()
                    
                    pdf_date_formats = [
                        "D:%Y%m%d%H%M%S%z",    
                        "D:%Y%m%d%H%M%S",
                        "D:%Y%m%d%H%M%SZ",
                        "%Y%m%d%H%M%S%z",
                        "%Y%m%d%H%M%S",
                        "%Y%m%d%H%M%SZ",
                    ]
                    def parse_pdf_date(date_val_str_or_dt):
                        if isinstance(date_val_str_or_dt, datetime): return date_val_str_or_dt
                        if not isinstance(date_val_str_or_dt, str): return None
                        clean_date_str = date_val_str_or_dt.strip().rstrip("'")
                        for fmt in pdf_date_formats:
                            try: return datetime.strptime(clean_date_str, fmt)
                            except ValueError: continue
                        return None
                    

                    raw_creation_date = info.get("/CreationDate") if isinstance(info, dict) else getattr(info, 'creation_date', None)
                    creation_date_obj = parse_pdf_date(raw_creation_date)

                    if creation_date_obj: result['parser_metadata']['creation_date'] = creation_date_obj.isoformat()
                    
                    raw_mod_date = info.get("/ModDate") if isinstance(info, dict) else getattr(info, 'modification_date', None)
                    modification_date_obj = parse_pdf_date(raw_mod_date)
                    
                    if modification_date_obj: result['parser_metadata']['modification_date'] = modification_date_obj.isoformat()

                result['parser_metadata']['page_count'] = len(reader.pages)
        except Exception as e_meta:
            logger.warning(f"Metadata: Error using {extractor_name} for {file_base_name}: {e_meta}", exc_info=True)
            if 'page_count' not in result['parser_metadata'] and FITZ_AVAILABLE and fitz: # Fallback page count
                try:
                    doc_fitz_pc = fitz.open(file_path)
                    result['parser_metadata']['page_count'] = len(doc_fitz_pc)
                    doc_fitz_pc.close()
                except: pass


    return result

def _extract_docx_elements(file_path: str) -> Dict[str, Any]:
    if not (DOCX_AVAILABLE and DocxDocument and PIL_AVAILABLE and Image):
        logger.error("python-docx or Pillow not available. DOCX parsing will be limited.")
        return _make_empty_extraction_result()
    
    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    text_content_parts = []

    try:
        doc = DocxDocument(file_path)
        # Text
        for para in doc.paragraphs:
            if para.text.strip():
                text_content_parts.append(para.text.strip())
        result['text_content'] = "\n".join(text_content_parts).strip() or None

        # Tables
        for i, table in enumerate(doc.tables):
            table_list = [[cell.text.strip() for cell in row.cells] for row in table.rows]
            if not table_list: continue
            if PANDAS_AVAILABLE and pd:
                try:
                    if len(table_list) > 1 and all(c for c in table_list[0]): # Use first row as header
                        result['tables'].append(pd.DataFrame(table_list[1:], columns=table_list[0]))
                    else:
                        result['tables'].append(pd.DataFrame(table_list))
                except Exception as df_err:
                    logger.warning(f"docx: DataFrame conversion error for table {i} in {file_base_name}: {df_err}. Storing as list.")
                    result['tables'].append(table_list)
            else:
                result['tables'].append(table_list)
        if result['tables']: logger.info(f"docx: Extracted {len(result['tables'])} tables from {file_base_name}.")

        # Images (Inline shapes)
        for rel_id, image_part in doc.part.image_parts:
             try:
                 img = Image.open(io.BytesIO(image_part.blob))
                 result['images'].append(img)
             except Exception as e_img:
                 logger.warning(f"docx: Error processing an image from {file_base_name}: {e_img}")
        # A more thorough way for inline_shapes if doc.part.image_parts is not sufficient:
        # for shape in doc.inline_shapes:
        #    if shape.type == MSO_SHAPE_TYPE.PICTURE: # Requires from docx.enum.shape import MSO_SHAPE_TYPE
        #        try:
        #            image_part = doc.part.related_parts[shape._inline.graphic.graphicData.pic.blipFill.blip.embed]
        #            img = Image.open(io.BytesIO(image_part.blob))
        #            result['images'].append(img)
        #        except Exception: pass # ignore if not an image or error
        if result['images']: logger.info(f"docx: Extracted {len(result['images'])} images from {file_base_name}.")


        # Metadata
        props = doc.core_properties
        if props.title: result['parser_metadata']['title'] = props.title
        if props.author: result['parser_metadata']['author'] = props.author
        if props.created: result['parser_metadata']['creation_date'] = props.created.isoformat()
        if props.modified: result['parser_metadata']['modification_date'] = props.modified.isoformat()
        result['parser_metadata']['page_count'] = len(doc.paragraphs) // 20 or 1 # Rough estimate

        # Scanned Heuristic
        if not result['text_content'] and result['images']:
            result['is_scanned_heuristic'] = True
            logger.info(f"DOCX {file_base_name} potentially image-based (no text, images present).")

    except FileNotFoundError:
        logger.error(f"docx: File not found: {file_path}")
    except Exception as e:
        logger.error(f"docx: Error parsing DOCX {file_base_name}: {e}", exc_info=True)
    
    return result

def _extract_pptx_elements(file_path: str) -> Dict[str, Any]:
    if not (PPTX_AVAILABLE and Presentation and PIL_AVAILABLE and Image):
        logger.error("python-pptx or Pillow not available. PPTX parsing will be limited.")
        return _make_empty_extraction_result()

    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    text_content_parts = []

    try:
        prs = Presentation(file_path)
        for slide_idx, slide in enumerate(prs.slides):
            slide_texts = []
            for shape in slide.shapes:
                if hasattr(shape, "text_frame") and shape.text_frame and shape.text_frame.text.strip():
                    slide_texts.append(shape.text_frame.text.strip())
                elif hasattr(shape, "text") and shape.text.strip(): # For shapes with direct text
                    slide_texts.append(shape.text.strip())
                
                # Image extraction
                if hasattr(shape, "image"): # If shape is an image
                    try:
                        image_bytes = shape.image.blob
                        img = Image.open(io.BytesIO(image_bytes))
                        result['images'].append(img)
                    except Exception as e_img_shape:
                        logger.warning(f"pptx: Error extracting image from shape on slide {slide_idx} of {file_base_name}: {e_img_shape}")
            
            if slide_texts:
                text_content_parts.append("\n".join(slide_texts))
        
        result['text_content'] = "\n\n".join(text_content_parts).strip() or None
        if result['images']: logger.info(f"pptx: Extracted {len(result['images'])} images from {file_base_name}.")

        # Metadata
        props = prs.core_properties
        if props.title: result['parser_metadata']['title'] = props.title
        if props.author: result['parser_metadata']['author'] = props.author
        if props.created: result['parser_metadata']['creation_date'] = props.created.isoformat()
        if props.last_modified_by : result['parser_metadata']['last_modified_by'] = props.last_modified_by
        if props.modified : result['parser_metadata']['modification_date'] = props.modified.isoformat()

        result['parser_metadata']['page_count'] = len(prs.slides)

        # Scanned Heuristic
        if not result['text_content'] and result['images']:
            result['is_scanned_heuristic'] = True
            logger.info(f"PPTX {file_base_name} potentially image-based (no text, images present).")

    except FileNotFoundError:
        logger.error(f"pptx: File not found: {file_path}")
    except Exception as e:
        logger.error(f"pptx: Error parsing PPTX {file_base_name}: {e}", exc_info=True)

    return result

def _extract_csv_elements(file_path: str) -> Dict[str, Any]:
    if not (PANDAS_AVAILABLE and pd):
        logger.error("pandas not available. CSV parsing will be limited.")
        return _extract_generic_text_elements(file_path, ".csv") # Fallback to text

    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    try:
        df = pd.read_csv(file_path)
        result['tables'].append(df)
        # Create a text representation of the CSV for text_content
        # Could be markdown, simple string, or first N rows.
        # Using to_string() for now. Consider to_markdown() for better structure if text will be LLM input.
        result['text_content'] = df.to_string(index=False, na_rep='NULL').strip() or None
        logger.info(f"csv: Extracted 1 table (shape: {df.shape}) from {file_base_name}.")
    except FileNotFoundError:
        logger.error(f"csv: File not found: {file_path}")
    except Exception as e:
        logger.error(f"csv: Error parsing CSV {file_base_name}: {e}", exc_info=True)
        # Fallback to generic text if pandas fails
        return _extract_generic_text_elements(file_path, ".csv")
    return result


def _extract_generic_text_elements(file_path: str, file_type_ext: str) -> Dict[str, Any]:
    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            text = f.read()
        result['text_content'] = text.strip() or None
        
        # For HTML/XML, optionally strip tags (basic)
        if file_type_ext in ['.html', '.xml'] and result['text_content']:
            stripped_text = re.sub(r'<[^>]+>', ' ', result['text_content'])
            result['text_content'] = re.sub(r'\s+', ' ', stripped_text).strip() or None

    except FileNotFoundError:
        logger.error(f"txt-like: File not found: {file_path}")
    except Exception as e:
        logger.error(f"txt-like: Error parsing {file_base_name}: {e}", exc_info=True)
    return result

def _extract_image_file_elements(file_path: str) -> Dict[str, Any]:
    if not (PIL_AVAILABLE and Image):
        logger.error("Pillow (PIL) not available. Image file parsing will fail.")
        return _make_empty_extraction_result()

    result = _make_empty_extraction_result()
    file_base_name = os.path.basename(file_path)
    try:
        img = Image.open(file_path)
        result['images'].append(img)
        result['is_scanned_heuristic'] = True # By definition, an image file is "scanned" for OCR
        logger.info(f"Image file {file_base_name} opened.")
    except FileNotFoundError:
        logger.error(f"image-file: File not found: {file_path}")
    except Exception as e:
        logger.error(f"image-file: Error opening {file_base_name}: {e}", exc_info=True)
    return result


def _get_rich_extraction_results(file_path: str) -> Dict[str, Any]:
    """Dispatcher for rich element extraction based on file type."""
    ext = os.path.splitext(file_path)[1].lower()
    logger.info(f"Rich extraction: Dispatching for file type '{ext}' ({os.path.basename(file_path)})")

    if ext == '.pdf':
        return _extract_pdf_elements(file_path)
    elif ext == '.docx':
        return _extract_docx_elements(file_path)
    elif ext == '.pptx':
        return _extract_pptx_elements(file_path)
    elif ext == '.csv':
        return _extract_csv_elements(file_path)
    elif ext in ['.txt', '.py', '.js', '.md', '.log', '.html', '.xml', '.json']:
        return _extract_generic_text_elements(file_path, ext)
    elif ext in ['.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif']:
        return _extract_image_file_elements(file_path)
    else:
        logger.warning(f"Unsupported file extension for rich extraction: {ext} ({os.path.basename(file_path)}). Attempting generic text.")
        return _extract_generic_text_elements(file_path, ext) # Fallback for unknown types


# ==============================================================================
# Phase 3: Streamlined Main Processing Pipeline
# ==============================================================================

def _get_initial_parsed_document(file_path: str) -> Dict[str, Any]:
    """Calls the appropriate rich element extractor for the file."""
    return _get_rich_extraction_results(file_path)


# --- Stages 2-7 (OCR, Cleaning, Layout, Metadata, Chunking, Embedding) ---
# These functions are largely the same as your corrected versions, but will now consume
# the structured output from _get_initial_parsed_document.

def perform_ocr_on_images(image_objects: List[Any], file_base_name_for_log: str ="") -> str: # Added filename for logging
    if not image_objects: return ""
    if not (PYTESSERACT_AVAILABLE and pytesseract):
        logger.error(f"Pytesseract not available. OCR for {file_base_name_for_log} cannot be performed.")
        return ""

    logger.info(f"Performing OCR on {len(image_objects)} image(s) for {file_base_name_for_log}.")
    ocr_text_parts = []
    images_ocrd = 0
    for i, img_obj in enumerate(image_objects):
        try:
            if not (PIL_AVAILABLE and Image and isinstance(img_obj, Image.Image)):
                logger.warning(f"Skipping non-PIL Image object at index {i} for OCR of {file_base_name_for_log}.")
                continue
            # Improve image for OCR: convert to grayscale, potentially apply thresholding if needed
            processed_img_for_ocr = img_obj.convert('L') # Grayscale
            text = pytesseract.image_to_string(processed_img_for_ocr)
            if text and text.strip():
                ocr_text_parts.append(text.strip())
                images_ocrd += 1
        except Exception as e:
            if TESSERACT_ERROR and isinstance(e, TESSERACT_ERROR): # Check specific Tesseract error
                logger.critical(f"Tesseract executable not found or error for {file_base_name_for_log}. OCR will fail. Error: {e}")
                # Re-raise if it's a critical setup issue that will affect all subsequent OCR
                # For now, we'll let it try other images, but this indicates a setup problem.
            logger.error(f"Error during OCR for image {i+1}/{len(image_objects)} of {file_base_name_for_log}: {e}", exc_info=True)
    
    full_ocr_text = "\n\n--- OCR Text from Image ---\n\n".join(ocr_text_parts).strip()
    logger.info(f"OCR for {file_base_name_for_log}: Extracted {len(full_ocr_text)} chars from {images_ocrd} image(s).")
    return full_ocr_text


def clean_and_normalize_text_content(text: str, file_base_name_for_log: str ="") -> str:
    if not text or not text.strip(): return ""
    logger.info(f"Text cleaning for {file_base_name_for_log}: Initial length {len(text)}")
    
    # Basic regex cleaning (order matters)
    text = re.sub(r'<script[^>]*>.*?</script>|<style[^>]*>.*?</style>', ' ', text, flags=re.I | re.S) # Remove script/style
    text = re.sub(r'<[^>]+>', ' ', text) # Remove all other HTML tags
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE) # Remove URLs
    text = re.sub(r'\S*@\S*\s?', '', text, flags=re.MULTILINE) # Remove emails
    text = re.sub(r'\s*&\w+;\s*', ' ', text) # Remove HTML entities like  
    text = re.sub(r'[\n\r\t]+', ' ', text) # Normalize whitespace (newlines, tabs to single space)
    text = re.sub(r'\s+', ' ', text).strip() # Consolidate multiple spaces to one and strip ends
    
    # Character filtering (allow more common punctuation useful for context)
    # text = re.sub(r'[^\w\s.,!?"\'():;-]', '', text) # Keeps more standard punctuation
    # For more aggressive cleaning for embedding, you might use:
    text = re.sub(r'[^a-zA-Z0-9\s.,!?-]', '', text) # More restrictive, closer to your original

    text_lower = text.lower() # Convert to lowercase AFTER regex to preserve case for URLs/emails if needed

    if not (SPACY_MODEL_LOADED and nlp_spacy_core):
        logger.warning(f"SpaCy model not loaded for {file_base_name_for_log}. Skipping lemmatization. Returning regex-cleaned text.")
        return text_lower
    
    try:
        # Process in chunks if text is very long to avoid SpaCy memory issues, though less likely after cleaning
        max_spacy_len = 1000000 # SpaCy's default internal limit for nlp()
        if len(text_lower) > max_spacy_len:
            logger.warning(f"Text for SpaCy in {file_base_name_for_log} exceeds {max_spacy_len} chars. Processing in parts or truncating.")
            # Simple truncation for now, chunking for spacy is more complex
            text_lower = text_lower[:max_spacy_len]

        doc = nlp_spacy_core(text_lower, disable=['parser', 'ner']) # Disable unused pipes
        lemmatized_tokens = [
            token.lemma_ for token in doc 
            if not token.is_stop and \
               not token.is_punct and \
               not token.is_space and \
               len(token.lemma_) > 1 and \
               token.lemma_ != '-PRON-' # Exclude pronouns after lemmatization
        ]
        final_cleaned_text = " ".join(lemmatized_tokens)
        logger.info(f"SpaCy cleaning for {file_base_name_for_log}: Final length {len(final_cleaned_text)}")
        return final_cleaned_text
    except Exception as e:
        logger.error(f"SpaCy processing failed for {file_base_name_for_log}: {e}. Returning pre-SpaCy cleaned text.", exc_info=True)
        return text_lower


def reconstruct_document_layout(text_content: str, tables_data: List[Any], file_type: str, file_base_name_for_log: str ="") -> str:
    if not text_content and not tables_data: return ""
    logger.info(f"Layout reconstruction for {file_base_name_for_log} ({file_type}): Text len {len(text_content)}, Tables {len(tables_data)}")
    
    # Hyphenated word de-joining (if text_content is not None)
    processed_text = text_content if text_content else ""
    processed_text = re.sub(r'(\w+)-\s*\n\s*(\w+)', r'\1\2', processed_text) # Across newlines
    # processed_text = re.sub(r'(\w+)-(\w+)', r'\1\2', processed_text) # Within same line (less common needed after initial parse)

    if tables_data:
        table_md_parts = []
        for i, table_obj in enumerate(tables_data):
            table_header = f"\n\n[START OF TABLE {i+1} extracted from {file_base_name_for_log}]\n"
            table_footer = f"\n[END OF TABLE {i+1}]\n"
            md_table_content = ""
            try:
                if PANDAS_AVAILABLE and pd and isinstance(table_obj, pd.DataFrame):
                    md_table_content = table_obj.to_markdown(index=False)
                elif isinstance(table_obj, list) and table_obj and all(isinstance(row, list) for row in table_obj):
                    # Basic list of lists to Markdown
                    if table_obj[0]: # Assume first row is header
                        md_table_content = "| " + " | ".join(map(str, table_obj[0])) + " |\n"
                        md_table_content += "| " + " | ".join(["---"] * len(table_obj[0])) + " |\n"
                        for row_data in table_obj[1:]:
                            if len(row_data) == len(table_obj[0]):
                                md_table_content += "| " + " | ".join(map(str, row_data)) + " |\n"
                            else: logger.warning(f"Table {i+1} (list) row length mismatch in {file_base_name_for_log}.")
                    else: md_table_content = "[Empty Table Data]"
                else: md_table_content = str(table_obj) # Fallback
            except Exception as e_table_md:
                logger.warning(f"Table {i+1} to Markdown conversion error for {file_base_name_for_log}: {e_table_md}. Using raw string.")
                md_table_content = str(table_obj)
            
            if md_table_content.strip():
                table_md_parts.append(table_header + md_table_content.strip() + table_footer)
        
        if table_md_parts:
            processed_text += "\n\n" + "\n\n".join(table_md_parts)
    
    # Final whitespace cleanup
    final_layout_text = re.sub(r'\s{2,}', ' ', processed_text).strip() # Consolidate multiple spaces
    logger.info(f"Layout reconstruction for {file_base_name_for_log}: Final length {len(final_layout_text)}")
    return final_layout_text


def extract_document_metadata_info(
    file_path: str, 
    processed_text: str, 
    parsed_doc_elements: Dict[str, Any], # Output from _get_initial_parsed_document
    original_file_name: str, 
    user_id: str
) -> Dict[str, Any]:
    logger.info(f"Metadata extraction for: {original_file_name} (User: {user_id})")
    
    parser_meta = parsed_doc_elements.get('parser_metadata', {})
    file_type_from_parser = os.path.splitext(original_file_name)[1].lower() # Fallback if not in parser_meta

    doc_meta = {
        'file_name': original_file_name,
        'file_path_on_server': file_path,
        'original_file_type': parser_meta.get('file_type', file_type_from_parser),
        'processing_user': user_id,
        'title': parser_meta.get('title', original_file_name), # Prioritize parser title
        'author': parser_meta.get('author', "Unknown"),       # Prioritize parser author
        'creation_date': parser_meta.get('creation_date'),   # Expect ISO format from parser
        'modification_date': parser_meta.get('modification_date'), # Expect ISO format
        'page_count': parser_meta.get('page_count', 0),
        'char_count_processed_text': len(processed_text),
        'named_entities': {},
        'structural_elements': "Paragraphs" + (", Tables" if parsed_doc_elements.get('tables') else ""),
        'is_scanned_document': parsed_doc_elements.get('is_scanned_heuristic', False), # Initial guess
        'ocr_applied': False # Will be set to True if OCR text was actually used
    }

    # OS-level metadata (can augment or be overridden by parser_meta)
    try:
        doc_meta['file_size_bytes'] = os.path.getsize(file_path)
        if PANDAS_AVAILABLE and pd: # Using pandas for robust timestamp conversion
            # Only set OS dates if not already provided by a more specific parser
            if not doc_meta['creation_date']:
                 doc_meta['creation_date_os'] = pd.Timestamp(os.path.getctime(file_path), unit='s').isoformat()
            if not doc_meta['modification_date']:
                 doc_meta['modification_date_os'] = pd.Timestamp(os.path.getmtime(file_path), unit='s').isoformat()
    except Exception as e_os_meta:
        logger.warning(f"Metadata: OS metadata error for {original_file_name}: {e_os_meta}")

    # If page_count is still 0 after parser, estimate from text
    if doc_meta['page_count'] == 0 and processed_text:
        doc_meta['page_count'] = max(1, processed_text.count('\n\n') + 1) # Rough estimate

    # NER (Named Entity Recognition) - using SpaCy
    if processed_text and SPACY_MODEL_LOADED and nlp_spacy_core:
        logger.info(f"Extracting named entities for {original_file_name}...")
        try:
            text_for_ner = processed_text[:MAX_TEXT_LENGTH_FOR_NER] # Use config alias
            spacy_doc = nlp_spacy_core(text_for_ner) # NER pipe should be enabled by default
            
            entities_by_type = {}
            for ent in spacy_doc.ents:
                entities_by_type.setdefault(ent.label_, set()).add(ent.text)
            
            doc_meta['named_entities'] = {label: sorted(list(texts)) for label, texts in entities_by_type.items()}
            num_entities_found = sum(len(v) for v in doc_meta['named_entities'].values())
            logger.info(f"Extracted {num_entities_found} unique named entities for {original_file_name}.")
        except Exception as e_ner:
            logger.error(f"Metadata: NER error for {original_file_name}: {e_ner}", exc_info=True)
    else:
        logger.info(f"Skipping NER for {original_file_name} (no text or SpaCy model not loaded/configured for NER).")
    
    logger.info(f"Metadata extraction complete for {original_file_name}.")
    return doc_meta

# Chunking and Embedding functions remain largely the same as your corrected versions,
# just ensure they consume the correct data.
def chunk_document_into_segments(
    text_to_chunk: str,
    document_level_metadata: Dict[str, Any] # This is the output from extract_document_metadata_info
) -> List[Dict[str, Any]]:
    if not text_to_chunk or not text_to_chunk.strip():
        logger.warning(f"Chunking: No text for {document_level_metadata.get('file_name', 'unknown')}.")
        return []

    if not (LANGCHAIN_SPLITTER_AVAILABLE and RecursiveCharacterTextSplitter):
        logger.error("RecursiveCharacterTextSplitter not available. Cannot chunk text.")
        return []
        
    chunk_s = AI_CORE_CHUNK_SIZE
    chunk_o = AI_CORE_CHUNK_OVERLAP
    original_doc_name_for_log = document_level_metadata.get('file_name', 'unknown_doc')
    logger.info(f"Chunking {original_doc_name_for_log}: Size={chunk_s}, Overlap={chunk_o}")
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_s,
        chunk_overlap=chunk_o,
        length_function=len,
        separators=["\n\n", "\n", ". ", " ", ""], 
        keep_separator=True # Consider if True or False is better for your LLM
    )

    try:
        raw_text_segments: List[str] = text_splitter.split_text(text_to_chunk)
    except Exception as e_split: 
        logger.error(f"Chunking: Error splitting text for {original_doc_name_for_log}: {e_split}", exc_info=True)
        return []
        
    output_chunks: List[Dict[str, Any]] = []
    # Use a more robust base name if original name contains problematic characters for reference
    base_file_name_for_ref = re.sub(r'[^a-zA-Z0-9_-]', '_', os.path.splitext(original_doc_name_for_log)[0])


    for i, segment_content in enumerate(raw_text_segments):
        if not segment_content.strip(): 
            logger.debug(f"Skipping empty chunk at index {i} for {original_doc_name_for_log}.")
            continue

        # Create a deep copy of document-level metadata for each chunk
        chunk_specific_metadata = copy.deepcopy(document_level_metadata)
        
        qdrant_point_id = str(uuid.uuid4()) # Unique ID for this chunk in Qdrant

        # Add chunk-specific details to its metadata
        chunk_specific_metadata['chunk_id'] = qdrant_point_id 
        chunk_specific_metadata['chunk_reference_name'] = f"{base_file_name_for_ref}_chunk_{i:04d}"
        chunk_specific_metadata['chunk_index'] = i
        chunk_specific_metadata['chunk_char_count'] = len(segment_content)
        # Remove potentially very large or redundant fields from chunk metadata if necessary
        # e.g., chunk_specific_metadata.pop('named_entities', None) if too verbose per chunk
        
        output_chunks.append({
            'id': qdrant_point_id, # This ID is for Qdrant
            'text_content': segment_content,
            'metadata': chunk_specific_metadata # This payload goes into Qdrant
        })
    
    logger.info(f"Chunking: Split '{original_doc_name_for_log}' into {len(output_chunks)} non-empty chunks.")
    return output_chunks

def generate_segment_embeddings(document_chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    if not document_chunks: return []
    if not (EMBEDDING_MODEL_LOADED and document_embedding_model):
        logger.error("Embedding model not loaded. Cannot generate embeddings.")
        for chunk_dict in document_chunks: chunk_dict['embedding'] = None
        return document_chunks

    model_name_for_logging = DOCUMENT_EMBEDDING_MODEL_NAME
    logger.info(f"Embedding {len(document_chunks)} chunks using {model_name_for_logging}.")
    
    texts_to_embed: List[str] = []
    valid_chunk_indices: List[int] = [] # To map embeddings back to original chunk objects

    for i, chunk_dict in enumerate(document_chunks):
        text_content = chunk_dict.get('text_content')
        if text_content and text_content.strip():
            texts_to_embed.append(text_content)
            valid_chunk_indices.append(i)
        else:
            chunk_dict['embedding'] = None # Ensure 'embedding' key exists
            logger.debug(f"Embedding: Chunk {chunk_dict.get('id', i)} has no text, skipping.")

    if not texts_to_embed:
        logger.warning("Embedding: No text content found in chunks to generate embeddings.")
        return document_chunks

    try:
        embeddings_np_array = document_embedding_model.encode(texts_to_embed, show_progress_bar=True) # Set to True for long lists
        
        for i, original_chunk_idx in enumerate(valid_chunk_indices):
            if i < len(embeddings_np_array):
                document_chunks[original_chunk_idx]['embedding'] = embeddings_np_array[i].tolist()
            else: # Should not happen if encode works correctly
                logger.error(f"Embedding: Mismatch in embedding count for chunk at original index {original_chunk_idx}.")
                document_chunks[original_chunk_idx]['embedding'] = None
        
        logger.info(f"Embedding: Generated and assigned embeddings to {len(valid_chunk_indices)} chunks.")
    except Exception as e_embed:
        logger.error(f"Embedding: Error during generation with {model_name_for_logging}: {e_embed}", exc_info=True)
        for original_chunk_idx in valid_chunk_indices: # Ensure all attempted chunks get None on error
            document_chunks[original_chunk_idx]['embedding'] = None
            
    return document_chunks


# --- Main Orchestration Function ---
def process_document_for_qdrant(file_path: str, original_name: str, user_id: str) -> tuple[List[Dict[str, Any]], Optional[str], List[Dict[str, Any]]]:
    """
    Main orchestrator for processing a document.
    Returns:
        - final_chunks_for_qdrant: List of chunks with embeddings for Qdrant.
        - text_for_node_analysis: Consolidated text for Node.js general analysis (FAQ, Topics).
        - chunks_for_kg_worker: List of chunks with metadata (no embeddings) for KG worker.
    """
    logger.info(f"ai_core: Orchestrating document processing for '{original_name}', user '{user_id}'")
    if not os.path.exists(file_path):
        logger.error(f"File not found at ai_core entry: {file_path}")
        # Return empty tuple of expected types
        return [], None, []


    # Default return values for failure cases
    empty_qdrant_chunks = []
    no_analysis_text = None
    empty_kg_chunks = []

    try:
        # 1. Initial Parsing (Rich Element Extraction)
        parsed_doc_elements = _get_initial_parsed_document(file_path)
        initial_text_from_parser = parsed_doc_elements.get('text_content')
        images_from_parser = parsed_doc_elements.get('images', [])
        tables_from_parser = parsed_doc_elements.get('tables', [])
        is_scanned_heuristic = parsed_doc_elements.get('is_scanned_heuristic', False)
        file_type_from_parser = os.path.splitext(original_name)[1].lower() # Or get from parsed_doc_elements if available

        # 2. OCR if needed
        ocr_text_output = ""
        ocr_applied_flag = False
        # Decide if OCR is necessary:
        # - Explicitly image file types.
        # - Parser's heuristic says scanned.
        # - Parser extracted no text but found images (strong indicator for OCR).
        # - Parser extracted minimal text and images are present (e.g., a DOCX that's mostly a picture).
        should_ocr = is_scanned_heuristic or \
                     (file_type_from_parser in ['.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif']) or \
                     (not initial_text_from_parser and images_from_parser) or \
                     (initial_text_from_parser and len(initial_text_from_parser) < 200 * len(images_from_parser) and images_from_parser) # Heuristic for low text + images

        if should_ocr and images_from_parser:
            if PYTESSERACT_AVAILABLE and pytesseract:
                logger.info(f"OCR triggered for {original_name} based on heuristics/file type.")
                ocr_text_output = perform_ocr_on_images(images_from_parser, original_name)
                if ocr_text_output: ocr_applied_flag = True
            else:
                logger.warning(f"OCR needed for {original_name} but Pytesseract not available. Content may be incomplete.")
        
        # 3. Combine Text (Parser + OCR)
        combined_raw_text_parts = []
        if initial_text_from_parser: combined_raw_text_parts.append(initial_text_from_parser)
        if ocr_text_output: combined_raw_text_parts.append(ocr_text_output)
        combined_raw_text = "\n\n".join(combined_raw_text_parts).strip()

        if not combined_raw_text and not tables_from_parser:
            logger.warning(f"No text content or tables for {original_name} after initial parsing/OCR. Processing cannot continue.")
            return empty_qdrant_chunks, no_analysis_text, empty_kg_chunks

        # 4. Clean Text
        cleaned_text = clean_and_normalize_text_content(combined_raw_text, original_name)
        if not cleaned_text and not tables_from_parser: # If cleaning results in empty text
            logger.warning(f"No meaningful text for {original_name} after cleaning, and no tables. Processing cannot continue.")
            return empty_qdrant_chunks, no_analysis_text, empty_kg_chunks

        # 5. Reconstruct Layout (Integrate Tables as Markdown)
        text_for_further_processing = reconstruct_document_layout(
            cleaned_text, # Use the cleaned text
            tables_from_parser,
            file_type_from_parser,
            original_name
        )
        # This `text_for_further_processing` is a good candidate for Node.js analysis (FAQ, topics)
        # as it's cleaned and has table context.
        raw_text_for_node_analysis = text_for_further_processing 

        # 6. Extract Comprehensive Metadata
        doc_metadata = extract_document_metadata_info(
            file_path,
            text_for_further_processing, # Pass the final text that will be chunked
            parsed_doc_elements, # Pass the full initial parse results
            original_name,
            user_id
        )
        doc_metadata['ocr_applied'] = ocr_applied_flag # Update with actual OCR status

        # 7. Chunk Document
        # We chunk `text_for_further_processing` which includes table representations.
        chunks_with_metadata_for_qdrant_and_kg = chunk_document_into_segments(
            text_for_further_processing,
            doc_metadata # Pass rich metadata to chunks
        )
        if not chunks_with_metadata_for_qdrant_and_kg:
            logger.warning(f"No chunks produced for {original_name}. Cannot proceed with Qdrant/KG.")
            # Still return raw_text_for_node_analysis if it exists
            return empty_qdrant_chunks, raw_text_for_node_analysis, empty_kg_chunks

        # Prepare chunks for KG worker (these don't need embeddings yet)
        # Important: Deep copy if you modify this list before embedding,
        # or if embedding modifies in-place (unlikely with current generate_segment_embeddings)
        chunks_for_kg_worker = copy.deepcopy(chunks_with_metadata_for_qdrant_and_kg) 
        # Remove embedding from KG chunks if it somehow got there, or any very large fields not needed by KG LLM
        for chunk in chunks_for_kg_worker:
            chunk.pop('embedding', None) 
            # Consider removing other large metadata fields if KG LLM doesn't need them from each chunk's metadata

        # 8. Generate Embeddings for Qdrant chunks
        final_chunks_for_qdrant = generate_segment_embeddings(chunks_with_metadata_for_qdrant_and_kg)
        
        logger.info(f"ai_core: Successfully processed '{original_name}'. Generated {len(final_chunks_for_qdrant)} chunks for Qdrant.")
        return final_chunks_for_qdrant, raw_text_for_node_analysis, chunks_for_kg_worker

    except Exception as e:
        # Check for specific critical errors like Tesseract not found
        if TESSERACT_ERROR and isinstance(e, TESSERACT_ERROR):
            logger.critical(f"ai_core: Tesseract (OCR) not found processing {original_name}. OCR failed. Error: {e}", exc_info=False)
            # Depending on policy, you might still want to return any text extracted *before* OCR attempt.
            # For now, re-raise to indicate critical failure to the caller (app.py).
            raise
        
        logger.error(f"ai_core: Critical error processing {original_name}: {e}", exc_info=True)
        # Re-raise the exception to be handled by the caller in app.py
        raise
```

`server/rag_service/app.py`

```python
# server/rag_service/app.py

import os
import sys
import traceback
from flask import Flask, request, jsonify, current_app
import logging
import atexit # For graceful shutdown

# --- Add server directory to sys.path ---
SERVER_DIR = os.path.dirname(os.path.abspath(__file__))
if SERVER_DIR not in sys.path:
    sys.path.insert(0, SERVER_DIR)

import config
config.setup_logging() # Initialize logging as per your config

# --- Import configurations and services ---
try:
    from vector_db_service import VectorDBService
    import ai_core
    import neo4j_handler 
    from neo4j import exceptions as neo4j_exceptions # For specific error handling
except ImportError as e:
    print(f"CRITICAL IMPORT ERROR: {e}. Ensure all modules are correctly placed and server directory is in PYTHONPATH.")
    print("PYTHONPATH:", sys.path)
    sys.exit(1)

logger = logging.getLogger(__name__)
app = Flask(__name__)

# --- Initialize VectorDBService (Qdrant) ---
vector_service = None
try:
    logger.info("Initializing VectorDBService for Qdrant...")
    vector_service = VectorDBService()
    vector_service.setup_collection()
    app.vector_service = vector_service
    logger.info("VectorDBService initialized and Qdrant collection setup successfully.")
except Exception as e:
    logger.critical(f"Failed to initialize VectorDBService or setup Qdrant collection: {e}", exc_info=True)
    app.vector_service = None

# --- Initialize Neo4j Driver (via handler) ---
try:
    neo4j_handler.init_driver() # Initialize Neo4j driver on app start
except Exception as e:
    logger.critical(f"Neo4j driver failed to initialize on startup: {e}. KG endpoints will likely fail.")
    # Depending on how critical Neo4j is, you might sys.exit(1) here.

# Register Neo4j driver close function for app exit
atexit.register(neo4j_handler.close_driver)


# --- Helper for Error Responses ---
def create_error_response(message, status_code=500, details=None):
    log_message = f"API Error ({status_code}): {message}"
    if details:
        log_message += f" | Details: {details}"
    current_app.logger.error(log_message)
    response_payload = {"error": message}
    if details and status_code != 500:
        response_payload["details"] = details
    return jsonify(response_payload), status_code

# === API Endpoints ===

@app.route('/health', methods=['GET'])
def health_check():
    current_app.logger.info("--- Health Check Request ---")
    # ... (Qdrant health check part from your existing code) ...
    status_details = {
        "status": "error",
        "qdrant_service": "not_initialized",
        "qdrant_collection_name": config.QDRANT_COLLECTION_NAME,
        "qdrant_collection_status": "unknown",
        "document_embedding_model": config.DOCUMENT_EMBEDDING_MODEL_NAME,
        "query_embedding_model": config.QUERY_EMBEDDING_MODEL_NAME,
        "neo4j_service": "not_initialized_via_handler", # Updated message
        "neo4j_connection": "unknown"
    }
    http_status_code = 503

    # Qdrant Check
    if not vector_service:
        status_details["qdrant_service"] = "failed_to_initialize"
    else:
        status_details["qdrant_service"] = "initialized"
        try:
            vector_service.client.get_collection(collection_name=vector_service.collection_name)
            status_details["qdrant_collection_status"] = "exists_and_accessible"
        except Exception as e:
            status_details["qdrant_collection_status"] = f"error_accessing_collection: {str(e)}"
            current_app.logger.error(f"Health check: Error accessing Qdrant collection: {e}", exc_info=False)
    
    # Neo4j Check
    neo4j_ok, neo4j_conn_status = neo4j_handler.check_neo4j_connectivity()
    if neo4j_ok:
        status_details["neo4j_service"] = "initialized_via_handler"
        status_details["neo4j_connection"] = "connected"
    else:
        status_details["neo4j_service"] = "initialization_failed_or_handler_error"
        status_details["neo4j_connection"] = neo4j_conn_status


    if status_details["qdrant_service"] == "initialized" and \
       status_details["qdrant_collection_status"] == "exists_and_accessible" and \
       neo4j_ok: # Check the boolean return from neo4j_handler
        status_details["status"] = "ok"
        http_status_code = 200
        current_app.logger.info("Health check successful (Qdrant & Neo4j).")
    else:
        current_app.logger.warning(f"Health check issues found: Qdrant service: {status_details['qdrant_service']}, Qdrant collection: {status_details['qdrant_collection_status']}, Neo4j service: {status_details['neo4j_service']}, Neo4j connection: {status_details['neo4j_connection']}")
        
    return jsonify(status_details), http_status_code

@app.route('/add_document', methods=['POST'])
def add_document_qdrant():
    # ... (your existing /add_document endpoint logic)
    # This remains unchanged as it deals with Qdrant.
    current_app.logger.info("--- /add_document Request (Qdrant) ---")
    if not request.is_json:
        return create_error_response("Request must be JSON", 400)

    if not vector_service:
        return create_error_response("VectorDBService (Qdrant) is not available.", 503)

    data = request.get_json()
    user_id = data.get('user_id')
    file_path = data.get('file_path')
    original_name = data.get('original_name')

    if not all([user_id, file_path, original_name]):
        return create_error_response("Missing required fields: user_id, file_path, original_name", 400)

    current_app.logger.info(f"Processing file: '{original_name}' (Path: '{file_path}') for user: '{user_id}' for Qdrant")

    if not os.path.exists(file_path):
        current_app.logger.error(f"File not found at server path: {file_path}")
        return create_error_response(f"File not found at server path: {file_path}", 404)

    try:
        current_app.logger.info(f"Calling ai_core to process document: '{original_name}' for Qdrant")
        # ai_core.process_document_for_qdrant returns: processed_chunks_with_embeddings, raw_text_for_node_analysis, chunks_with_metadata
        processed_chunks_with_embeddings, raw_text_for_node_analysis, chunks_with_metadata_for_kg = ai_core.process_document_for_qdrant(
            file_path=file_path,
            original_name=original_name,
            user_id=user_id
        )
        
        num_chunks_added_to_qdrant = 0
        processing_status = "processed_no_content_for_qdrant"

        if processed_chunks_with_embeddings:
            current_app.logger.info(f"ai_core generated {len(processed_chunks_with_embeddings)} chunks for '{original_name}'. Adding to Qdrant.")
            num_chunks_added_to_qdrant = app.vector_service.add_processed_chunks(processed_chunks_with_embeddings)
            if num_chunks_added_to_qdrant > 0:
                processing_status = "added_to_qdrant"
            else:
                processing_status = "processed_qdrant_chunks_not_added"
        elif raw_text_for_node_analysis:
             current_app.logger.info(f"ai_core produced no processable Qdrant chunks for '{original_name}', but raw text was extracted.")
             processing_status = "processed_for_analysis_only_no_qdrant"
        else:
            current_app.logger.warning(f"ai_core produced no Qdrant chunks and no raw text for '{original_name}'.")
            return jsonify({
                "message": f"Processed '{original_name}' but no content was extracted for Qdrant or analysis.",
                "status": "no_content_extracted",
                "filename": original_name,
                "user_id": user_id,
                "num_chunks_added_to_qdrant": 0,
                "raw_text_for_analysis": ""
            }), 200

        response_payload = {
            "message": f"Successfully processed '{original_name}' for Qdrant. Status: {processing_status}.",
            "status": "added",
            "filename": original_name,
            "user_id": user_id,
            "num_chunks_added_to_qdrant": num_chunks_added_to_qdrant,
            "raw_text_for_analysis": raw_text_for_node_analysis if raw_text_for_node_analysis is not None else "",
            "chunks_with_metadata": chunks_with_metadata_for_kg # Pass this to Node.js for KG worker
        }
        current_app.logger.info(f"Successfully processed '{original_name}' for Qdrant. Returning raw text and Qdrant status.")
        return jsonify(response_payload), 201

    except FileNotFoundError as e:
        current_app.logger.error(f"Add Document (Qdrant) Error for '{original_name}' - FileNotFoundError: {e}", exc_info=True)
        return create_error_response(f"File not found during Qdrant processing: {str(e)}", 404)
    except config.TESSERACT_ERROR:
        current_app.logger.critical(f"Add Document (Qdrant) Error for '{original_name}' - Tesseract (OCR) not found.")
        return create_error_response("OCR engine (Tesseract) not found or not configured correctly on the server.", 500)
    except ValueError as e:
        current_app.logger.error(f"Add Document (Qdrant) Error for '{original_name}' - ValueError: {e}", exc_info=True)
        return create_error_response(f"Configuration or data error for Qdrant: {str(e)}", 400)
    except Exception as e:
        current_app.logger.error(f"Add Document (Qdrant) Error for '{original_name}' - Unexpected Exception: {e}\n{traceback.format_exc()}", exc_info=True)
        return create_error_response(f"Failed to process document '{original_name}' for Qdrant due to an internal error.", 500)


@app.route('/query', methods=['POST'])
def search_qdrant_documents_and_get_kg(): # Renamed for clarity
    current_app.logger.info("--- /query Request (Qdrant Search + Optional KG Retrieval) ---")
    if not request.is_json:
        return create_error_response("Request must be JSON", 400)

    if not vector_service: # Assuming vector_service is your initialized VectorDBService instance
        return create_error_response("VectorDBService (Qdrant) is not available.", 503)
    
    data = request.get_json()
    current_app.logger.info(f"--- /query RAW REQUEST DATA: {data} ---") # Log raw request
    
    query_text = data.get('query')
    user_id_from_request = data.get('user_id')
    k = data.get('k', config.QDRANT_DEFAULT_SEARCH_K)
    filter_payload_from_request = data.get('filter') # This is the Qdrant filter from client
    documentContextName = data.get('documentContextName') # For specific document filtering
    use_kg_for_critical_thinking = data.get('use_kg_critical_thinking', False) 
    
    current_app.logger.info(f"KG Critical Thinking Requested: {use_kg_for_critical_thinking}")
    if documentContextName:
        current_app.logger.info(f"Document Context Name for filtering: '{documentContextName}'")
    if filter_payload_from_request:
        current_app.logger.info(f"Client-provided filter payload: {filter_payload_from_request}")


    # Check Neo4j driver availability ONLY if KG is requested
    if use_kg_for_critical_thinking:
        try:
            neo4j_handler.get_driver_instance() 
        except ConnectionError: 
            current_app.logger.error("Neo4j driver unavailable but KG was requested.")
            return create_error_response("Knowledge Graph service (Neo4j) is not available, but KG retrieval was requested.", 503)
        except Exception as e: 
            current_app.logger.error(f"Error checking Neo4j driver availability: {e}")
            return create_error_response(f"Error initializing Knowledge Graph service: {str(e)}", 503)


    if not query_text:
        return create_error_response("Missing 'query' field in request body", 400)
    if not user_id_from_request:
        return create_error_response("Missing 'user_id' field in request body", 400)

    try:
        k = int(k)
    except ValueError:
        return create_error_response("'k' must be an integer", 400)

    # --- Qdrant Filter Setup (Revised Logic) ---
    qdrant_filters = None 

    try:
        from qdrant_client import models as qdrant_models
    except ImportError:
        current_app.logger.error("qdrant_client library is not installed. Cannot build filters.")
        return create_error_response("Internal server error: Qdrant client library missing.", 500)

    must_conditions = [] # List to hold all conditions to be ANDed

    # 1. Add filter from `documentContextName` if provided
    if documentContextName:
        current_app.logger.info(f"Condition for documentContextName: '{documentContextName}' on field 'file_name' will be added to 'must' conditions.")
        must_conditions.append(qdrant_models.FieldCondition(
            key="file_name",  # IMPORTANT: This key MUST match the field name in your Qdrant payload
            match=qdrant_models.MatchValue(value=documentContextName)
        ))

    # 2. Add filters from `filter_payload_from_request` if provided
    #    (assuming it's a simple key-value dict for FieldConditions)
    if filter_payload_from_request and isinstance(filter_payload_from_request, dict):
        current_app.logger.info(f"Processing Qdrant filters from client payload (simple key-value): {filter_payload_from_request}")
        for key, value in filter_payload_from_request.items():
            if isinstance(key, str) and isinstance(value, (str, int, float, bool)):
                 current_app.logger.info(f"Condition for client filter: key='{key}', value='{value}' will be added to 'must' conditions.")
                 must_conditions.append(qdrant_models.FieldCondition(key=key, match=qdrant_models.MatchValue(value=value)))
            else:
                current_app.logger.warning(f"Skipping invalid client filter condition: key='{key}', value='{value}'. Key must be string, value must be primitive.")

    # 3. Construct the final qdrant_filters object if any conditions were added
    if must_conditions:
        qdrant_filters = qdrant_models.Filter(must=must_conditions)
        try:
            filter_dict_for_log = qdrant_filters.model_dump() # Try Pydantic V2 method
        except AttributeError:
            try:
                filter_dict_for_log = qdrant_filters.dict() # Try Pydantic V1 method
            except AttributeError:
                filter_dict_for_log = str(qdrant_filters) # Fallback
        current_app.logger.info(f"Final Qdrant filter to be applied: {filter_dict_for_log}")
    else:
        current_app.logger.info("No Qdrant filter explicitly provided or derived for this query.")
    
    current_app.logger.info(f"Performing Qdrant search for user '{user_id_from_request}', query (first 50): '{query_text[:50]}...' with k={k}")

    try:
        # 1. Perform Qdrant Search
        qdrant_retrieved_docs, formatted_context_snippet, qdrant_docs_map = vector_service.search_documents(
            query=query_text,
            k=k,
            filter_conditions=qdrant_filters # Pass the combined filters
        )

        # 2. Conditionally Prepare KG Retrieval based on Qdrant results
        knowledge_graphs_data = {} 
        
        if use_kg_for_critical_thinking and qdrant_retrieved_docs:
            current_app.logger.info("KG retrieval is ENABLED and Qdrant returned documents.")
            unique_doc_names_for_kg = set()
            for doc_obj in qdrant_retrieved_docs:
                doc_payload = doc_obj.payload if hasattr(doc_obj, 'payload') else doc_obj.metadata
                
                doc_name_for_kg = None
                if documentContextName: 
                    doc_name_for_kg = documentContextName
                else: 
                    doc_name_for_kg = doc_payload.get('documentName', doc_payload.get('original_name', doc_payload.get('file_name')))
                
                if doc_name_for_kg:
                    unique_doc_names_for_kg.add(doc_name_for_kg)
                else:
                    qdrant_doc_id = doc_obj.id if hasattr(doc_obj, 'id') else doc_payload.get('qdrant_id', 'N/A')
                    current_app.logger.warning(f"Qdrant doc payload missing document identifier for chunk ID {qdrant_doc_id}. Cannot fetch KG.")
            
            current_app.logger.info(f"Found {len(unique_doc_names_for_kg)} unique document(s) in Qdrant results to fetch KGs for: {list(unique_doc_names_for_kg)}")

            for doc_name in unique_doc_names_for_kg:
                try:
                    current_app.logger.info(f"Fetching KG for document '{doc_name}' (User: {user_id_from_request})")
                    kg_content = neo4j_handler.get_knowledge_graph(user_id_from_request, doc_name)
                    if kg_content and (kg_content.get("nodes") or kg_content.get("edges")): 
                        knowledge_graphs_data[doc_name] = kg_content
                        current_app.logger.info(f"Successfully retrieved KG for '{doc_name}'. Nodes: {len(kg_content.get('nodes',[]))}, Edges: {len(kg_content.get('edges',[]))}")
                    else:
                        current_app.logger.info(f"No KG data found in Neo4j for document '{doc_name}' (User: {user_id_from_request}).")
                        knowledge_graphs_data[doc_name] = {"nodes": [], "edges": [], "message": "KG not found or contains no data"}
                except Exception as kg_err: 
                    current_app.logger.error(f"Error retrieving KG for document '{doc_name}': {kg_err}", exc_info=True)
                    knowledge_graphs_data[doc_name] = {"nodes": [], "edges": [], "error": f"Failed to retrieve KG: {str(kg_err)}"}
        elif not use_kg_for_critical_thinking:
            current_app.logger.info("KG retrieval is DISABLED by request.")
        elif not qdrant_retrieved_docs:
            current_app.logger.info("KG retrieval was requested, but no documents were found by Qdrant. Skipping KG fetch.")


        # 3. Construct Final Response Payload
        response_payload = {
            "query": query_text,
            "k_requested": k,
            "user_id_processed": user_id_from_request,
            "qdrant_filter_applied": { 
                "client_filter": filter_payload_from_request, # What was received
                "document_context_filter": documentContextName # What was received
            },
            "qdrant_results_count": len(qdrant_retrieved_docs),
            "formatted_context_snippet": formatted_context_snippet,
            "retrieved_documents_map": qdrant_docs_map,
            "retrieved_documents_list": [doc.to_dict() for doc in qdrant_retrieved_docs],
            "knowledge_graphs": knowledge_graphs_data, 
            "kg_retrieval_attempted": use_kg_for_critical_thinking and bool(qdrant_retrieved_docs)
        }
        
        log_message_kg_part = "and KGs" if use_kg_for_critical_thinking and any(v.get("nodes") or v.get("edges") for v in knowledge_graphs_data.values() if isinstance(v,dict)) else ("and KG retrieval was SKIPPED" if not use_kg_for_critical_thinking else "and no KGs found/retrieved")
        current_app.logger.info(f"Qdrant search {log_message_kg_part} successful. Returning {len(qdrant_retrieved_docs)} Qdrant docs.")
        return jsonify(response_payload), 200

    except ConnectionError as ce:
        current_app.logger.error(f"Service connection error during /query processing: {ce}", exc_info=True)
        return create_error_response(f"A dependent service is unavailable: {str(ce)}", 503)
    except Exception as e:
        # import traceback # Ensure traceback is imported if you use .format_exc()
        current_app.logger.error(f"/query processing failed: {e}\n{traceback.format_exc()}", exc_info=True)
        return create_error_response(f"Error during query processing: {str(e)}", 500)



@app.route('/delete_qdrant_document_data', methods=['DELETE']) # Ensure this route is defined
def delete_qdrant_data_route():
    current_app.logger.info("--- DELETE /delete_qdrant_document_data Request ---")
    if not request.is_json:
        return create_error_response("Request must be JSON", 400)

    if not vector_service:
        return create_error_response("VectorDBService (Qdrant) is not available.", 503)

    data = request.get_json()
    user_id = data.get('user_id')
    document_name = data.get('document_name') 

    if not user_id or not document_name:
        return create_error_response("Missing 'user_id' or 'document_name' in request body.", 400)

    try:
        # This assumes you have a method 'delete_document_vectors' in your vector_service
        result = vector_service.delete_document_vectors(user_id, document_name) 
        
        if result.get("success"):
            return jsonify({"message": result.get("message", "Qdrant vectors for document processed for deletion.")}), 200
        else:
            return create_error_response(result.get("message", "Failed to delete Qdrant vectors."), 500) # Or a more specific code
            
    except ConnectionError as ce:
        current_app.logger.error(f"Qdrant connection error during /delete_qdrant_document_data for user {user_id}, doc {document_name}: {ce}", exc_info=True)
        return create_error_response(f"Qdrant service connection error: {str(ce)}", 503)
    except Exception as e:
        current_app.logger.error(f"/delete_qdrant_document_data for user {user_id}, doc {document_name} failed: {e}", exc_info=True)
        return create_error_response(f"Error during Qdrant data deletion: {str(e)}", 500)

# === KG (Neo4j) Endpoints ===

@app.route('/kg', methods=['POST'])
def add_or_update_kg_route():
    current_app.logger.info("--- POST /kg Request (Neo4j Ingestion) ---")
    if not request.is_json:
        return create_error_response("Request must be JSON", 400)

    data = request.get_json()
    user_id = data.get('userId') # Key from Node.js
    original_name = data.get('originalName') # Key from Node.js
    nodes = data.get('nodes')
    edges = data.get('edges')

    if not all([user_id, original_name, isinstance(nodes, list), isinstance(edges, list)]):
        missing_fields = []
        if not user_id: missing_fields.append("userId")
        if not original_name: missing_fields.append("originalName")
        if not isinstance(nodes, list): missing_fields.append("nodes (must be a list)")
        if not isinstance(edges, list): missing_fields.append("edges (must be a list)")
        return create_error_response(f"Missing or invalid fields: {', '.join(missing_fields)}", 400,
                                     details=f"Received: userId type {type(user_id)}, originalName type {type(original_name)}, nodes type {type(nodes)}, edges type {type(edges)}")

    logger.info(f"Attempting to ingest KG for user '{user_id}', document '{original_name}'. Nodes: {len(nodes)}, Edges: {len(edges)}")

    try:
        result = neo4j_handler.ingest_knowledge_graph(user_id, original_name, nodes, edges)
        if result["success"]:
            return jsonify({
                "message": result["message"],
                "userId": user_id,
                "documentName": original_name, # Consistent key name
                "nodes_affected": result["nodes_affected"],
                "edges_affected": result["edges_affected"],
                "status": "completed" # Status field as expected by Node.js
            }), 201
        else: # Should not happen if ingest_knowledge_graph raises on error
            return create_error_response(result.get("message", "KG ingestion failed."), 500)
            
    except ConnectionError as e:
        logger.error(f"Neo4j connection error during KG ingestion for '{original_name}': {e}", exc_info=True)
        return create_error_response(f"Neo4j connection error: {str(e)}. Please check service.", 503)
    except neo4j_exceptions.Neo4jError as e:
        logger.error(f"Neo4jError during KG ingestion for '{original_name}': {e}", exc_info=True)
        return create_error_response(f"Neo4j database error: {e.message}", 500)
    except Exception as e:
        logger.error(f"Unexpected error during KG ingestion for '{original_name}': {e}\n{traceback.format_exc()}", exc_info=True)
        return create_error_response(f"Failed to ingest Knowledge Graph: {str(e)}", 500)


@app.route('/kg/<user_id>/<path:document_name>', methods=['GET']) # Use <path:document_name> to allow slashes
def get_kg_route(user_id, document_name):
    current_app.logger.info(f"--- GET /kg/{user_id}/{document_name} Request (Neo4j Retrieval) ---")

    # Basic sanitization (you might want more robust URL segment sanitization if needed)
    sanitized_user_id = user_id.replace("..","").strip()
    sanitized_document_name = document_name.replace("..","").strip()

    if not sanitized_user_id or not sanitized_document_name:
        return create_error_response("User ID and Document Name URL parameters are required and cannot be empty.", 400)

    logger.info(f"Retrieving KG for user '{sanitized_user_id}', document '{sanitized_document_name}'.")

    try:
        kg_data = neo4j_handler.get_knowledge_graph(sanitized_user_id, sanitized_document_name)

        if kg_data is None: # Handler returns None if not found
            logger.info(f"No KG data found for user '{sanitized_user_id}', document '{sanitized_document_name}'.")
            return create_error_response("Knowledge Graph not found for the specified user and document.", 404)

        logger.info(f"Successfully retrieved KG for document '{sanitized_document_name}'. Nodes: {len(kg_data.get('nodes',[]))}, Edges: {len(kg_data.get('edges',[]))}")
        return jsonify(kg_data), 200

    except ConnectionError as e:
        logger.error(f"Neo4j connection error during KG retrieval: {e}", exc_info=True)
        return create_error_response(f"Neo4j connection error: {str(e)}. Please check service.", 503)
    except neo4j_exceptions.Neo4jError as e:
        logger.error(f"Neo4jError during KG retrieval: {e}", exc_info=True)
        return create_error_response(f"Neo4j database error: {e.message}", 500)
    except Exception as e:
        logger.error(f"Unexpected error during KG retrieval: {e}\n{traceback.format_exc()}", exc_info=True)
        return create_error_response(f"Failed to retrieve Knowledge Graph: {str(e)}", 500)


@app.route('/kg/<user_id>/<path:document_name>', methods=['DELETE']) # Use <path:document_name>
def delete_kg_route(user_id, document_name):
    current_app.logger.info(f"--- DELETE /kg/{user_id}/{document_name} Request (Neo4j Deletion) ---")

    sanitized_user_id = user_id.replace("..","").strip()
    sanitized_document_name = document_name.replace("..","").strip()

    if not sanitized_user_id or not sanitized_document_name:
        return create_error_response("User ID and Document Name URL parameters are required and cannot be empty.", 400)

    logger.info(f"Attempting to delete KG for user '{sanitized_user_id}', document '{sanitized_document_name}'.")

    try:
        deleted = neo4j_handler.delete_knowledge_graph(sanitized_user_id, sanitized_document_name)
        if deleted:
            logger.info(f"Knowledge Graph for document '{sanitized_document_name}' (User: {sanitized_user_id}) deleted successfully.")
            return jsonify({"message": "Knowledge Graph deleted successfully."}), 200
        else:
            logger.info(f"No Knowledge Graph found for document '{sanitized_document_name}' (User: {sanitized_user_id}) to delete.")
            return create_error_response("Knowledge Graph not found for deletion.", 404)

    except ConnectionError as e:
        logger.error(f"Neo4j connection error during KG deletion: {e}", exc_info=True)
        return create_error_response(f"Neo4j connection error: {str(e)}. Please check service.", 503)
    except neo4j_exceptions.Neo4jError as e:
        logger.error(f"Neo4jError during KG deletion: {e}", exc_info=True)
        return create_error_response(f"Neo4j database error: {e.message}", 500)
    except Exception as e:
        logger.error(f"Unexpected error during KG deletion: {e}\n{traceback.format_exc()}", exc_info=True)
        return create_error_response(f"Failed to delete Knowledge Graph: {str(e)}", 500)


if __name__ == '__main__':
    logger.info(f"--- Starting RAG API Service (with KG) on port {config.API_PORT} ---")
    logger.info(f"Qdrant Host: {config.QDRANT_HOST}, Port: {config.QDRANT_PORT}, Collection: {config.QDRANT_COLLECTION_NAME}")
    logger.info(f"Neo4j URI: {config.NEO4J_URI}, User: {config.NEO4J_USERNAME}, DB: {config.NEO4J_DATABASE}")
    logger.info(f"Document Embedding Model (ai_core): {config.DOCUMENT_EMBEDDING_MODEL_NAME} (Dim: {config.DOCUMENT_VECTOR_DIMENSION})")
    logger.info(f"Query Embedding Model (vector_db_service): {config.QUERY_EMBEDDING_MODEL_NAME} (Dim: {config.QUERY_VECTOR_DIMENSION})")
    
    app.run(host='0.0.0.0', port=config.API_PORT, debug=True) # debug=True for development
```

`server/rag_service/config.py`

```python
# server/config.py
import os
import logging

# ─── Logging Configuration ───────────────────────────
logger = logging.getLogger(__name__)
LOGGING_LEVEL_NAME = os.getenv('LOGGING_LEVEL', 'INFO').upper()
LOGGING_LEVEL      = getattr(logging, LOGGING_LEVEL_NAME, logging.INFO)
LOGGING_FORMAT     = '%(asctime)s - %(levelname)s - [%(name)s:%(lineno)d] - %(message)s'

# === Base Directory ===
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
logger.info(f"[Config] Base Directory: {BASE_DIR}")



def setup_logging():
    """Configure logging across the app."""
    root_logger = logging.getLogger()
    if not root_logger.handlers:  # prevent duplicate handlers
        handler = logging.StreamHandler()
        formatter = logging.Formatter(LOGGING_FORMAT)
        handler.setFormatter(formatter)
        root_logger.addHandler(handler)
        root_logger.setLevel(LOGGING_LEVEL)

    logging.getLogger("urllib3").setLevel(logging.WARNING)
    logging.getLogger("httpx").setLevel(logging.WARNING)
    logging.getLogger("faiss.loader").setLevel(logging.WARNING)
    logging.getLogger(__name__).info(f"Logging initialized at {LOGGING_LEVEL_NAME}")

NEO4J_URI = os.getenv("NEO4J_URI", "bolt://localhost:7687")
NEO4J_USERNAME = os.getenv("NEO4J_USERNAME", "neo4j")
NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD", "password") # IMPORTANT: Change this default or use ENV VAR!
NEO4J_DATABASE = os.getenv("NEO4J_DATABASE", "neo4j")
# === Embedding Model Configuration ===
DEFAULT_DOC_EMBED_MODEL = 'mixedbread-ai/mxbai-embed-large-v1'
DOCUMENT_EMBEDDING_MODEL_NAME = os.getenv('DOCUMENT_EMBEDDING_MODEL_NAME', DEFAULT_DOC_EMBED_MODEL)
MAX_TEXT_LENGTH_FOR_NER = int(os.getenv("MAX_TEXT_LENGTH_FOR_NER", 500000))
logger.info(f"[Config] Document Embedding Model: {DOCUMENT_EMBEDDING_MODEL_NAME}")

# Model dimension mapping
_MODEL_TO_DIM_MAPPING = {
    'mixedbread-ai/mxbai-embed-large-v1': 1024,
    'BAAI/bge-large-en-v1.5': 1024,
    'all-MiniLM-L6-v2': 384,
    'sentence-transformers/all-mpnet-base-v2': 768,
}
_FALLBACK_DIM = 768

DOCUMENT_VECTOR_DIMENSION = int(os.getenv(
    "DOCUMENT_VECTOR_DIMENSION",
    _MODEL_TO_DIM_MAPPING.get(DOCUMENT_EMBEDDING_MODEL_NAME, _FALLBACK_DIM)
))
logger.info(f"[Config] Document Vector Dimension: {DOCUMENT_VECTOR_DIMENSION}")

# === AI Core Chunking Config ===
AI_CORE_CHUNK_SIZE = int(os.getenv("AI_CORE_CHUNK_SIZE", 512))
AI_CORE_CHUNK_OVERLAP = int(os.getenv("AI_CORE_CHUNK_OVERLAP", 100))
logger.info(f"[Config] Chunk Size: {AI_CORE_CHUNK_SIZE}, Overlap: {AI_CORE_CHUNK_OVERLAP}")

# === SpaCy Configuration ===
SPACY_MODEL_NAME = os.getenv('SPACY_MODEL_NAME', 'en_core_web_sm')
logger.info(f"[Config] SpaCy Model: {SPACY_MODEL_NAME}")

# === Qdrant Configuration ===
QDRANT_HOST = os.getenv("QDRANT_HOST", "localhost")
QDRANT_PORT = int(os.getenv("QDRANT_PORT", 6333))
QDRANT_COLLECTION_NAME = os.getenv("QDRANT_COLLECTION_NAME", "my_qdrant_rag_collection")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY", None)
QDRANT_URL = os.getenv("QDRANT_URL", None)

QDRANT_COLLECTION_VECTOR_DIM = DOCUMENT_VECTOR_DIMENSION
logger.info(f"[Config] Qdrant Vector Dimension: {QDRANT_COLLECTION_VECTOR_DIM}")

# === Query Embedding Configuration ===
QUERY_EMBEDDING_MODEL_NAME = os.getenv("QUERY_EMBEDDING_MODEL_NAME", DOCUMENT_EMBEDDING_MODEL_NAME)
QUERY_VECTOR_DIMENSION = int(os.getenv(
    "QUERY_VECTOR_DIMENSION",
    _MODEL_TO_DIM_MAPPING.get(QUERY_EMBEDDING_MODEL_NAME, _FALLBACK_DIM)
))

if QUERY_VECTOR_DIMENSION != QDRANT_COLLECTION_VECTOR_DIM:
    logger.info(f"[⚠️ Config Warning] Query vector dim ({QUERY_VECTOR_DIMENSION}) != Qdrant dim ({QDRANT_COLLECTION_VECTOR_DIM})")
    # Optionally enforce consistency
    # raise ValueError("Query and Document vector dimensions do not match!")
else:
    logger.info(f"[Config] Query Model: {QUERY_EMBEDDING_MODEL_NAME}")
    logger.info(f"[Config] Query Vector Dimension: {QUERY_VECTOR_DIMENSION}")

QDRANT_DEFAULT_SEARCH_K = int(os.getenv("QDRANT_DEFAULT_SEARCH_K", 5))
QDRANT_SEARCH_MIN_RELEVANCE_SCORE = float(os.getenv("QDRANT_SEARCH_MIN_RELEVANCE_SCORE", 0.1))

# === API Port Configuration ===
API_PORT = int(os.getenv('API_PORT', 5000))
logger.info(f"[Config] API Running Port: {API_PORT}")

# === Optional: Tesseract OCR Path (uncomment if used) ===
# TESSERACT_CMD = os.getenv('TESSERACT_CMD')
# if TESSERACT_CMD:
#     import pytesseract
#     pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD
#     logger.info(f"[Config] Tesseract Path: {TESSERACT_CMD}")


# ─── Library Availability Flags ──────────────────────
try:
    import pypdf
    PYPDF_AVAILABLE      = True
    PYPDF_PDFREADERROR   = pypdf.errors.PdfReadError
except ImportError:
    PYPDF_AVAILABLE      = False
    PYPDF_PDFREADERROR   = Exception

try:
    from docx import Document as DocxDocument
    DOCX_AVAILABLE       = True
except ImportError:
    DOCX_AVAILABLE       = False
    DocxDocument         = None

try:
    from pptx import Presentation
    PPTX_AVAILABLE       = True
except ImportError:
    PPTX_AVAILABLE       = False
    Presentation         = None

try:
    import pdfplumber
    PDFPLUMBER_AVAILABLE = True
except ImportError:
    PDFPLUMBER_AVAILABLE = False
    pdfplumber           = None

try:
    import pandas as pd
    PANDAS_AVAILABLE     = True
except ImportError:
    PANDAS_AVAILABLE     = False
    pd                   = None

try:
    from PIL import Image
    PIL_AVAILABLE        = True
except ImportError:
    PIL_AVAILABLE        = False
    Image                = None

try:
    import fitz
    FITZ_AVAILABLE       = True
except ImportError:
    FITZ_AVAILABLE       = False
    fitz                 = None

try:
    import pytesseract
    PYTESSERACT_AVAILABLE = True
    TESSERACT_ERROR       = pytesseract.TesseractNotFoundError
except ImportError:
    PYTESSERACT_AVAILABLE = False
    pytesseract           = None
    TESSERACT_ERROR       = Exception

try:
    import PyPDF2
    PYPDF2_AVAILABLE      = True
except ImportError:
    PYPDF2_AVAILABLE      = False
    PyPDF2                = None

# ─── Optional: Preload SpaCy & Embedding Model ───────

TESSERACT_CMD = os.getenv('TESSERACT_CMD', r'C:\Program Files\Tesseract-OCR\tesseract.exe')

if PYTESSERACT_AVAILABLE and pytesseract:
    pytesseract.pytesseract.tesseract_cmd = TESSERACT_CMD
    logger.info(f"[Config] Tesseract Path set to: {TESSERACT_CMD}")

try:
    import spacy
    SPACY_LIB_AVAILABLE = True
    nlp_spacy_core      = spacy.load(SPACY_MODEL_NAME)
    SPACY_MODEL_LOADED  = True
except Exception as e:
    SPACY_LIB_AVAILABLE = False
    nlp_spacy_core      = None
    SPACY_MODEL_LOADED  = False
    logger.warning(f"Failed to load SpaCy model '{SPACY_MODEL_NAME}': {e}")

try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_LIB_AVAILABLE = True
    document_embedding_model = SentenceTransformer(DOCUMENT_EMBEDDING_MODEL_NAME)
    EMBEDDING_MODEL_LOADED = True
except Exception as e:
    SENTENCE_TRANSFORMERS_LIB_AVAILABLE = False
    document_embedding_model = None
    EMBEDDING_MODEL_LOADED = False
    logger.warning(f"Failed to load Sentence transformers: {e}")

try:
    from langchain.text_splitter import RecursiveCharacterTextSplitter
    LANGCHAIN_SPLITTER_AVAILABLE = True
except ImportError:
    LANGCHAIN_SPLITTER_AVAILABLE = False
    RecursiveCharacterTextSplitter = None # Placeholder
```

`server/rag_service/file_parser.py`

```python
# server/rag_service/file_parser.py
import os
try:
    import pypdf
except ImportError:
    print("pypdf not found, PDF parsing will fail. Install with: pip install pypdf")
    pypdf = None # Set to None if not installed

try:
    from docx import Document as DocxDocument
except ImportError:
    print("python-docx not found, DOCX parsing will fail. Install with: pip install python-docx")
    DocxDocument = None

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.documents import Document as LangchainDocument
from rag_service import config # Import from package
import logging

# Configure logger for this module
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO) # Or DEBUG for more details
handler = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
if not logger.hasHandlers():
    logger.addHandler(handler)


def parse_pdf(file_path):
    """Extracts text content from a PDF file using pypdf."""
    if not pypdf: return None # Check if library loaded
    text = ""
    try:
        reader = pypdf.PdfReader(file_path)
        num_pages = len(reader.pages)
        # logger.debug(f"Reading {num_pages} pages from PDF: {os.path.basename(file_path)}")
        for i, page in enumerate(reader.pages):
            try:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + "\n" # Add newline between pages
            except Exception as page_err:
                 logger.warning(f"Error extracting text from page {i+1} of {os.path.basename(file_path)}: {page_err}")
        # logger.debug(f"Extracted {len(text)} characters from PDF.")
        return text.strip() if text.strip() else None # Return None if empty after stripping
    except FileNotFoundError:
        logger.error(f"PDF file not found: {file_path}")
        return None
    except pypdf.errors.PdfReadError as pdf_err:
        logger.error(f"Error reading PDF {os.path.basename(file_path)} (possibly corrupted or encrypted): {pdf_err}")
        return None
    except Exception as e:
        logger.error(f"Unexpected error parsing PDF {os.path.basename(file_path)}: {e}", exc_info=True)
        return None

def parse_docx(file_path):
    """Extracts text content from a DOCX file."""
    if not DocxDocument: return None # Check if library loaded
    try:
        doc = DocxDocument(file_path)
        text = "\n".join([para.text for para in doc.paragraphs if para.text.strip()])
        # logger.debug(f"Extracted {len(text)} characters from DOCX.")
        return text.strip() if text.strip() else None
    except Exception as e:
        logger.error(f"Error parsing DOCX {os.path.basename(file_path)}: {e}", exc_info=True)
        return None

def parse_txt(file_path):
    """Reads text content from a TXT file (or similar plain text like .py, .js)."""
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            text = f.read()
        # logger.debug(f"Read {len(text)} characters from TXT file.")
        return text.strip() if text.strip() else None
    except Exception as e:
        logger.error(f"Error parsing TXT {os.path.basename(file_path)}: {e}", exc_info=True)
        return None

# Add PPTX parsing (requires python-pptx)
try:
    from pptx import Presentation
    PPTX_SUPPORTED = True
    def parse_pptx(file_path):
        """Extracts text content from a PPTX file."""
        text = ""
        try:
            prs = Presentation(file_path)
            for slide in prs.slides:
                for shape in slide.shapes:
                    if hasattr(shape, "text"):
                        shape_text = shape.text.strip()
                        if shape_text:
                            text += shape_text + "\n" # Add newline between shape texts
            # logger.debug(f"Extracted {len(text)} characters from PPTX.")
            return text.strip() if text.strip() else None
        except Exception as e:
            logger.error(f"Error parsing PPTX {os.path.basename(file_path)}: {e}", exc_info=True)
            return None
except ImportError:
    PPTX_SUPPORTED = False
    logger.warning("python-pptx not installed. PPTX parsing will be skipped.")
    def parse_pptx(file_path):
        logger.warning(f"Skipping PPTX file {os.path.basename(file_path)} as python-pptx is not installed.")
        return None


def parse_file(file_path):
    """Parses a file based on its extension, returning text content or None."""
    _, ext = os.path.splitext(file_path)
    ext = ext.lower()
    logger.debug(f"Attempting to parse file: {os.path.basename(file_path)} (Extension: {ext})")

    if ext == '.pdf':
        return parse_pdf(file_path)
    elif ext == '.docx':
        return parse_docx(file_path)
    elif ext == '.pptx':
        return parse_pptx(file_path) # Use the conditional function
    elif ext in ['.txt', '.py', '.js', '.md', '.log', '.csv', '.html', '.xml', '.json']: # Expand text-like types
        return parse_txt(file_path)
    # Add other parsers here if needed (e.g., for .doc, .xls)
    elif ext == '.doc':
        # Requires antiword or similar external tool, more complex
        logger.warning(f"Parsing for legacy .doc files is not implemented: {os.path.basename(file_path)}")
        return None
    else:
        logger.warning(f"Unsupported file extension for parsing: {ext} ({os.path.basename(file_path)})")
        return None

def chunk_text(text, file_name, user_id):
    """Chunks text and creates Langchain Documents with metadata."""
    if not text or not isinstance(text, str):
        logger.warning(f"Invalid text input for chunking (file: {file_name}). Skipping.")
        return []

    # Use splitter configured in config.py
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=config.CHUNK_SIZE,
        chunk_overlap=config.CHUNK_OVERLAP,
        length_function=len,
        is_separator_regex=False, # Use default separators
        # separators=["\n\n", "\n", " ", ""] # Default separators
    )

    try:
        chunks = text_splitter.split_text(text)
        if not chunks:
             logger.warning(f"Text splitting resulted in zero chunks for file: {file_name}")
             return []

        documents = []
        for i, chunk in enumerate(chunks):
             # Ensure chunk is not just whitespace before creating Document
             if chunk and chunk.strip():
                 documents.append(
                     LangchainDocument(
                         page_content=chunk,
                         metadata={
                             'userId': user_id, # Store user ID
                             'documentName': file_name, # Store original filename
                             'chunkIndex': i # Store chunk index for reference
                         }
                     )
                 )
        if documents:
            logger.info(f"Split '{file_name}' into {len(documents)} non-empty chunks.")
        else:
            logger.warning(f"No non-empty chunks created for file: {file_name} after splitting.")
        return documents
    except Exception as e:
        logger.error(f"Error during text splitting for file {file_name}: {e}", exc_info=True)
        return [] # Return empty list on error

```

`server/rag_service/neo4j_handler.py`

```python
# server/rag_service/neo4j_handler.py

import logging
from neo4j import GraphDatabase, exceptions as neo4j_exceptions
import config # Assumes config.py is in the same directory or python path is set correctly

logger = logging.getLogger(__name__)

# --- Neo4j Driver Management ---
_neo4j_driver = None

def init_driver():
    """Initializes the Neo4j driver instance."""
    global _neo4j_driver
    if _neo4j_driver is not None:
        try: # Check if existing driver is still connected
            _neo4j_driver.verify_connectivity()
            logger.info("Neo4j driver already initialized and connected.")
            return
        except Exception:
            logger.warning("Existing Neo4j driver lost connection or failed verification. Re-initializing.")
            if _neo4j_driver:
                _neo4j_driver.close()
            _neo4j_driver = None # Force re-initialization

    try:
        _neo4j_driver = GraphDatabase.driver(
            config.NEO4J_URI,
            auth=(config.NEO4J_USERNAME, config.NEO4J_PASSWORD)
        )
        _neo4j_driver.verify_connectivity()
        logger.info(f"Neo4j driver initialized. Connected to: {config.NEO4J_URI} (DB: {config.NEO4J_DATABASE})")
    except neo4j_exceptions.ServiceUnavailable:
        logger.critical(f"Failed to connect to Neo4j at {config.NEO4J_URI}. Ensure Neo4j is running and accessible.")
        _neo4j_driver = None
    except neo4j_exceptions.AuthError:
        logger.critical(f"Neo4j authentication failed for user '{config.NEO4J_USERNAME}'. Check credentials.")
        _neo4j_driver = None
    except Exception as e:
        logger.critical(f"An unexpected error occurred while initializing Neo4j driver: {e}", exc_info=True)
        _neo4j_driver = None

def get_driver_instance():
    """Returns the active Neo4j driver instance, initializing if necessary."""
    if _neo4j_driver is None:
        init_driver()
    if _neo4j_driver is None: # Check again after trying to init
        raise ConnectionError("Neo4j driver is not available. Initialization failed.")
    return _neo4j_driver

def close_driver():
    """Closes the Neo4j driver instance if it exists."""
    global _neo4j_driver
    if _neo4j_driver:
        _neo4j_driver.close()
        _neo4j_driver = None
        logger.info("Neo4j driver closed.")

def check_neo4j_connectivity():
    """Checks if the Neo4j driver can connect."""
    try:
        driver = get_driver_instance() # This will try to init if not already
        driver.verify_connectivity()
        return True, "connected"
    except Exception as e:
        logger.warning(f"Neo4j connectivity check failed: {str(e)}")
        return False, f"disconnected_or_error: {str(e)}"

# --- Private Transaction Helper Functions ---
def _execute_read_tx(tx_function, *args, **kwargs):
    driver = get_driver_instance()
    with driver.session(database=config.NEO4J_DATABASE) as session:
        return session.execute_read(tx_function, *args, **kwargs)

def _execute_write_tx(tx_function, *args, **kwargs):
    driver = get_driver_instance()
    with driver.session(database=config.NEO4J_DATABASE) as session:
        return session.execute_write(tx_function, *args, **kwargs)

# --- Private Transactional Cypher Functions ---
def _delete_kg_transactional(tx, user_id, document_name):
    logger.info(f"Neo4j TX: Deleting KG for user '{user_id}', document '{document_name}'")
    query = (
        "MATCH (n:KnowledgeNode {userId: $userId, documentName: $documentName}) "
        "DETACH DELETE n"
    )
    result = tx.run(query, userId=user_id, documentName=document_name)
    summary = result.consume()
    deleted_count = summary.counters.nodes_deleted + summary.counters.relationships_deleted
    logger.info(f"Neo4j TX: Deleted {summary.counters.nodes_deleted} nodes and {summary.counters.relationships_deleted} relationships for '{document_name}'.")
    return deleted_count > 0

def _add_nodes_transactional(tx, nodes_param, user_id, document_name):
    logger.info(f"Neo4j TX: Adding/merging {len(nodes_param)} nodes for user '{user_id}', document '{document_name}'")
    # Ensure nodes have a type, default to "concept" if not provided
    # And llm_parent_id for parent from LLM's perspective
    processed_nodes = []
    for node_data in nodes_param:
        # Ensure ID is a string and not empty
        if not isinstance(node_data.get("id"), str) or not node_data.get("id").strip():
            logger.warning(f"Skipping node with invalid or missing ID: {node_data}")
            continue
        
        processed_node = {
            "id": node_data["id"].strip(), # Use the LLM's 'id' as 'nodeId'
            "type": node_data.get("type", "concept"), # Default type
            "description": node_data.get("description", ""),
            "llm_parent_id": node_data.get("parent", None) # Store the 'parent' from LLM
        }
        processed_nodes.append(processed_node)

    if not processed_nodes:
        logger.warning("No valid nodes to process after filtering.")
        return 0

    query = (
        "UNWIND $nodes_data as node_props "
        "MERGE (n:KnowledgeNode {nodeId: node_props.id, userId: $userId, documentName: $documentName}) "
        "ON CREATE SET n.type = node_props.type, "
        "              n.description = node_props.description, "
        "              n.llm_parent_id = node_props.llm_parent_id, "
        "              n.userId = $userId, " # Ensure userId is set on create
        "              n.documentName = $documentName " # Ensure documentName is set on create
        "ON MATCH SET n.type = node_props.type, " # Update existing nodes too
        "             n.description = node_props.description, "
        "             n.llm_parent_id = node_props.llm_parent_id "
        "RETURN count(n) as nodes_affected"
    )
    result = tx.run(query, nodes_data=processed_nodes, userId=user_id, documentName=document_name)
    count = result.single()[0] if result.peek() else 0
    logger.info(f"Neo4j TX: Affected (created or merged) {count} nodes for '{document_name}'.")
    return count

def _add_edges_transactional(tx, edges_param, user_id, document_name):
    logger.info(f"Neo4j TX: Adding/merging {len(edges_param)} edges for user '{user_id}', document '{document_name}'")
    if not edges_param:
        logger.info("Neo4j TX: No edges provided to add.")
        return 0
        
    # Filter out invalid edges
    valid_edges = []
    for edge_data in edges_param:
        if not (isinstance(edge_data.get("from"), str) and edge_data.get("from").strip() and
                isinstance(edge_data.get("to"), str) and edge_data.get("to").strip() and
                isinstance(edge_data.get("relationship"), str) and edge_data.get("relationship").strip()):
            logger.warning(f"Skipping invalid edge data: {edge_data}")
            continue
        valid_edges.append({
            "from": edge_data["from"].strip(),
            "to": edge_data["to"].strip(),
            "relationship": edge_data["relationship"].strip().upper().replace(" ", "_") # Sanitize relationship type
        })

    if not valid_edges:
        logger.warning("No valid edges to process after filtering.")
        return 0

    # Cypher query to create relationships. Note: relationship type is dynamic using brackets.
    # We use MERGE to avoid duplicate relationships with the same type between the same nodes.
    # Relationship properties are set using SET.
    query = (
        "UNWIND $edges_data as edge_props "
        "MATCH (startNode:KnowledgeNode {nodeId: edge_props.from, userId: $userId, documentName: $documentName}) "
        "MATCH (endNode:KnowledgeNode {nodeId: edge_props.to, userId: $userId, documentName: $documentName}) "
        "CALL apoc.merge.relationship(startNode, edge_props.relationship, {}, {type: edge_props.relationship}, endNode) YIELD rel "
        # MERGE (startNode)-[r:HAS_RELATIONSHIP]->(endNode) " # Simpler, but cannot set type dynamically easily.
        # "SET r.type = edge_props.relationship "
        "RETURN count(rel) as edges_affected"
    )
    # Note: The above MERGE using apoc.merge.relationship is more robust for dynamic relationship types.
    # If APOC is not available, a simpler MERGE (startNode)-[r:REL {type:edge_props.relationship}]->(endNode) would work.
    # Or create relationships with a generic type like :RELATED_TO and store the specific type as a property.
    # For this example, assuming APOC for dynamic relationship types. If not, adjust the query.
    # Simpler, if APOC is not available (relationship type becomes a property of a generic :RELATED_TO relationship):
    simple_query = (
        "UNWIND $edges_data as edge_props "
        "MATCH (startNode:KnowledgeNode {nodeId: edge_props.from, userId: $userId, documentName: $documentName}) "
        "MATCH (endNode:KnowledgeNode {nodeId: edge_props.to, userId: $userId, documentName: $documentName}) "
        "MERGE (startNode)-[r:RELATED_TO {type: edge_props.relationship}]->(endNode) "
        "RETURN count(r) as edges_affected"
    )
    # Let's use the simpler query for broader compatibility without APOC.
    
    result = tx.run(simple_query, edges_data=valid_edges, userId=user_id, documentName=document_name)
    count = result.single()[0] if result.peek() else 0
    logger.info(f"Neo4j TX: Affected (created or merged) {count} relationships for '{document_name}'.")
    return count

def _get_kg_transactional(tx, user_id, document_name):
    logger.info(f"Neo4j TX: Retrieving KG for user '{user_id}', document '{document_name}'")
    nodes_query = (
        "MATCH (n:KnowledgeNode {userId: $userId, documentName: $documentName}) "
        "RETURN n.nodeId AS id, n.type AS type, n.description AS description, n.llm_parent_id AS parent"
    )
    nodes_result = tx.run(nodes_query, userId=user_id, documentName=document_name)
    # Convert Neo4j records to dictionaries
    nodes_data = [dict(record) for record in nodes_result]

    edges_query = (
        "MATCH (startNode:KnowledgeNode {userId: $userId, documentName: $documentName})"
        "-[r:RELATED_TO]->" # Using the generic relationship type from the simple_query
        "(endNode:KnowledgeNode {userId: $userId, documentName: $documentName}) "
        "RETURN startNode.nodeId AS from, endNode.nodeId AS to, r.type AS relationship"
    )
    edges_result = tx.run(edges_query, userId=user_id, documentName=document_name)
    edges_data = [dict(record) for record in edges_result]

    logger.info(f"Neo4j TX: Retrieved {len(nodes_data)} nodes and {len(edges_data)} edges for '{document_name}'.")
    return {"nodes": nodes_data, "edges": edges_data}


# --- Public Service Functions ---
def ingest_knowledge_graph(user_id: str, document_name: str, nodes: list, edges: list) -> dict:
    """
    Deletes existing KG for the document and ingests new nodes and edges.
    Returns a summary of operations.
    """
    try:
        logger.info(f"Attempting to delete old KG (if any) for document '{document_name}' (User: {user_id}).")
        _execute_write_tx(_delete_kg_transactional, user_id, document_name)
        logger.info(f"Old KG (if any) deleted for '{document_name}'. Proceeding with ingestion.")

        nodes_affected = 0
        if nodes and len(nodes) > 0:
            nodes_affected = _execute_write_tx(_add_nodes_transactional, nodes, user_id, document_name)
        
        edges_affected = 0
        if edges and len(edges) > 0:
            edges_affected = _execute_write_tx(_add_edges_transactional, edges, user_id, document_name)

        message = "Knowledge Graph successfully ingested/updated."
        logger.info(f"{message} Doc: '{document_name}', User: '{user_id}'. Nodes: {nodes_affected}, Edges: {edges_affected}")
        return {
            "success": True,
            "message": message,
            "nodes_affected": nodes_affected,
            "edges_affected": edges_affected
        }
    except Exception as e:
        logger.error(f"Error during KG ingestion for document '{document_name}', user '{user_id}': {e}", exc_info=True)
        raise # Re-raise to be caught by the route handler

def get_knowledge_graph(user_id: str, document_name: str) -> dict:
    """
    Retrieves the knowledge graph for a given user and document name.
    """
    try:
        kg_data = _execute_read_tx(_get_kg_transactional, user_id, document_name)
        if not kg_data["nodes"] and not kg_data["edges"]:
            logger.info(f"No KG data found for user '{user_id}', document '{document_name}'.")
            return None # Indicate not found
        return kg_data
    except Exception as e:
        logger.error(f"Error retrieving KG for document '{document_name}', user '{user_id}': {e}", exc_info=True)
        raise

def delete_knowledge_graph(user_id: str, document_name: str) -> bool:
    """
    Deletes the knowledge graph for a given user and document name.
    Returns True if data was deleted, False otherwise.
    """
    try:
        was_deleted = _execute_write_tx(_delete_kg_transactional, user_id, document_name)
        return was_deleted
    except Exception as e:
        logger.error(f"Error deleting KG for document '{document_name}', user '{user_id}': {e}", exc_info=True)
        raise
```

`server/rag_service/Readne.txt`

```
conda activate RAG
python server/rag_service/app.py
OR
python -m server.rag_service.app

For testing
curl -X POST -H "Content-Type: application/json" -d '{"user_id": "__DEFAULT__", "query": "machine learning"}' http://localhost:5002/query

for production
pip install gunicorn
gunicorn --bind 0.0.0.0:5002 server.rag_service.app:app


```

`server/rag_service/requirements.txt`

```
flask
requests
faiss-cpu # or faiss-gpu
langchain
langchain-huggingface
pypdf
PyPDF2
python-docx
python-dotenv
ollama # Keep if using Ollama embeddings
python-pptx # Added for PPTX parsing
uuid
langchain-community
pdfplumber
fitz # PyMuPDF for PDF parsing
pytesseract
nltk
spacy-layout
pandas
numpy
typing
pytesseract # OCR
pillow
qdrant-client
neo4j
sentence_transformers
spacy
<<<<<<< HEAD
=======
opencv-python
>>>>>>> 4a970a932e10e0b46602c5eda49013a83c98ac9c




```

`server/rag_service/vector_db_service.py`

```python
import uuid
import logging
from typing import List, Dict, Tuple, Optional, Any

from qdrant_client import QdrantClient, models
from sentence_transformers import SentenceTransformer

# Assuming vector_db_service.py and config.py are in the same package directory (e.g., rag_service/)
# and you run your application as a module (e.g., python -m rag_service.main_app)
# or have otherwise correctly set up the Python path.
import config # Changed to relative import

# Configure basic logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class Document: # For search result formatting
    def __init__(self, page_content: str, metadata: dict):
        self.page_content = page_content
        self.metadata = metadata

    def to_dict(self):
        return {"page_content": self.page_content, "metadata": self.metadata}

class VectorDBService:
    def __init__(self):
        logger.info("Initializing VectorDBService...")
        logger.info(f"  Qdrant Host: {config.QDRANT_HOST}, Port: {config.QDRANT_PORT}, URL: {config.QDRANT_URL}")
        logger.info(f"  Collection: {config.QDRANT_COLLECTION_NAME}")
        logger.info(f"  Query Embedding Model: {config.QUERY_EMBEDDING_MODEL_NAME}")
        
        # The vector dimension for the Qdrant collection is defined by the DOCUMENT embedding model
        # This is set in config.QDRANT_COLLECTION_VECTOR_DIM
        self.vector_dim = config.QDRANT_COLLECTION_VECTOR_DIM
        logger.info(f"  Service expects Vector Dim for Qdrant collection: {self.vector_dim} (from document model config)")

        if config.QDRANT_URL:
            self.client = QdrantClient(
                url=config.QDRANT_URL,
                api_key=config.QDRANT_API_KEY,
                timeout=30
            )
        else:
            self.client = QdrantClient(
                host=config.QDRANT_HOST,
                port=config.QDRANT_PORT,
                api_key=config.QDRANT_API_KEY,
                timeout=30
            )

        try:
            # This model is for encoding search queries.
            # Its output dimension MUST match self.vector_dim (QDRANT_COLLECTION_VECTOR_DIM).
            logger.info(f"  Loading query embedding model: '{config.QUERY_EMBEDDING_MODEL_NAME}'")
            self.model = SentenceTransformer(config.QUERY_EMBEDDING_MODEL_NAME)
            model_embedding_dim = self.model.get_sentence_embedding_dimension()
            logger.info(f"  Query model loaded. Output dimension: {model_embedding_dim}")

            if model_embedding_dim != self.vector_dim:
                error_msg = (
                    f"CRITICAL DIMENSION MISMATCH: Query model '{config.QUERY_EMBEDDING_MODEL_NAME}' "
                    f"outputs embeddings of dimension {model_embedding_dim}, but the Qdrant collection "
                    f"is configured for dimension {self.vector_dim} (derived from document model: "
                    f"'{config.DOCUMENT_EMBEDDING_MODEL_NAME}'). Search functionality will fail. "
                    "Ensure query and document models produce compatible embedding dimensions, "
                    "or environment variables for dimensions are correctly set."
                )
                logger.error(error_msg)
                raise ValueError(error_msg) # Critical error, stop initialization
            else:
                logger.info(f"  Query model output dimension ({model_embedding_dim}) matches "
                            f"Qdrant collection dimension ({self.vector_dim}).")

        except Exception as e:
            logger.error(f"Error initializing SentenceTransformer model '{config.QUERY_EMBEDDING_MODEL_NAME}' for query encoding: {e}", exc_info=True)
            raise # Re-raise to prevent service startup with a non-functional query encoder

        self.collection_name = config.QDRANT_COLLECTION_NAME
        # No ThreadPoolExecutor needed here if document encoding is external

    def _recreate_qdrant_collection(self):
        logger.info(f"Attempting to (re)create collection '{self.collection_name}' with vector size {self.vector_dim}.")
        try:
            self.client.recreate_collection(
                collection_name=self.collection_name,
                vectors_config=models.VectorParams(
                    size=self.vector_dim,
                    distance=models.Distance.COSINE,
                ),
            )
            logger.info(f"Collection '{self.collection_name}' (re)created successfully.")
        except Exception as e_recreate:
            logger.error(f"Failed to (re)create collection '{self.collection_name}': {e_recreate}", exc_info=True)
            raise

    def setup_collection(self):
        try:
            collection_info = self.client.get_collection(collection_name=self.collection_name)
            logger.info(f"Collection '{self.collection_name}' already exists.")
            
            # Handle different Qdrant client versions for accessing vector config
            current_vectors_config = None
            if hasattr(collection_info.config.params, 'vectors'): # For simple vector config
                if isinstance(collection_info.config.params.vectors, models.VectorParams):
                     current_vectors_config = collection_info.config.params.vectors
                elif isinstance(collection_info.config.params.vectors, dict): # For named vectors
                    # Assuming default unnamed vector or first one if named
                    default_vector_name = '' # Common for single vector setup
                    if default_vector_name in collection_info.config.params.vectors:
                        current_vectors_config = collection_info.config.params.vectors[default_vector_name]
                    elif collection_info.config.params.vectors: # Get first one if default not found
                        current_vectors_config = next(iter(collection_info.config.params.vectors.values()))

            if not current_vectors_config:
                 logger.error(f"Could not determine vector configuration for existing collection '{self.collection_name}'. Recreating.")
                 self._recreate_qdrant_collection()
            elif current_vectors_config.size != self.vector_dim:
                logger.warning(f"Collection '{self.collection_name}' vector size {current_vectors_config.size} "
                               f"differs from service's expected {self.vector_dim}. Recreating.")
                self._recreate_qdrant_collection()
            elif current_vectors_config.distance != models.Distance.COSINE: # Ensure distance is also checked
                logger.warning(f"Collection '{self.collection_name}' distance {current_vectors_config.distance} "
                               f"differs from expected {models.Distance.COSINE}. Recreating.")
                self._recreate_qdrant_collection()
            else:
                logger.info(f"Collection '{self.collection_name}' configuration is compatible (Size: {current_vectors_config.size}, Distance: {current_vectors_config.distance}).")

        except Exception as e: # Broad exception for Qdrant client errors
            # More specific check for "Not found" type errors
            if "not found" in str(e).lower() or \
               (hasattr(e, 'status_code') and e.status_code == 404) or \
               " ভাগ্যবান" in str(e).lower(): # "Lucky" in Bengali, seems to be part of an error message you encountered
                 logger.info(f"Collection '{self.collection_name}' not found. Attempting to create...")
            else:
                 logger.warning(f"Error checking collection '{self.collection_name}': {type(e).__name__} - {e}. Attempting to (re)create anyway...")
            self._recreate_qdrant_collection()

    def add_processed_chunks(self, processed_chunks: List[Dict[str, Any]]) -> int:
        if not processed_chunks:
            logger.warning("add_processed_chunks received an empty list. No points to upsert.")
            return 0

        points_to_upsert = []
        doc_name_for_logging = "Unknown Document"

        for chunk_data in processed_chunks:
            point_id = chunk_data.get('id', str(uuid.uuid4()))
            vector = chunk_data.get('embedding')
            
            payload = chunk_data.get('metadata', {}).copy()
            payload['chunk_text_content'] = chunk_data.get('text_content', '')

            if not doc_name_for_logging or doc_name_for_logging == "Unknown Document":
                doc_name_for_logging = payload.get('original_name', payload.get('document_name', "Unknown Document"))

            if not vector:
                logger.warning(f"Chunk with ID '{point_id}' from '{doc_name_for_logging}' is missing 'embedding'. Skipping.")
                continue
            if not isinstance(vector, list) or not all(isinstance(x, (float, int)) for x in vector): # Allow int too, SentenceTransformer can return float32 which might be int-like in lists
                logger.warning(f"Chunk with ID '{point_id}' from '{doc_name_for_logging}' has an invalid 'embedding' format. Skipping.")
                continue
            if len(vector) != self.vector_dim:
                logger.error(f"Chunk with ID '{point_id}' from '{doc_name_for_logging}' has embedding dimension {len(vector)}, "
                             f"but collection expects {self.vector_dim}. Skipping. "
                             f"Ensure ai_core's document embedding model ('{config.DOCUMENT_EMBEDDING_MODEL_NAME}') "
                             f"output dimension matches configuration.")
                continue

            points_to_upsert.append(models.PointStruct(
                id=point_id,
                vector=[float(v) for v in vector], # Ensure all are floats for Qdrant
                payload=payload
            ))

        if not points_to_upsert:
            logger.warning(f"No valid points constructed from processed_chunks for document: {doc_name_for_logging}.")
            return 0

        try:
            self.client.upsert(collection_name=self.collection_name, points=points_to_upsert, wait=True) # wait=True can be useful for debugging
            logger.info(f"Successfully upserted {len(points_to_upsert)} chunks for document: {doc_name_for_logging} into Qdrant.")
            return len(points_to_upsert)
        except Exception as e:
            logger.error(f"Error upserting processed chunks to Qdrant for document: {doc_name_for_logging}: {e}", exc_info=True)
            raise

    def search_documents(self, query: str, k: int = -1, filter_conditions: Optional[models.Filter] = None) -> Tuple[List[Document], str, Dict]:
        # Use default k from config if not provided or invalid
        if k <= 0:
            k_to_use = config.QDRANT_DEFAULT_SEARCH_K
        else:
            k_to_use = k

        context_docs = []
        formatted_context_text = "No relevant context was found in the available documents."
        context_docs_map = {}

        logger.info(f"Searching with query (first 50 chars): '{query[:50]}...', k: {k_to_use}")
        if filter_conditions:
            try: filter_dict = filter_conditions.dict()
            except AttributeError: # For older Pydantic versions
                try: filter_dict = filter_conditions.model_dump()
                except AttributeError: filter_dict = str(filter_conditions) # Fallback
            logger.info(f"Applying filter: {filter_dict}")
        else:
            logger.info("No filter applied for search.")

        try:
            query_embedding = self.model.encode(query).tolist()
            logger.debug(f"Generated query_embedding (length: {len(query_embedding)}, first 5 dims: {query_embedding[:5]})")

            search_results = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_embedding,
                query_filter=filter_conditions,
                limit=k_to_use,
                with_payload=True,
                score_threshold=config.QDRANT_SEARCH_MIN_RELEVANCE_SCORE # Apply score threshold directly in search
            )
            logger.info(f"Qdrant client.search returned {len(search_results)} results (after score threshold).")

            if not search_results:
                return context_docs, formatted_context_text, context_docs_map

            for idx, point in enumerate(search_results):
                # Score threshold is already applied by Qdrant if score_threshold parameter is used.
                # If not using score_threshold in client.search, uncomment this:
                # if point.score < config.QDRANT_SEARCH_MIN_RELEVANCE_SCORE:
                #     logger.debug(f"Skipping point ID {point.id} with score {point.score:.4f} (below threshold {config.QDRANT_SEARCH_MIN_RELEVANCE_SCORE})")
                #     continue

                payload = point.payload
                content = payload.get("chunk_text_content", payload.get("text_content", payload.get("chunk_text", "")))

                retrieved_metadata = payload.copy()
                retrieved_metadata["qdrant_id"] = point.id
                retrieved_metadata["score"] = point.score

                doc = Document(page_content=content, metadata=retrieved_metadata)
                context_docs.append(doc)

            # Format context and citations
            formatted_context_parts = []
            for i, doc_obj in enumerate(context_docs):
                citation_index = i + 1
                doc_meta = doc_obj.metadata
                # Use more robust fetching of metadata keys
                display_subject = doc_meta.get("title", doc_meta.get("subject", "Unknown Subject")) # Prefer title for subject
                doc_name = doc_meta.get("original_name", doc_meta.get("file_name", "N/A"))
                page_num_info = f" (Page: {doc_meta.get('page_number', 'N/A')})" if doc_meta.get('page_number') else "" # Add page number if available
                
                content_preview = doc_obj.page_content[:200] + "..." if len(doc_obj.page_content) > 200 else doc_obj.page_content

                formatted = (f"[{citation_index}] Score: {doc_meta.get('score', 0.0):.4f} | "
                             f"Source: {doc_name}{page_num_info} | Subject: {display_subject}\n"
                             f"Content: {content_preview}") # Show content preview
                formatted_context_parts.append(formatted)

                context_docs_map[str(citation_index)] = {
                    "subject": display_subject,
                    "document_name": doc_name,
                    "page_number": doc_meta.get("page_number"),
                    "content_preview": content_preview, # Store preview
                    "full_content": doc_obj.page_content, # Store full content for potential later use
                    "score": doc_meta.get("score", 0.0),
                    "qdrant_id": doc_meta.get("qdrant_id"),
                    "original_metadata": doc_meta # Store all original metadata from payload
                }
            if formatted_context_parts:
                formatted_context_text = "\n\n---\n\n".join(formatted_context_parts)
            else:
                formatted_context_text = "No sufficiently relevant context was found after filtering."

        except Exception as e:
            logger.error(f"Qdrant search/RAG error: {e}", exc_info=True)
            formatted_context_text = "Error retrieving context due to an internal server error."

        return context_docs, formatted_context_text, context_docs_map
    
    # Add this method to the VectorDBService class in vector_db_service.py

    def delete_document_vectors(self, user_id: str, document_name: str) -> Dict[str, Any]:
        logger.info(f"Attempting to delete vectors for document: '{document_name}', user: '{user_id}' from Qdrant collection '{self.collection_name}'.")
        
        # These metadata keys must match what's stored during ingestion from ai_core.py
        # 'processing_user' was the user_id passed to ai_core
        # 'file_name' was the original_name passed to ai_core
        qdrant_filter = models.Filter(
            must=[
                models.FieldCondition(
                    key="processing_user", # The metadata field storing the user ID
                    match=models.MatchValue(value=user_id)
                ),
                models.FieldCondition(
                    key="file_name", # The metadata field storing the original document name
                    match=models.MatchValue(value=document_name)
                )
            ]
        )
        
        try:
            # Optional: Count points before deleting for logging/confirmation
            # count_response = self.client.count(collection_name=self.collection_name, count_filter=qdrant_filter)
            # num_to_delete = count_response.count
            # logger.info(f"Qdrant: Found {num_to_delete} points matching criteria for document '{document_name}', user '{user_id}'.")

            # if num_to_delete == 0:
            #     logger.info(f"Qdrant: No points found to delete for document '{document_name}', user '{user_id}'.")
            #     return {"success": True, "message": "No matching vectors found in Qdrant to delete.", "deleted_count": 0}

            delete_result = self.client.delete(
                collection_name=self.collection_name,
                points_selector=models.FilterSelector(filter=qdrant_filter),
                wait=True # Make it synchronous
            )
            
            # Check the status of the delete operation
            # delete_result should be an UpdateResult object
            if delete_result.status == models.UpdateStatus.COMPLETED or delete_result.status == models.UpdateStatus.ACKNOWLEDGED:
                # The actual number of deleted points isn't directly returned by filter-based delete.
                # We can infer it was successful if no error.
                # For a precise count, you'd need to list IDs by filter, then delete by IDs.
                logger.info(f"Qdrant delete operation for document '{document_name}', user '{user_id}' acknowledged/completed. Status: {delete_result.status}")
                return {"success": True, "message": f"Qdrant vector deletion for document '{document_name}' completed. Status: {delete_result.status}."}
            else:
                logger.warning(f"Qdrant delete operation for document '{document_name}', user '{user_id}' returned status: {delete_result.status}")
                return {"success": False, "message": f"Qdrant delete operation status: {delete_result.status}"}

        except Exception as e:
            logger.error(f"Error deleting document vectors from Qdrant for document '{document_name}', user '{user_id}': {e}", exc_info=True)
            # Check for specific Qdrant client errors if possible, e.g., if the collection doesn't exist.
            return {"success": False, "message": f"Failed to delete Qdrant vectors: {str(e)}"}

    def close(self):
        logger.info("VectorDBService close called.")
        # No specific resources like ThreadPoolExecutor to release in this version.
        # QdrantClient does not have an explicit close() method in recent versions.
```

`server/rag_service/__init__.py`

```python

```

`server/routes/analysis.js`

```javascript
// server/routes/analysis.js
const express = require('express');
const router = express.Router();
const { authMiddleware } = require('../middleware/authMiddleware');
const User = require('../models/User');

// @route   GET /api/analysis/:documentFilename
// @desc    Get analysis data (faq, topics, mindmap) for a specific document
// @access  Private (requires auth)
router.get('/:documentFilename', authMiddleware, async (req, res) => {
    const userId = req.user._id; // From authMiddleware
    const { documentFilename } = req.params;
    
    if (!documentFilename) {
        return res.status(400).json({ message: 'Document filename parameter is required.' });
    }

    try {
        const user = await User.findById(userId).select('uploadedDocuments');
        if (!user) {
            return res.status(404).json({ message: 'User not found.' });
        }

        const document = user.uploadedDocuments.find(doc => doc.filename === documentFilename);

        if (!document) {
            return res.status(404).json({ message: `Document '${documentFilename}' not found for this user.` });
        }

        if (!document.analysis) {
            // This case might happen if the analysis object itself is missing, though schema has defaults.
            console.warn(`Analysis object missing for document '${documentFilename}', user '${userId}'. Sending empty analysis.`);
            return res.status(200).json({
                faq: "",
                topics: "",
                mindmap: ""
            });
        }
        
        // Send the analysis sub-document
        res.status(200).json(document.analysis);

    } catch (error) {
        console.error(`Error fetching analysis for document '${documentFilename}', user '${userId}':`, error);
        res.status(500).json({ message: 'Server error while retrieving document analysis.' });
    }
});

module.exports = router;
```

`server/routes/auth.js`

```javascript
// server/routes/auth.js
const express = require('express');
const jwt = require('jsonwebtoken'); // <-- Import jsonwebtoken
const { v4: uuidv4 } = require('uuid');
const User = require('../models/User');
const { authMiddleware } = require('../middleware/authMiddleware');
require('dotenv').config(); // Ensures process.env has values from .env

const router = express.Router();

const JWT_EXPIRATION = process.env.JWT_EXPIRATION || '1h'; // Default to 1 hour

// --- @route   POST /api/auth/signup ---
// --- @desc    Register a new user ---
// --- @access  Public ---
router.post('/signup', async (req, res) => {
  const { username, password } = req.body;

  if (!username || !password) {
    return res.status(400).json({ message: 'Please provide username and password' });
  }
  if (password.length < 6) {
     return res.status(400).json({ message: 'Password must be at least 6 characters long' });
  }

  try {
    const existingUser = await User.findOne({ username });
    if (existingUser) {
      return res.status(400).json({ message: 'Username already exists' });
    }

    const newUser = new User({ username, password });
    await newUser.save();

    const sessionId = uuidv4(); // Initial session ID

    // Create JWT Payload
    const payload = {
      userId: newUser._id,
      username: newUser.username,
    };

    // Sign the token
    const token = jwt.sign(
      payload,
      process.env.JWT_SECRET, // Make sure JWT_SECRET is in your .env
      { expiresIn: JWT_EXPIRATION }
    );

    res.status(201).json({
      token: token, // <-- Send token
      _id: newUser._id,
      username: newUser.username,
      sessionId: sessionId,
      message: 'User registered successfully',
    });

  } catch (error) {
    console.error('Signup Error:', error);
    if (error.code === 11000) {
        return res.status(400).json({ message: 'Username already exists.' });
    }
    res.status(500).json({ message: 'Server error during signup' });
  }
});

// --- @route   POST /api/auth/signin ---
// --- @desc    Authenticate user & return JWT ---
// --- @access  Public ---
router.post('/signin', async (req, res) => {
  const { username, password } = req.body;

  if (!username || !password) {
    return res.status(400).json({ message: 'Please provide username and password' });
  }

  try {
    const user = await User.findByCredentials(username, password);

    if (!user) {
      return res.status(401).json({ message: 'Invalid credentials' });
    }

    const sessionId = uuidv4(); // New session ID for this login

    // Create JWT Payload
    const payload = {
      userId: user._id,
      username: user.username,
    };

    // Sign the token
    const token = jwt.sign(
      payload,
      process.env.JWT_SECRET,
      { expiresIn: JWT_EXPIRATION }
    );

    res.status(200).json({
      token: token, // <-- Send token
      _id: user._id,
      username: user.username,
      sessionId: sessionId,
      message: 'Login successful',
    });

  } catch (error) {
    console.error('Signin Error:', error);
    res.status(500).json({ message: 'Server error during signin' });
  }
});

// --- @route   GET /api/auth/me ---
// --- @desc    Get current authenticated user's details (requires JWT middleware) ---
// --- @access  Private ---
// We will add the middleware for this route in server.js
router.get('/me',authMiddleware, async (req, res) => {
    // If the JWT middleware (to be created next) runs successfully,
    // req.user will be populated.
    if (!req.user) {
        // This should ideally be caught by the middleware itself,
        // but as a fallback.
        return res.status(401).json({ message: 'Not authorized, user context missing.' });
    }
    try {
        // req.user is already the user document (excluding password typically)
        // thanks to the upcoming authMiddleware.
        res.status(200).json({
            _id: req.user._id,
            username: req.user.username,
            // Add any other fields you want the frontend to know about the user
            // e.g., email, roles, preferences, if stored.
        });
    } catch (error) {
        console.error('Error in /api/auth/me:', error);
        res.status(500).json({ message: 'Server error fetching user details.' });
    }
});


module.exports = router;
```

`server/routes/chat.js`

```javascript
// server/routes/chat.js
const express = require('express');
const { v4: uuidv4 } = require('uuid');
const ChatHistory = require('../models/ChatHistory');
const { generateContentWithHistory } = require('../services/geminiService');
// Import CHAT_MAIN_SYSTEM_PROMPT which no longer mandates <thinking> output
const { CHAT_MAIN_SYSTEM_PROMPT, CHAT_USER_PROMPT_TEMPLATES } = require('../config/promptTemplates');
const axios = require('axios');

const router = express.Router();

// --- Helper to call Python RAG Query Endpoint ---
async function queryPythonRagService(
    userId,
    query,
    criticalThinkingEnabled, // boolean: for use_kg_critical_thinking
    documentContextNameToPass, // string: for documentContextName
    clientFilter = null, // object: for the generic 'filter'
    k = 5 // Default k value
) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
    if (!pythonServiceUrl) {
        console.error("PYTHON_RAG_SERVICE_URL is not set. RAG features disabled for this request.");
        return []; // Or throw an error / return a specific error structure
    }
    const searchUrl = `${pythonServiceUrl}/query`;
    console.log(`Querying Python RAG: User ${userId}, Query (first 50): "${query.substring(0, 50)}...", k=${k}, CriticalThinking=${criticalThinkingEnabled}, DocContext=${documentContextNameToPass}`);

    const payload = {
        query: query,
        k: k,
        user_id: userId,
        use_kg_critical_thinking: !!criticalThinkingEnabled, // Ensure boolean for Python
        documentContextName: documentContextNameToPass || null // Send null if undefined/empty
    };

    // Add the generic 'filter' object to the payload if it's provided and valid
    if (clientFilter && typeof clientFilter === 'object' && Object.keys(clientFilter).length > 0) {
        payload.filter = clientFilter;
        console.log(`  Applying generic filter to Python RAG search:`, clientFilter);
    } else {
        console.log(`  No generic client filter applied to Python RAG search.`);
    }

    try {
        const response = await axios.post(searchUrl, payload, {
            headers: { 'Content-Type': 'application/json' },
            timeout: process.env.PYTHON_RAG_TIMEOUT || 30000 // 30 seconds, configurable
        });

        if (response.data && Array.isArray(response.data.retrieved_documents_list)) {
            console.log(`Python RAG service /query returned ${response.data.retrieved_documents_list.length} results.`);
            // Transform the Python response to the structure expected by Node.js
            return response.data.retrieved_documents_list.map(doc => ({
                documentName: doc.metadata?.file_name || doc.metadata?.original_name || doc.metadata?.title || 'Unknown Document',
                content: doc.page_content || "",
                score: doc.metadata?.score,
                // You can add more metadata here if needed by the Node.js layer
                // e.g., qdrant_id: doc.metadata?.qdrant_id
            }));
        }
        console.warn(`Python RAG /query returned unexpected data structure:`, response.data);
        return [];
    } catch (error) {
        let errorMsg = error.message;
        if (error.response && error.response.data && error.response.data.error) {
            errorMsg = `Python Service Error: ${error.response.data.error}`;
            if (error.response.data.details) {
                errorMsg += ` | Details: ${JSON.stringify(error.response.data.details)}`;
            }
        } else if (error.code === 'ECONNABORTED') {
            errorMsg = 'Python RAG service request timed out.';
        }
        console.error(`Error querying Python RAG service at ${searchUrl}:`, errorMsg);
        // Depending on how you want to handle errors, you might throw,
        // or return an empty array, or a specific error indicator.
        // For now, returning empty array to maintain existing behavior.
        return []; 
    }
}


// --- @route   POST /api/chat/message ---
// --- @desc    Send a message, get AI response, save interaction ---
// --- @access  Private (authMiddleware applied in server.js) ---
router.post('/message', async (req, res) => {
    const { 
        query, 
        history, 
        sessionId, 
        useRag, 
        llmProvider, 
        systemPrompt: clientProvidedSystemInstruction,
        criticalThinkingEnabled, 
        documentContextName,
        filter // <<< ADDED: Destructure the generic filter from client
    } = req.body;
    const userId = req.user._id; 

    // ... (validations remain the same) ...
    if (!query || typeof query !== 'string' || query.trim() === '') {
        return res.status(400).json({ message: 'Query message text required.' });
    }
    if (!sessionId || typeof sessionId !== 'string') {
        return res.status(400).json({ message: 'Session ID required.' });
    }
    if (!Array.isArray(history)) {
        return res.status(400).json({ message: 'Invalid history format.' });
    }
    if (criticalThinkingEnabled !== undefined && typeof criticalThinkingEnabled !== 'boolean') {
        return res.status(400).json({ message: 'Invalid criticalThinkingEnabled value. Must be a boolean.' });
    }
    if (filter !== undefined && (typeof filter !== 'object' || filter === null) && Object.keys(filter || {}).length > 0) { // Allow empty object or null/undefined
        // More robust validation for filter if needed, e.g. checking its structure
        console.warn("Received 'filter' parameter with unexpected type or structure:", filter);
        // Depending on strictness, you might return 400 or just ignore it
    }


    const currentTimestamp = new Date();
    const userMessageForDb = { /* ... */ };

    console.log(`>>> POST /api/chat/message: User=${userId}, Session=${sessionId}, RAG=${useRag}, CriticalThinking=${criticalThinkingEnabled}, DocContext=${documentContextName}, ClientFilter=${!!filter}, Query: "${query.substring(0,50)}..."`);

    try {
        let aiResponseMessageText;
        let referencesForResponse = [];
        let actualSourcePipeline = `${llmProvider || 'gemini'}-direct`;
        let contextForLLMString = "";
        let relevantDocsFromRag = [];
        const mainSystemPromptText = CHAT_MAIN_SYSTEM_PROMPT ? CHAT_MAIN_SYSTEM_PROMPT() : ""; 

        if (useRag) {
            actualSourcePipeline = `${llmProvider || 'gemini'}-rag`;
            console.log(`   Querying RAG service for user ${userId}, query "${query.trim()}", criticalThinking: ${criticalThinkingEnabled}, docContext: ${documentContextName}, clientFilter: ${JSON.stringify(filter)}`);
            
            // MODIFIED: Call queryPythonRagService with all relevant parameters
            relevantDocsFromRag = await queryPythonRagService(
                userId.toString(), 
                query.trim(), 
                criticalThinkingEnabled, // For use_kg_critical_thinking
                documentContextName,     // For documentContextName
                filter                   // For the generic 'filter' payload
                // k value can be passed here if needed, or Python service uses its default
            );

            if (relevantDocsFromRag && relevantDocsFromRag.length > 0) {
                // ... (context assembly for LLM - this part looks good) ...
                let ragContextForPromptAssembly = "";
                relevantDocsFromRag.forEach((doc, index) => {
                    ragContextForPromptAssembly += `\n[${index + 1}] Source Document: ${doc.documentName}\n(Score: ${doc.score ? doc.score.toFixed(3) : 'N/A'})\nContent:\n${doc.content}\n---\n`;
                    referencesForResponse.push({
                        number: index + 1,
                        source: doc.documentName,
                        content_preview: doc.content.substring(0, 100) + (doc.content.length > 100 ? "..." : "")
                    });
                });
                contextForLLMString = ragContextForPromptAssembly.trim();
            } else {
                contextForLLMString = ""; 
            }
        }

        // ... (rest of the /message route logic for LLM call, DB save, response)
        // This part seems largely correct based on your existing code.

        const historyForLLM = history
            .map(msg => ({
                role: msg.sender === 'bot' ? 'model' : 'user',
                parts: msg.parts && Array.isArray(msg.parts) ? msg.parts.map(part => ({ text: part.text || '' })) : [{ text: msg.text || '' }]
            }))
            .filter(msg => msg.role && msg.parts && msg.parts.length > 0 && typeof msg.parts[0].text === 'string');

        let queryForLLM;
        if (useRag && contextForLLMString) {
            queryForLLM = CHAT_USER_PROMPT_TEMPLATES.rag(query.trim(), contextForLLMString, clientProvidedSystemInstruction);
        } else {
            queryForLLM = CHAT_USER_PROMPT_TEMPLATES.direct(query.trim(), clientProvidedSystemInstruction);
        }
        
        const fullHistoryForLLM = [
            ...historyForLLM,
            { role: 'user', parts: [{ text: queryForLLM }] }
        ];
        
        console.log(`   Calling ${llmProvider || 'Gemini'} API. History length for LLM: ${fullHistoryForLLM.length}. System Prompt Used: ${!!mainSystemPromptText}. Query for LLM (first 150 chars): ${queryForLLM.substring(0,150)}...`);
        
        aiResponseMessageText = await generateContentWithHistory(fullHistoryForLLM, mainSystemPromptText);
        
        const aiMessageForDbAndClient = {
            sender: 'bot',
            role: 'model',
            parts: [{ text: aiResponseMessageText }],
            text: aiResponseMessageText,
            timestamp: new Date(),
            thinking: null, 
            references: referencesForResponse,
            source_pipeline: actualSourcePipeline,
            critical_thinking_applied_details: useRag && criticalThinkingEnabled && relevantDocsFromRag.length > 0 ? "KG-enhanced RAG" : (criticalThinkingEnabled ? "Requested, not RAG/KG path" : "Not requested")
        };

        const dbUserMessageForSave = { role: 'user', parts: userMessageForDb.parts, timestamp: userMessageForDb.timestamp };
        const dbAiMessageForSave = { 
            role: 'model', 
            parts: aiMessageForDbAndClient.parts, 
            timestamp: aiMessageForDbAndClient.timestamp, 
            thinking: aiMessageForDbAndClient.thinking, 
            references: aiMessageForDbAndClient.references, 
            source_pipeline: aiMessageForDbAndClient.source_pipeline,
            critical_thinking_requested: !!criticalThinkingEnabled 
        };

        await ChatHistory.findOneAndUpdate(
            { sessionId: sessionId, userId: userId },
            {
                $push: { messages: { $each: [dbUserMessageForSave, dbAiMessageForSave] } },
                $set: { updatedAt: new Date() } 
            },
            { upsert: true, new: true, setDefaultsOnInsert: true }
        );

        console.log(`<<< POST /api/chat/message successful for Session ${sessionId}.`);
        res.status(200).json({ reply: aiMessageForDbAndClient }); 

    } catch (error) {
        // ... (your existing error handling logic - looks good) ...
        console.error(`!!! Error processing chat message for Session ${sessionId} (RAG: ${useRag}, CriticalThinking: ${criticalThinkingEnabled}):`, error);
        let statusCode = error.status || error.response?.status || 500;
        let clientMessage = error.message || error.response?.data?.message || "Failed to get response from AI service.";
        if (error.response && error.response.data && error.response.data.error) {
            clientMessage = `Error from dependent service: ${error.response.data.error}`;
        }


        const errorMessageForChat = {
            sender: 'bot',
            role: 'model',
            parts: [{ text: `Error: ${clientMessage}` }],
            text: `Error: ${clientMessage}`,
            timestamp: new Date(),
            thinking: `Error occurred during processing: ${error.message}`, 
            references: [],
            source_pipeline: 'error-pipeline'
        };
        
        try {
            const dbUserMessageOnError = { role: 'user', parts: userMessageForDb.parts, timestamp: userMessageForDb.timestamp };
            const dbAiErrorMsg = { 
                role: 'model', 
                parts: errorMessageForChat.parts, 
                timestamp: errorMessageForChat.timestamp, 
                thinking: errorMessageForChat.thinking,
                references: errorMessageForChat.references, 
                source_pipeline: errorMessageForChat.source_pipeline,
                critical_thinking_requested: !!criticalThinkingEnabled
            };

            await ChatHistory.findOneAndUpdate(
                { sessionId: sessionId, userId: userId },
                {
                    $push: { messages: { $each: [dbUserMessageOnError, dbAiErrorMsg] } },
                    $set: { updatedAt: new Date() }
                },
                { upsert: true, new: true, setDefaultsOnInsert: true }
            );
        } catch (dbError) {
            console.error(`!!! CRITICAL: Failed to save error message to chat history for Session ${sessionId}:`, dbError);
        }
        res.status(statusCode).json({ message: clientMessage, reply: errorMessageForChat });
    }
});

// --- @route   POST /api/chat/history ---
// ... (rest of the file remains the same as your last provided version)
// --- @desc    Primarily for generating a new session ID for "New Chat" button.
// ---           Can also save an entire batch of messages if needed, but /message handles incremental.
// --- @access  Private ---
router.post('/history', async (req, res) => {
    const { sessionId, messages } = req.body;
    const userId = req.user._id;

    if (!sessionId || sessionId.startsWith('client-initiate-') || (Array.isArray(messages) && messages.length === 0)) {
        const newServerSessionId = uuidv4();
        console.log(`>>> POST /api/chat/history (New Session ID): User=${userId}. Client Temp SID: ${sessionId}. Generated New SID: ${newServerSessionId}`);
        return res.status(200).json({
            message: 'New session ID generated.',
            savedSessionId: null, 
            newSessionId: newServerSessionId 
        });
    }

    if (!Array.isArray(messages) || messages.length === 0) {
        return res.status(400).json({ message: 'No valid messages provided to save for existing session.' });
    }

    console.log(`>>> POST /api/chat/history (Explicit Save): User=${userId}, Session=${sessionId}, Messages=${messages.length}`);
    try {
        const validMessagesForDb = messages.filter(m =>
            m && typeof (m.sender === 'user' ? 'user' : (m.sender === 'bot' ? 'model' : undefined)) === 'string' &&
            Array.isArray(m.parts) && m.parts.length > 0 &&
            typeof m.parts[0].text === 'string' &&
            m.timestamp
        ).map(m => ({
            role: m.sender === 'user' ? 'user' : 'model',
            parts: m.parts.map(p => ({ text: p.text || ''})),
            timestamp: new Date(m.timestamp),
            thinking: m.thinking || null, 
            references: m.references || [], 
            source_pipeline: m.source_pipeline || undefined
        }));

        if (validMessagesForDb.length === 0) {
            return res.status(400).json({ message: 'No valid messages to save after filtering.' });
        }

        const savedHistory = await ChatHistory.findOneAndUpdate(
            { sessionId: sessionId, userId: userId },
            { $set: { userId: userId, sessionId: sessionId, messages: validMessagesForDb, updatedAt: Date.now() } },
            { new: true, upsert: true, setDefaultsOnInsert: true } 
        );

        console.log(`<<< POST /api/chat/history (Explicit Save): History saved for session ${savedHistory.sessionId}.`);
        res.status(200).json({
            message: 'Chat history explicitly saved successfully.',
            savedSessionId: savedHistory.sessionId,
            newSessionId: savedHistory.sessionId
        });
    } catch (error) {
        console.error(`!!! Error explicitly saving chat history for session ${sessionId}:`, error);
        if (error.name === 'ValidationError') return res.status(400).json({ message: "Validation Error: " + error.message });
        res.status(500).json({ message: 'Failed to save chat history due to a server error.' });
    }
});


// --- @route   GET /api/chat/sessions ---
// --- @desc    Get a list of user's past chat sessions ---
// --- @access  Private ---
router.get('/sessions', async (req, res) => {
    const userId = req.user._id;
    console.log(`>>> GET /api/chat/sessions: User=${userId}`);
    try {
        const sessions = await ChatHistory.find({ userId: userId })
            .sort({ updatedAt: -1 })
            .select('sessionId createdAt updatedAt messages')
            .lean();

        const sessionSummaries = sessions.map(session => {
            const firstUserMessage = session.messages?.find(m => m.role === 'user');
            let preview = 'Chat Session';
            if (firstUserMessage?.parts?.[0]?.text) {
                preview = firstUserMessage.parts[0].text.substring(0, 75);
                if (firstUserMessage.parts[0].text.length > 75) preview += '...';
            } else if (session.messages?.length > 0 && session.messages[0]?.parts?.[0]?.text) {
                preview = session.messages[0].parts[0].text.substring(0, 75) + (session.messages[0].parts[0].text.length > 75 ? "..." : "");
            }

            return {
                sessionId: session.sessionId,
                createdAt: session.createdAt,
                updatedAt: session.updatedAt,
                messageCount: session.messages?.length || 0,
                preview: preview
            };
        });
        console.log(`<<< GET /api/chat/sessions: Found ${sessionSummaries.length} sessions for User ${userId}.`);
        res.status(200).json(sessionSummaries);
    } catch (error) {
        console.error(`!!! Error fetching chat sessions for user ${userId}:`, error);
        res.status(500).json({ message: 'Failed to retrieve chat sessions.' });
    }
});


// --- @route   GET /api/chat/session/:sessionId ---
// --- @desc    Get all messages for a specific session ---
// --- @access  Private ---
router.get('/session/:sessionId', async (req, res) => {
    const userId = req.user._id;
    const { sessionId } = req.params;
    console.log(`>>> GET /api/chat/session/${sessionId}: User=${userId}`);

    if (!sessionId) {
        return res.status(400).json({ message: 'Session ID parameter is required.' });
    }

    try {
        const session = await ChatHistory.findOne({ sessionId: sessionId, userId: userId }).lean();
        if (!session) {
            console.log(`--- GET /api/chat/session/${sessionId}: Session not found for User ${userId}.`);
            return res.status(404).json({ message: 'Chat session not found or access denied.' });
        }
        console.log(`<<< GET /api/chat/session/${sessionId}: Session found for User ${userId}. Messages: ${session.messages?.length}`);
        
        const messagesForFrontend = (session.messages || []).map(msg => ({
            id: msg._id?.toString() || uuidv4(),
            sender: msg.role === 'model' ? 'bot' : 'user',
            text: msg.parts?.[0]?.text || '',
            thinking: msg.thinking, 
            references: msg.references, 
            timestamp: msg.timestamp,
            source_pipeline: msg.source_pipeline
        }));
        
        res.status(200).json({ ...session, messages: messagesForFrontend });
    } catch (error) {
        console.error(`!!! Error fetching chat session ${sessionId} for user ${userId}:`, error);
        res.status(500).json({ message: 'Failed to retrieve chat session details.' });
    }
});

// --- @route   POST /api/chat/rag ---
// --- @desc    Directly test RAG (not part of main chat flow if /message handles RAG) ---
// --- @access  Private ---
router.post('/rag', async (req, res) => {
    const { message, filter, k } = req.body; // k can also be passed from client for this test route
    const userId = req.user._id.toString();

    if (!message || typeof message !== 'string' || message.trim() === '') {
        return res.status(400).json({ message: 'Query message text required.' });
    }
    console.log(`>>> POST /api/chat/rag (Direct Test): User=${userId}. Query: "${message.substring(0, 50)}..."`);
    try {
        const kValue = parseInt(k) || parseInt(process.env.RAG_DEFAULT_K) || 5;
        const clientFilterToPass = filter && typeof filter === 'object' ? filter : null;

        // For this direct /rag test route, documentContextName and criticalThinkingEnabled
        // are not typically part of its direct purpose, but you could add them if needed.
        // Assuming criticalThinkingEnabled = false and documentContextName = null for this test.
        const relevantDocs = await queryPythonRagService(
            userId, 
            message.trim(), 
            false, // criticalThinkingEnabled for this test
            null,  // documentContextName for this test
            clientFilterToPass,
            kValue
        );
        console.log(`<<< POST /api/chat/rag successful for User ${userId}. Found ${relevantDocs.length} docs.`);
        res.status(200).json({ relevantDocs }); 
    } catch (error) {
        console.error(`!!! Error processing RAG query for User ${userId}:`, error.message);
        res.status(500).json({ message: error.message || "Failed to retrieve relevant documents." });
    }
});

module.exports = router;
```

`server/routes/files.js`

```javascript
// server/routes/files.js
const express = require('express');
const fs = require('fs').promises;
const path = require('path');
const { authMiddleware } = require('../middleware/authMiddleware');
const User = require('../models/User');
const axios = require('axios');
const router = express.Router();

const ASSETS_DIR = path.join(__dirname, '..', 'assets');
const BACKUP_DIR = path.join(__dirname, '..', 'backup_assets');

// --- Helper functions (sanitizeUsernameForDir, parseServerFilename, ensureDirExists are existing) ---
const sanitizeUsernameForDir = (username) => {
    if (!username) return '';
    return username.replace(/[^a-zA-Z0-9_-]/g, '_');
};

const parseServerFilename = (filename) => {
    // Matches "timestamp-originalName.ext"
    // Allows originalName to contain dots now.
    const match = filename.match(/^(\d+)-(.+?)(\.\w+)$/);
    if (match && match.length === 4) {
        return { timestamp: match[1], originalName: `${match[2]}${match[3]}`, extension: match[3] };
    }
    // Fallback for names that might not perfectly fit the new pattern, or originalName without extension before timestamp
    const ext = path.extname(filename);
    const baseWithoutExt = filename.substring(0, filename.length - ext.length);
    const tsMatch = baseWithoutExt.match(/^(\d+)-(.*)$/);
    if (tsMatch) {
        return { timestamp: tsMatch[1], originalName: `${tsMatch[2]}${ext}`, extension: ext };
    }
    // Final fallback if no timestamp prefix is reliably parsed
    return { timestamp: null, originalName: filename, extension: path.extname(filename) };
};

const ensureDirExists = async (dirPath) => {
    try { await fs.mkdir(dirPath, { recursive: true }); }
    catch (error) { if (error.code !== 'EEXIST') { console.error(`Error creating dir ${dirPath}:`, error); throw error; } }
};

async function callPythonDeletionEndpoint(method, endpointPath, userId, originalName, logContext) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL || process.env.DEFAULT_PYTHON_RAG_URL || 'http://localhost:5000'; // Fallback if not set
    if (!pythonServiceUrl) {
        console.error(`Python Service Deletion Error for ${logContext}: PYTHON_RAG_SERVICE_URL not set.`);
        return { success: false, message: "Python service URL not configured." };
    }

    const deleteUrl = `${pythonServiceUrl.replace(/\/$/, '')}${endpointPath}`;

    try {
        console.log(`Calling Python Service (${method.toUpperCase()}) for deletion: ${deleteUrl} (Doc: ${originalName}, User: ${userId})`);
        let response;
        if (method.toUpperCase() === 'DELETE') {
            // For DELETE, data is often in query params or path, but axios allows a 'data' field for body
            response = await axios.delete(deleteUrl, {
                data: { // For Python endpoints that expect a body (like a new Qdrant delete one)
                    user_id: userId,
                    document_name: originalName
                },
                timeout: 30000 // 30s timeout
            });
        } else {
            throw new Error(`Unsupported method for Python deletion: ${method}`);
        }

        if (response.status === 200 || response.status === 204) { // 204 No Content is also success
            return { success: true, message: response.data?.message || `Successfully deleted from ${endpointPath}` };
        } else {
            return { success: false, message: response.data?.message || `Python service returned ${response.status} for ${endpointPath}` };
        }
    } catch (error) {
        const errorMsg = error.response?.data?.error || error.response?.data?.message || error.message || `Unknown error deleting from ${endpointPath}`;
        console.error(`Error calling Python Service for deletion (${deleteUrl}) for ${originalName} (User: ${userId}): ${errorMsg}`, error.response ? { status: error.response.status, data: error.response.data } : error);
        return { success: false, message: `Python service call failed for ${endpointPath}: ${errorMsg}` };
    }
}
// --- End Helper Functions ---


// --- @route   GET /api/files ---
// Use authMiddleware middleware 
// TO GET FILE NAMES
router.get('/', authMiddleware, async (req, res) => {
    
    const userFiles = []
    try {
        const userId = req.user._id.toString();

        // Find user by ID, select only uploadedDocuments to optimize
        const user = await User.findById(userId).select('uploadedDocuments');

        if (!user) return res.status(404).json({ msg: 'User not found' });

        // Extract filenames
        const filenames = user.uploadedDocuments
        .map(doc => doc.filename)
        .filter(Boolean)  // filter out undefined or null filenames just in case
        .reverse();       // reverse the order

        return res.json({ filenames });

    } catch (error) {
        console.log(error.message);
        return res.status(500).json({ msg: 'Server error' });
    }
});


// --- @route   DELETE /api/files/:serverFilename ---
// Use authMiddleware middleware
router.delete('/:serverFilename', authMiddleware, async (req, res) => {
  
    const { serverFilename } = req.params;
    const userId = req.user._id.toString(); // Get userId from authenticated user
    const usernameForLog = req.user.username;

    if (!serverFilename) {
        return res.status(400).json({ message: 'Server filename parameter is required.' });
    }

    const parsedFileDetails = parseServerFilename(serverFilename);
    const originalName = parsedFileDetails.originalName;
    if (!originalName) {
        console.error(`DELETE /api/files: Could not parse originalName from serverFilename: ${serverFilename}`);
        return res.status(400).json({ message: 'Invalid server filename format for deletion.' });
    }
    const logContext = `File: '${originalName}' (server: ${serverFilename}), User: ${usernameForLog} (${userId})`;
    console.log(`Attempting to delete all data for ${logContext}`);

    const results = {
        mongodb: { success: false, message: "Not attempted" },
        qdrant: { success: false, message: "Not attempted" },
        neo4j: { success: false, message: "Not attempted" },
        filesystem: { success: false, message: "Not attempted" },
    };
    let overallSuccess = true; // Assume success, set to false if any critical step fails
    let httpStatus = 200;
    let fileFoundInMongo = false;
    let physicalFileFound = false;

    try {
        // 1. Delete from MongoDB
        try {
            const user = await User.findById(userId);
            if (!user) {
                results.mongodb.message = "User not found.";
                // If user not found, we can't confirm if the file was theirs.
                // Treat as if the file wasn't found for this user.
            } else {
                const docIndex = user.uploadedDocuments.findIndex(doc => doc.filename === originalName);
                if (docIndex > -1) {
                    fileFoundInMongo = true;
                    user.uploadedDocuments.splice(docIndex, 1);
                    await user.save();
                    results.mongodb.success = true;
                    results.mongodb.message = "Successfully removed from user's document list.";
                    console.log(`MongoDB: Document entry '${originalName}' removed for user ${userId}.`);
                } else {
                    results.mongodb.message = "Document not found in user's list.";
                    console.log(`MongoDB: Document entry '${originalName}' not found for user ${userId}.`);
                }
            }
        } catch (mongoError) {
            console.error(`MongoDB Deletion Error for ${logContext}:`, mongoError);
            results.mongodb.message = `MongoDB deletion failed: ${mongoError.message}`;
            overallSuccess = false; // DB error is critical
        }

        // 2. Delete from Qdrant (via Python service)
        // This endpoint will need to be created in Python: e.g., /delete_qdrant_document_data
        // It should expect { user_id: userId, document_name: originalName } in the body
        const qdrantDeleteResult = await callPythonDeletionEndpoint(
            'DELETE',
            `/delete_qdrant_document_data`,
            userId,
            originalName,
            logContext
        );
        results.qdrant = qdrantDeleteResult;
        if (!qdrantDeleteResult.success) {
            console.warn(`Qdrant deletion failed or reported no data for ${logContext}. Message: ${qdrantDeleteResult.message}`);
            // overallSuccess = false; // Non-critical for now, but log
        }

        // 3. Delete from Neo4j (via Python service)
        // This uses the existing Python endpoint: /kg/<user_id>/<document_name>
        const neo4jEndpointPath = `/kg/${userId}/${encodeURIComponent(originalName)}`;
        const neo4jDeleteResult = await callPythonDeletionEndpoint(
            'DELETE',
            neo4jEndpointPath, // userId and originalName are in the path
            userId, // still pass for logging consistency in helper
            originalName, // still pass for logging consistency in helper
            logContext
        );
        results.neo4j = neo4jDeleteResult;
        if (!neo4jDeleteResult.success) {
            console.warn(`Neo4j deletion failed or reported no data for ${logContext}. Message: ${neo4jDeleteResult.message}`);
            // overallSuccess = false; // Non-critical for now, but log
        }

        // 4. Move physical file to backup (filesystem operation)
        let currentPath = null;
        let fileType = '';
        const fileTypesToSearch = ['docs', 'images', 'code', 'others'];
        const sanitizedUsernameForPath = sanitizeUsernameForDir(usernameForLog);

        for (const type of fileTypesToSearch) {
            const potentialPath = path.join(ASSETS_DIR, sanitizedUsernameForPath, type, serverFilename);
            try {
                await fs.access(potentialPath); // Check if file exists
                currentPath = potentialPath;
                fileType = type;
                physicalFileFound = true;
                break;
            } catch (e) {
                if (e.code !== 'ENOENT') {
                    console.warn(`Filesystem: Error accessing ${potentialPath} during delete scan: ${e.message}`);
                }
            }
        }

        if (currentPath) { // If physical file was found
            const backupUserDir = path.join(BACKUP_DIR, sanitizedUsernameForPath, fileType);
            await ensureDirExists(backupUserDir);
            const backupPath = path.join(backupUserDir, serverFilename);
            try {
                await fs.rename(currentPath, backupPath);
                results.filesystem = { success: true, message: "File moved to backup successfully." };
                console.log(`Filesystem: Moved '${currentPath}' to '${backupPath}'.`);
            } catch (fsError) {
                console.error(`Filesystem: Error moving file ${currentPath} to backup for ${logContext}:`, fsError);
                results.filesystem.message = `Filesystem move to backup failed: ${fsError.message}`;
                // overallSuccess = false; // Decide if this is critical enough to mark overall failure
            }
        } else {
            results.filesystem.message = "Physical file not found in assets, or already moved.";
            console.log(`Filesystem: Physical file '${serverFilename}' not found for user ${usernameForLog}.`);
        }

        // Determine final status and message
        const successfulDeletes = [results.mongodb.success, results.qdrant.success, results.neo4j.success, results.filesystem.success].filter(Boolean).length;

        if (!fileFoundInMongo && !physicalFileFound) {
            httpStatus = 404;
            finalMessage = `File '${originalName}' not found for user.`;
        } else if (results.mongodb.success) { // Primary record deleted
            if (successfulDeletes === 4) {
                finalMessage = `Successfully deleted all data associated with '${originalName}'.`;
                httpStatus = 200;
            } else {
                finalMessage = `File '${originalName}' removed from your list. Some backend data cleanup attempts had issues. Check server logs for details.`;
                httpStatus = 207; // Multi-Status
            }
        } else { // MongoDB deletion failed, but file might have existed
            finalMessage = `Failed to remove '${originalName}' from your list. Some backend data cleanup may have also failed. Check server logs.`;
            httpStatus = 500;
        }

        console.log(`Deletion outcome for ${logContext}: HTTP Status=${httpStatus}, Overall Success Flag (was pre-status logic)=${overallSuccess}`);
        return res.status(httpStatus).json({
            message: finalMessage,
            details: results
        });

    } catch (error) {
        console.error(`!!! UNEXPECTED Error in DELETE /api/files/${serverFilename} for user ${usernameForLog}:`, error);
        return res.status(500).json({
            message: 'An unexpected server error occurred during file deletion.',
            details: results // Send partial results if any
        });
    }
});


module.exports = router;

```

`server/routes/mindmap.js`

```javascript
// server/routes/mindmap.js
const express = require('express');
const router = express.Router();
const { authMiddleware } = require('../middleware/authMiddleware');
const User = require('../models/User'); // For a more advanced implementation

// @route   GET /api/mindmap
// @desc    Get Mermaid code for a mind map
// @access  Private (requires auth)
router.get('/', authMiddleware, async (req, res) => {
    const userId = req.user._id; // User is authenticated
    console.log(`>>> GET /api/mindmap: User=${userId}`);

    try {
        const user = await User.findById(userId).select('uploadedDocuments.filename uploadedDocuments.analysis.mindmap'); // Select only necessary fields
        
        let mindmapCode = null;
        let sourceDocumentName = "Unknown Document";

        if (user && user.uploadedDocuments && user.uploadedDocuments.length > 0) {
            // Find the most recent document that has a mindmap analysis.
            // This assumes higher index means more recent, or you'd sort by an explicit timestamp if available.
            for (let i = user.uploadedDocuments.length - 1; i >= 0; i--) {
                const doc = user.uploadedDocuments[i];
                if (doc.analysis && typeof doc.analysis.mindmap === 'string' && doc.analysis.mindmap.trim() !== "") {
                    mindmapCode = doc.analysis.mindmap.trim();
                    sourceDocumentName = doc.filename || "Untitled Document";
                    console.log(`   Found mindmap for document '${sourceDocumentName}' for user ${userId}.`);
                    break;
                }
            }
        }

        if (mindmapCode) {
            // Basic check if the code starts with a known Mermaid diagram type.
            // This is a simple heuristic. Robust validation is complex.
            const trimmedCode = mindmapCode; // Already trimmed
            const validMermaidPrefixes = ['mindmap', 'graph', 'flowchart', 'sequenceDiagram', 'gantt', 'classDiagram', 'stateDiagram', 'pie', 'erDiagram', 'journey', 'requirementDiagram', 'gitGraph'];
            
            const isPotentiallyValidMermaid = validMermaidPrefixes.some(prefix => 
                trimmedCode.toLowerCase().startsWith(prefix)
            );

            if (!isPotentiallyValidMermaid) {
                // If the stored code doesn't look like Mermaid, prepend 'mindmap'
                // This is an assumption that the stored data *should* be a mindmap if it's in this field.
                console.warn(`   Mindmap code for '${sourceDocumentName}' does not start with a recognized Mermaid type. Prefixing with 'mindmap'.`);
                mindmapCode = `mindmap\n${trimmedCode}`; 
            } else if (!trimmedCode.toLowerCase().startsWith('mindmap')) {
                 // If it's valid Mermaid but not explicitly 'mindmap' (e.g. 'graph TD'),
                 // and the user specifically clicked "Mind Map", it's still okay to send.
                 // The Mermaid library on the frontend can render various diagram types.
                console.log(`   Sending stored analysis as Mermaid diagram. Type: ${trimmedCode.split('\n')[0].trim()}`);
            }
            return res.status(200).json({ mermaidCode: mindmapCode, source: sourceDocumentName });
        } else {
            console.log(`   No mindmap analysis found for user ${userId}. Returning default mindmap.`);
            const defaultMermaidCode = `
mindmap
  root((No Mind Map Available))
    (Please upload a document and ensure its analysis includes a mind map.)
    (Or, no documents processed yet.)
`;
            return res.status(200).json({ mermaidCode: defaultMermaidCode, source: "Default" });
        }

    } catch (error) {
        console.error(`!!! Error in GET /api/mindmap for User ${userId}:`, error);
        res.status(500).json({ message: "Failed to retrieve mind map code due to a server error." });
    }
});

module.exports = router;
```

`server/routes/network.js`

```javascript
const express = require('express');
const router = express.Router();
const os = require('os');

function getAllIPs() {
    const interfaces = os.networkInterfaces();
    const ips = new Set(['localhost']); // Include localhost by default

    for (const [name, netInterface] of Object.entries(interfaces)) {
        // Skip loopback and potentially virtual interfaces if desired
        if (name.includes('lo') || name.toLowerCase().includes('virtual') || name.toLowerCase().includes('vmnet')) continue;

        for (const addr of netInterface) {
            // Focus on IPv4, non-internal addresses
            if (addr.family === 'IPv4' && !addr.internal) {
                ips.add(addr.address);
            }
        }
    }
    return Array.from(ips);
}

router.get('/ip', (req, res) => {
    res.json({
        ips: getAllIPs(),
        // req.ip might be less reliable behind proxies, but can be included
        // currentRequestIp: req.ip
    });
});

module.exports = router;

```

`server/routes/syllabus.js`

```javascript
// server/routes/syllabus.js
const express = require('express');
const fs = require('fs').promises;
const path = require('path');
const { authMiddleware } = require('../middleware/authMiddleware'); // Protect the route

const router = express.Router();
const SYLLABI_DIR = path.join(__dirname, '..', 'syllabi');

// --- @route   GET /api/syllabus/:subjectId ---
// --- @desc    Get syllabus content for a specific subject ---
// --- @access  Private (requires auth) ---
router.get('/:subjectId', authMiddleware, async (req, res) => {
    const { subjectId } = req.params;

    // Basic sanitization: Allow only alphanumeric and underscores
    // Prevents directory traversal (e.g., ../../etc/passwd)
    const sanitizedSubjectId = subjectId.replace(/[^a-zA-Z0-9_]/g, '');

    if (!sanitizedSubjectId || sanitizedSubjectId !== subjectId) {
        console.warn(`Syllabus request rejected due to invalid characters: ${subjectId}`);
        return res.status(400).json({ message: 'Invalid subject identifier format.' });
    }

    const filePath = path.join(SYLLABI_DIR, `${sanitizedSubjectId}.md`);

    try {
        // Check if file exists first (more specific error)
        await fs.access(filePath);

        // Read the file content
        const content = await fs.readFile(filePath, 'utf-8');

        res.status(200).json({ syllabus: content });

    } catch (error) {
        if (error.code === 'ENOENT') {
            console.warn(`Syllabus file not found: ${filePath}`);
            return res.status(404).json({ message: `Syllabus for '${subjectId}' not found.` });
        } else {
            console.error(`Error reading syllabus file ${filePath}:`, error);
            return res.status(500).json({ message: 'Server error retrieving syllabus.' });
        }
    }
});

module.exports = router;

```

`server/routes/upload.js`

```javascript
// server/routes/upload.js
const express = require('express');
const multer = require('multer');
const path = require('path');
const fs = require('fs');
const axios = require('axios');
const { authMiddleware } = require('../middleware/authMiddleware');
const User = require('../models/User'); // Import the User model
const { Worker } = require('worker_threads');
// const { ANALYSIS_PROMPTS } = require('../config/promptTemplates'); 
// const geminiService = require('../services/geminiService');

const router = express.Router();

// --- Constants ---
const UPLOAD_DIR = path.join(__dirname, '..', 'assets');
const MAX_FILE_SIZE = 20 * 1024 * 1024; // 20 MB

// Define allowed types by mimetype and extension (lowercase)
// Mapping mimetype to subfolder name
const allowedMimeTypes = {
    // Documents -> 'docs'
    'application/pdf': 'docs',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document': 'docs', // .docx
    'application/msword': 'docs', // .doc (Might be less reliable mimetype)
    'application/vnd.openxmlformats-officedocument.presentationml.presentation': 'docs', // .pptx
    'application/vnd.ms-powerpoint': 'docs', // .ppt (Might be less reliable mimetype)
    'text/plain': 'docs', // .txt
    // Code -> 'code'
    'text/x-python': 'code', // .py
    'application/javascript': 'code', // .js
    'text/javascript': 'code', // .js (alternative)
    'text/markdown': 'code', // .md
    'text/html': 'code', // .html
    'application/xml': 'code', // .xml
    'text/xml': 'code', // .xml
    'application/json': 'code', // .json
    'text/csv': 'code', // .csv
    // Images -> 'images'
    'image/jpeg': 'images',
    'image/png': 'images',
    'image/bmp': 'images',
    'image/gif': 'images',
    // Add more specific types if needed, otherwise they fall into 'others'
};
// Define allowed extensions (lowercase) - This is a secondary check
const allowedExtensions = [
    '.pdf', '.docx', '.doc', '.pptx', '.ppt', '.txt',
    '.py', '.js', '.md', '.html', '.xml', '.json', '.csv', '.log', // Added .log
    '.jpg', '.jpeg', '.png', '.bmp', '.gif'
];

// --- Multer Config ---
const storage = multer.diskStorage({
    destination: (req, file, cb) => {
        // authMiddleware middleware ensures req.user exists here
        if (!req.user || !req.user.username) {
            // This should ideally not happen if authMiddleware works correctly
            console.error("Multer Destination Error: User context missing after auth middleware.");
            return cb(new Error("Authentication error: User context not found."));
        }
        const sanitizedUsername = req.user.username.replace(/[^a-zA-Z0-9_-]/g, '_');
        const fileMimeType = file.mimetype.toLowerCase();

        // Determine subfolder based on mimetype, default to 'others'
        const fileTypeSubfolder = allowedMimeTypes[fileMimeType] || 'others';
        const destinationPath = path.join(UPLOAD_DIR, sanitizedUsername, fileTypeSubfolder);

        // Ensure the destination directory exists (use async for safety)
        fs.mkdir(destinationPath, { recursive: true }, (err) => {
             if (err) {
                 console.error(`Error creating destination path ${destinationPath}:`, err);
                 cb(err);
             } else {
                 cb(null, destinationPath);
             }
         });
    },
    filename: (req, file, cb) => {
        const timestamp = Date.now();
        const fileExt = path.extname(file.originalname).toLowerCase();
        // Sanitize base name: remove extension, replace invalid chars, limit length
        const sanitizedBaseName = path.basename(file.originalname, fileExt)
                                      .replace(/[^a-zA-Z0-9._-]/g, '_') // Allow letters, numbers, dot, underscore, hyphen
                                      .substring(0, 100); // Limit base name length
        const uniqueFilename = `${timestamp}-${sanitizedBaseName}${fileExt}`;
        cb(null, uniqueFilename);
    }
});

const fileFilter = (req, file, cb) => {
    // authMiddleware middleware should run before this, ensuring req.user exists
    if (!req.user) {
         console.warn(`Upload Rejected (File Filter): User context missing.`);
         const error = new multer.MulterError('UNAUTHENTICATED'); // Custom code?
         error.message = `User not authenticated.`;
         return cb(error, false);
    }

    const fileExt = path.extname(file.originalname).toLowerCase();
    const mimeType = file.mimetype.toLowerCase();

    // Primary check: Mimetype must be in our known list OR extension must be allowed
    // Secondary check: Extension must be in the allowed list
    const isMimeTypeKnown = !!allowedMimeTypes[mimeType];
    const isExtensionAllowed = allowedExtensions.includes(fileExt);

    // Allow if (MIME type is known OR extension is explicitly allowed) AND extension is in the allowed list
    // This allows known MIME types even if extension isn't listed, and listed extensions even if MIME isn't known (e.g. text/plain for .log)
    // But we always require the extension itself to be in the allowed list for safety.
    // if ((isMimeTypeKnown || isExtensionAllowed) && isExtensionAllowed) {

    // Stricter: Allow only if BOTH mimetype is known AND extension is allowed
    if (isMimeTypeKnown && isExtensionAllowed) {
        cb(null, true); // Accept file
    } else {
        console.warn(`Upload Rejected (File Filter): User='${req.user.username}', File='${file.originalname}', MIME='${mimeType}', Ext='${fileExt}'. MimeKnown=${isMimeTypeKnown}, ExtAllowed=${isExtensionAllowed}`);
        const error = new multer.MulterError('LIMIT_UNEXPECTED_FILE');
        error.message = `Invalid file type or extension. Allowed extensions: ${allowedExtensions.join(', ')}`;
        cb(error, false); // Reject file
    }
};

const upload = multer({
    storage: storage,
    fileFilter: fileFilter,
    limits: { fileSize: MAX_FILE_SIZE }
});
// --- End Multer Config ---


// --- Function to call Python RAG service ---
async function triggerPythonRagProcessing(userId, filePath, originalName) {
    const pythonServiceUrl = process.env.PYTHON_RAG_SERVICE_URL;
    if (!pythonServiceUrl) {
        console.error("PYTHON_RAG_SERVICE_URL is not set in environment. Cannot trigger RAG processing.");
        return {
            success: false,
            message: "RAG service URL not configured.",
            status: 'error', // Indicate a config error
            text: null,
            chunksForKg: []
        };
    }

    const addDocumentUrl = `${pythonServiceUrl}/add_document`;
    console.log(`Calling Python RAG Service: ${addDocumentUrl} for document '${originalName}' (User: ${userId})`);

    try {
        const response = await axios.post(addDocumentUrl, {
            user_id: userId,
            file_path: filePath, // Absolute path to the file on the server
            original_name: originalName
        }); // 5 minute timeout

        const pythonData = response.data;
        // console.log(`Python RAG service response for '${originalName}':`, JSON.stringify(pythonData).substring(0, 500) + "..."); // Log snippet

        // Extract data carefully, providing defaults
        const text = pythonData?.raw_text_for_analysis || null;
        const chunksForKg = pythonData?.chunks_with_metadata || [];
        const pythonStatus = pythonData?.status; // e.g., 'added', 'skipped_no_content', 'processed_qdrant_chunks_not_added', etc.
        let pythonMessage = pythonData?.message || "No specific message from Python RAG service.";

        // Determine overall success for the RAG step based on Python's status
        // 'added' means Qdrant was updated, which is the primary goal for RAG.
        // 'processed_for_analysis_only_no_qdrant' means text was extracted but Qdrant failed/skipped. This might still be a "partial success" if text is valuable.
        // For now, let's consider 'added' as the main success criteria for proceeding with text-dependent tasks.
        const isRagStepSuccessful = pythonStatus === 'added';

        if (!isRagStepSuccessful && !text) {
            // If RAG didn't succeed in adding to Qdrant AND there's no text, it's a more significant failure.
            pythonMessage = `RAG processing critical failure: ${pythonMessage} (Status: ${pythonStatus})`;
        } else if (!isRagStepSuccessful && text) {
            pythonMessage = `RAG processing partial: ${pythonMessage} (Status: ${pythonStatus}). Text was extracted, but Qdrant step may have issues.`;
        }


        return {
            success: isRagStepSuccessful, // True primarily if pythonStatus is 'added'
            status: pythonStatus,         // The actual status string from Python
            message: pythonMessage,
            text: text,                   // Extracted text (can be null)
            chunksForKg: chunksForKg      // Chunks for KG (can be empty)
        };

    } catch (error) {
        const errorMsg = error.response?.data?.error || error.response?.data?.message || error.message || "Unknown error calling Python RAG service";
        console.error(`Error calling Python RAG service for '${originalName}': ${errorMsg}`);
        // Log more details if available from error.response
        if (error.response && error.response.data) {
            // console.error("Python service error details:", error.response.data);
        }
        return {
            success: false,
            message: `Python RAG service call failed: ${errorMsg}`,
            status: 'error_calling_python', // Custom status for this type of failure
            text: null,
            chunksForKg: []
        };
    }
}
// --- End Function ---


// --- Function to call Generate Analysis
async function triggerAnalysisGeneration(userId, originalName, textForAnalysis) {
    console.log(`Starting analysis generation for document '${originalName}', User ID: ${userId}. Text length: ${textForAnalysis.length}`);

    let allAnalysesSuccessful = true; // Assume success initially
    const analysisResults = {
        faq: null,
        topics: null,
        mindmap: null
    };
    const logCtx = { userId, originalName }; // Context for logging within generateSingleAnalysis

    // Inner helper function to generate a single type of analysis
    async function generateSingleAnalysis(type, promptContent, context) {
        try {
            console.log(`Attempting to generate ${type} for '${context.originalName}' (User: ${context.userId}).`);

            // Prepare history for geminiService.generateContentWithHistory
            // The 'promptContent' (which is the system prompt) will be passed as the second argument.
            const historyForGemini = [
                { role: 'user', parts: [{ text: "Please perform the requested analysis based on the system instruction provided." }] }
            ];

            const generatedText = await geminiService.generateContentWithHistory(
                historyForGemini,
                promptContent // This is passed as systemPromptText to generateContentWithHistory
            );

            if (!generatedText || typeof generatedText !== 'string' || generatedText.trim() === "") {
                console.warn(`Gemini returned empty or invalid content for ${type} for '${context.originalName}'.`);
                allAnalysesSuccessful = false; // Update the outer scope variable
                return `Notice: No content was generated by the AI for ${type}. The input text might have been unsuitable or the AI returned an empty response.`;
            }

            console.log(`${type} generation successful for '${context.originalName}'. Length: ${generatedText.length}`);
            return generatedText.trim();

        } catch (error) {
            console.error(`Error during ${type} generation for '${context.originalName}' (User: ${context.userId}): ${error.message}`);
            allAnalysesSuccessful = false; // Update the outer scope variable
            // Return a user-friendly error message, or a snippet of the technical error
            const errorMessage = error.message || "Unknown error during AI generation.";
            return `Error generating ${type}: ${errorMessage.split('\n')[0].substring(0, 250)}`; // First line of error, truncated
        }
    }

    // 1. Generate FAQs
    console.log(`[Analysis Step 1/3] Preparing FAQ generation for '${originalName}'.`);
    const faqPrompt = ANALYSIS_PROMPTS.faq.getPrompt(textForAnalysis);
    analysisResults.faq = await generateSingleAnalysis('FAQ', faqPrompt, logCtx);
    if (!allAnalysesSuccessful) {
        console.warn(`FAQ generation failed or produced no content for '${originalName}'. Continuing to next analysis type.`);
        // We continue even if one fails, allAnalysesSuccessful flag will reflect the overall status.
    }

    // 2. Generate Topics
    console.log(`[Analysis Step 2/3] Preparing Topics generation for '${originalName}'.`);
    const topicsPrompt = ANALYSIS_PROMPTS.topics.getPrompt(textForAnalysis);
    analysisResults.topics = await generateSingleAnalysis('Topics', topicsPrompt, logCtx);
    if (!allAnalysesSuccessful && analysisResults.topics.startsWith("Error generating Topics:")) { // Check if this specific step failed
        console.warn(`Topics generation failed or produced no content for '${originalName}'. Continuing to next analysis type.`);
    }


    // 3. Generate Mindmap
    console.log(`[Analysis Step 3/3] Preparing Mindmap generation for '${originalName}'.`);
    const mindmapPrompt = ANALYSIS_PROMPTS.mindmap.getPrompt(textForAnalysis);
    analysisResults.mindmap = await generateSingleAnalysis('Mindmap', mindmapPrompt, logCtx);
    if (!allAnalysesSuccessful && analysisResults.mindmap.startsWith("Error generating Mindmap:")) { // Check if this specific step failed
        console.warn(`Mindmap generation failed or produced no content for '${originalName}'.`);
    }

    // Log final outcome of the analysis generation process
    if (allAnalysesSuccessful) {
        console.log(`All analyses (FAQ, Topics, Mindmap) appear to have been generated successfully for '${originalName}'.`);
    } else {
        console.warn(`One or more analyses failed or produced no content for '${originalName}'. Review individual results for details.`);
        // Log the specific results for easier debugging
        console.warn(`FAQ Result for '${originalName}': ${analysisResults.faq.substring(0,100)}...`);
        console.warn(`Topics Result for '${originalName}': ${analysisResults.topics.substring(0,100)}...`);
        console.warn(`Mindmap Result for '${originalName}': ${analysisResults.mindmap.substring(0,100)}...`);
    }

    return {
        success: allAnalysesSuccessful,
        results: analysisResults
    };
}
// --- End Analysis Generation Function ---


router.post('/', authMiddleware, (req, res) => {
    const uploader = upload.single('file');

    uploader(req, res, async function (err) {
        if (!req.user) {
            console.error("Upload Route: User context missing after auth middleware.");
            return res.status(401).json({ message: "Authentication error: User context not found." });
        }
        const userId = req.user._id.toString();
        const username = req.user.username;

        let absoluteFilePath = null; // Will be set if file is processed by multer
        let originalName = null;
        let serverFilename = null;

        if (err) {
            console.error(`Upload Route: Multer error for user '${username}': ${err.message}`);
            if (err instanceof multer.MulterError) {
                return res.status(400).json({ message: err.message });
            }
            return res.status(500).json({ message: "Server error during upload preparation." });
        }

        if (!req.file) {
            console.warn(`Upload Route: No file received for user '${username}'.`);
            return res.status(400).json({ message: "No file received or file type rejected by filter." });
        }

        // File successfully received by multer
        absoluteFilePath = path.resolve(req.file.path);
        originalName = req.file.originalname;
        serverFilename = req.file.filename;
        console.log(`Upload Route: File received for user '${username}'. Server Filename: ${serverFilename}, Original: ${originalName}`);

        try {
            // ----- STAGE 1: MongoDB Pre-check for existing originalName -----
            const userForPreCheck = await User.findById(userId).select('uploadedDocuments.filename'); // Only need filename
            if (!userForPreCheck) {
                console.error(`Upload Route: User ${userId} ('${username}') not found during pre-check. Deleting uploaded file: ${absoluteFilePath}`);
                await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Upload Route Cleanup: Error deleting file (user not found): ${e.message}`));
                return res.status(404).json({ message: "User not found, cannot process upload." });
            }
            const existingDocument = userForPreCheck.uploadedDocuments.find(doc => doc.filename === originalName);
            if (existingDocument) {
                console.log(`Upload Route: File '${originalName}' already exists for user '${username}'. Deleting uploaded file: ${absoluteFilePath}`);
                await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Upload Route Cleanup: Error deleting file (duplicate): ${e.message}`));
                return res.status(409).json({
                    message: `File '${originalName}' already exists. No new processing initiated.`,
                    filename: serverFilename,
                    originalname: originalName,
                });
            }
            console.log(`Upload Route: Pre-check passed for '${originalName}' (User: '${username}'). Proceeding to RAG processing.`);

            // ----- STAGE 2: RAG Processing (Synchronous Call to Python Service) -----
            // This call extracts text, chunks, and gets data ready for Qdrant.
            // It needs to complete before we can save the initial document record and respond to the user.
            const ragResult = await triggerPythonRagProcessing(userId, absoluteFilePath, originalName);
            // Expected ragResult: { success, status ('added' or 'skipped'), text, chunksForKg, message }

            if (!ragResult.success || ragResult.status !== 'added' || !ragResult.text || ragResult.text.trim() === '') {
                const errorMessage = (ragResult && ragResult.message) || "RAG processing failed or returned insufficient data from Python service.";
                console.error(`Upload Route Error: RAG processing failed for '${originalName}' (User: '${username}'): ${errorMessage}. Python Status: ${ragResult.status}. Deleting file.`);
                if (absoluteFilePath) { // Check if path is still valid
                    await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Upload Route Cleanup: Error deleting file (RAG fail): ${e.message}`));
                }
                return res.status(500).json({ // Or 422 if it's a content issue from RAG
                    message: errorMessage,
                    filename: serverFilename, originalname: originalName
                });
            }
            console.log(`Upload Route: RAG processing by Python service completed for '${originalName}'. Text obtained. Python Status: ${ragResult.status}.`);

            // ----- STAGE 2.5: Initial MongoDB Save for the Document Entry -----
            // This creates the document shell with the text from RAG and pending statuses.
            const newDocumentEntryData = {
                filename: originalName,
                text: ragResult.text, // Save the text obtained from RAG
                analysis: { faq: "", topics: "", mindmap: "" }, // Initialize
                uploadedAt: new Date(),
                ragStatus: ragResult.status, // Should be 'added' here
                analysisStatus: "pending",   // Will be updated by analysisWorker
                kgStatus: "pending"          // Will be updated by kgWorker
            };

            try {
                await User.updateOne(
                    { _id: userId },
                    { $push: { uploadedDocuments: newDocumentEntryData } }
                );
                console.log(`Upload Route: Initial document entry for '${originalName}' saved to user '${username}' in MongoDB.`);
            } catch (dbError) {
                console.error(`Upload Route Error: MongoDB error saving initial document entry for '${originalName}': ${dbError.message}. Deleting file.`);
                if (absoluteFilePath) {
                    await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Upload Route Cleanup: Error deleting file (initial DB save fail): ${e.message}`));
                }
                // This is a server error, RAG was successful but we couldn't save.
                return res.status(500).json({ message: `Database error after RAG processing: ${dbError.message}`, filename: serverFilename, originalname: originalName });
            }

            // ----- IMMEDIATE RESPONSE TO CLIENT -----
            // Respond now, indicating acceptance and background processing.
            res.status(202).json({ // HTTP 202 Accepted
                message: `File '${originalName}' uploaded successfully. Processing has started in the background.`,
                filename: serverFilename, // Server-generated filename
                originalname: originalName,   // Original filename from user
                initialStatus: {
                    rag: ragResult.status,
                    analysis: "pending",
                    knowledgeGraph: "pending"
                }
            });
            console.log(`Upload Route: Sent 202 Accepted to client for '${originalName}'. Offloading further tasks.`);


            // ----- BACKGROUND PROCESSING INITIATION (AFTER RESPONSE) -----

            // Offload Analysis Generation to a Worker
            if (ragResult.text && ragResult.text.trim() !== '') {
                console.log(`[Upload Route BG] Initiating Analysis Worker for '${originalName}'`);
                const analysisWorkerPath = path.resolve(__dirname, '../workers/analysisWorker.js');
                try {
                    const analysisWorker = new Worker(analysisWorkerPath, {
                        workerData: {
                            userId: userId,
                            originalName: originalName,
                            textForAnalysis: ragResult.text // Pass the full text
                        }
                    });
                    analysisWorker.on('message', (msg) => console.log(`[Upload Route BG] Analysis Worker [Doc: ${msg.originalName || originalName}]: ${msg.message || JSON.stringify(msg)}`));
                    analysisWorker.on('error', (err) => console.error(`[Upload Route BG] Analysis Worker Error [Doc: ${originalName}]:`, err));
                    analysisWorker.on('exit', (code) => console.log(`[Upload Route BG] Analysis Worker [Doc: ${originalName}] exited (code ${code}).`));
                } catch (workerLaunchError) {
                    console.error(`[Upload Route BG] Failed to launch Analysis Worker for '${originalName}':`, workerLaunchError);
                    // Log this error, perhaps update DB doc analysisStatus to 'launch_failed'
                    User.updateOne(
                        { _id: userId, "uploadedDocuments.filename": originalName },
                        { $set: { "uploadedDocuments.$.analysisStatus": "launch_failed" } }
                    ).catch(e => console.error("DB update error for analysis launch fail (background):", e));
                }
            } else {
                console.warn(`[Upload Route BG] Skipping Analysis Worker for '${originalName}' due to no text from RAG.`);
                User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: { "uploadedDocuments.$.analysisStatus": "skipped_no_text" } }
                ).catch(e => console.error("DB update error for analysis skipped (background):", e));
            }

            // Offload KG Generation to a Worker
            // Ensure ragResult.chunksForKg is correctly populated by triggerPythonRagProcessing
            if (ragResult.status === "added" && ragResult.chunksForKg && ragResult.chunksForKg.length > 0) {
                console.log(`[Upload Route BG] Initiating KG Worker for '${originalName}'. Chunks: ${ragResult.chunksForKg.length}`);
                const kgWorkerScriptPath = path.resolve(__dirname, '../workers/kgWorker.js');
                try {
                    const kgWorker = new Worker(kgWorkerScriptPath, {
                        workerData: {
                            chunksForKg: ragResult.chunksForKg, // This comes from Python
                            userId: userId,
                            originalName: originalName,
                        }
                    });
                    kgWorker.on('message', (msg) => console.log(`[Upload Route BG] KG Worker [Doc: ${msg.originalName || originalName}]: ${msg.message || JSON.stringify(msg)}`));
                    kgWorker.on('error', (workerErr) => console.error(`[Upload Route BG] KG Worker Error [Doc: ${originalName}]:`, workerErr));
                    kgWorker.on('exit', (code) => console.log(`[Upload Route BG] KG Worker [Doc: ${originalName}] exited (code ${code}).`));
                } catch (workerLaunchError) {
                    console.error(`[Upload Route BG] Failed to launch KG worker for '${originalName}':`, workerLaunchError);
                    User.updateOne(
                        { _id: userId, "uploadedDocuments.filename": originalName },
                        { $set: { "uploadedDocuments.$.kgStatus": "launch_failed" } }
                    ).catch(e => console.error("DB update error for KG launch fail (background):", e));
                }
            } else {
                let kgSkipReason = "skipped_rag_issue";
                if (ragResult.chunksForKg && ragResult.chunksForKg.length === 0) {
                    kgSkipReason = "skipped_no_chunks";
                }
                console.log(`[Upload Route BG] KG Worker not triggered for '${originalName}'. RAG Status: ${ragResult.status}, Chunks: ${ragResult.chunksForKg ? ragResult.chunksForKg.length : 'N/A'}`);
                User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: { "uploadedDocuments.$.kgStatus": kgSkipReason } }
                ).catch(e => console.error("DB update error for KG skipped (background):", e));
            }

            // Optional: Delete the physical uploaded file from the 'assets' directory
            // Do this only if the text content is reliably stored in MongoDB (ragResult.text)
            // and workers have what they need (text or chunk data).
            if (absoluteFilePath) {
                console.log(`[Upload Route BG] Attempting to delete temporary uploaded file: ${absoluteFilePath} as processing is fully offloaded.`);
                await fs.promises.unlink(absoluteFilePath)
                    .catch(e => console.error(`[Upload Route BG] Non-critical: Failed to delete temp file ${absoluteFilePath} after offloading: ${e.message}`));
                absoluteFilePath = null; // Mark as deleted
            }

        } catch (processError) {
            // This catch block handles errors from STAGE 1, 2, or 2.5, or any unhandled synchronous error
            console.error(`Upload Route: !!! Overall processing error for ${originalName || 'unknown file'} (User: '${username}'):`, processError.message, processError.stack);
            if (absoluteFilePath) { // If file path is known, try to delete it
                await fs.promises.unlink(absoluteFilePath).catch(e => console.error(`Upload Route Cleanup: Error deleting file (overall fail): ${e.message}`));
            }
            // If res hasn't been sent (e.g., error before 202 response)
            if (!res.headersSent) {
                return res.status(500).json({
                    message: `Server error during file processing: ${processError.message || 'Unknown error.'}`,
                    filename: serverFilename, // May be null if error was very early
                    originalname: originalName // May be null
                });
            } else {
                // If response was already sent, we can only log the error.
                // A separate mechanism might be needed to update the user/DB about this failure.
                console.error(`Upload Route: Error occurred for ${originalName} after 202 response was sent. This indicates a problem in the background initiation logic itself or unhandled promise rejection before workers fully take over.`);
            }
        }
    }); 
});



module.exports = router;

```

`server/server.js`

```javascript
// server/server.js
const express = require('express');
const dotenv = require('dotenv');
const cors = require('cors');
const path = require('path');
const { getLocalIPs } = require('./utils/networkUtils');
const fs = require('fs'); // Keep fs for existsSync, fs.promises for async operations
const axios = require('axios');
const os = require('os');
const mongoose = require('mongoose');
const readline = require('readline').createInterface({
  input: process.stdin,
  output: process.stdout,
});

// --- Custom Modules ---
const connectDB = require('./config/db');
const { performAssetCleanup } = require('./utils/assetCleanup');
 // Import new middleware

// --- Configuration Loading ---
dotenv.config(); // Load environment variables

// --- Configuration Defaults & Variables ---
const DEFAULT_PORT = 5001;
const DEFAULT_MONGO_URI = 'mongodb://localhost:27017/chatbotGeminiDB';
const DEFAULT_PYTHON_RAG_URL = 'http://localhost:5000';

let port = process.env.PORT || DEFAULT_PORT;
let mongoUri = process.env.MONGO_URI || '';
let pythonRagUrl = process.env.PYTHON_RAG_SERVICE_URL || '';
let geminiApiKey = process.env.GEMINI_API_KEY || '';

// Ensure JWT_SECRET is loaded and available
if (!process.env.JWT_SECRET) {
    console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
    console.error("!!! FATAL: JWT_SECRET environment variable is not set.       !!!");
    console.error("!!! Please set it in your .env file before running:        !!!");
    console.error("!!! JWT_SECRET='your_super_strong_and_secret_jwt_key'      !!!");
    console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
    process.exit(1);
}

// --- Express Application Setup ---
const app = express();

// --- Core Middleware ---
app.use(cors());
app.use(express.json());

// --- Basic Root Route ---
app.get('/', (req, res) => res.send('Chatbot Backend API is running...'));

// --- API Route Mounting ---
// Public routes (like network info, and the auth routes for signup/signin)
// server/server.js
// ... other imports ...
const { authMiddleware } = require('./middleware/authMiddleware'); // Correct import

// ...
// --- API Route Mounting ---
app.use('/api/network', require('./routes/network'));
app.use('/api/auth', require('./routes/auth'));

// Protected routes
app.use('/api/chat', authMiddleware, require('./routes/chat'));
app.use('/api/upload', authMiddleware, require('./routes/upload'));
app.use('/api/files', authMiddleware, require('./routes/files'));
app.use('/api/syllabus', authMiddleware, require('./routes/syllabus'));
app.use('/api/mindmap', authMiddleware, require('./routes/mindmap'));
app.use('/api/analysis', authMiddleware, require('./routes/analysis')); 
// app.use('/api/kg', authMiddleware, require('./routes/kg'));


// --- Centralized Error Handling Middleware ---
app.use((err, req, res, next) => {
    console.error("Unhandled Error:", err.stack || err);
    const statusCode = err.status || 500;
    let message = err.message || 'An internal server error occurred.';
    if (process.env.NODE_ENV === 'production' && statusCode === 500) {
        message = 'An internal server error occurred.';
    }
    if (req.originalUrl.startsWith('/api/')) {
         return res.status(statusCode).json({ message: message });
    }
    // Fallback for non-API routes if any
    res.status(statusCode).send(message);
});

// --- Server Instance Variable ---
let server;

// --- Graceful Shutdown Logic ---
const gracefulShutdown = async (signal) => {
    console.log(`\n${signal} received. Shutting down gracefully...`);
    readline.close();
    try {
        if (server) {
            server.close(async () => {
                console.log('HTTP server closed.');
                try {
                    await mongoose.connection.close();
                    console.log('MongoDB connection closed.');
                } catch (dbCloseError) {
                    console.error("Error closing MongoDB connection:", dbCloseError);
                }
                process.exit(0);
            });
        } else {
             try {
                 await mongoose.connection.close();
                 console.log('MongoDB connection closed (no HTTP server instance).');
             } catch (dbCloseError) {
                 console.error("Error closing MongoDB connection:", dbCloseError);
             }
            process.exit(0);
        }

        setTimeout(() => {
            console.error('Graceful shutdown timed out, forcing exit.');
            process.exit(1);
        }, 10000);

    } catch (shutdownError) {
        console.error("Error during graceful shutdown initiation:", shutdownError);
        process.exit(1);
    }
};

process.on('SIGTERM', () => gracefulShutdown('SIGTERM'));
process.on('SIGINT', () => gracefulShutdown('SIGINT'));

// --- RAG Service Health Check ---
async function checkRagService(url) {
    console.log(`\nChecking RAG service health at ${url}...`);
    try {
        const response = await axios.get(`${url}/health`, { timeout: 7000 });
        if (response.status === 200 && response.data?.status === 'ok') {
            console.log('✓ Python RAG service is available and healthy.');
            // Log details from the Python health check
            const services = response.data.services || {};
            const qdrantStatus = services.qdrant?.status || 'unknown';
            const neo4jStatus = services.neo4j?.status || 'unknown';
            const embeddingModel = response.data.embedding_models?.document_embedding_model || 'N/A';
            
            console.log(`  Embedding Model: ${embeddingModel}`);
            console.log(`  Qdrant Status: ${qdrantStatus}`);
            console.log(`  Neo4j Status: ${neo4jStatus}`);

            if (response.data.message && response.data.message.includes("Warning:")) {
                 console.warn(`  RAG Health Warning: ${response.data.message}`);
            }
            return true;
        } else {
             console.warn(`! Python RAG service responded but status is not OK: ${response.status} - ${JSON.stringify(response.data)}`);
             return false;
        }
    } catch (error) {
        console.warn('! Python RAG service is not reachable.');
        if (error.code === 'ECONNREFUSED') {
             console.warn(`  Connection refused at ${url}. Ensure the Python RAG service (e.g., server/rag_service/app.py) is running.`);
        } else if (error.code === 'ECONNABORTED' || error.message.includes('timeout')) {
             console.warn(`  Connection timed out to ${url}. The Python RAG service might be slow to start or unresponsive.`);
        } else {
             console.warn(`  Error connecting to Python RAG Service: ${error.message}`);
        }
        console.warn('  RAG-dependent features (document upload processing, context retrieval) will be unavailable.');
        return false;
    }
}

// --- Directory Structure Check ---
async function ensureServerDirectories() {
    const dirs = [
        path.join(__dirname, 'assets'),
        path.join(__dirname, 'backup_assets'),
        path.join(__dirname, 'syllabi') // Added syllabi directory check
    ];
    console.log("\nEnsuring server directories exist...");
    try {
        for (const dir of dirs) {
            if (!fs.existsSync(dir)) {
                await fs.promises.mkdir(dir, { recursive: true });
                console.log(`  Created directory: ${dir}`);
            }
        }
        console.log("✓ Server directories checked/created.");
    } catch (error) {
        console.error('!!! Error creating essential server directories:', error);
        throw error;
    }
}

// --- Prompt for Configuration ---
function askQuestion(query) {
    return new Promise(resolve => readline.question(query, resolve));
}

async function configureAndStart() {
    console.log("--- Starting Server Configuration ---");
    
    if (!geminiApiKey) {
        console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
        console.error("!!! FATAL: GEMINI_API_KEY environment variable is not set. !!!");
        console.error("!!! Please set it before running the server:               !!!");
        console.error("!!! export GEMINI_API_KEY='YOUR_API_KEY'                   !!!");
        console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
        process.exit(1);
    } else {
        console.log("✓ GEMINI_API_KEY found.");
    }
    // JWT_SECRET is checked at the top of the file.

    if (!mongoUri) {
        const answer = await askQuestion(`Enter MongoDB URI or press Enter for default (${DEFAULT_MONGO_URI}): `);
        mongoUri = answer.trim() || DEFAULT_MONGO_URI;
    }
    console.log(`Using MongoDB URI: ${mongoUri}`);

    if (!pythonRagUrl) {
        const answer = await askQuestion(`Enter Python RAG Service URL or press Enter for default (${DEFAULT_PYTHON_RAG_URL}): `);
        pythonRagUrl = answer.trim() || DEFAULT_PYTHON_RAG_URL;
    }
    console.log(`Using Python RAG Service URL: ${pythonRagUrl}`);
    console.log(`Node.js server will listen on port: ${port}`);
    readline.close();

    process.env.MONGO_URI = mongoUri;
    process.env.PYTHON_RAG_SERVICE_URL = pythonRagUrl;

    console.log("--- Configuration Complete ---");
    await startServer();
}

// --- Asynchronous Server Startup Function ---
async function startServer() {
    console.log("\n--- Starting Server Initialization ---");
    try {
        await ensureServerDirectories();
        await connectDB(mongoUri); 
        await performAssetCleanup(); 
        await checkRagService(pythonRagUrl);

        const PORT = port;
        const availableIPs = getLocalIPs();

        server = app.listen(PORT, '0.0.0.0', () => {
            console.log('\n=== Node.js Server Ready ===');
            console.log(`🚀 Server listening on port ${PORT}`);
            console.log('   Access the application via these URLs (using common frontend ports):');
            const frontendPorts = [3000, 3001, 8080, 5173]; 
            availableIPs.forEach(ip => {
                 frontendPorts.forEach(fp => {
                    console.log(`   - http://${ip}:${fp} (Frontend) -> Connects to Backend at http://${ip}:${PORT}`);
                 });
            });
            console.log('============================\n');
            console.log("💡 Hint: Client automatically detects backend IP based on how you access the frontend.");
            console.log(`   Ensure firewalls allow connections on port ${PORT} (Backend) and your frontend port.`);
            console.log("--- Server Initialization Complete ---");
        });

    } catch (error) {
        console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
        console.error("!!! Failed to start Node.js server:", error.message);
        console.error("!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!");
        process.exit(1);
    }
}

// --- Execute Configuration and Server Start ---
configureAndStart();
```

`server/services/geminiService.js`

```javascript
// server/services/geminiService.js
const { GoogleGenerativeAI, HarmCategory, HarmBlockThreshold } = require('@google/generative-ai');

const API_KEY = process.env.GEMINI_API_KEY;
const MODEL_NAME = "gemini-1.5-flash"; // Or "gemini-1.5-pro" if you switch

if (!API_KEY) {
    console.error("FATAL ERROR: GEMINI_API_KEY is not available in the environment. Server should have exited.");
    throw new Error("GEMINI_API_KEY is missing.");
}

const genAI = new GoogleGenerativeAI(API_KEY);

const DEFAULT_MAX_OUTPUT_TOKENS_CHAT = 8192; // Increased default for potentially longer thinking + answer
const DEFAULT_MAX_OUTPUT_TOKENS_KG = 65536;   // Default specific for KG, might need adjustment

const baseSafetySettings = [
    { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH },
    { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH },
    { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH },
    { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_ONLY_HIGH },
];

// Modified function to accept maxTokens override
const generateContentWithHistory = async (
    chatHistory,
    systemPromptText = null,
    customMaxOutputTokens = null 
) => {
    try {
        if (!Array.isArray(chatHistory) || chatHistory.length === 0) {
             throw new Error("Chat history must be a non-empty array.");
        }
        // It's good practice to ensure history ends with a user role for many models
        // if (chatHistory[chatHistory.length - 1].role !== 'user') {
        //     console.warn("Warning: Chat history for Gemini API call does not end with a 'user' role. This might lead to unexpected behavior. Last role:", chatHistory[chatHistory.length - 1].role);
        // }

        const effectiveMaxOutputTokens = customMaxOutputTokens || DEFAULT_MAX_OUTPUT_TOKENS_CHAT;

        const generationConfig = {
            temperature: 0.7, // Or make this configurable too
            maxOutputTokens: effectiveMaxOutputTokens,
        };

        const modelOptions = {
            model: MODEL_NAME,
            generationConfig: generationConfig,
            safetySettings: baseSafetySettings,
            ...(systemPromptText && typeof systemPromptText === 'string' && systemPromptText.trim() !== '' && {
                systemInstruction: {
                    // Gemini API expects systemInstruction to be an object with a 'parts' array
                    parts: [{ text: systemPromptText.trim() }]
                }
             })
        };
        const model = genAI.getGenerativeModel(modelOptions);

        const historyForStartChat = chatHistory.slice(0, -1) 
            .map(msg => ({
                 role: msg.role, 
                 parts: Array.isArray(msg.parts) ? msg.parts.map(part => ({ text: part.text || '' })) : [{text: ''}] 
            }))
            .filter(msg => msg.role && msg.parts && msg.parts.length > 0 && typeof msg.parts[0].text === 'string');

        const chat = model.startChat({
            history: historyForStartChat,
        });

        let lastUserMessageParts = chatHistory[chatHistory.length - 1]?.parts;
        if (!Array.isArray(lastUserMessageParts) || lastUserMessageParts.length === 0 || typeof lastUserMessageParts[0].text !== 'string') {
            console.error("Invalid last user message structure:", chatHistory[chatHistory.length - 1]);
            throw new Error("Internal error: Last user message for API call is malformed.");
        }
        let lastUserMessageText = lastUserMessageParts[0].text;


        console.log(`Sending message to Gemini. History sent to startChat: ${historyForStartChat.length}. System Prompt: ${!!modelOptions.systemInstruction}. Max Output Tokens: ${effectiveMaxOutputTokens}`);
        // console.log("Last User Message Text Sent to Gemini (first 200 chars):", lastUserMessageText.substring(0, 200) + "...");

        const result = await chat.sendMessage(lastUserMessageText);
        const response = result.response;
        const candidate = response?.candidates?.[0];

        if (candidate && (candidate.finishReason === 'STOP' || candidate.finishReason === 'MAX_TOKENS')) {
            const responseText = candidate?.content?.parts?.[0]?.text;
            if (typeof responseText === 'string') {
                if (candidate.finishReason === 'MAX_TOKENS') {
                    console.warn("Gemini response was truncated due to MAX_TOKENS limit.");
                }
                return responseText;
            } else {
                 console.warn("Gemini response finished normally but text content is missing or invalid.", { finishReason: candidate?.finishReason, content: candidate?.content });
                 throw new Error("Received an empty or invalid response from the AI service.");
            }
        } else {
             const finishReason = candidate?.finishReason || 'Unknown';
             const safetyRatings = candidate?.safetyRatings;
             console.warn("Gemini response was potentially blocked or had issues.", { finishReason, safetyRatings });
             let blockMessage = `AI response generation failed or was blocked.`;
             if (finishReason === 'SAFETY') {
                 blockMessage += ` Reason: SAFETY.`;
                 if (safetyRatings) {
                    const blockedCategories = safetyRatings.filter(r => r.blocked).map(r => r.category).join(', ');
                    if (blockedCategories) blockMessage += ` Blocked Categories: ${blockedCategories}.`;
                 }
             } else if (finishReason) {
                 blockMessage += ` Reason: ${finishReason}.`;
             }
             const error = new Error(blockMessage);
             error.status = 400; 
             throw error;
        }
    } catch (error) {
        console.error("Gemini API Call Error:", error?.message || error);
        let clientMessage = "Failed to get response from AI service.";
        if (error.message?.includes("API key not valid")) clientMessage = "AI Service Error: Invalid API Key.";
        else if (error.message?.includes("blocked due to safety")) clientMessage = "AI response blocked due to safety settings.";
        else if (error.message?.includes("Invalid JSON payload")) clientMessage = "AI Service Error: Invalid request format sent to AI.";
        else if (error.message?.includes("User location is not supported")) clientMessage = "AI Service Error: User location is not supported for this model.";
        else if (error.status === 400) clientMessage = `AI Service Error: ${error.message}`; 
        
        const enhancedError = new Error(clientMessage);
        enhancedError.status = error.status || 500; 
        enhancedError.originalError = error; 
        throw enhancedError;
    }
};

module.exports = {
    generateContentWithHistory,
    DEFAULT_MAX_OUTPUT_TOKENS_KG 
};
```

`server/services/kgService.js`

```javascript
// server/services/kgService.js
const geminiService = require('./geminiService');
const { v4: uuidv4 } = require('uuid');
const axios = require('axios');
// --- IMPORT THE PROMPTS ---
const {
    KG_GENERATION_SYSTEM_PROMPT,
    KG_BATCH_USER_PROMPT_TEMPLATE // Import the new template
} = require('../config/promptTemplates');

// --- MODIFIED: Function to construct the user prompt for a BATCH of chunks ---
function constructKgPromptForBatch(chunkTexts) {
    // chunkTexts is an array of strings, where each string is the text_content of a chunk.
    let formattedChunkTexts = "";
    chunkTexts.forEach((chunkText, index) => {
        formattedChunkTexts += `
--- START OF CHUNK ${index + 1} ---
${chunkText}
--- END OF CHUNK ${index + 1} ---
`;
    });

    // Replace the placeholder in the template with the actual formatted chunk texts
    return KG_BATCH_USER_PROMPT_TEMPLATE.replace('{BATCHED_CHUNK_TEXTS_HERE}', formattedChunkTexts);
}

// --- NEW: Internal function to process a single BATCH of chunks ---
// (This function _processBatchOfChunksForKg remains the same as in the previous good answer)
async function _processBatchOfChunksForKg(batchOfChunkObjects, batchIndex) {
    // batchOfChunkObjects is an array of the original chunk objects
    // e.g., [{ text_content: "...", metadata: {...} }, ...]
    const logPrefix = `[KG Service Batch ${batchIndex}]`;

    const chunkTextsForPrompt = batchOfChunkObjects.map(chunk => chunk.text_content);

    if (chunkTextsForPrompt.length === 0) {
        console.log(`${logPrefix} No text content in this batch. Skipping.`);
        return [];
    }

    const userPromptForBatch = constructKgPromptForBatch(chunkTextsForPrompt); // Uses the new templated function
    const chatHistory = [
        { role: 'user', parts: [{ text: userPromptForBatch }] }
    ];

    try {
        console.log(`${logPrefix} Processing ${chunkTextsForPrompt.length} chunks for KG generation.`);
        const responseText = await geminiService.generateContentWithHistory(
            chatHistory,
            KG_GENERATION_SYSTEM_PROMPT, // System prompt applies to EACH chunk's processing logic
            geminiService.DEFAULT_MAX_OUTPUT_TOKENS_KG
        );

        if (!responseText) {
            console.warn(`${logPrefix} Empty response from Gemini for batch.`);
            return [];
        }

        let cleanedResponseText = responseText.trim();
        // More robust cleaning for ```json ... ``` or ``` ... ``` blocks
        if (cleanedResponseText.startsWith("```json")) {
            cleanedResponseText = cleanedResponseText.substring(7); // Remove ```json
            if (cleanedResponseText.endsWith("```")) {
                cleanedResponseText = cleanedResponseText.slice(0, -3); // Remove ```
            }
        } else if (cleanedResponseText.startsWith("```")) {
            cleanedResponseText = cleanedResponseText.substring(3); // Remove ```
            if (cleanedResponseText.endsWith("```")) {
                cleanedResponseText = cleanedResponseText.slice(0, -3); // Remove ```
            }
        }
        cleanedResponseText = cleanedResponseText.trim();
        console.log("-----------------------------------------------------------------------------------------------------");
        console.log(cleanedResponseText);
        const graphFragmentsArray = JSON.parse(cleanedResponseText);

        if (!Array.isArray(graphFragmentsArray)) {
            console.warn(`${logPrefix} Gemini response was not a JSON array. Response (first 200 chars):`, cleanedResponseText.substring(0, 200));
            return [];
        }

        if (graphFragmentsArray.length !== batchOfChunkObjects.length) {
            console.warn(`${logPrefix} Mismatch: Expected ${batchOfChunkObjects.length} KG fragments, but received ${graphFragmentsArray.length}. Results might be misaligned.`);
        }
        
        const validFragments = [];
        graphFragmentsArray.forEach((fragment, i) => {
            if (fragment && typeof fragment === 'object' && Array.isArray(fragment.nodes) && Array.isArray(fragment.edges)) {
                validFragments.push(fragment);
            } else {
                const chunkRef = batchOfChunkObjects[i]?.metadata?.chunk_reference_name || `chunk index ${i} in batch`;
                console.warn(`${logPrefix} Invalid graph structure from Gemini for ${chunkRef}. Discarding this fragment. Fragment:`, JSON.stringify(fragment).substring(0,100));
            }
        });
        console.log(`${logPrefix} Successfully parsed ${validFragments.length} valid KG fragments from Gemini response.`);
        return validFragments;

    } catch (error) {
        console.error(`${logPrefix} Error processing batch:`, error.message);
        if (error.originalError) console.error(`${logPrefix} Original Gemini error:`, error.originalError);
        if (error.response?.data) console.error(`${logPrefix} Gemini error data:`, error.response.data);
        return [];
    }
}


// --- MERGE FUNCTION (remains the same as your provided version or my previous good one) ---
function _mergeGraphFragments(graphFragments) {
    console.log(`[KG Service] Merging ${graphFragments.length} graph fragments...`);
    const finalNodesMap = new Map();
    const finalEdgesSet = new Set(); // Using a Set to store unique stringified edges

    for (const fragment of graphFragments) {
        if (!fragment || !fragment.nodes || !fragment.edges) {
            console.warn("[KG Service Merge] Skipping invalid or null graph fragment.");
            continue;
        }
        
        // Process Nodes
        for (const node of fragment.nodes) {
            if (!node || typeof node.id !== 'string' || !node.id.trim()) {
                console.warn("[KG Service Merge] Skipping invalid node (missing/empty ID):", node);
                continue;
            }
            const nodeId = node.id.trim();
            if (!finalNodesMap.has(nodeId)) {
                finalNodesMap.set(nodeId, { ...node, id: nodeId });
            } else {
                const existingNode = finalNodesMap.get(nodeId);
                if (node.description && typeof node.description === 'string' &&
                    (!existingNode.description || node.description.length > existingNode.description.length)) {
                    existingNode.description = node.description;
                }
                if (node.type && (!existingNode.type || existingNode.type === "generic" || existingNode.type.toLowerCase() === "unknown")) {
                    existingNode.type = node.type;
                }
                if (node.parent && !existingNode.parent) {
                    existingNode.parent = node.parent;
                }
            }
        }

        // Process Edges
        for (const edge of fragment.edges) {
            if (!edge || typeof edge.from !== 'string' || typeof edge.to !== 'string' || typeof edge.relationship !== 'string' ||
                !edge.from.trim() || !edge.to.trim() || !edge.relationship.trim()) {
                console.warn("[KG Service Merge] Skipping invalid edge (missing from/to/relationship or empty):", edge);
                continue;
            }
            const edgeKey = `${edge.from.trim()}|${edge.to.trim()}|${edge.relationship.trim().toUpperCase()}`;
            finalEdgesSet.add(edgeKey);
        }
    }

    const mergedNodes = Array.from(finalNodesMap.values());
    const mergedEdges = Array.from(finalEdgesSet).map(edgeKey => {
        const [from, to, relationship] = edgeKey.split('|');
        return { from, to, relationship };
    });

    console.log(`[KG Service Merge] Merged into ${mergedNodes.length} nodes and ${mergedEdges.length} edges.`);
    return { nodes: mergedNodes, edges: mergedEdges };
}

// --- MODIFIED: Main function for KG generation and storage ---
// (This function generateAndStoreKg remains the same as in the previous good answer)
async function generateAndStoreKg(chunksForKg, userId, originalName) {
    const logPrefix = `[KG Service Doc: ${originalName}, User: ${userId}]`;
    console.log(`${logPrefix} Starting KG generation with ${chunksForKg.length} initial chunks.`);

    if (!chunksForKg || chunksForKg.length === 0) {
        console.warn(`${logPrefix} No chunks provided for KG generation.`);
        return { success: true, message: "No chunks to process for KG.", finalKgNodesCount: 0, finalKgEdgesCount: 0 };
    }

    const allGraphFragments = [];
    const BATCH_SIZE = parseInt(process.env.KG_GENERATION_BATCH_SIZE) || 50;
    console.log(`${logPrefix} Using batch size: ${BATCH_SIZE}`);
    let batchIndex = 0;

    for (let i = 0; i < chunksForKg.length; i += BATCH_SIZE) {
        batchIndex++;
        const currentBatchOfChunks = chunksForKg.slice(i, i + BATCH_SIZE);
        
        const validChunksInBatch = currentBatchOfChunks.filter(chunk => chunk && chunk.text_content && chunk.text_content.trim() !== '');
        if (validChunksInBatch.length === 0) {
            console.log(`${logPrefix} Batch ${batchIndex} has no valid chunks with text. Skipping.`);
            continue;
        }
        
        console.log(`${logPrefix} Processing batch ${batchIndex} (chunks ${i} to ${Math.min(i + BATCH_SIZE - 1, chunksForKg.length - 1)}), ${validChunksInBatch.length} valid chunks.`);
        
        const fragmentsFromBatch = await _processBatchOfChunksForKg(validChunksInBatch, batchIndex); // Calls the new batch processor
        if (fragmentsFromBatch && fragmentsFromBatch.length > 0) {
            allGraphFragments.push(...fragmentsFromBatch);
        } else {
            console.warn(`${logPrefix} Batch ${batchIndex} yielded no valid graph fragments.`);
        }
    }

    if (allGraphFragments.length === 0) {
        console.warn(`${logPrefix} No valid graph fragments were generated from any batch.`);
        return { success: true, message: "No KG data extracted from any document chunks.", finalKgNodesCount: 0, finalKgEdgesCount: 0 };
    }

    console.log(`${logPrefix} Generated a total of ${allGraphFragments.length} raw graph fragments. Merging...`);
    const finalKg = _mergeGraphFragments(allGraphFragments);
    
    if (!finalKg || finalKg.nodes.length === 0) {
        console.warn(`${logPrefix} Merged KG has no nodes. Nothing to store.`);
         return { success: true, message: "Merged KG was empty after processing all fragments.", finalKgNodesCount: 0, finalKgEdgesCount: 0 };
    }
    console.log(`${logPrefix} Merged KG successfully. Nodes: ${finalKg.nodes.length}, Edges: ${finalKg.edges.length}.`);

    // --- Storing the KG (your existing logic) ---
    const baseRagUrl = process.env.PYTHON_RAG_SERVICE_URL || process.env.DEFAULT_PYTHON_RAG_URL || 'http://localhost:5000';
    const kgIngestionApiUrl = `${baseRagUrl.replace(/\/$/, '')}/kg`;

    if (!kgIngestionApiUrl.startsWith('http')) {
        console.error(`${logPrefix} KG Ingestion API URL is invalid: ${kgIngestionApiUrl}. Check PYTHON_RAG_SERVICE_URL.`);
        return {
            success: false,
            message: "KG generated, but KG Ingestion API URL is invalid. KG not stored.",
            finalKgNodesCount: finalKg.nodes.length,
            finalKgEdgesCount: finalKg.edges.length
        };
    }

    console.log(`${logPrefix} Sending final merged KG to Ingestion API: ${kgIngestionApiUrl}`);
    try {
        const payload = {
            userId: userId,
            originalName: originalName,
            nodes: finalKg.nodes,
            edges: finalKg.edges
        };

        const serviceResponse = await axios.post(kgIngestionApiUrl, payload, {
            timeout: 300000
        });

        const responseData = serviceResponse.data;
        const API_SUCCESS_STATUS_VALUE = "completed";

        if (serviceResponse.status >= 200 && serviceResponse.status < 300 && responseData && responseData.status === API_SUCCESS_STATUS_VALUE) {
            if (responseData['documentName'] !== originalName || responseData.userId !== userId) {
                console.warn(`${logPrefix} Mismatch in KG API response. Expected doc/user: ${originalName}/${userId}, Got: ${responseData['documentName']}/${responseData.userId}`);
            }
            const successMessage = `KG for '${originalName}' successfully processed by Ingestion API. Status: ${responseData.status}. Nodes: ${finalKg.nodes.length}, Edges: ${finalKg.edges.length}`;
            console.log(`${logPrefix} ${successMessage}`);
            return {
                success: true,
                message: successMessage,
                serviceResponseData: responseData,
                finalKgNodesCount: finalKg.nodes.length,
                finalKgEdgesCount: finalKg.edges.length
            };
        } else {
            const failureMessage = `KG Ingestion API for '${originalName}' indicated failure or unexpected status. HTTP: ${serviceResponse.status}, API Status: '${responseData?.status || "N/A"}'. API Msg: ${responseData?.message || responseData?.error || 'No specific error from API.'}`;
            console.warn(`${logPrefix} ${failureMessage}`);
            return {
                success: false,
                message: failureMessage,
                serviceResponseData: responseData,
                finalKgNodesCount: finalKg.nodes.length,
                finalKgEdgesCount: finalKg.edges.length
            };
        }
    } catch (error) {
        const errorMsg = error.response?.data?.message || error.response?.data?.error || error.message || "Unknown error calling KG Ingestion API";
        console.error(`${logPrefix} Error calling KG Ingestion API:`, errorMsg);
        if (error.response?.data) console.error(`${logPrefix} KG API Error Response Data:`, error.response.data);
        if (error.code === 'ECONNABORTED' || error.message.toLowerCase().includes('timeout')) {
            console.error(`${logPrefix} KG Ingestion API call timed out.`);
        }
        return {
            success: false,
            message: `KG generated, but error calling KG Ingestion API: ${errorMsg}`,
            finalKgNodesCount: finalKg.nodes.length,
            finalKgEdgesCount: finalKg.edges.length
        };
    }
}

module.exports = { generateAndStoreKg };
```

`server/utils/assetCleanup.js`

```javascript
const fs = require('fs').promises; // Use fs.promises for async operations
const path = require('path');

// Define constants relative to this file's location (server/utils)
const ASSETS_DIR = path.join(__dirname, '..', 'assets'); // Go up one level to server/assets
const BACKUP_DIR = path.join(__dirname, '..', 'backup_assets'); // Go up one level to server/backup_assets
const FOLDER_TYPES = ['docs', 'images', 'code', 'others']; // Folders within each user's asset dir

/**
 * Moves existing user asset folders (docs, images, code, others) to a timestamped
 * backup location and recreates empty asset folders for each user on server startup.
 */
async function performAssetCleanup() {
    console.log("\n--- Starting Asset Cleanup ---");
    try {
        // Ensure backup base directory exists
        await fs.mkdir(BACKUP_DIR, { recursive: true });

        // List potential user directories in assets
        let userDirs = [];
        try {
            userDirs = await fs.readdir(ASSETS_DIR);
        } catch (err) {
            if (err.code === 'ENOENT') {
                console.log("Assets directory doesn't exist yet, creating it and skipping cleanup.");
                await fs.mkdir(ASSETS_DIR, { recursive: true }); // Ensure assets dir exists
                console.log("--- Finished Asset Cleanup (No existing assets found) ---");
                return; // Nothing to clean up
            }
            throw err; // Re-throw other errors accessing assets dir
        }

        if (userDirs.length === 0) {
             console.log("Assets directory is empty. Skipping backup/move operations.");
             console.log("--- Finished Asset Cleanup (No user assets found) ---");
             return;
        }

        const timestamp = new Date().toISOString().replace(/[:.]/g, '-'); // Create a safe timestamp string

        for (const userName of userDirs) {
            const userAssetPath = path.join(ASSETS_DIR, userName);
            const userBackupPathBase = path.join(BACKUP_DIR, userName);
            const userTimestampBackupPath = path.join(userBackupPathBase, `backup_${timestamp}`);

            try {
                // Check if the item in assets is actually a directory
                const stats = await fs.stat(userAssetPath);
                if (!stats.isDirectory()) {
                    console.log(`  Skipping non-directory item in assets: ${userName}`);
                    continue;
                }

                console.log(`  Processing assets for user: [${userName}]`);
                let backupDirCreated = false; // Track if backup dir was created for this user/run
                let movedSomething = false; // Track if anything was actually moved

                // Process each defined folder type (docs, images, etc.)
                for (const type of FOLDER_TYPES) {
                    const sourceTypePath = path.join(userAssetPath, type);
                    try {
                        // Check if the source type directory exists before trying to move
                        await fs.access(sourceTypePath);

                        // If source exists, ensure the timestamped backup directory is ready
                        if (!backupDirCreated) {
                            await fs.mkdir(userTimestampBackupPath, { recursive: true });
                            backupDirCreated = true;
                            // console.log(`    Created backup directory: ${userTimestampBackupPath}`);
                        }

                        // Define the destination path in the backup folder
                        const backupTypePath = path.join(userTimestampBackupPath, type);
                        // console.log(`    Moving ${sourceTypePath} to ${backupTypePath}`);
                        // Move the existing type folder to the backup location
                        await fs.rename(sourceTypePath, backupTypePath);
                        movedSomething = true;

                    } catch (accessErr) {
                        // Ignore error if the source directory doesn't exist (ENOENT)
                        if (accessErr.code !== 'ENOENT') {
                            console.error(`    Error accessing source folder ${sourceTypePath}:`, accessErr.message);
                        }
                        // If ENOENT, the folder doesn't exist, nothing to move.
                    }

                    // Always ensure the empty type directory exists in the main assets folder
                    try {
                        // console.log(`    Ensuring empty directory: ${sourceTypePath}`);
                        await fs.mkdir(sourceTypePath, { recursive: true });
                    } catch (mkdirErr) {
                         console.error(`    Failed to recreate directory ${sourceTypePath}:`, mkdirErr.message);
                    }
                } // End loop through FOLDER_TYPES

                 if (movedSomething) {
                     console.log(`  Finished backup for user [${userName}] to backup_${timestamp}`);
                 } else {
                     console.log(`  No existing asset types found to backup for user [${userName}]`);
                 }


            } catch (userDirStatErr) {
                 // Error checking if the item in assets is a directory
                 console.error(`Error processing potential user asset directory ${userAssetPath}:`, userDirStatErr.message);
            }
        } // End loop through userDirs

        console.log("--- Finished Asset Cleanup ---");

    } catch (error) {
        // Catch errors related to backup dir creation or reading the main assets dir
        console.error("!!! Critical Error during Asset Cleanup process:", error);
    }
}

// Export the function to be used elsewhere
module.exports = { performAssetCleanup };

```

`server/utils/networkUtils.js`

```javascript
const os = require('os');

function getLocalIPs() {
    const interfaces = os.networkInterfaces();
    const ips = new Set(['localhost']); // Include localhost

    for (const iface of Object.values(interfaces)) {
        for (const addr of iface) {
            // Include IPv4 non-internal addresses
            if (addr.family === 'IPv4' && !addr.internal) {
                ips.add(addr.address);
            }
        }
    }
    return Array.from(ips);
}

function getPreferredLocalIP() {
    const ips = getLocalIPs();
    // Prioritize non-localhost, non-link-local (169.254) IPs
    // Often 192.168.* or 10.* or 172.16-31.* are common private ranges
    return ips.find(ip => !ip.startsWith('169.254.') && ip !== 'localhost' && (ip.startsWith('192.168.') || ip.startsWith('10.') || ip.match(/^172\.(1[6-9]|2[0-9]|3[0-1])\./))) ||
           ips.find(ip => !ip.startsWith('169.254.') && ip !== 'localhost') || // Any other non-link-local
           'localhost'; // Fallback
}

module.exports = { getLocalIPs, getPreferredLocalIP };

```

`server/workers/analysisWorker.js`

```javascript
// server/workers/analysisWorker.js
const { workerData, parentPort } = require('worker_threads');
const mongoose = require('mongoose');
// const path = require('path'); // Not strictly needed if paths below are correct

// Assuming worker is in server/workers/ and services/models are in server/services/, server/models/
const User = require('../models/User');
const connectDB = require('../config/db');
const geminiService = require('../services/geminiService'); // For actual LLM calls
const { ANALYSIS_PROMPTS } = require('../config/promptTemplates'); // For prompts

// This function will now contain the actual analysis generation logic
async function performFullAnalysis(userId, originalName, textForAnalysis) {
    console.log(`[Analysis Worker ${process.pid}] Starting actual analysis generation for '${originalName}'. Text length: ${textForAnalysis.length}`);

    const analysisResults = { faq: "", topics: "", mindmap: "" };
    let allIndividualAnalysesSuccessful = true; // Tracks if each specific analysis type was successful

    // Helper for a single analysis type, similar to what was in upload.js
    async function generateSingleAnalysis(type, promptContentForLLM, context) {
        try {
            console.log(`[Analysis Worker] Generating ${type} for '${context.originalName}' (User: ${context.userId}).`);
            const historyForGemini = [{ role: 'user', parts: [{ text: "Please perform the requested analysis based on the system instruction provided." }] }];
            
            const generatedText = await geminiService.generateContentWithHistory(
                historyForGemini,
                promptContentForLLM // This is the full prompt including the document text
            );

            if (!generatedText || typeof generatedText !== 'string' || generatedText.trim() === "") {
                console.warn(`[Analysis Worker] Gemini returned empty content for ${type} for '${context.originalName}'.`);
                return { success: false, content: `Notice: No content generated by the AI for ${type}.` };
            }
            console.log(`[Analysis Worker] ${type} generation successful for '${context.originalName}'.`);
            return { success: true, content: generatedText.trim() };
        } catch (error) {
            console.error(`[Analysis Worker] Error during ${type} generation for '${context.originalName}': ${error.message}`);
            allIndividualAnalysesSuccessful = false; // Mark that at least one analysis type failed
            return { success: false, content: `Error generating ${type}: ${error.message.split('\n')[0].substring(0, 250)}` };
        }
    }

    const logCtx = { userId, originalName };

    // --- Generate FAQ, Topics, and Mindmap IN PARALLEL within this worker ---
    // This makes the worker itself more efficient if the LLM calls are independent.
    const analysisPromises = [
        generateSingleAnalysis('FAQ', ANALYSIS_PROMPTS.faq.getPrompt(textForAnalysis), logCtx),
        generateSingleAnalysis('Topics', ANALYSIS_PROMPTS.topics.getPrompt(textForAnalysis), logCtx),
        generateSingleAnalysis('Mindmap', ANALYSIS_PROMPTS.mindmap.getPrompt(textForAnalysis), logCtx)
    ];

    const [faqOutcome, topicsOutcome, mindmapOutcome] = await Promise.allSettled(analysisPromises);

    // Process outcomes from Promise.allSettled
    if (faqOutcome.status === 'fulfilled') {
        analysisResults.faq = faqOutcome.value.content;
        if (!faqOutcome.value.success) allIndividualAnalysesSuccessful = false;
    } else { // rejected
        analysisResults.faq = `Error generating FAQ: ${faqOutcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
        allIndividualAnalysesSuccessful = false;
        console.error(`[Analysis Worker] FAQ generation promise rejected for ${originalName}:`, faqOutcome.reason);
    }

    if (topicsOutcome.status === 'fulfilled') {
        analysisResults.topics = topicsOutcome.value.content;
        if (!topicsOutcome.value.success) allIndividualAnalysesSuccessful = false;
    } else { // rejected
        analysisResults.topics = `Error generating Topics: ${topicsOutcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
        allIndividualAnalysesSuccessful = false;
        console.error(`[Analysis Worker] Topics generation promise rejected for ${originalName}:`, topicsOutcome.reason);
    }

    if (mindmapOutcome.status === 'fulfilled') {
        analysisResults.mindmap = mindmapOutcome.value.content;
        if (!mindmapOutcome.value.success) allIndividualAnalysesSuccessful = false;
    } else { // rejected
        analysisResults.mindmap = `Error generating Mindmap: ${mindmapOutcome.reason?.message?.substring(0,100) || 'Promise rejected'}`;
        allIndividualAnalysesSuccessful = false;
        console.error(`[Analysis Worker] Mindmap generation promise rejected for ${originalName}:`, mindmapOutcome.reason);
    }
    
    // Update MongoDB with all results (even if some failed, we store what we have or the error messages)
    const finalAnalysisStatus = allIndividualAnalysesSuccessful ? "completed" : "failed_partial";
    try {
        await User.updateOne(
            { _id: userId, "uploadedDocuments.filename": originalName },
            {
                $set: {
                    "uploadedDocuments.$.analysis.faq": analysisResults.faq,
                    "uploadedDocuments.$.analysis.topics": analysisResults.topics,
                    "uploadedDocuments.$.analysis.mindmap": analysisResults.mindmap,
                    "uploadedDocuments.$.analysisStatus": finalAnalysisStatus,
                    "uploadedDocuments.$.analysisTimestamp": new Date()
                }
            }
        );
        console.log(`[Analysis Worker ${process.pid}] Analysis results for '${originalName}' (Status: ${finalAnalysisStatus}) stored in DB.`);
        return { success: allIndividualAnalysesSuccessful, message: `Analysis ${allIndividualAnalysesSuccessful ? 'completed successfully' : 'completed with some failures'}.`, results: analysisResults };
    } catch (dbError) {
        console.error(`[Analysis Worker ${process.pid}] DB Error storing analysis results for '${originalName}':`, dbError);
        // This is a critical error for the worker's task.
        // The 'analysisStatus' might remain 'processing' or be whatever it was before this attempt.
        return { success: false, message: `DB Error storing analysis: ${dbError.message}`, results: analysisResults };
    }
}

async function run() {
    const { userId, originalName, textForAnalysis } = workerData;
    let dbConnected = false;
    let overallTaskSuccess = false; // Renamed for clarity for the worker's overall task
    let finalMessageToParent = "Analysis worker encountered an issue.";

    try {
        console.log(`[Analysis Worker ${process.pid}] Received task for: ${originalName}, User: ${userId}`);
        if (!process.env.MONGO_URI) {
            throw new Error("MONGO_URI not set in Analysis worker environment.");
        }
        if (!userId || !originalName) {
            throw new Error("Missing userId or originalName in workerData.");
        }
        
        await connectDB(process.env.MONGO_URI);
        dbConnected = true;
        console.log(`[Analysis Worker ${process.pid}] DB Connected for ${originalName}.`);

        // Update status to 'processing_analysis'
        await User.updateOne(
            { _id: userId, "uploadedDocuments.filename": originalName },
            { $set: { "uploadedDocuments.$.analysisStatus": "processing" } }
        );
        console.log(`[Analysis Worker ${process.pid}] Set analysisStatus to 'processing' for ${originalName}.`);


        if (!textForAnalysis || textForAnalysis.trim() === '') {
            console.warn(`[Analysis Worker ${process.pid}] No text provided for analysis for ${originalName}. Marking as skipped.`);
            await User.updateOne(
                { _id: userId, "uploadedDocuments.filename": originalName },
                { $set: { "uploadedDocuments.$.analysisStatus": "skipped_no_text", "uploadedDocuments.$.analysisTimestamp": new Date() } }
            );
            overallTaskSuccess = true; // Not a failure of the worker, just nothing to do.
            finalMessageToParent = "Analysis skipped: No text provided.";
            // Fall through to postMessage and finally block.
        } else {
            const analysisServiceResult = await performFullAnalysis(userId, originalName, textForAnalysis);
            overallTaskSuccess = analysisServiceResult.success;
            finalMessageToParent = analysisServiceResult.message;
        }

        if (parentPort) {
            parentPort.postMessage({
                success: overallTaskSuccess,
                originalName: originalName,
                message: finalMessageToParent
                // Optionally send back analysisServiceResult.results if the main thread needs them
            });
        }

    } catch (error) {
        console.error(`[Analysis Worker ${process.pid}] Critical error processing '${originalName}':`, error.message, error.stack);
        finalMessageToParent = error.message || "Unknown critical error in Analysis worker.";
        overallTaskSuccess = false; // Ensure this is false on critical error
        if (dbConnected && userId && originalName) { // Check if userId & originalName are defined
            try {
                await User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: { "uploadedDocuments.$.analysisStatus": "failed_critical" } }
                );
            } catch (dbUpdateError) {
                console.error(`[Analysis Worker ${process.pid}] Failed to update status to 'failed_critical' for ${originalName} after error:`, dbUpdateError);
            }
        }
        if (parentPort) {
            parentPort.postMessage({ success: false, originalName, error: finalMessageToParent });
        }
    } finally {
        if (dbConnected) {
            await mongoose.disconnect().catch(e => console.error("[Analysis Worker] Error disconnecting DB:", e));
            console.log(`[Analysis Worker ${process.pid}] DB Disconnected for ${originalName}.`);
        }
        // The worker will exit automatically after the run() promise fulfills or rejects.
        // If parentPort exists, Node.js waits for messages or explicit exit.
        // If no parentPort (e.g. direct execution), we might need process.exit.
        // Since we expect parentPort, this is okay.
        console.log(`[Analysis Worker ${process.pid}] Finished task for ${originalName}. Overall Success: ${overallTaskSuccess}`);
    }
}

run();
```

`server/workers/kgWorker.js`

```javascript
// server/workers/kgWorker.js
const { workerData, parentPort } = require('worker_threads');
const mongoose = require('mongoose');

const User = require('../models/User');
const connectDB = require('../config/db');
const kgService = require('../services/kgService');

async function runKgGeneration() {
    const { chunksForKg: allInitialChunks, userId, originalName } = workerData;
    let dbConnected = false;
    let overallSuccess = false;
    let finalMessage = "KG processing encountered an issue.";
    const logPrefix = `[KG Worker ${process.pid}, Doc: ${originalName}]`;

    try {
        console.log(`${logPrefix} Received task. User: ${userId}, Initial Chunks: ${allInitialChunks ? allInitialChunks.length : 0}`);
        if (!process.env.MONGO_URI) throw new Error("MONGO_URI not set in KG worker environment.");
        if (!userId || !originalName) throw new Error("Missing userId or originalName in KG workerData.");

        await connectDB(process.env.MONGO_URI);
        dbConnected = true;
        console.log(`${logPrefix} DB Connected.`);

        await User.updateOne(
            { _id: userId, "uploadedDocuments.filename": originalName },
            { $set: { "uploadedDocuments.$.kgStatus": "processing" } }
        );
        console.log(`${logPrefix} Status set to 'processing'.`);

        if (!allInitialChunks || allInitialChunks.length === 0) {
            console.log(`${logPrefix} No chunks provided for KG generation. Marking as skipped.`);
            await User.updateOne(
                { _id: userId, "uploadedDocuments.filename": originalName },
                { $set: { "uploadedDocuments.$.kgStatus": "skipped_no_chunks", "uploadedDocuments.$.kgTimestamp": new Date() } }
            );
            finalMessage = "No chunks provided for KG generation.";
            overallSuccess = true; // Not a failure of this worker's process
        } else {
            const kgExtractionResult = await kgService.generateAndStoreKg(allInitialChunks, userId, originalName);

            if (kgExtractionResult && kgExtractionResult.success) {
                await User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: {
                        "uploadedDocuments.$.kgStatus": "completed",
                        "uploadedDocuments.$.kgNodesCount": kgExtractionResult.finalKgNodesCount,
                        "uploadedDocuments.$.kgEdgesCount": kgExtractionResult.finalKgEdgesCount,
                        "uploadedDocuments.$.kgTimestamp": new Date()
                        }
                    }
                );
                overallSuccess = true;
                finalMessage = kgExtractionResult.message || "KG generation and storage completed successfully.";
                console.log(`${logPrefix} SUCCESS: ${finalMessage}`);
            } else {
                await User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: { "uploadedDocuments.$.kgStatus": "failed_extraction" } }
                );
                finalMessage = (kgExtractionResult && kgExtractionResult.message) ? kgExtractionResult.message : "KG detailed extraction or storage failed.";
                console.error(`${logPrefix} FAILED (Extraction/Store): ${finalMessage}`);
                overallSuccess = false;
            }
        }

        if (parentPort) {
            parentPort.postMessage({ success: overallSuccess, originalName, message: finalMessage });
        }

    } catch (error) {
        console.error(`${logPrefix} CRITICAL error:`, error.message, error.stack);
        finalMessage = error.message || "Unknown critical error in KG worker.";
        overallSuccess = false;
        if (dbConnected && userId && originalName) {
            try {
                await User.updateOne(
                    { _id: userId, "uploadedDocuments.filename": originalName },
                    { $set: { "uploadedDocuments.$.kgStatus": "failed_critical" } }
                );
            } catch (dbUpdateError) {
                console.error(`${logPrefix} DB update error on critical fail:`, dbUpdateError);
            }
        }
        if (parentPort) {
            parentPort.postMessage({ success: false, originalName, error: finalMessage });
        }
    } finally {
        if (dbConnected) {
            await mongoose.disconnect().catch(e => console.error(`${logPrefix} Error disconnecting DB:`, e));
            console.log(`${logPrefix} DB Disconnected.`);
        }
        console.log(`${logPrefix} Finished task. Overall Success: ${overallSuccess}`);
    }
}

runKgGeneration();
```

`testing/abhishek_story.txt`

```
The Rising Star: The Story of Abhishek Sharma

In the bustling city of Amritsar, Punjab, where cricket isn't just a sport but a way of life, a young boy named Abhishek Sharma would spend hours under the sweltering sun, perfecting his cover drives on cracked concrete pitches. From the very beginning, there was something different about him. With a bat in hand, he moved with the calm confidence of someone who belonged to the game.

Abhishek was born on September 4, 2000, into a middle-class family that recognized his potential early. His father, a school principal and former cricketer himself, ensured that education and discipline walked hand-in-hand with cricket practice. By the age of 15, Abhishek had already made headlines in junior cricket circles, known for his aggressive batting and handy left-arm orthodox spin.

His big breakthrough came during the 2018 ICC Under-19 World Cup, where he played a crucial role in India’s victorious campaign under Prithvi Shaw's captaincy. The cricketing world saw a glimpse of his potential—a fearless middle-order batter who could swing the momentum of a game in just a few overs.

Soon after, he was picked up by the Delhi Daredevils (now Delhi Capitals) in the IPL auction. On his debut in 2018, he smashed a blistering 46 off just 19 balls, immediately making the cricketing fraternity sit up and take notice. That innings wasn’t just about runs—it was a statement: Abhishek Sharma had arrived.

But like many young prodigies, the journey wasn't without its share of challenges. Competition in Indian cricket is fierce. Inconsistent form and a lack of opportunities meant that he had to wait, watch, and work harder than ever. He spent the next few years honing his craft—sharpening his power-hitting, building patience, and refining his bowling.

In 2022, playing for Sunrisers Hyderabad, Abhishek finally found his rhythm. Promoted to open the batting, he blossomed. He became known for his elegant yet explosive stroke play—especially his fearless lofted shots over cover. That year, he scored over 400 runs in the IPL, becoming one of the team's most reliable performers.

What made Abhishek special wasn’t just his talent, but his temperament. He never let success get to his head or failures drag him down. Off the field, he remained grounded, often visiting his childhood coach in Amritsar and inspiring young kids from his city to believe in their dreams.

By 2025, Abhishek Sharma had transformed from a promising youngster into a dependable performer in both IPL and domestic cricket. Whispers of an India call-up grew louder. And when it finally came—a T20 debut against South Africa in front of a packed crowd in Mumbai—Abhishek walked in with his usual calm demeanor. He struck a fluent half-century, mixing finesse with fire, and earned the "Player of the Match" on debut.

As the Indian flag fluttered behind him during the national anthem that evening, Abhishek knew his journey had just begun. From the narrow gullies of Amritsar to international stadiums filled with roaring fans, he had carved his path—not just with talent, but with relentless hard work, humility, and heart.

And as fans across the country began chanting his name, a new cricketing chapter was being written—one led by Abhishek Sharma, the boy who dared to dream.









```

